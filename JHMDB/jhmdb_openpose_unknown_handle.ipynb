{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# <project_root>/ddnet/ddnet.py\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(''), '..', 'ddnet'))\n",
    "import ddnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(T, C, le, exclude_labels=[], max_per_class=None):\n",
    "    \"\"\"\n",
    "    Generate X (list of arrays) and Y (array) from a dict \n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    labels = []\n",
    "    counter = collections.Counter()\n",
    "    for p, L in zip(T['pose'], T['label']):\n",
    "        if L not in exclude_labels and (max_per_class is None or counter[L] < max_per_class):\n",
    "            poses.append(p)\n",
    "            labels.append(L)\n",
    "            counter[L] += 1\n",
    "    \n",
    "    X = poses # list of arrays\n",
    "    Y = np.zeros(shape=(len(labels), C.clc_num)) # 2D array one-hot encoding of labels\n",
    "    Y[range(Y.shape[0]), le.transform(labels)] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for plotting\n",
    "# history is a history object from keras\n",
    "def plot_accuracy(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_nan(X):\n",
    "    return sum([np.count_nonzero(np.isnan(x)) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory that contains pickle files\n",
    "undoctored_data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'JHMDB_openpose_pkl')\n",
    "doctored_data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'JHMDB_openpose_doctored_pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classses:  21 ['brush_hair' 'catch' 'clap' 'climb_stairs' 'golf' 'jump' 'kick_ball'\n",
      " 'pick' 'pour' 'pullup' 'push' 'run' 'shoot_ball' 'shoot_bow' 'shoot_gun'\n",
      " 'sit' 'stand' 'swing_baseball' 'throw' 'walk' 'wave']\n"
     ]
    }
   ],
   "source": [
    "# Load pickle files\n",
    "Train_undoctored = pickle.load(open(os.path.join(undoctored_data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test_undoctored = pickle.load(open(os.path.join(undoctored_data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "Train_doctored = pickle.load(open(os.path.join(doctored_data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test_doctored = pickle.load(open(os.path.join(doctored_data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train_undoctored['label'])\n",
    "print(\"Classses: \", len(le.classes_), le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pose', 'label', 'filename'])\n",
      "wave wave/Maddin_winkt_wave_h_cm_np1_fr_med_1\n",
      "float64\n",
      "Nose\n",
      " [[217.41  111.526]\n",
      " [216.107 107.003]\n",
      " [205.713 106.334]\n",
      " [196.635 106.364]\n",
      " [197.279 106.35 ]\n",
      " [197.935 106.334]\n",
      " [198.586 106.337]\n",
      " [194.704 102.465]\n",
      " [193.385 102.465]\n",
      " [190.808 104.415]\n",
      " [190.808 104.416]\n",
      " [189.483  96.63 ]\n",
      " [193.388  95.314]\n",
      " [203.14   95.949]\n",
      " [217.418  94.665]\n",
      " [224.554  92.069]\n",
      " [225.851  92.065]\n",
      " [222.612  86.869]\n",
      " [221.977  92.076]\n",
      " [228.466  95.981]\n",
      " [231.706  96.606]\n",
      " [231.693  96.649]\n",
      " [231.06   96.64 ]\n",
      " [227.174 101.836]\n",
      " [227.805 106.336]\n",
      " [231.69  109.607]\n",
      " [232.365 110.902]\n",
      " [233.658 112.221]\n",
      " [234.944 112.222]\n",
      " [235.604 117.402]\n",
      " [234.309 117.38 ]\n",
      " [226.535 117.387]\n",
      " [221.956 121.958]\n",
      " [221.33  121.967]\n",
      " [226.492 119.36 ]\n",
      " [226.526 121.307]\n",
      " [226.538 120.659]\n",
      " [225.867 118.05 ]]\n",
      "RElbow\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "RWrist\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "LElbow\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "RWrist\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# examine some known strange videos\n",
    "print(Train_undoctored.keys())\n",
    "for p, L, filename in zip(Train_undoctored['pose'], Train_undoctored['label'], Train_undoctored['filename']):\n",
    "    if 'Maddin_winkt_wave_h_cm_np1_fr_med_1' in filename:\n",
    "        print(L, filename)\n",
    "        print(p.dtype)\n",
    "        print('Nose\\n', p[:, 0, :])\n",
    "        print('RElbow\\n', p[:, 3, :])\n",
    "        print('RWrist\\n', p[:, 4, :])\n",
    "        print('LElbow\\n', p[:, 6, :])\n",
    "        print('RWrist\\n', p[:, 7, :])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally Combine doctored and undoctored train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 (30, 25, 2) (630, 21)\n",
      "251 (31, 25, 2) (251, 21)\n"
     ]
    }
   ],
   "source": [
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=15, joint_dim=2, num_classes=21, num_filters=64)\n",
    "\n",
    "X_doctored, Y_doctored = data_generator(Train_doctored,C,le)\n",
    "X_undoctored, Y_undoctored = data_generator(Train_undoctored,C,le)\n",
    "\n",
    "# print(\"Combine doctored and undoctored training sets!\")\n",
    "# X = X_doctored + X_undoctored\n",
    "# Y = np.concatenate([Y_doctored, Y_undoctored])\n",
    "\n",
    "X = X_undoctored\n",
    "Y = Y_undoctored\n",
    "\n",
    "# X = X_doctored\n",
    "# Y = Y_doctored\n",
    "\n",
    "X_test,Y_test = data_generator(Test_undoctored,C,le) #, exclude_labels=['climb_stairs', 'jump', 'kick_ball', 'run', 'sit', 'stand', 'walk'])\n",
    "# X_test,Y_test = data_generator(Test_doctored,C,le) #, exclude_labels=['climb_stairs', 'jump', 'kick_ball', 'run', 'sit', 'stand', 'walk'])\n",
    "\n",
    "print(len(X), X[0].shape, Y.shape)\n",
    "print(len(X_test), X_test[0].shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with undetected joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NANify undetection joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ddnet.OpenPoseDataCleaner(copy=True)\n",
    "\n",
    "X_nan = list(map(cleaner.make_nan, X))\n",
    "X_test_nan = list(map(cleaner.make_nan, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter on visible subset of joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "RWrist, LWrist = 4, 7\n",
    "RElbow, LElbow = 3, 6\n",
    "RShoulder, LShoulder = 2, 5\n",
    "MidHip = 8\n",
    "\n",
    "def has_joint(p, joint, thresh=3):\n",
    "    return np.count_nonzero(~np.isnan(p[:,joint, 0])) >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 -> 546\n",
      "251 -> 216\n"
     ]
    }
   ],
   "source": [
    "# Now let's filter the points with both hands visible\n",
    "\n",
    "X_subset, Y_subset = zip(*[(x, y) for x,y in zip(X_nan, Y) \\\n",
    "                           if has_joint(x, RWrist) and has_joint(x, LWrist) \\\n",
    "                            and has_joint(x, RElbow) and has_joint(x, LElbow) \\\n",
    "                            and has_joint(x, RShoulder) and has_joint(x, LShoulder)])\n",
    "Y_subset=np.array(Y_subset)\n",
    "\n",
    "X_test_subset, Y_test_subset = zip(*[(x, y) for x,y in zip(X_test_nan, Y_test) \\\n",
    "                                     if has_joint(x, RWrist) and has_joint(x, LWrist) \\\n",
    "                                     and has_joint(x, RShoulder) and has_joint(x, LShoulder)])\n",
    "Y_test_subset=np.array(Y_test_subset)\n",
    "\n",
    "print(len(X), '->', len(X_subset))\n",
    "print(len(X_test), '->', len(X_test_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter good joints, temporal interpolation and normalize (still have NANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = list(map(cleaner.transform_point, X_subset))\n",
    "X_test_clean = list(map(cleaner.transform_point, X_test_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 105) (32, 15, 2)\n",
      "49176\n",
      "17142\n",
      "302624 46656\n",
      "106496 16448\n"
     ]
    }
   ],
   "source": [
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=X_clean[0].shape[1], joint_dim=2, num_classes=21, num_filters=64)\n",
    "\n",
    "X_0_nan, X_1_nan = ddnet.preprocess_batch(X_clean, C)\n",
    "X_test_0_nan, X_test_1_nan = ddnet.preprocess_batch(X_test_clean, C)\n",
    "print(X_0_nan[0].shape, X_1_nan[0].shape)\n",
    "\n",
    "print(count_all_nan(X_clean))\n",
    "print(count_all_nan(X_test_clean))\n",
    "print(count_all_nan(X_0_nan), count_all_nan(X_1_nan))\n",
    "print(count_all_nan(X_test_0_nan), count_all_nan(X_test_1_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -0.67236289 -0.12806191  0.34851914 -0.64562701\n",
      " -0.127683    0.24071769  0.28964901  0.3258977   1.05732743  0.30842156\n",
      "  1.08297145         nan         nan -0.29555449  0.24202608 -0.31812232\n",
      "  0.07823552  0.34635176  0.31814922  0.30022394  1.035761    0.39424704\n",
      "  1.12121901         nan         nan -0.44721973  0.1263697   0.01945649\n",
      " -0.01153824 -0.18848676 -0.2966201   0.39888682 -0.01398037  0.55986753\n",
      "         nan         nan  0.52456371  0.13465957 -0.16194191 -0.46053211\n",
      " -0.67106053 -0.13103635 -0.22094804  0.09293588         nan         nan\n",
      " -0.26004057  0.20485558  0.33732916  0.42694392  1.12431263  0.29100426\n",
      "  1.08528387         nan         nan -0.4937615  -0.26375026 -0.09665573\n",
      "  0.48906169 -0.39504314  0.38329644         nan         nan -0.68746891\n",
      " -0.47328433 -0.01085616 -0.89818804 -0.11639256         nan         nan\n",
      " -0.78344852 -0.21297155 -0.75936504 -0.19638021         nan         nan\n",
      " -0.26255595 -0.54310224 -0.14341915         nan         nan -0.11233835\n",
      " -0.61714272         nan         nan -0.20569668         nan         nan\n",
      "         nan         nan         nan]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.67236289 -0.12806191  0.34851914 -0.64562701\n",
      " -0.127683    0.24071769  0.28964901  0.3258977   1.05732743  0.30842156\n",
      "  1.08297145  0.          0.         -0.29555449  0.24202608 -0.31812232\n",
      "  0.07823552  0.34635176  0.31814922  0.30022394  1.035761    0.39424704\n",
      "  1.12121901  0.          0.         -0.44721973  0.1263697   0.01945649\n",
      " -0.01153824 -0.18848676 -0.2966201   0.39888682 -0.01398037  0.55986753\n",
      "  0.          0.          0.52456371  0.13465957 -0.16194191 -0.46053211\n",
      " -0.67106053 -0.13103635 -0.22094804  0.09293588  0.          0.\n",
      " -0.26004057  0.20485558  0.33732916  0.42694392  1.12431263  0.29100426\n",
      "  1.08528387  0.          0.         -0.4937615  -0.26375026 -0.09665573\n",
      "  0.48906169 -0.39504314  0.38329644  0.          0.         -0.68746891\n",
      " -0.47328433 -0.01085616 -0.89818804 -0.11639256  0.          0.\n",
      " -0.78344852 -0.21297155 -0.75936504 -0.19638021  0.          0.\n",
      " -0.26255595 -0.54310224 -0.14341915  0.          0.         -0.11233835\n",
      " -0.61714272  0.          0.         -0.20569668  0.          0.\n",
      "  0.          0.          0.        ]\n",
      "[[        nan         nan]\n",
      " [-0.09975051 -0.41909254]\n",
      " [ 0.13081909 -0.39975416]\n",
      " [ 0.25998282  0.08066901]\n",
      " [ 0.24009139  0.47053841]\n",
      " [-0.34976591 -0.43015867]\n",
      " [-0.45996304  0.08065361]\n",
      " [-0.34964919  0.42071706]\n",
      " [-0.14034682  0.49075956]\n",
      " [ 0.01128307  0.5106573 ]\n",
      " [-0.00981026  1.03101706]\n",
      " [-0.30998583  0.48068749]\n",
      " [-0.28000817  1.04082733]\n",
      " [        nan         nan]\n",
      " [        nan         nan]]\n",
      "[[ 0.          0.        ]\n",
      " [-0.09975051 -0.41909254]\n",
      " [ 0.13081909 -0.39975416]\n",
      " [ 0.25998282  0.08066901]\n",
      " [ 0.24009139  0.47053841]\n",
      " [-0.34976591 -0.43015867]\n",
      " [-0.45996304  0.08065361]\n",
      " [-0.34964919  0.42071706]\n",
      " [-0.14034682  0.49075956]\n",
      " [ 0.01128307  0.5106573 ]\n",
      " [-0.00981026  1.03101706]\n",
      " [-0.30998583  0.48068749]\n",
      " [-0.28000817  1.04082733]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Impute JCD with 0\n",
    "X_0_imp = X_0_nan.copy()\n",
    "X_0_imp[np.isnan(X_0_imp)] = 0.\n",
    "X_test_0_imp = X_test_0_nan.copy()\n",
    "X_test_0_imp[np.isnan(X_test_0_imp)] = 0.\n",
    "print(X_0_nan[0][0])\n",
    "print(X_0_imp[0][0])\n",
    "\n",
    "# Impute Cartessian with 0\n",
    "X_1_imp = X_1_nan.copy()\n",
    "X_1_imp[np.isnan(X_1_imp)] = 0.\n",
    "X_test_1_imp = X_test_1_nan.copy()\n",
    "X_test_1_imp[np.isnan(X_test_1_imp)] = 0.\n",
    "print(X_1_nan[0][0])\n",
    "print(X_1_imp[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 32, 105) (546, 32, 15, 2)\n",
      "(216, 32, 105) (216, 32, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_input = Y_subset\n",
    "Y_test_input = Y_test_subset\n",
    "X_0, X_1 = X_0_imp, X_1_imp\n",
    "X_test_0, X_test_1 = X_test_0_imp, X_test_1_imp\n",
    "print(X_0.shape, X_1.shape)\n",
    "print(X_test_0.shape, X_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale sample weight to balance classes\n",
    "def get_sample_weight(Y):\n",
    "    cls_ids = np.argmax(Y, axis=1)\n",
    "    assert cls_ids.shape[0] == Y.shape[0]\n",
    "    cls_histo = np.array([np.count_nonzero(cls_ids==i) for i in range(Y.shape[1])])\n",
    "    cls_weight = np.max(cls_histo) / cls_histo # balanced\n",
    "    print(cls_histo)\n",
    "    print(cls_weight)\n",
    "    sample_weight = cls_weight[cls_ids]\n",
    "    assert sample_weight.shape[0] == Y.shape[0]\n",
    "    return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 34 24 27 30 19 22 20 36 38 19 27 18 35 24 19 16 39 31 26 23]\n",
      "[2.05263158 1.14705882 1.625      1.44444444 1.3        2.05263158\n",
      " 1.77272727 1.95       1.08333333 1.02631579 2.05263158 1.44444444\n",
      " 2.16666667 1.11428571 1.625      2.05263158 2.4375     1.\n",
      " 1.25806452 1.5        1.69565217]\n",
      "(546,)\n",
      "[1.77272727 2.16666667 2.05263158 1.08333333 2.05263158 1.11428571]\n"
     ]
    }
   ],
   "source": [
    "sample_weight = get_sample_weight(Y_input)\n",
    "print(sample_weight.shape)\n",
    "print(sample_weight[::100][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Net, Train and plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 105)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 15, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 4, 512)       1714816     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 512)          0           model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65536       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 128)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16384       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 128)          0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 21)           2709        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,800,469\n",
      "Trainable params: 1,794,837\n",
      "Non-trainable params: 5,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random.seed(456)\n",
    "\n",
    "DD_Net = ddnet.build_DD_Net(C)\n",
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 546 samples, validate on 216 samples\n",
      "Epoch 1/1000\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 5.7799 - accuracy: 0.0440 - val_loss: 3.0410 - val_accuracy: 0.0602\n",
      "Epoch 2/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 5.2276 - accuracy: 0.0513 - val_loss: 3.0393 - val_accuracy: 0.0787\n",
      "Epoch 3/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 4.8334 - accuracy: 0.0989 - val_loss: 3.0366 - val_accuracy: 0.0741\n",
      "Epoch 4/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 4.7533 - accuracy: 0.1007 - val_loss: 3.0326 - val_accuracy: 0.1157\n",
      "Epoch 5/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 4.3443 - accuracy: 0.1520 - val_loss: 3.0276 - val_accuracy: 0.1481\n",
      "Epoch 6/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 4.3580 - accuracy: 0.1520 - val_loss: 3.0215 - val_accuracy: 0.1898\n",
      "Epoch 7/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 4.1093 - accuracy: 0.1923 - val_loss: 3.0150 - val_accuracy: 0.1620\n",
      "Epoch 8/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 4.0344 - accuracy: 0.2198 - val_loss: 3.0083 - val_accuracy: 0.1574\n",
      "Epoch 9/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 3.8998 - accuracy: 0.2473 - val_loss: 3.0016 - val_accuracy: 0.1481\n",
      "Epoch 10/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 3.8476 - accuracy: 0.2253 - val_loss: 2.9957 - val_accuracy: 0.1389\n",
      "Epoch 11/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 3.6654 - accuracy: 0.2894 - val_loss: 2.9891 - val_accuracy: 0.1296\n",
      "Epoch 12/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 3.5266 - accuracy: 0.3168 - val_loss: 2.9827 - val_accuracy: 0.1296\n",
      "Epoch 13/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 3.4858 - accuracy: 0.3297 - val_loss: 2.9774 - val_accuracy: 0.1157\n",
      "Epoch 14/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 3.3375 - accuracy: 0.3168 - val_loss: 2.9727 - val_accuracy: 0.1019\n",
      "Epoch 15/1000\n",
      "546/546 [==============================] - 0s 242us/step - loss: 3.1556 - accuracy: 0.3864 - val_loss: 2.9666 - val_accuracy: 0.1111\n",
      "Epoch 16/1000\n",
      "546/546 [==============================] - 0s 217us/step - loss: 3.2031 - accuracy: 0.3700 - val_loss: 2.9592 - val_accuracy: 0.1435\n",
      "Epoch 17/1000\n",
      "546/546 [==============================] - 0s 186us/step - loss: 2.9399 - accuracy: 0.4158 - val_loss: 2.9507 - val_accuracy: 0.1481\n",
      "Epoch 18/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 2.9551 - accuracy: 0.4158 - val_loss: 2.9428 - val_accuracy: 0.1620\n",
      "Epoch 19/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 2.8568 - accuracy: 0.4341 - val_loss: 2.9341 - val_accuracy: 0.1991\n",
      "Epoch 20/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 2.7940 - accuracy: 0.4396 - val_loss: 2.9247 - val_accuracy: 0.2222\n",
      "Epoch 21/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 2.8244 - accuracy: 0.4414 - val_loss: 2.9165 - val_accuracy: 0.2454\n",
      "Epoch 22/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 2.5861 - accuracy: 0.5000 - val_loss: 2.9080 - val_accuracy: 0.2315\n",
      "Epoch 23/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 2.5486 - accuracy: 0.4799 - val_loss: 2.8989 - val_accuracy: 0.2176\n",
      "Epoch 24/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 2.5138 - accuracy: 0.5000 - val_loss: 2.8904 - val_accuracy: 0.2130\n",
      "Epoch 25/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 2.3272 - accuracy: 0.5403 - val_loss: 2.8829 - val_accuracy: 0.2130\n",
      "Epoch 26/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 2.2377 - accuracy: 0.5806 - val_loss: 2.8765 - val_accuracy: 0.2454\n",
      "Epoch 27/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 2.2672 - accuracy: 0.5604 - val_loss: 2.8731 - val_accuracy: 0.2407\n",
      "Epoch 28/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 2.1166 - accuracy: 0.6117 - val_loss: 2.8734 - val_accuracy: 0.2269\n",
      "Epoch 29/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 2.1679 - accuracy: 0.5714 - val_loss: 2.8740 - val_accuracy: 0.2361\n",
      "Epoch 30/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 2.1400 - accuracy: 0.5824 - val_loss: 2.8767 - val_accuracy: 0.2361\n",
      "Epoch 31/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 2.0087 - accuracy: 0.6154 - val_loss: 2.8807 - val_accuracy: 0.2361\n",
      "Epoch 32/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 1.9418 - accuracy: 0.6227 - val_loss: 2.8848 - val_accuracy: 0.2315\n",
      "Epoch 33/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 1.8570 - accuracy: 0.6429 - val_loss: 2.8898 - val_accuracy: 0.2407\n",
      "Epoch 34/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 1.7753 - accuracy: 0.6758 - val_loss: 2.8930 - val_accuracy: 0.2361\n",
      "Epoch 35/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 1.7514 - accuracy: 0.6795 - val_loss: 2.8932 - val_accuracy: 0.2407\n",
      "Epoch 36/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 1.7072 - accuracy: 0.6813 - val_loss: 2.8921 - val_accuracy: 0.2315\n",
      "Epoch 37/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.5949 - accuracy: 0.7198 - val_loss: 2.8899 - val_accuracy: 0.2269\n",
      "Epoch 38/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 1.5768 - accuracy: 0.7253 - val_loss: 2.8880 - val_accuracy: 0.2130\n",
      "Epoch 39/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.5687 - accuracy: 0.7179 - val_loss: 2.8867 - val_accuracy: 0.2130\n",
      "Epoch 40/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 1.5001 - accuracy: 0.7363 - val_loss: 2.8877 - val_accuracy: 0.2130\n",
      "Epoch 41/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 1.4836 - accuracy: 0.7088 - val_loss: 2.8897 - val_accuracy: 0.2222\n",
      "Epoch 42/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 1.3943 - accuracy: 0.7399 - val_loss: 2.8904 - val_accuracy: 0.2269\n",
      "Epoch 43/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 1.3187 - accuracy: 0.7747 - val_loss: 2.8959 - val_accuracy: 0.2222\n",
      "Epoch 44/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.3588 - accuracy: 0.7509 - val_loss: 2.9017 - val_accuracy: 0.2222\n",
      "Epoch 45/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 1.2448 - accuracy: 0.7949 - val_loss: 2.9107 - val_accuracy: 0.2222\n",
      "Epoch 46/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.2262 - accuracy: 0.7857 - val_loss: 2.9173 - val_accuracy: 0.2130\n",
      "Epoch 47/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 1.1822 - accuracy: 0.8004 - val_loss: 2.9202 - val_accuracy: 0.2083\n",
      "Epoch 48/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 1.1314 - accuracy: 0.8114 - val_loss: 2.9249 - val_accuracy: 0.2130\n",
      "Epoch 49/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 1.1224 - accuracy: 0.8150 - val_loss: 2.9283 - val_accuracy: 0.2083\n",
      "Epoch 50/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 1.0147 - accuracy: 0.8425 - val_loss: 2.9282 - val_accuracy: 0.2083\n",
      "Epoch 51/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 1.0140 - accuracy: 0.8498 - val_loss: 2.9316 - val_accuracy: 0.2083\n",
      "Epoch 52/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.9939 - accuracy: 0.8407 - val_loss: 2.9419 - val_accuracy: 0.2083\n",
      "Epoch 53/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.9864 - accuracy: 0.8388 - val_loss: 2.9486 - val_accuracy: 0.2083\n",
      "Epoch 54/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.9687 - accuracy: 0.8480 - val_loss: 2.9546 - val_accuracy: 0.2083\n",
      "Epoch 55/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.9080 - accuracy: 0.8590 - val_loss: 2.9575 - val_accuracy: 0.2083\n",
      "Epoch 56/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.8922 - accuracy: 0.8553 - val_loss: 2.9672 - val_accuracy: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.9044 - accuracy: 0.8626 - val_loss: 2.9755 - val_accuracy: 0.1991\n",
      "Epoch 58/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.8414 - accuracy: 0.8791 - val_loss: 2.9882 - val_accuracy: 0.2083\n",
      "Epoch 59/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.7780 - accuracy: 0.8846 - val_loss: 3.0016 - val_accuracy: 0.2083\n",
      "Epoch 60/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.7607 - accuracy: 0.8974 - val_loss: 3.0128 - val_accuracy: 0.1991\n",
      "Epoch 61/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.7059 - accuracy: 0.9158 - val_loss: 3.0084 - val_accuracy: 0.2130\n",
      "Epoch 62/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.6952 - accuracy: 0.8993 - val_loss: 2.9952 - val_accuracy: 0.2176\n",
      "Epoch 63/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.6812 - accuracy: 0.9103 - val_loss: 2.9754 - val_accuracy: 0.2083\n",
      "Epoch 64/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.6423 - accuracy: 0.9158 - val_loss: 2.9564 - val_accuracy: 0.2083\n",
      "Epoch 65/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.6398 - accuracy: 0.9212 - val_loss: 2.9564 - val_accuracy: 0.2130\n",
      "Epoch 66/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.5863 - accuracy: 0.9194 - val_loss: 2.9625 - val_accuracy: 0.2130\n",
      "Epoch 67/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.6825 - accuracy: 0.8956 - val_loss: 2.9837 - val_accuracy: 0.2130\n",
      "Epoch 68/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.5989 - accuracy: 0.9103 - val_loss: 3.0191 - val_accuracy: 0.2176\n",
      "Epoch 69/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.5789 - accuracy: 0.9322 - val_loss: 3.0480 - val_accuracy: 0.2176\n",
      "Epoch 70/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.5622 - accuracy: 0.9194 - val_loss: 3.0699 - val_accuracy: 0.2176\n",
      "Epoch 71/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.5003 - accuracy: 0.9469 - val_loss: 3.0891 - val_accuracy: 0.2083\n",
      "Epoch 72/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.4937 - accuracy: 0.9359 - val_loss: 3.0972 - val_accuracy: 0.2083\n",
      "Epoch 73/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.4914 - accuracy: 0.9414 - val_loss: 3.0913 - val_accuracy: 0.2176\n",
      "Epoch 74/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.5001 - accuracy: 0.9359 - val_loss: 3.0732 - val_accuracy: 0.2176\n",
      "Epoch 75/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.4673 - accuracy: 0.9469 - val_loss: 3.0565 - val_accuracy: 0.2083\n",
      "Epoch 76/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.4628 - accuracy: 0.9579 - val_loss: 3.0375 - val_accuracy: 0.2083\n",
      "Epoch 77/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.4111 - accuracy: 0.9579 - val_loss: 3.0310 - val_accuracy: 0.2130\n",
      "Epoch 78/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.4506 - accuracy: 0.9505 - val_loss: 3.0466 - val_accuracy: 0.2083\n",
      "Epoch 79/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.4266 - accuracy: 0.9579 - val_loss: 3.0710 - val_accuracy: 0.2037\n",
      "Epoch 80/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.4026 - accuracy: 0.9505 - val_loss: 3.0948 - val_accuracy: 0.2037\n",
      "Epoch 81/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.3654 - accuracy: 0.9670 - val_loss: 3.1215 - val_accuracy: 0.2037\n",
      "Epoch 82/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.3535 - accuracy: 0.9670 - val_loss: 3.1422 - val_accuracy: 0.2037\n",
      "Epoch 83/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.3825 - accuracy: 0.9579 - val_loss: 3.1717 - val_accuracy: 0.2130\n",
      "Epoch 84/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.3546 - accuracy: 0.9670 - val_loss: 3.1944 - val_accuracy: 0.2130\n",
      "Epoch 85/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.3724 - accuracy: 0.9579 - val_loss: 3.2269 - val_accuracy: 0.2130\n",
      "Epoch 86/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.3473 - accuracy: 0.9689 - val_loss: 3.2431 - val_accuracy: 0.1944\n",
      "Epoch 87/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.3374 - accuracy: 0.9634 - val_loss: 3.2700 - val_accuracy: 0.1944\n",
      "Epoch 88/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.3683 - accuracy: 0.9689 - val_loss: 3.2894 - val_accuracy: 0.1944\n",
      "Epoch 89/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.3620 - accuracy: 0.9615 - val_loss: 3.3098 - val_accuracy: 0.1759\n",
      "Epoch 90/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.3104 - accuracy: 0.9707 - val_loss: 3.3316 - val_accuracy: 0.1759\n",
      "Epoch 91/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.2772 - accuracy: 0.9853 - val_loss: 3.3557 - val_accuracy: 0.1852\n",
      "Epoch 92/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.3205 - accuracy: 0.9652 - val_loss: 3.3807 - val_accuracy: 0.1806\n",
      "Epoch 93/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.2972 - accuracy: 0.9707 - val_loss: 3.3837 - val_accuracy: 0.1852\n",
      "Epoch 94/1000\n",
      "546/546 [==============================] - 0s 186us/step - loss: 0.2723 - accuracy: 0.9799 - val_loss: 3.3758 - val_accuracy: 0.1898\n",
      "Epoch 95/1000\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.2988 - accuracy: 0.9707 - val_loss: 3.3747 - val_accuracy: 0.1898\n",
      "Epoch 96/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.2485 - accuracy: 0.9817 - val_loss: 3.3873 - val_accuracy: 0.1852\n",
      "Epoch 97/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.2699 - accuracy: 0.9780 - val_loss: 3.4049 - val_accuracy: 0.1898\n",
      "Epoch 98/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.2614 - accuracy: 0.9835 - val_loss: 3.4289 - val_accuracy: 0.1898\n",
      "Epoch 99/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.2809 - accuracy: 0.9707 - val_loss: 3.4474 - val_accuracy: 0.2083\n",
      "Epoch 100/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.2257 - accuracy: 0.9780 - val_loss: 3.4699 - val_accuracy: 0.2130\n",
      "Epoch 101/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.2341 - accuracy: 0.9817 - val_loss: 3.4997 - val_accuracy: 0.2176\n",
      "Epoch 102/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.2543 - accuracy: 0.9817 - val_loss: 3.5448 - val_accuracy: 0.2083\n",
      "Epoch 103/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.2320 - accuracy: 0.9762 - val_loss: 3.5672 - val_accuracy: 0.2083\n",
      "Epoch 104/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.2066 - accuracy: 0.9908 - val_loss: 3.5784 - val_accuracy: 0.2130\n",
      "Epoch 105/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.2225 - accuracy: 0.9835 - val_loss: 3.5514 - val_accuracy: 0.2130\n",
      "Epoch 106/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.2059 - accuracy: 0.9835 - val_loss: 3.5118 - val_accuracy: 0.2037\n",
      "Epoch 107/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.2016 - accuracy: 0.9908 - val_loss: 3.4766 - val_accuracy: 0.1898\n",
      "Epoch 108/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.2181 - accuracy: 0.9835 - val_loss: 3.4361 - val_accuracy: 0.1991\n",
      "Epoch 109/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1853 - accuracy: 0.9908 - val_loss: 3.4014 - val_accuracy: 0.2083\n",
      "Epoch 110/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1961 - accuracy: 0.9945 - val_loss: 3.3747 - val_accuracy: 0.2222\n",
      "Epoch 111/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.2074 - accuracy: 0.9872 - val_loss: 3.3687 - val_accuracy: 0.2176\n",
      "Epoch 112/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1977 - accuracy: 0.9872 - val_loss: 3.3718 - val_accuracy: 0.2176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1709 - accuracy: 0.9908 - val_loss: 3.3804 - val_accuracy: 0.2315\n",
      "Epoch 114/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1920 - accuracy: 0.9872 - val_loss: 3.3881 - val_accuracy: 0.2361\n",
      "Epoch 115/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1980 - accuracy: 0.9890 - val_loss: 3.4068 - val_accuracy: 0.2315\n",
      "Epoch 116/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1400 - accuracy: 0.9908 - val_loss: 3.4305 - val_accuracy: 0.2315\n",
      "Epoch 117/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1717 - accuracy: 0.9908 - val_loss: 3.4624 - val_accuracy: 0.2361\n",
      "Epoch 118/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1923 - accuracy: 0.9853 - val_loss: 3.4786 - val_accuracy: 0.2361\n",
      "Epoch 119/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1515 - accuracy: 0.9927 - val_loss: 3.5119 - val_accuracy: 0.2176\n",
      "Epoch 120/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1759 - accuracy: 0.9908 - val_loss: 3.5199 - val_accuracy: 0.2222\n",
      "Epoch 121/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1643 - accuracy: 0.9908 - val_loss: 3.5281 - val_accuracy: 0.2222\n",
      "Epoch 122/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1660 - accuracy: 0.9890 - val_loss: 3.5254 - val_accuracy: 0.2315\n",
      "Epoch 123/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1558 - accuracy: 0.9872 - val_loss: 3.5087 - val_accuracy: 0.2361\n",
      "Epoch 124/1000\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1456 - accuracy: 0.9908 - val_loss: 3.4959 - val_accuracy: 0.2361\n",
      "Epoch 125/1000\n",
      "546/546 [==============================] - 0s 129us/step - loss: 0.1492 - accuracy: 0.9908 - val_loss: 3.4938 - val_accuracy: 0.2315\n",
      "Epoch 126/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1693 - accuracy: 0.9890 - val_loss: 3.5038 - val_accuracy: 0.2315\n",
      "Epoch 127/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1496 - accuracy: 0.9908 - val_loss: 3.5256 - val_accuracy: 0.2315\n",
      "Epoch 128/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1562 - accuracy: 0.9890 - val_loss: 3.5394 - val_accuracy: 0.2315\n",
      "Epoch 129/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1311 - accuracy: 0.9890 - val_loss: 3.5549 - val_accuracy: 0.2315\n",
      "Epoch 130/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1430 - accuracy: 0.9945 - val_loss: 3.5701 - val_accuracy: 0.2315\n",
      "Epoch 131/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1324 - accuracy: 0.9927 - val_loss: 3.5873 - val_accuracy: 0.2315\n",
      "Epoch 132/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1374 - accuracy: 0.9945 - val_loss: 3.6049 - val_accuracy: 0.2315\n",
      "Epoch 133/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1477 - accuracy: 0.9908 - val_loss: 3.6244 - val_accuracy: 0.2269\n",
      "Epoch 134/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1239 - accuracy: 0.9963 - val_loss: 3.6410 - val_accuracy: 0.2269\n",
      "Epoch 135/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1378 - accuracy: 0.9945 - val_loss: 3.6343 - val_accuracy: 0.2315\n",
      "Epoch 136/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1526 - accuracy: 0.9908 - val_loss: 3.6173 - val_accuracy: 0.2361\n",
      "Epoch 137/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1334 - accuracy: 0.9945 - val_loss: 3.5990 - val_accuracy: 0.2407\n",
      "Epoch 138/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1427 - accuracy: 0.9945 - val_loss: 3.5857 - val_accuracy: 0.2361\n",
      "Epoch 139/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1308 - accuracy: 0.9908 - val_loss: 3.5735 - val_accuracy: 0.2407\n",
      "Epoch 140/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1570 - accuracy: 0.9872 - val_loss: 3.5689 - val_accuracy: 0.2500\n",
      "Epoch 141/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1355 - accuracy: 0.9927 - val_loss: 3.5657 - val_accuracy: 0.2546\n",
      "Epoch 142/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1272 - accuracy: 0.9927 - val_loss: 3.5667 - val_accuracy: 0.2546\n",
      "Epoch 143/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1539 - accuracy: 0.9927 - val_loss: 3.5675 - val_accuracy: 0.2500\n",
      "Epoch 144/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1214 - accuracy: 0.9963 - val_loss: 3.5716 - val_accuracy: 0.2500\n",
      "Epoch 145/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1281 - accuracy: 0.9945 - val_loss: 3.5795 - val_accuracy: 0.2500\n",
      "Epoch 146/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1009 - accuracy: 0.9963 - val_loss: 3.5878 - val_accuracy: 0.2546\n",
      "Epoch 147/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1329 - accuracy: 0.9963 - val_loss: 3.5927 - val_accuracy: 0.2546\n",
      "Epoch 148/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1402 - accuracy: 0.9945 - val_loss: 3.5967 - val_accuracy: 0.2546\n",
      "Epoch 149/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1256 - accuracy: 0.9963 - val_loss: 3.6006 - val_accuracy: 0.2546\n",
      "Epoch 150/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1337 - accuracy: 0.9963 - val_loss: 3.6031 - val_accuracy: 0.2500\n",
      "Epoch 151/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1115 - accuracy: 0.9963 - val_loss: 3.5996 - val_accuracy: 0.2500\n",
      "Epoch 152/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1269 - accuracy: 0.9872 - val_loss: 3.5963 - val_accuracy: 0.2500\n",
      "Epoch 153/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1190 - accuracy: 0.9890 - val_loss: 3.5923 - val_accuracy: 0.2546\n",
      "Epoch 154/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1185 - accuracy: 0.9927 - val_loss: 3.5880 - val_accuracy: 0.2546\n",
      "Epoch 155/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1285 - accuracy: 0.9945 - val_loss: 3.5843 - val_accuracy: 0.2593\n",
      "Epoch 156/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0993 - accuracy: 0.9963 - val_loss: 3.5815 - val_accuracy: 0.2639\n",
      "Epoch 157/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1134 - accuracy: 0.9963 - val_loss: 3.5766 - val_accuracy: 0.2639\n",
      "Epoch 158/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1175 - accuracy: 0.9963 - val_loss: 3.5737 - val_accuracy: 0.2639\n",
      "Epoch 159/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1237 - accuracy: 0.9963 - val_loss: 3.5691 - val_accuracy: 0.2639\n",
      "Epoch 160/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1197 - accuracy: 0.9945 - val_loss: 3.5635 - val_accuracy: 0.2639\n",
      "Epoch 161/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1147 - accuracy: 0.9963 - val_loss: 3.5577 - val_accuracy: 0.2639\n",
      "Epoch 162/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1388 - accuracy: 0.9908 - val_loss: 3.5531 - val_accuracy: 0.2639\n",
      "Epoch 163/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1465 - accuracy: 0.9908 - val_loss: 3.5494 - val_accuracy: 0.2639\n",
      "Epoch 164/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1276 - accuracy: 0.9963 - val_loss: 3.5453 - val_accuracy: 0.2639\n",
      "Epoch 165/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1189 - accuracy: 0.9945 - val_loss: 3.5408 - val_accuracy: 0.2639\n",
      "Epoch 166/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1246 - accuracy: 0.9927 - val_loss: 3.5368 - val_accuracy: 0.2685\n",
      "Epoch 167/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1090 - accuracy: 0.9982 - val_loss: 3.5332 - val_accuracy: 0.2685\n",
      "Epoch 168/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1439 - accuracy: 0.9927 - val_loss: 3.5299 - val_accuracy: 0.2685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1242 - accuracy: 0.9927 - val_loss: 3.5258 - val_accuracy: 0.2731\n",
      "Epoch 170/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1158 - accuracy: 0.9963 - val_loss: 3.5213 - val_accuracy: 0.2731\n",
      "Epoch 171/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1371 - accuracy: 0.9890 - val_loss: 3.5153 - val_accuracy: 0.2731\n",
      "Epoch 172/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 3.5090 - val_accuracy: 0.2731\n",
      "Epoch 173/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1200 - accuracy: 0.9982 - val_loss: 3.5035 - val_accuracy: 0.2731\n",
      "Epoch 174/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1176 - accuracy: 0.9890 - val_loss: 3.4982 - val_accuracy: 0.2731\n",
      "Epoch 175/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1216 - accuracy: 0.9945 - val_loss: 3.4927 - val_accuracy: 0.2731\n",
      "Epoch 176/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 3.4882 - val_accuracy: 0.2731\n",
      "Epoch 177/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1141 - accuracy: 0.9945 - val_loss: 3.4840 - val_accuracy: 0.2778\n",
      "Epoch 178/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1409 - accuracy: 0.9927 - val_loss: 3.4800 - val_accuracy: 0.2824\n",
      "Epoch 179/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1191 - accuracy: 0.9982 - val_loss: 3.4764 - val_accuracy: 0.2824\n",
      "Epoch 180/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1017 - accuracy: 0.9963 - val_loss: 3.4721 - val_accuracy: 0.2824\n",
      "Epoch 181/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1050 - accuracy: 0.9982 - val_loss: 3.4683 - val_accuracy: 0.2870\n",
      "Epoch 182/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1112 - accuracy: 0.9927 - val_loss: 3.4645 - val_accuracy: 0.2870\n",
      "Epoch 183/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1196 - accuracy: 0.9908 - val_loss: 3.4608 - val_accuracy: 0.2870\n",
      "Epoch 184/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1055 - accuracy: 0.9963 - val_loss: 3.4567 - val_accuracy: 0.2917\n",
      "Epoch 185/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1097 - accuracy: 0.9982 - val_loss: 3.4528 - val_accuracy: 0.2917\n",
      "Epoch 186/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1077 - accuracy: 0.9982 - val_loss: 3.4486 - val_accuracy: 0.2917\n",
      "Epoch 187/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 3.4458 - val_accuracy: 0.2917\n",
      "Epoch 188/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1138 - accuracy: 0.9963 - val_loss: 3.4421 - val_accuracy: 0.2917\n",
      "Epoch 189/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1105 - accuracy: 0.9945 - val_loss: 3.4382 - val_accuracy: 0.2917\n",
      "Epoch 190/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1133 - accuracy: 0.9890 - val_loss: 3.4345 - val_accuracy: 0.2917\n",
      "Epoch 191/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1083 - accuracy: 0.9963 - val_loss: 3.4306 - val_accuracy: 0.2917\n",
      "Epoch 192/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1134 - accuracy: 0.9963 - val_loss: 3.4272 - val_accuracy: 0.2917\n",
      "Epoch 193/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1167 - accuracy: 0.9927 - val_loss: 3.4236 - val_accuracy: 0.2917\n",
      "Epoch 194/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 3.4200 - val_accuracy: 0.2917\n",
      "Epoch 195/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1031 - accuracy: 0.9945 - val_loss: 3.4165 - val_accuracy: 0.2917\n",
      "Epoch 196/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1138 - accuracy: 0.9945 - val_loss: 3.4128 - val_accuracy: 0.2917\n",
      "Epoch 197/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0997 - accuracy: 0.9982 - val_loss: 3.4087 - val_accuracy: 0.2917\n",
      "Epoch 198/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 3.4045 - val_accuracy: 0.2917\n",
      "Epoch 199/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1344 - accuracy: 0.9945 - val_loss: 3.4003 - val_accuracy: 0.2917\n",
      "Epoch 200/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1212 - accuracy: 0.9945 - val_loss: 3.3960 - val_accuracy: 0.2917\n",
      "Epoch 201/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1244 - accuracy: 0.9927 - val_loss: 3.3913 - val_accuracy: 0.2917\n",
      "Epoch 202/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1142 - accuracy: 0.9945 - val_loss: 3.3873 - val_accuracy: 0.2917\n",
      "Epoch 203/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1006 - accuracy: 0.9982 - val_loss: 3.3828 - val_accuracy: 0.2917\n",
      "Epoch 204/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1126 - accuracy: 0.9927 - val_loss: 3.3784 - val_accuracy: 0.2917\n",
      "Epoch 205/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1120 - accuracy: 0.9945 - val_loss: 3.3739 - val_accuracy: 0.2917\n",
      "Epoch 206/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1194 - accuracy: 0.9927 - val_loss: 3.3690 - val_accuracy: 0.2917\n",
      "Epoch 207/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1254 - accuracy: 0.9927 - val_loss: 3.3641 - val_accuracy: 0.2917\n",
      "Epoch 208/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1236 - accuracy: 0.9890 - val_loss: 3.3589 - val_accuracy: 0.2917\n",
      "Epoch 209/1000\n",
      "546/546 [==============================] - 0s 220us/step - loss: 0.1094 - accuracy: 0.9982 - val_loss: 3.3537 - val_accuracy: 0.2963\n",
      "Epoch 210/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1127 - accuracy: 0.9963 - val_loss: 3.3485 - val_accuracy: 0.2963\n",
      "Epoch 211/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1039 - accuracy: 0.9963 - val_loss: 3.3440 - val_accuracy: 0.3009\n",
      "Epoch 212/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1242 - accuracy: 0.9927 - val_loss: 3.3385 - val_accuracy: 0.3009\n",
      "Epoch 213/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1131 - accuracy: 0.9945 - val_loss: 3.3332 - val_accuracy: 0.3009\n",
      "Epoch 214/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1148 - accuracy: 0.9908 - val_loss: 3.3277 - val_accuracy: 0.3009\n",
      "Epoch 215/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1234 - accuracy: 0.9982 - val_loss: 3.3231 - val_accuracy: 0.3009\n",
      "Epoch 216/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1008 - accuracy: 0.9945 - val_loss: 3.3176 - val_accuracy: 0.3009\n",
      "Epoch 217/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1143 - accuracy: 0.9945 - val_loss: 3.3120 - val_accuracy: 0.3056\n",
      "Epoch 218/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1059 - accuracy: 0.9945 - val_loss: 3.3064 - val_accuracy: 0.3056\n",
      "Epoch 219/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1118 - accuracy: 0.9945 - val_loss: 3.3014 - val_accuracy: 0.3102\n",
      "Epoch 220/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1256 - accuracy: 0.9927 - val_loss: 3.2965 - val_accuracy: 0.3102\n",
      "Epoch 221/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0985 - accuracy: 0.9963 - val_loss: 3.2914 - val_accuracy: 0.3148\n",
      "Epoch 222/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1087 - accuracy: 0.9945 - val_loss: 3.2862 - val_accuracy: 0.3148\n",
      "Epoch 223/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1124 - accuracy: 0.9927 - val_loss: 3.2806 - val_accuracy: 0.3148\n",
      "Epoch 224/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1326 - accuracy: 0.9872 - val_loss: 3.2751 - val_accuracy: 0.3148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1115 - accuracy: 0.9982 - val_loss: 3.2696 - val_accuracy: 0.3148\n",
      "Epoch 226/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1263 - accuracy: 0.9963 - val_loss: 3.2640 - val_accuracy: 0.3194\n",
      "Epoch 227/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1227 - accuracy: 0.9927 - val_loss: 3.2579 - val_accuracy: 0.3241\n",
      "Epoch 228/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1154 - accuracy: 0.9945 - val_loss: 3.2526 - val_accuracy: 0.3241\n",
      "Epoch 229/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1141 - accuracy: 0.9945 - val_loss: 3.2469 - val_accuracy: 0.3241\n",
      "Epoch 230/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 3.2413 - val_accuracy: 0.3241\n",
      "Epoch 231/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1136 - accuracy: 0.9982 - val_loss: 3.2357 - val_accuracy: 0.3241\n",
      "Epoch 232/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 3.2303 - val_accuracy: 0.3241\n",
      "Epoch 233/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1163 - accuracy: 0.9963 - val_loss: 3.2240 - val_accuracy: 0.3241\n",
      "Epoch 234/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1228 - accuracy: 0.9927 - val_loss: 3.2177 - val_accuracy: 0.3241\n",
      "Epoch 235/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1422 - accuracy: 0.9872 - val_loss: 3.2114 - val_accuracy: 0.3241\n",
      "Epoch 236/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1148 - accuracy: 0.9927 - val_loss: 3.2053 - val_accuracy: 0.3241\n",
      "Epoch 237/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1069 - accuracy: 0.9945 - val_loss: 3.1994 - val_accuracy: 0.3287\n",
      "Epoch 238/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1033 - accuracy: 0.9945 - val_loss: 3.1935 - val_accuracy: 0.3287\n",
      "Epoch 239/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1086 - accuracy: 0.9945 - val_loss: 3.1869 - val_accuracy: 0.3287\n",
      "Epoch 240/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1235 - accuracy: 0.9945 - val_loss: 3.1805 - val_accuracy: 0.3287\n",
      "Epoch 241/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 3.1737 - val_accuracy: 0.3287\n",
      "Epoch 242/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1245 - accuracy: 0.9908 - val_loss: 3.1672 - val_accuracy: 0.3287\n",
      "Epoch 243/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1218 - accuracy: 0.9927 - val_loss: 3.1606 - val_accuracy: 0.3333\n",
      "Epoch 244/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1137 - accuracy: 0.9945 - val_loss: 3.1538 - val_accuracy: 0.3333\n",
      "Epoch 245/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1103 - accuracy: 0.9982 - val_loss: 3.1467 - val_accuracy: 0.3333\n",
      "Epoch 246/1000\n",
      "546/546 [==============================] - 0s 131us/step - loss: 0.1066 - accuracy: 0.9963 - val_loss: 3.1394 - val_accuracy: 0.3380\n",
      "Epoch 247/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1138 - accuracy: 0.9982 - val_loss: 3.1328 - val_accuracy: 0.3426\n",
      "Epoch 248/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1196 - accuracy: 0.9982 - val_loss: 3.1264 - val_accuracy: 0.3472\n",
      "Epoch 249/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1321 - accuracy: 0.9927 - val_loss: 3.1198 - val_accuracy: 0.3519\n",
      "Epoch 250/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1171 - accuracy: 0.9963 - val_loss: 3.1131 - val_accuracy: 0.3519\n",
      "Epoch 251/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1113 - accuracy: 0.9963 - val_loss: 3.1062 - val_accuracy: 0.3565\n",
      "Epoch 252/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 3.1002 - val_accuracy: 0.3565\n",
      "Epoch 253/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1275 - accuracy: 0.9908 - val_loss: 3.0937 - val_accuracy: 0.3565\n",
      "Epoch 254/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1281 - accuracy: 0.9927 - val_loss: 3.0875 - val_accuracy: 0.3565\n",
      "Epoch 255/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1176 - accuracy: 0.9963 - val_loss: 3.0814 - val_accuracy: 0.3565\n",
      "Epoch 256/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1155 - accuracy: 0.9945 - val_loss: 3.0756 - val_accuracy: 0.3565\n",
      "Epoch 257/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1240 - accuracy: 0.9927 - val_loss: 3.0695 - val_accuracy: 0.3565\n",
      "Epoch 258/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1242 - accuracy: 0.9927 - val_loss: 3.0634 - val_accuracy: 0.3565\n",
      "Epoch 259/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1211 - accuracy: 0.9927 - val_loss: 3.0574 - val_accuracy: 0.3565\n",
      "Epoch 260/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1011 - accuracy: 0.9945 - val_loss: 3.0513 - val_accuracy: 0.3565\n",
      "Epoch 261/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1234 - accuracy: 0.9982 - val_loss: 3.0451 - val_accuracy: 0.3565\n",
      "Epoch 262/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1019 - accuracy: 0.9945 - val_loss: 3.0389 - val_accuracy: 0.3611\n",
      "Epoch 263/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1156 - accuracy: 0.9945 - val_loss: 3.0326 - val_accuracy: 0.3611\n",
      "Epoch 264/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1107 - accuracy: 0.9908 - val_loss: 3.0266 - val_accuracy: 0.3611\n",
      "Epoch 265/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1160 - accuracy: 0.9963 - val_loss: 3.0196 - val_accuracy: 0.3611\n",
      "Epoch 266/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1266 - accuracy: 0.9963 - val_loss: 3.0134 - val_accuracy: 0.3611\n",
      "Epoch 267/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1199 - accuracy: 0.9927 - val_loss: 3.0070 - val_accuracy: 0.3611\n",
      "Epoch 268/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1197 - accuracy: 0.9963 - val_loss: 3.0011 - val_accuracy: 0.3611\n",
      "Epoch 269/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1146 - accuracy: 0.9963 - val_loss: 2.9949 - val_accuracy: 0.3611\n",
      "Epoch 270/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1098 - accuracy: 0.9945 - val_loss: 2.9890 - val_accuracy: 0.3704\n",
      "Epoch 271/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1002 - accuracy: 0.9945 - val_loss: 2.9822 - val_accuracy: 0.3704\n",
      "Epoch 272/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1003 - accuracy: 0.9982 - val_loss: 2.9763 - val_accuracy: 0.3704\n",
      "Epoch 273/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1272 - accuracy: 0.9963 - val_loss: 2.9703 - val_accuracy: 0.3704\n",
      "Epoch 274/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1174 - accuracy: 0.9963 - val_loss: 2.9635 - val_accuracy: 0.3704\n",
      "Epoch 275/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1130 - accuracy: 0.9982 - val_loss: 2.9571 - val_accuracy: 0.3704\n",
      "Epoch 276/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1208 - accuracy: 0.9982 - val_loss: 2.9506 - val_accuracy: 0.3704\n",
      "Epoch 277/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1022 - accuracy: 1.0000 - val_loss: 2.9446 - val_accuracy: 0.3704\n",
      "Epoch 278/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0926 - accuracy: 0.9963 - val_loss: 2.9386 - val_accuracy: 0.3704\n",
      "Epoch 279/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1151 - accuracy: 0.9982 - val_loss: 2.9328 - val_accuracy: 0.3704\n",
      "Epoch 280/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1339 - accuracy: 0.9945 - val_loss: 2.9266 - val_accuracy: 0.3704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1299 - accuracy: 0.9927 - val_loss: 2.9206 - val_accuracy: 0.3750\n",
      "Epoch 282/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1150 - accuracy: 0.9982 - val_loss: 2.9148 - val_accuracy: 0.3750\n",
      "Epoch 283/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0990 - accuracy: 0.9982 - val_loss: 2.9086 - val_accuracy: 0.3796\n",
      "Epoch 284/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1195 - accuracy: 0.9963 - val_loss: 2.9021 - val_accuracy: 0.3750\n",
      "Epoch 285/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1321 - accuracy: 0.9872 - val_loss: 2.8961 - val_accuracy: 0.3750\n",
      "Epoch 286/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1090 - accuracy: 0.9963 - val_loss: 2.8904 - val_accuracy: 0.3750\n",
      "Epoch 287/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1105 - accuracy: 0.9927 - val_loss: 2.8848 - val_accuracy: 0.3750\n",
      "Epoch 288/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1047 - accuracy: 0.9945 - val_loss: 2.8791 - val_accuracy: 0.3750\n",
      "Epoch 289/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1381 - accuracy: 0.9872 - val_loss: 2.8735 - val_accuracy: 0.3750\n",
      "Epoch 290/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1097 - accuracy: 0.9982 - val_loss: 2.8676 - val_accuracy: 0.3750\n",
      "Epoch 291/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1144 - accuracy: 0.9945 - val_loss: 2.8624 - val_accuracy: 0.3750\n",
      "Epoch 292/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1164 - accuracy: 0.9945 - val_loss: 2.8564 - val_accuracy: 0.3843\n",
      "Epoch 293/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 2.8507 - val_accuracy: 0.3843\n",
      "Epoch 294/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1061 - accuracy: 0.9963 - val_loss: 2.8446 - val_accuracy: 0.3843\n",
      "Epoch 295/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1204 - accuracy: 0.9945 - val_loss: 2.8379 - val_accuracy: 0.3843\n",
      "Epoch 296/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1060 - accuracy: 0.9963 - val_loss: 2.8304 - val_accuracy: 0.3843\n",
      "Epoch 297/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1256 - accuracy: 0.9945 - val_loss: 2.8233 - val_accuracy: 0.3889\n",
      "Epoch 298/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1076 - accuracy: 0.9945 - val_loss: 2.8163 - val_accuracy: 0.3889\n",
      "Epoch 299/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1109 - accuracy: 0.9927 - val_loss: 2.8094 - val_accuracy: 0.3889\n",
      "Epoch 300/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1258 - accuracy: 0.9963 - val_loss: 2.8024 - val_accuracy: 0.3889\n",
      "Epoch 301/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1081 - accuracy: 0.9963 - val_loss: 2.7950 - val_accuracy: 0.3935\n",
      "Epoch 302/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1127 - accuracy: 0.9927 - val_loss: 2.7883 - val_accuracy: 0.3935\n",
      "Epoch 303/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1121 - accuracy: 0.9963 - val_loss: 2.7816 - val_accuracy: 0.3935\n",
      "Epoch 304/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1122 - accuracy: 0.9908 - val_loss: 2.7748 - val_accuracy: 0.3935\n",
      "Epoch 305/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1072 - accuracy: 0.9982 - val_loss: 2.7679 - val_accuracy: 0.3935\n",
      "Epoch 306/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1161 - accuracy: 0.9890 - val_loss: 2.7612 - val_accuracy: 0.3981\n",
      "Epoch 307/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1321 - accuracy: 0.9945 - val_loss: 2.7544 - val_accuracy: 0.3981\n",
      "Epoch 308/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1144 - accuracy: 0.9945 - val_loss: 2.7478 - val_accuracy: 0.3981\n",
      "Epoch 309/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1104 - accuracy: 0.9963 - val_loss: 2.7410 - val_accuracy: 0.4028\n",
      "Epoch 310/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 2.7345 - val_accuracy: 0.3981\n",
      "Epoch 311/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.3981\n",
      "Epoch 312/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 2.7211 - val_accuracy: 0.3981\n",
      "Epoch 313/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1102 - accuracy: 0.9963 - val_loss: 2.7142 - val_accuracy: 0.3981\n",
      "Epoch 314/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1138 - accuracy: 0.9945 - val_loss: 2.7078 - val_accuracy: 0.3981\n",
      "Epoch 315/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0997 - accuracy: 0.9982 - val_loss: 2.7008 - val_accuracy: 0.3981\n",
      "Epoch 316/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1223 - accuracy: 0.9963 - val_loss: 2.6943 - val_accuracy: 0.3981\n",
      "Epoch 317/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1105 - accuracy: 0.9982 - val_loss: 2.6880 - val_accuracy: 0.3981\n",
      "Epoch 318/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1217 - accuracy: 0.9945 - val_loss: 2.6808 - val_accuracy: 0.3981\n",
      "Epoch 319/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1276 - accuracy: 0.9982 - val_loss: 2.6737 - val_accuracy: 0.4028\n",
      "Epoch 320/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1073 - accuracy: 0.9963 - val_loss: 2.6673 - val_accuracy: 0.4028\n",
      "Epoch 321/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1134 - accuracy: 0.9927 - val_loss: 2.6605 - val_accuracy: 0.4028\n",
      "Epoch 322/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1207 - accuracy: 0.9945 - val_loss: 2.6534 - val_accuracy: 0.4028\n",
      "Epoch 323/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1104 - accuracy: 0.9927 - val_loss: 2.6464 - val_accuracy: 0.4074\n",
      "Epoch 324/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1302 - accuracy: 0.9945 - val_loss: 2.6388 - val_accuracy: 0.4074\n",
      "Epoch 325/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1335 - accuracy: 0.9890 - val_loss: 2.6315 - val_accuracy: 0.4074\n",
      "Epoch 326/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1117 - accuracy: 0.9963 - val_loss: 2.6241 - val_accuracy: 0.4074\n",
      "Epoch 327/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0980 - accuracy: 0.9982 - val_loss: 2.6169 - val_accuracy: 0.4167\n",
      "Epoch 328/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 2.6098 - val_accuracy: 0.4167\n",
      "Epoch 329/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1162 - accuracy: 0.9963 - val_loss: 2.6022 - val_accuracy: 0.4167\n",
      "Epoch 330/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1084 - accuracy: 0.9945 - val_loss: 2.5952 - val_accuracy: 0.4167\n",
      "Epoch 331/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1078 - accuracy: 0.9927 - val_loss: 2.5881 - val_accuracy: 0.4167\n",
      "Epoch 332/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1148 - accuracy: 0.9945 - val_loss: 2.5807 - val_accuracy: 0.4213\n",
      "Epoch 333/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1108 - accuracy: 0.9945 - val_loss: 2.5736 - val_accuracy: 0.4213\n",
      "Epoch 334/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 2.5670 - val_accuracy: 0.4213\n",
      "Epoch 335/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1120 - accuracy: 0.9982 - val_loss: 2.5606 - val_accuracy: 0.4259\n",
      "Epoch 336/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1020 - accuracy: 0.9963 - val_loss: 2.5535 - val_accuracy: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1169 - accuracy: 0.9927 - val_loss: 2.5465 - val_accuracy: 0.4306\n",
      "Epoch 338/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1370 - accuracy: 0.9908 - val_loss: 2.5392 - val_accuracy: 0.4306\n",
      "Epoch 339/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1229 - accuracy: 0.9945 - val_loss: 2.5313 - val_accuracy: 0.4306\n",
      "Epoch 340/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1187 - accuracy: 0.9963 - val_loss: 2.5233 - val_accuracy: 0.4306\n",
      "Epoch 341/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1231 - accuracy: 0.9963 - val_loss: 2.5159 - val_accuracy: 0.4306\n",
      "Epoch 342/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1229 - accuracy: 0.9908 - val_loss: 2.5084 - val_accuracy: 0.4306\n",
      "Epoch 343/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1232 - accuracy: 0.9908 - val_loss: 2.5017 - val_accuracy: 0.4306\n",
      "Epoch 344/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0947 - accuracy: 0.9982 - val_loss: 2.4945 - val_accuracy: 0.4306\n",
      "Epoch 345/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1166 - accuracy: 0.9982 - val_loss: 2.4875 - val_accuracy: 0.4306\n",
      "Epoch 346/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1143 - accuracy: 0.9945 - val_loss: 2.4813 - val_accuracy: 0.4306\n",
      "Epoch 347/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1068 - accuracy: 0.9982 - val_loss: 2.4749 - val_accuracy: 0.4352\n",
      "Epoch 348/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1336 - accuracy: 0.9927 - val_loss: 2.4681 - val_accuracy: 0.4398\n",
      "Epoch 349/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1356 - accuracy: 0.9908 - val_loss: 2.4609 - val_accuracy: 0.4444\n",
      "Epoch 350/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1121 - accuracy: 0.9963 - val_loss: 2.4539 - val_accuracy: 0.4491\n",
      "Epoch 351/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1024 - accuracy: 0.9982 - val_loss: 2.4465 - val_accuracy: 0.4491\n",
      "Epoch 352/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1197 - accuracy: 0.9945 - val_loss: 2.4396 - val_accuracy: 0.4491\n",
      "Epoch 353/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1179 - accuracy: 0.9908 - val_loss: 2.4327 - val_accuracy: 0.4491\n",
      "Epoch 354/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 2.4256 - val_accuracy: 0.4491\n",
      "Epoch 355/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1192 - accuracy: 0.9908 - val_loss: 2.4192 - val_accuracy: 0.4491\n",
      "Epoch 356/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1146 - accuracy: 0.9927 - val_loss: 2.4124 - val_accuracy: 0.4491\n",
      "Epoch 357/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1165 - accuracy: 0.9927 - val_loss: 2.4055 - val_accuracy: 0.4491\n",
      "Epoch 358/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1159 - accuracy: 0.9963 - val_loss: 2.3983 - val_accuracy: 0.4491\n",
      "Epoch 359/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.4491\n",
      "Epoch 360/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0970 - accuracy: 0.9982 - val_loss: 2.3839 - val_accuracy: 0.4491\n",
      "Epoch 361/1000\n",
      "546/546 [==============================] - 0s 190us/step - loss: 0.1188 - accuracy: 0.9890 - val_loss: 2.3770 - val_accuracy: 0.4491\n",
      "Epoch 362/1000\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.1161 - accuracy: 0.9963 - val_loss: 2.3697 - val_accuracy: 0.4537\n",
      "Epoch 363/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1154 - accuracy: 0.9927 - val_loss: 2.3627 - val_accuracy: 0.4537\n",
      "Epoch 364/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1209 - accuracy: 0.9945 - val_loss: 2.3558 - val_accuracy: 0.4537\n",
      "Epoch 365/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1094 - accuracy: 0.9927 - val_loss: 2.3485 - val_accuracy: 0.4583\n",
      "Epoch 366/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1126 - accuracy: 0.9963 - val_loss: 2.3416 - val_accuracy: 0.4583\n",
      "Epoch 367/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1099 - accuracy: 0.9945 - val_loss: 2.3352 - val_accuracy: 0.4583\n",
      "Epoch 368/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1165 - accuracy: 0.9908 - val_loss: 2.3285 - val_accuracy: 0.4630\n",
      "Epoch 369/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 2.3218 - val_accuracy: 0.4630\n",
      "Epoch 370/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1228 - accuracy: 0.9927 - val_loss: 2.3152 - val_accuracy: 0.4676\n",
      "Epoch 371/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1058 - accuracy: 0.9982 - val_loss: 2.3084 - val_accuracy: 0.4676\n",
      "Epoch 372/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1171 - accuracy: 0.9908 - val_loss: 2.3016 - val_accuracy: 0.4676\n",
      "Epoch 373/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1118 - accuracy: 0.9963 - val_loss: 2.2948 - val_accuracy: 0.4676\n",
      "Epoch 374/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1124 - accuracy: 0.9982 - val_loss: 2.2875 - val_accuracy: 0.4676\n",
      "Epoch 375/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1088 - accuracy: 0.9945 - val_loss: 2.2801 - val_accuracy: 0.4676\n",
      "Epoch 376/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0972 - accuracy: 0.9982 - val_loss: 2.2731 - val_accuracy: 0.4722\n",
      "Epoch 377/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0934 - accuracy: 0.9945 - val_loss: 2.2664 - val_accuracy: 0.4722\n",
      "Epoch 378/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1289 - accuracy: 0.9927 - val_loss: 2.2596 - val_accuracy: 0.4722\n",
      "Epoch 379/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1134 - accuracy: 0.9927 - val_loss: 2.2533 - val_accuracy: 0.4722\n",
      "Epoch 380/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1191 - accuracy: 0.9927 - val_loss: 2.2473 - val_accuracy: 0.4722\n",
      "Epoch 381/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1036 - accuracy: 0.9982 - val_loss: 2.2404 - val_accuracy: 0.4815\n",
      "Epoch 382/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1112 - accuracy: 0.9982 - val_loss: 2.2342 - val_accuracy: 0.4815\n",
      "Epoch 383/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1100 - accuracy: 0.9963 - val_loss: 2.2275 - val_accuracy: 0.4769\n",
      "Epoch 384/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1314 - accuracy: 0.9908 - val_loss: 2.2206 - val_accuracy: 0.4769\n",
      "Epoch 385/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1074 - accuracy: 0.9963 - val_loss: 2.2140 - val_accuracy: 0.4815\n",
      "Epoch 386/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1008 - accuracy: 0.9927 - val_loss: 2.2068 - val_accuracy: 0.4815\n",
      "Epoch 387/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1013 - accuracy: 0.9982 - val_loss: 2.2002 - val_accuracy: 0.4815\n",
      "Epoch 388/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1350 - accuracy: 0.9945 - val_loss: 2.1935 - val_accuracy: 0.4815\n",
      "Epoch 389/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1209 - accuracy: 0.9908 - val_loss: 2.1871 - val_accuracy: 0.4861\n",
      "Epoch 390/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1122 - accuracy: 0.9982 - val_loss: 2.1809 - val_accuracy: 0.4907\n",
      "Epoch 391/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1053 - accuracy: 0.9963 - val_loss: 2.1747 - val_accuracy: 0.4954\n",
      "Epoch 392/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1105 - accuracy: 0.9945 - val_loss: 2.1689 - val_accuracy: 0.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0938 - accuracy: 0.9963 - val_loss: 2.1626 - val_accuracy: 0.4954\n",
      "Epoch 394/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1157 - accuracy: 0.9945 - val_loss: 2.1563 - val_accuracy: 0.4954\n",
      "Epoch 395/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1315 - accuracy: 0.9927 - val_loss: 2.1494 - val_accuracy: 0.4954\n",
      "Epoch 396/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0943 - accuracy: 0.9963 - val_loss: 2.1424 - val_accuracy: 0.5000\n",
      "Epoch 397/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1182 - accuracy: 0.9963 - val_loss: 2.1361 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1323 - accuracy: 0.9945 - val_loss: 2.1298 - val_accuracy: 0.5000\n",
      "Epoch 399/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1048 - accuracy: 0.9945 - val_loss: 2.1172 - val_accuracy: 0.5000\n",
      "Epoch 401/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0996 - accuracy: 0.9982 - val_loss: 2.1105 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1187 - accuracy: 0.9963 - val_loss: 2.1043 - val_accuracy: 0.5000\n",
      "Epoch 403/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1052 - accuracy: 0.9945 - val_loss: 2.0977 - val_accuracy: 0.5046\n",
      "Epoch 404/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1034 - accuracy: 0.9908 - val_loss: 2.0913 - val_accuracy: 0.5046\n",
      "Epoch 405/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0999 - accuracy: 0.9982 - val_loss: 2.0854 - val_accuracy: 0.5139\n",
      "Epoch 406/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1554 - accuracy: 0.9908 - val_loss: 2.0791 - val_accuracy: 0.5139\n",
      "Epoch 407/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0981 - accuracy: 0.9982 - val_loss: 2.0730 - val_accuracy: 0.5185\n",
      "Epoch 408/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1358 - accuracy: 0.9872 - val_loss: 2.0673 - val_accuracy: 0.5185\n",
      "Epoch 409/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1141 - accuracy: 0.9908 - val_loss: 2.0612 - val_accuracy: 0.5185\n",
      "Epoch 410/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1185 - accuracy: 0.9963 - val_loss: 2.0547 - val_accuracy: 0.5185\n",
      "Epoch 411/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 2.0487 - val_accuracy: 0.5185\n",
      "Epoch 412/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1185 - accuracy: 0.9853 - val_loss: 2.0425 - val_accuracy: 0.5185\n",
      "Epoch 413/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1049 - accuracy: 0.9963 - val_loss: 2.0361 - val_accuracy: 0.5185\n",
      "Epoch 414/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1232 - accuracy: 0.9945 - val_loss: 2.0298 - val_accuracy: 0.5185\n",
      "Epoch 415/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 2.0239 - val_accuracy: 0.5185\n",
      "Epoch 416/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1227 - accuracy: 0.9945 - val_loss: 2.0180 - val_accuracy: 0.5185\n",
      "Epoch 417/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0933 - accuracy: 0.9982 - val_loss: 2.0124 - val_accuracy: 0.5185\n",
      "Epoch 418/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1149 - accuracy: 0.9927 - val_loss: 2.0069 - val_accuracy: 0.5185\n",
      "Epoch 419/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.5185\n",
      "Epoch 420/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1215 - accuracy: 0.9982 - val_loss: 1.9965 - val_accuracy: 0.5185\n",
      "Epoch 421/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1140 - accuracy: 0.9945 - val_loss: 1.9910 - val_accuracy: 0.5185\n",
      "Epoch 422/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1120 - accuracy: 0.9945 - val_loss: 1.9853 - val_accuracy: 0.5185\n",
      "Epoch 423/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0970 - accuracy: 0.9982 - val_loss: 1.9795 - val_accuracy: 0.5185\n",
      "Epoch 424/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1113 - accuracy: 0.9945 - val_loss: 1.9741 - val_accuracy: 0.5185\n",
      "Epoch 425/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1001 - accuracy: 0.9982 - val_loss: 1.9685 - val_accuracy: 0.5231\n",
      "Epoch 426/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1302 - accuracy: 0.9908 - val_loss: 1.9629 - val_accuracy: 0.5231\n",
      "Epoch 427/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0973 - accuracy: 0.9963 - val_loss: 1.9573 - val_accuracy: 0.5231\n",
      "Epoch 428/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1177 - accuracy: 0.9945 - val_loss: 1.9521 - val_accuracy: 0.5231\n",
      "Epoch 429/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1079 - accuracy: 0.9945 - val_loss: 1.9464 - val_accuracy: 0.5231\n",
      "Epoch 430/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1015 - accuracy: 0.9963 - val_loss: 1.9412 - val_accuracy: 0.5231\n",
      "Epoch 431/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1091 - accuracy: 0.9963 - val_loss: 1.9358 - val_accuracy: 0.5231\n",
      "Epoch 432/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1055 - accuracy: 0.9982 - val_loss: 1.9307 - val_accuracy: 0.5231\n",
      "Epoch 433/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1001 - accuracy: 0.9945 - val_loss: 1.9258 - val_accuracy: 0.5324\n",
      "Epoch 434/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1179 - accuracy: 0.9963 - val_loss: 1.9212 - val_accuracy: 0.5324\n",
      "Epoch 435/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1274 - accuracy: 0.9890 - val_loss: 1.9157 - val_accuracy: 0.5370\n",
      "Epoch 436/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1034 - accuracy: 0.9927 - val_loss: 1.9104 - val_accuracy: 0.5417\n",
      "Epoch 437/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0966 - accuracy: 0.9945 - val_loss: 1.9054 - val_accuracy: 0.5417\n",
      "Epoch 438/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1053 - accuracy: 0.9963 - val_loss: 1.9004 - val_accuracy: 0.5463\n",
      "Epoch 439/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0948 - accuracy: 0.9982 - val_loss: 1.8952 - val_accuracy: 0.5463\n",
      "Epoch 440/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1082 - accuracy: 0.9963 - val_loss: 1.8900 - val_accuracy: 0.5509\n",
      "Epoch 441/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1039 - accuracy: 0.9963 - val_loss: 1.8851 - val_accuracy: 0.5463\n",
      "Epoch 442/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1034 - accuracy: 0.9927 - val_loss: 1.8796 - val_accuracy: 0.5509\n",
      "Epoch 443/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1030 - accuracy: 0.9963 - val_loss: 1.8745 - val_accuracy: 0.5556\n",
      "Epoch 444/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1062 - accuracy: 0.9963 - val_loss: 1.8696 - val_accuracy: 0.5556\n",
      "Epoch 445/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1219 - accuracy: 0.9963 - val_loss: 1.8652 - val_accuracy: 0.5556\n",
      "Epoch 446/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1070 - accuracy: 0.9945 - val_loss: 1.8603 - val_accuracy: 0.5556\n",
      "Epoch 447/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.1040 - accuracy: 0.9963 - val_loss: 1.8557 - val_accuracy: 0.5556\n",
      "Epoch 448/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1059 - accuracy: 0.9982 - val_loss: 1.8511 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1166 - accuracy: 0.9982 - val_loss: 1.8469 - val_accuracy: 0.5556\n",
      "Epoch 450/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1118 - accuracy: 0.9945 - val_loss: 1.8425 - val_accuracy: 0.5556\n",
      "Epoch 451/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1046 - accuracy: 0.9982 - val_loss: 1.8380 - val_accuracy: 0.5556\n",
      "Epoch 452/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1106 - accuracy: 0.9982 - val_loss: 1.8338 - val_accuracy: 0.5556\n",
      "Epoch 453/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.1130 - accuracy: 0.9963 - val_loss: 1.8295 - val_accuracy: 0.5556\n",
      "Epoch 454/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1148 - accuracy: 0.9927 - val_loss: 1.8252 - val_accuracy: 0.5556\n",
      "Epoch 455/1000\n",
      "546/546 [==============================] - 0s 180us/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.5556\n",
      "Epoch 456/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1199 - accuracy: 0.9927 - val_loss: 1.8168 - val_accuracy: 0.5602\n",
      "Epoch 457/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1027 - accuracy: 0.9982 - val_loss: 1.8126 - val_accuracy: 0.5602\n",
      "Epoch 458/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1178 - accuracy: 0.9945 - val_loss: 1.8084 - val_accuracy: 0.5602\n",
      "Epoch 459/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1012 - accuracy: 0.9963 - val_loss: 1.8042 - val_accuracy: 0.5602\n",
      "Epoch 460/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1087 - accuracy: 0.9982 - val_loss: 1.8001 - val_accuracy: 0.5602\n",
      "Epoch 461/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1202 - accuracy: 0.9927 - val_loss: 1.7959 - val_accuracy: 0.5602\n",
      "Epoch 462/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1046 - accuracy: 0.9982 - val_loss: 1.7917 - val_accuracy: 0.5602\n",
      "Epoch 463/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1293 - accuracy: 0.9927 - val_loss: 1.7876 - val_accuracy: 0.5602\n",
      "Epoch 464/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0976 - accuracy: 0.9908 - val_loss: 1.7834 - val_accuracy: 0.5602\n",
      "Epoch 465/1000\n",
      "546/546 [==============================] - 0s 178us/step - loss: 0.1097 - accuracy: 0.9927 - val_loss: 1.7788 - val_accuracy: 0.5648\n",
      "Epoch 466/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1151 - accuracy: 0.9945 - val_loss: 1.7740 - val_accuracy: 0.5694\n",
      "Epoch 467/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1046 - accuracy: 0.9945 - val_loss: 1.7693 - val_accuracy: 0.5741\n",
      "Epoch 468/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 1.7650 - val_accuracy: 0.5741\n",
      "Epoch 469/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0999 - accuracy: 0.9982 - val_loss: 1.7610 - val_accuracy: 0.5741\n",
      "Epoch 470/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0989 - accuracy: 0.9963 - val_loss: 1.7569 - val_accuracy: 0.5741\n",
      "Epoch 471/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0959 - accuracy: 0.9982 - val_loss: 1.7530 - val_accuracy: 0.5741\n",
      "Epoch 472/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.0962 - accuracy: 0.9945 - val_loss: 1.7491 - val_accuracy: 0.5787\n",
      "Epoch 473/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1130 - accuracy: 0.9945 - val_loss: 1.7450 - val_accuracy: 0.5787\n",
      "Epoch 474/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0977 - accuracy: 0.9963 - val_loss: 1.7407 - val_accuracy: 0.5787\n",
      "Epoch 475/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1073 - accuracy: 0.9927 - val_loss: 1.7367 - val_accuracy: 0.5787\n",
      "Epoch 476/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 1.7331 - val_accuracy: 0.5787\n",
      "Epoch 477/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 1.7290 - val_accuracy: 0.5787\n",
      "Epoch 478/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1026 - accuracy: 0.9963 - val_loss: 1.7252 - val_accuracy: 0.5787\n",
      "Epoch 479/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1206 - accuracy: 0.9945 - val_loss: 1.7216 - val_accuracy: 0.5787\n",
      "Epoch 480/1000\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.1084 - accuracy: 0.9982 - val_loss: 1.7176 - val_accuracy: 0.5787\n",
      "Epoch 481/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0918 - accuracy: 0.9963 - val_loss: 1.7135 - val_accuracy: 0.5741\n",
      "Epoch 482/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1102 - accuracy: 0.9908 - val_loss: 1.7096 - val_accuracy: 0.5741\n",
      "Epoch 483/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.5741\n",
      "Epoch 484/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1166 - accuracy: 0.9982 - val_loss: 1.7018 - val_accuracy: 0.5741\n",
      "Epoch 485/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1099 - accuracy: 0.9963 - val_loss: 1.6980 - val_accuracy: 0.5741\n",
      "Epoch 486/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1097 - accuracy: 0.9982 - val_loss: 1.6944 - val_accuracy: 0.5741\n",
      "Epoch 487/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1205 - accuracy: 0.9982 - val_loss: 1.6907 - val_accuracy: 0.5741\n",
      "Epoch 488/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1171 - accuracy: 0.9890 - val_loss: 1.6870 - val_accuracy: 0.5741\n",
      "Epoch 489/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1086 - accuracy: 0.9982 - val_loss: 1.6837 - val_accuracy: 0.5741\n",
      "Epoch 490/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1000 - accuracy: 0.9982 - val_loss: 1.6803 - val_accuracy: 0.5787\n",
      "Epoch 491/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1217 - accuracy: 0.9890 - val_loss: 1.6769 - val_accuracy: 0.5833\n",
      "Epoch 492/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1160 - accuracy: 0.9927 - val_loss: 1.6735 - val_accuracy: 0.5833\n",
      "Epoch 493/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0980 - accuracy: 0.9927 - val_loss: 1.6701 - val_accuracy: 0.5833\n",
      "Epoch 494/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1100 - accuracy: 0.9963 - val_loss: 1.6667 - val_accuracy: 0.5880\n",
      "Epoch 495/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1203 - accuracy: 0.9945 - val_loss: 1.6635 - val_accuracy: 0.5880\n",
      "Epoch 496/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1044 - accuracy: 0.9945 - val_loss: 1.6605 - val_accuracy: 0.5880\n",
      "Epoch 497/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1143 - accuracy: 0.9982 - val_loss: 1.6576 - val_accuracy: 0.5880\n",
      "Epoch 498/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1021 - accuracy: 0.9963 - val_loss: 1.6546 - val_accuracy: 0.5880\n",
      "Epoch 499/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0913 - accuracy: 0.9982 - val_loss: 1.6516 - val_accuracy: 0.5880\n",
      "Epoch 500/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0930 - accuracy: 0.9963 - val_loss: 1.6485 - val_accuracy: 0.5880\n",
      "Epoch 501/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1445 - accuracy: 0.9890 - val_loss: 1.6453 - val_accuracy: 0.5880\n",
      "Epoch 502/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1096 - accuracy: 0.9963 - val_loss: 1.6422 - val_accuracy: 0.5926\n",
      "Epoch 503/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1064 - accuracy: 0.9982 - val_loss: 1.6392 - val_accuracy: 0.5926\n",
      "Epoch 504/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1082 - accuracy: 0.9927 - val_loss: 1.6360 - val_accuracy: 0.5972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0921 - accuracy: 0.9982 - val_loss: 1.6330 - val_accuracy: 0.5972\n",
      "Epoch 506/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0956 - accuracy: 0.9982 - val_loss: 1.6300 - val_accuracy: 0.5972\n",
      "Epoch 507/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1149 - accuracy: 0.9963 - val_loss: 1.6270 - val_accuracy: 0.5972\n",
      "Epoch 508/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1069 - accuracy: 0.9945 - val_loss: 1.6238 - val_accuracy: 0.5972\n",
      "Epoch 509/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1080 - accuracy: 0.9982 - val_loss: 1.6207 - val_accuracy: 0.5972\n",
      "Epoch 510/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.6178 - val_accuracy: 0.6019\n",
      "Epoch 511/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1141 - accuracy: 0.9927 - val_loss: 1.6150 - val_accuracy: 0.6019\n",
      "Epoch 512/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0994 - accuracy: 0.9963 - val_loss: 1.6122 - val_accuracy: 0.6019\n",
      "Epoch 513/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 1.6093 - val_accuracy: 0.6019\n",
      "Epoch 514/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1116 - accuracy: 0.9927 - val_loss: 1.6067 - val_accuracy: 0.6019\n",
      "Epoch 515/1000\n",
      "546/546 [==============================] - 0s 189us/step - loss: 0.0987 - accuracy: 0.9963 - val_loss: 1.6043 - val_accuracy: 0.6019\n",
      "Epoch 516/1000\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1270 - accuracy: 0.9945 - val_loss: 1.6018 - val_accuracy: 0.6019\n",
      "Epoch 517/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1158 - accuracy: 0.9982 - val_loss: 1.5994 - val_accuracy: 0.6019\n",
      "Epoch 518/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1041 - accuracy: 0.9945 - val_loss: 1.5967 - val_accuracy: 0.6019\n",
      "Epoch 519/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1150 - accuracy: 0.9945 - val_loss: 1.5941 - val_accuracy: 0.6019\n",
      "Epoch 520/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1073 - accuracy: 0.9927 - val_loss: 1.5914 - val_accuracy: 0.6019\n",
      "Epoch 521/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1074 - accuracy: 0.9963 - val_loss: 1.5888 - val_accuracy: 0.6019\n",
      "Epoch 522/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1117 - accuracy: 0.9963 - val_loss: 1.5864 - val_accuracy: 0.6019\n",
      "Epoch 523/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1091 - accuracy: 0.9963 - val_loss: 1.5841 - val_accuracy: 0.6019\n",
      "Epoch 524/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1105 - accuracy: 0.9908 - val_loss: 1.5820 - val_accuracy: 0.6019\n",
      "Epoch 525/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1043 - accuracy: 0.9963 - val_loss: 1.5799 - val_accuracy: 0.6019\n",
      "Epoch 526/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1019 - accuracy: 0.9945 - val_loss: 1.5774 - val_accuracy: 0.6019\n",
      "Epoch 527/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1064 - accuracy: 0.9963 - val_loss: 1.5752 - val_accuracy: 0.6019\n",
      "Epoch 528/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1265 - accuracy: 0.9890 - val_loss: 1.5731 - val_accuracy: 0.5972\n",
      "Epoch 529/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1183 - accuracy: 0.9927 - val_loss: 1.5712 - val_accuracy: 0.5972\n",
      "Epoch 530/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1151 - accuracy: 0.9945 - val_loss: 1.5691 - val_accuracy: 0.5972\n",
      "Epoch 531/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0948 - accuracy: 0.9963 - val_loss: 1.5675 - val_accuracy: 0.5972\n",
      "Epoch 532/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1176 - accuracy: 0.9963 - val_loss: 1.5656 - val_accuracy: 0.5972\n",
      "Epoch 533/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 1.5636 - val_accuracy: 0.5972\n",
      "Epoch 534/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1146 - accuracy: 0.9963 - val_loss: 1.5618 - val_accuracy: 0.5972\n",
      "Epoch 535/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1109 - accuracy: 0.9908 - val_loss: 1.5601 - val_accuracy: 0.5972\n",
      "Epoch 536/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1033 - accuracy: 0.9945 - val_loss: 1.5583 - val_accuracy: 0.5972\n",
      "Epoch 537/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1070 - accuracy: 0.9982 - val_loss: 1.5567 - val_accuracy: 0.5972\n",
      "Epoch 538/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1015 - accuracy: 0.9963 - val_loss: 1.5553 - val_accuracy: 0.5972\n",
      "Epoch 539/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1122 - accuracy: 0.9945 - val_loss: 1.5537 - val_accuracy: 0.5972\n",
      "Epoch 540/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.5518 - val_accuracy: 0.5972\n",
      "Epoch 541/1000\n",
      "546/546 [==============================] - 0s 178us/step - loss: 0.1186 - accuracy: 0.9890 - val_loss: 1.5502 - val_accuracy: 0.5972\n",
      "Epoch 542/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1200 - accuracy: 0.9982 - val_loss: 1.5482 - val_accuracy: 0.5972\n",
      "Epoch 543/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1157 - accuracy: 0.9982 - val_loss: 1.5464 - val_accuracy: 0.5972\n",
      "Epoch 544/1000\n",
      "546/546 [==============================] - 0s 182us/step - loss: 0.1141 - accuracy: 0.9963 - val_loss: 1.5443 - val_accuracy: 0.5972\n",
      "Epoch 545/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1054 - accuracy: 0.9945 - val_loss: 1.5426 - val_accuracy: 0.5972\n",
      "Epoch 546/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1047 - accuracy: 0.9963 - val_loss: 1.5410 - val_accuracy: 0.5972\n",
      "Epoch 547/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0936 - accuracy: 0.9963 - val_loss: 1.5393 - val_accuracy: 0.5972\n",
      "Epoch 548/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0994 - accuracy: 0.9982 - val_loss: 1.5377 - val_accuracy: 0.5972\n",
      "Epoch 549/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1062 - accuracy: 0.9982 - val_loss: 1.5360 - val_accuracy: 0.5972\n",
      "Epoch 550/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1041 - accuracy: 0.9963 - val_loss: 1.5342 - val_accuracy: 0.5972\n",
      "Epoch 551/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1201 - accuracy: 0.9908 - val_loss: 1.5325 - val_accuracy: 0.5972\n",
      "Epoch 552/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1107 - accuracy: 0.9982 - val_loss: 1.5307 - val_accuracy: 0.5972\n",
      "Epoch 553/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1159 - accuracy: 0.9945 - val_loss: 1.5291 - val_accuracy: 0.6019\n",
      "Epoch 554/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1052 - accuracy: 0.9963 - val_loss: 1.5274 - val_accuracy: 0.5972\n",
      "Epoch 555/1000\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.1204 - accuracy: 0.9927 - val_loss: 1.5258 - val_accuracy: 0.5972\n",
      "Epoch 556/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1021 - accuracy: 0.9982 - val_loss: 1.5238 - val_accuracy: 0.6065\n",
      "Epoch 557/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1291 - accuracy: 0.9908 - val_loss: 1.5223 - val_accuracy: 0.6065\n",
      "Epoch 558/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0917 - accuracy: 0.9982 - val_loss: 1.5208 - val_accuracy: 0.6065\n",
      "Epoch 559/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0971 - accuracy: 0.9982 - val_loss: 1.5190 - val_accuracy: 0.6065\n",
      "Epoch 560/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1143 - accuracy: 0.9945 - val_loss: 1.5173 - val_accuracy: 0.6065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1202 - accuracy: 0.9927 - val_loss: 1.5158 - val_accuracy: 0.6111\n",
      "Epoch 562/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1073 - accuracy: 0.9945 - val_loss: 1.5141 - val_accuracy: 0.6111\n",
      "Epoch 563/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0896 - accuracy: 0.9945 - val_loss: 1.5125 - val_accuracy: 0.6157\n",
      "Epoch 564/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0827 - accuracy: 0.9963 - val_loss: 1.5110 - val_accuracy: 0.6204\n",
      "Epoch 565/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 1.5094 - val_accuracy: 0.6204\n",
      "Epoch 566/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1168 - accuracy: 0.9963 - val_loss: 1.5081 - val_accuracy: 0.6204\n",
      "Epoch 567/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1153 - accuracy: 0.9945 - val_loss: 1.5068 - val_accuracy: 0.6204\n",
      "Epoch 568/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1133 - accuracy: 0.9945 - val_loss: 1.5055 - val_accuracy: 0.6204\n",
      "Epoch 569/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0945 - accuracy: 0.9945 - val_loss: 1.5043 - val_accuracy: 0.6204\n",
      "Epoch 570/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1022 - accuracy: 0.9982 - val_loss: 1.5031 - val_accuracy: 0.6250\n",
      "Epoch 571/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.1267 - accuracy: 0.9908 - val_loss: 1.5017 - val_accuracy: 0.6250\n",
      "Epoch 572/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1049 - accuracy: 0.9963 - val_loss: 1.5006 - val_accuracy: 0.6250\n",
      "Epoch 573/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0924 - accuracy: 0.9945 - val_loss: 1.4992 - val_accuracy: 0.6204\n",
      "Epoch 574/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0962 - accuracy: 0.9963 - val_loss: 1.4981 - val_accuracy: 0.6204\n",
      "Epoch 575/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 1.4968 - val_accuracy: 0.6204\n",
      "Epoch 576/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1038 - accuracy: 0.9963 - val_loss: 1.4954 - val_accuracy: 0.6204\n",
      "Epoch 577/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1146 - accuracy: 0.9945 - val_loss: 1.4939 - val_accuracy: 0.6204\n",
      "Epoch 578/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1106 - accuracy: 0.9927 - val_loss: 1.4926 - val_accuracy: 0.6204\n",
      "Epoch 579/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1068 - accuracy: 0.9982 - val_loss: 1.4913 - val_accuracy: 0.6204\n",
      "Epoch 580/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.1285 - accuracy: 0.9927 - val_loss: 1.4901 - val_accuracy: 0.6204\n",
      "Epoch 581/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1026 - accuracy: 0.9945 - val_loss: 1.4888 - val_accuracy: 0.6204\n",
      "Epoch 582/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1073 - accuracy: 0.9908 - val_loss: 1.4874 - val_accuracy: 0.6204\n",
      "Epoch 583/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0963 - accuracy: 0.9982 - val_loss: 1.4859 - val_accuracy: 0.6204\n",
      "Epoch 584/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.6204\n",
      "Epoch 585/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1139 - accuracy: 0.9908 - val_loss: 1.4831 - val_accuracy: 0.6204\n",
      "Epoch 586/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1257 - accuracy: 0.9963 - val_loss: 1.4814 - val_accuracy: 0.6204\n",
      "Epoch 587/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1214 - accuracy: 0.9945 - val_loss: 1.4802 - val_accuracy: 0.6204\n",
      "Epoch 588/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0969 - accuracy: 0.9963 - val_loss: 1.4791 - val_accuracy: 0.6204\n",
      "Epoch 589/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.4779 - val_accuracy: 0.6204\n",
      "Epoch 590/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1231 - accuracy: 0.9872 - val_loss: 1.4767 - val_accuracy: 0.6204\n",
      "Epoch 591/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1194 - accuracy: 0.9963 - val_loss: 1.4753 - val_accuracy: 0.6204\n",
      "Epoch 592/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1309 - accuracy: 0.9982 - val_loss: 1.4741 - val_accuracy: 0.6204\n",
      "Epoch 593/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1007 - accuracy: 0.9963 - val_loss: 1.4727 - val_accuracy: 0.6204\n",
      "Epoch 594/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0935 - accuracy: 0.9982 - val_loss: 1.4715 - val_accuracy: 0.6204\n",
      "Epoch 595/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0983 - accuracy: 0.9963 - val_loss: 1.4702 - val_accuracy: 0.6204\n",
      "Epoch 596/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1257 - accuracy: 0.9927 - val_loss: 1.4690 - val_accuracy: 0.6204\n",
      "Epoch 597/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1195 - accuracy: 0.9908 - val_loss: 1.4678 - val_accuracy: 0.6250\n",
      "Epoch 598/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1166 - accuracy: 0.9982 - val_loss: 1.4664 - val_accuracy: 0.6250\n",
      "Epoch 599/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1093 - accuracy: 0.9963 - val_loss: 1.4652 - val_accuracy: 0.6250\n",
      "Epoch 600/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0991 - accuracy: 0.9945 - val_loss: 1.4641 - val_accuracy: 0.6296\n",
      "Epoch 601/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0999 - accuracy: 0.9945 - val_loss: 1.4628 - val_accuracy: 0.6296\n",
      "Epoch 602/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1006 - accuracy: 0.9927 - val_loss: 1.4616 - val_accuracy: 0.6296\n",
      "Epoch 603/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0996 - accuracy: 0.9963 - val_loss: 1.4604 - val_accuracy: 0.6296\n",
      "Epoch 604/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 1.4593 - val_accuracy: 0.6296\n",
      "Epoch 605/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1026 - accuracy: 0.9945 - val_loss: 1.4581 - val_accuracy: 0.6296\n",
      "Epoch 606/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1074 - accuracy: 0.9908 - val_loss: 1.4572 - val_accuracy: 0.6296\n",
      "Epoch 607/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1219 - accuracy: 0.9908 - val_loss: 1.4564 - val_accuracy: 0.6250\n",
      "Epoch 608/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0966 - accuracy: 0.9982 - val_loss: 1.4552 - val_accuracy: 0.6250\n",
      "Epoch 609/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1048 - accuracy: 0.9963 - val_loss: 1.4541 - val_accuracy: 0.6296\n",
      "Epoch 610/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1033 - accuracy: 0.9982 - val_loss: 1.4529 - val_accuracy: 0.6296\n",
      "Epoch 611/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1110 - accuracy: 0.9927 - val_loss: 1.4519 - val_accuracy: 0.6296\n",
      "Epoch 612/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0985 - accuracy: 0.9945 - val_loss: 1.4509 - val_accuracy: 0.6296\n",
      "Epoch 613/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 1.4498 - val_accuracy: 0.6296\n",
      "Epoch 614/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1240 - accuracy: 0.9927 - val_loss: 1.4491 - val_accuracy: 0.6296\n",
      "Epoch 615/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0887 - accuracy: 0.9963 - val_loss: 1.4482 - val_accuracy: 0.6296\n",
      "Epoch 616/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1162 - accuracy: 0.9963 - val_loss: 1.4472 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1028 - accuracy: 0.9982 - val_loss: 1.4464 - val_accuracy: 0.6296\n",
      "Epoch 618/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1043 - accuracy: 0.9945 - val_loss: 1.4456 - val_accuracy: 0.6296\n",
      "Epoch 619/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1230 - accuracy: 0.9963 - val_loss: 1.4449 - val_accuracy: 0.6296\n",
      "Epoch 620/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1173 - accuracy: 0.9963 - val_loss: 1.4439 - val_accuracy: 0.6343\n",
      "Epoch 621/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0899 - accuracy: 0.9963 - val_loss: 1.4431 - val_accuracy: 0.6343\n",
      "Epoch 622/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1332 - accuracy: 0.9927 - val_loss: 1.4423 - val_accuracy: 0.6343\n",
      "Epoch 623/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1021 - accuracy: 0.9982 - val_loss: 1.4415 - val_accuracy: 0.6343\n",
      "Epoch 624/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1043 - accuracy: 0.9927 - val_loss: 1.4408 - val_accuracy: 0.6343\n",
      "Epoch 625/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1008 - accuracy: 0.9963 - val_loss: 1.4400 - val_accuracy: 0.6343\n",
      "Epoch 626/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0992 - accuracy: 0.9982 - val_loss: 1.4394 - val_accuracy: 0.6343\n",
      "Epoch 627/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1070 - accuracy: 0.9890 - val_loss: 1.4388 - val_accuracy: 0.6343\n",
      "Epoch 628/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.6343\n",
      "Epoch 629/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0928 - accuracy: 0.9982 - val_loss: 1.4372 - val_accuracy: 0.6343\n",
      "Epoch 630/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1045 - accuracy: 0.9963 - val_loss: 1.4368 - val_accuracy: 0.6343\n",
      "Epoch 631/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1071 - accuracy: 0.9945 - val_loss: 1.4361 - val_accuracy: 0.6343\n",
      "Epoch 632/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1156 - accuracy: 0.9927 - val_loss: 1.4355 - val_accuracy: 0.6343\n",
      "Epoch 633/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1111 - accuracy: 0.9963 - val_loss: 1.4349 - val_accuracy: 0.6343\n",
      "Epoch 634/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0944 - accuracy: 0.9982 - val_loss: 1.4342 - val_accuracy: 0.6343\n",
      "Epoch 635/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0999 - accuracy: 0.9963 - val_loss: 1.4336 - val_accuracy: 0.6343\n",
      "Epoch 636/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1080 - accuracy: 0.9982 - val_loss: 1.4331 - val_accuracy: 0.6343\n",
      "Epoch 637/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1164 - accuracy: 0.9890 - val_loss: 1.4327 - val_accuracy: 0.6343\n",
      "Epoch 638/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1145 - accuracy: 0.9927 - val_loss: 1.4321 - val_accuracy: 0.6343\n",
      "Epoch 639/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1134 - accuracy: 0.9927 - val_loss: 1.4317 - val_accuracy: 0.6343\n",
      "Epoch 640/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1100 - accuracy: 0.9982 - val_loss: 1.4313 - val_accuracy: 0.6343\n",
      "Epoch 641/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0945 - accuracy: 0.9982 - val_loss: 1.4308 - val_accuracy: 0.6343\n",
      "Epoch 642/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 1.4303 - val_accuracy: 0.6343\n",
      "Epoch 643/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1112 - accuracy: 0.9945 - val_loss: 1.4297 - val_accuracy: 0.6343\n",
      "Epoch 644/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 1.4295 - val_accuracy: 0.6343\n",
      "Epoch 645/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.4292 - val_accuracy: 0.6343\n",
      "Epoch 646/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1139 - accuracy: 0.9963 - val_loss: 1.4288 - val_accuracy: 0.6343\n",
      "Epoch 647/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1226 - accuracy: 0.9963 - val_loss: 1.4286 - val_accuracy: 0.6343\n",
      "Epoch 648/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1211 - accuracy: 0.9908 - val_loss: 1.4283 - val_accuracy: 0.6343\n",
      "Epoch 649/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0866 - accuracy: 0.9982 - val_loss: 1.4277 - val_accuracy: 0.6343\n",
      "Epoch 650/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1024 - accuracy: 0.9982 - val_loss: 1.4274 - val_accuracy: 0.6343\n",
      "Epoch 651/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0965 - accuracy: 0.9982 - val_loss: 1.4269 - val_accuracy: 0.6343\n",
      "Epoch 652/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1110 - accuracy: 0.9908 - val_loss: 1.4263 - val_accuracy: 0.6343\n",
      "Epoch 653/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1073 - accuracy: 0.9945 - val_loss: 1.4256 - val_accuracy: 0.6343\n",
      "Epoch 654/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1125 - accuracy: 0.9927 - val_loss: 1.4248 - val_accuracy: 0.6343\n",
      "Epoch 655/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1126 - accuracy: 0.9963 - val_loss: 1.4243 - val_accuracy: 0.6296\n",
      "Epoch 656/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1195 - accuracy: 0.9890 - val_loss: 1.4237 - val_accuracy: 0.6296\n",
      "Epoch 657/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1137 - accuracy: 0.9945 - val_loss: 1.4231 - val_accuracy: 0.6343\n",
      "Epoch 658/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1190 - accuracy: 0.9908 - val_loss: 1.4226 - val_accuracy: 0.6343\n",
      "Epoch 659/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0897 - accuracy: 0.9982 - val_loss: 1.4221 - val_accuracy: 0.6343\n",
      "Epoch 660/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1096 - accuracy: 0.9982 - val_loss: 1.4217 - val_accuracy: 0.6343\n",
      "Epoch 661/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0993 - accuracy: 0.9982 - val_loss: 1.4213 - val_accuracy: 0.6343\n",
      "Epoch 662/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1181 - accuracy: 0.9927 - val_loss: 1.4208 - val_accuracy: 0.6343\n",
      "Epoch 663/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0975 - accuracy: 0.9982 - val_loss: 1.4207 - val_accuracy: 0.6343\n",
      "Epoch 664/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1024 - accuracy: 0.9945 - val_loss: 1.4203 - val_accuracy: 0.6343\n",
      "Epoch 665/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 1.4201 - val_accuracy: 0.6343\n",
      "Epoch 666/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1007 - accuracy: 0.9945 - val_loss: 1.4197 - val_accuracy: 0.6343\n",
      "Epoch 667/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1129 - accuracy: 0.9908 - val_loss: 1.4194 - val_accuracy: 0.6343\n",
      "Epoch 668/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1451 - accuracy: 0.9817 - val_loss: 1.4193 - val_accuracy: 0.6343\n",
      "Epoch 669/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.6343\n",
      "Epoch 670/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1011 - accuracy: 0.9927 - val_loss: 1.4186 - val_accuracy: 0.6343\n",
      "Epoch 671/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 1.4184 - val_accuracy: 0.6343\n",
      "Epoch 672/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0843 - accuracy: 0.9982 - val_loss: 1.4180 - val_accuracy: 0.6343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0951 - accuracy: 0.9963 - val_loss: 1.4177 - val_accuracy: 0.6343\n",
      "Epoch 674/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1110 - accuracy: 0.9982 - val_loss: 1.4174 - val_accuracy: 0.6296\n",
      "Epoch 675/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1172 - accuracy: 0.9908 - val_loss: 1.4171 - val_accuracy: 0.6296\n",
      "Epoch 676/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1052 - accuracy: 0.9908 - val_loss: 1.4168 - val_accuracy: 0.6296\n",
      "Epoch 677/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1036 - accuracy: 0.9963 - val_loss: 1.4162 - val_accuracy: 0.6296\n",
      "Epoch 678/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1130 - accuracy: 0.9927 - val_loss: 1.4158 - val_accuracy: 0.6296\n",
      "Epoch 679/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1054 - accuracy: 0.9963 - val_loss: 1.4154 - val_accuracy: 0.6296\n",
      "Epoch 680/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1112 - accuracy: 0.9890 - val_loss: 1.4149 - val_accuracy: 0.6296\n",
      "Epoch 681/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0956 - accuracy: 0.9982 - val_loss: 1.4145 - val_accuracy: 0.6296\n",
      "Epoch 682/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0999 - accuracy: 0.9927 - val_loss: 1.4141 - val_accuracy: 0.6296\n",
      "Epoch 683/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0994 - accuracy: 0.9945 - val_loss: 1.4135 - val_accuracy: 0.6296\n",
      "Epoch 684/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.4129 - val_accuracy: 0.6296\n",
      "Epoch 685/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0947 - accuracy: 0.9945 - val_loss: 1.4125 - val_accuracy: 0.6296\n",
      "Epoch 686/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1042 - accuracy: 0.9927 - val_loss: 1.4120 - val_accuracy: 0.6343\n",
      "Epoch 687/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1058 - accuracy: 0.9927 - val_loss: 1.4114 - val_accuracy: 0.6389\n",
      "Epoch 688/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1137 - accuracy: 0.9963 - val_loss: 1.4109 - val_accuracy: 0.6389\n",
      "Epoch 689/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.6389\n",
      "Epoch 690/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 1.4099 - val_accuracy: 0.6389\n",
      "Epoch 691/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0839 - accuracy: 0.9982 - val_loss: 1.4095 - val_accuracy: 0.6389\n",
      "Epoch 692/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1124 - accuracy: 0.9982 - val_loss: 1.4089 - val_accuracy: 0.6389\n",
      "Epoch 693/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1077 - accuracy: 0.9908 - val_loss: 1.4083 - val_accuracy: 0.6389\n",
      "Epoch 694/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.6389\n",
      "Epoch 695/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 1.4072 - val_accuracy: 0.6389\n",
      "Epoch 696/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1023 - accuracy: 0.9963 - val_loss: 1.4066 - val_accuracy: 0.6389\n",
      "Epoch 697/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1086 - accuracy: 0.9982 - val_loss: 1.4059 - val_accuracy: 0.6389\n",
      "Epoch 698/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0891 - accuracy: 0.9982 - val_loss: 1.4052 - val_accuracy: 0.6389\n",
      "Epoch 699/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1105 - accuracy: 0.9963 - val_loss: 1.4045 - val_accuracy: 0.6389\n",
      "Epoch 700/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.6389\n",
      "Epoch 701/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1063 - accuracy: 0.9927 - val_loss: 1.4035 - val_accuracy: 0.6389\n",
      "Epoch 702/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1040 - accuracy: 0.9945 - val_loss: 1.4031 - val_accuracy: 0.6389\n",
      "Epoch 703/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1122 - accuracy: 0.9945 - val_loss: 1.4027 - val_accuracy: 0.6343\n",
      "Epoch 704/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1021 - accuracy: 0.9982 - val_loss: 1.4023 - val_accuracy: 0.6343\n",
      "Epoch 705/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1216 - accuracy: 0.9945 - val_loss: 1.4019 - val_accuracy: 0.6389\n",
      "Epoch 706/1000\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1139 - accuracy: 0.9945 - val_loss: 1.4014 - val_accuracy: 0.6389\n",
      "Epoch 707/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1051 - accuracy: 0.9963 - val_loss: 1.4009 - val_accuracy: 0.6389\n",
      "Epoch 708/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1081 - accuracy: 0.9963 - val_loss: 1.4004 - val_accuracy: 0.6389\n",
      "Epoch 709/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0962 - accuracy: 0.9982 - val_loss: 1.3999 - val_accuracy: 0.6389\n",
      "Epoch 710/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1035 - accuracy: 0.9945 - val_loss: 1.3997 - val_accuracy: 0.6389\n",
      "Epoch 711/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0969 - accuracy: 0.9982 - val_loss: 1.3992 - val_accuracy: 0.6389\n",
      "Epoch 712/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0927 - accuracy: 0.9963 - val_loss: 1.3988 - val_accuracy: 0.6435\n",
      "Epoch 713/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0806 - accuracy: 0.9982 - val_loss: 1.3984 - val_accuracy: 0.6435\n",
      "Epoch 714/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0890 - accuracy: 0.9945 - val_loss: 1.3980 - val_accuracy: 0.6435\n",
      "Epoch 715/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1135 - accuracy: 0.9927 - val_loss: 1.3979 - val_accuracy: 0.6435\n",
      "Epoch 716/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0958 - accuracy: 0.9982 - val_loss: 1.3977 - val_accuracy: 0.6435\n",
      "Epoch 717/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0890 - accuracy: 0.9963 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 718/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 1.3973 - val_accuracy: 0.6435\n",
      "Epoch 719/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0825 - accuracy: 0.9982 - val_loss: 1.3972 - val_accuracy: 0.6435\n",
      "Epoch 720/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1059 - accuracy: 0.9927 - val_loss: 1.3971 - val_accuracy: 0.6435\n",
      "Epoch 721/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1121 - accuracy: 0.9982 - val_loss: 1.3968 - val_accuracy: 0.6435\n",
      "Epoch 722/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0987 - accuracy: 0.9982 - val_loss: 1.3965 - val_accuracy: 0.6481\n",
      "Epoch 723/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1230 - accuracy: 0.9927 - val_loss: 1.3964 - val_accuracy: 0.6481\n",
      "Epoch 724/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1045 - accuracy: 0.9945 - val_loss: 1.3962 - val_accuracy: 0.6481\n",
      "Epoch 725/1000\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.1082 - accuracy: 0.9963 - val_loss: 1.3961 - val_accuracy: 0.6481\n",
      "Epoch 726/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1080 - accuracy: 0.9982 - val_loss: 1.3958 - val_accuracy: 0.6481\n",
      "Epoch 727/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0991 - accuracy: 0.9982 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 728/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1035 - accuracy: 0.9945 - val_loss: 1.3953 - val_accuracy: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0844 - accuracy: 0.9982 - val_loss: 1.3949 - val_accuracy: 0.6481\n",
      "Epoch 730/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1150 - accuracy: 0.9963 - val_loss: 1.3947 - val_accuracy: 0.6481\n",
      "Epoch 731/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1185 - accuracy: 0.9963 - val_loss: 1.3944 - val_accuracy: 0.6481\n",
      "Epoch 732/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0895 - accuracy: 0.9945 - val_loss: 1.3942 - val_accuracy: 0.6481\n",
      "Epoch 733/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0886 - accuracy: 0.9982 - val_loss: 1.3941 - val_accuracy: 0.6481\n",
      "Epoch 734/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0976 - accuracy: 0.9963 - val_loss: 1.3940 - val_accuracy: 0.6481\n",
      "Epoch 735/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0906 - accuracy: 0.9982 - val_loss: 1.3937 - val_accuracy: 0.6435\n",
      "Epoch 736/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1152 - accuracy: 0.9982 - val_loss: 1.3936 - val_accuracy: 0.6435\n",
      "Epoch 737/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1091 - accuracy: 0.9982 - val_loss: 1.3936 - val_accuracy: 0.6435\n",
      "Epoch 738/1000\n",
      "546/546 [==============================] - 0s 180us/step - loss: 0.0997 - accuracy: 0.9927 - val_loss: 1.3935 - val_accuracy: 0.6435\n",
      "Epoch 739/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0899 - accuracy: 0.9963 - val_loss: 1.3933 - val_accuracy: 0.6435\n",
      "Epoch 740/1000\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.1189 - accuracy: 0.9908 - val_loss: 1.3930 - val_accuracy: 0.6435\n",
      "Epoch 741/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1212 - accuracy: 0.9927 - val_loss: 1.3930 - val_accuracy: 0.6435\n",
      "Epoch 742/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.6435\n",
      "Epoch 743/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1037 - accuracy: 0.9963 - val_loss: 1.3929 - val_accuracy: 0.6435\n",
      "Epoch 744/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1004 - accuracy: 0.9963 - val_loss: 1.3930 - val_accuracy: 0.6435\n",
      "Epoch 745/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0977 - accuracy: 0.9963 - val_loss: 1.3928 - val_accuracy: 0.6435\n",
      "Epoch 746/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1020 - accuracy: 0.9945 - val_loss: 1.3930 - val_accuracy: 0.6435\n",
      "Epoch 747/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1055 - accuracy: 0.9963 - val_loss: 1.3931 - val_accuracy: 0.6435\n",
      "Epoch 748/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 1.3934 - val_accuracy: 0.6435\n",
      "Epoch 749/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0915 - accuracy: 0.9963 - val_loss: 1.3937 - val_accuracy: 0.6435\n",
      "Epoch 750/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1080 - accuracy: 0.9908 - val_loss: 1.3938 - val_accuracy: 0.6435\n",
      "Epoch 751/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0834 - accuracy: 0.9982 - val_loss: 1.3942 - val_accuracy: 0.6435\n",
      "Epoch 752/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0946 - accuracy: 0.9963 - val_loss: 1.3943 - val_accuracy: 0.6481\n",
      "Epoch 753/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0986 - accuracy: 0.9982 - val_loss: 1.3944 - val_accuracy: 0.6481\n",
      "Epoch 754/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1043 - accuracy: 0.9963 - val_loss: 1.3942 - val_accuracy: 0.6481\n",
      "Epoch 755/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1018 - accuracy: 0.9927 - val_loss: 1.3946 - val_accuracy: 0.6481\n",
      "Epoch 756/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0927 - accuracy: 0.9963 - val_loss: 1.3947 - val_accuracy: 0.6481\n",
      "Epoch 757/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0927 - accuracy: 0.9982 - val_loss: 1.3948 - val_accuracy: 0.6481\n",
      "Epoch 758/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1208 - accuracy: 0.9890 - val_loss: 1.3951 - val_accuracy: 0.6481\n",
      "Epoch 759/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1064 - accuracy: 0.9963 - val_loss: 1.3952 - val_accuracy: 0.6435\n",
      "Epoch 760/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.6435\n",
      "Epoch 761/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0990 - accuracy: 0.9963 - val_loss: 1.3957 - val_accuracy: 0.6435\n",
      "Epoch 762/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0949 - accuracy: 0.9982 - val_loss: 1.3958 - val_accuracy: 0.6435\n",
      "Epoch 763/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0958 - accuracy: 0.9982 - val_loss: 1.3960 - val_accuracy: 0.6435\n",
      "Epoch 764/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1050 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 765/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0985 - accuracy: 0.9982 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 766/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0958 - accuracy: 0.9982 - val_loss: 1.3964 - val_accuracy: 0.6435\n",
      "Epoch 767/1000\n",
      "546/546 [==============================] - 0s 178us/step - loss: 0.1092 - accuracy: 0.9963 - val_loss: 1.3966 - val_accuracy: 0.6435\n",
      "Epoch 768/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0970 - accuracy: 0.9963 - val_loss: 1.3966 - val_accuracy: 0.6435\n",
      "Epoch 769/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1013 - accuracy: 0.9945 - val_loss: 1.3968 - val_accuracy: 0.6435\n",
      "Epoch 770/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0952 - accuracy: 0.9963 - val_loss: 1.3972 - val_accuracy: 0.6435\n",
      "Epoch 771/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0951 - accuracy: 0.9963 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 772/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 1.3975 - val_accuracy: 0.6435\n",
      "Epoch 773/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0846 - accuracy: 0.9982 - val_loss: 1.3977 - val_accuracy: 0.6435\n",
      "Epoch 774/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1060 - accuracy: 0.9908 - val_loss: 1.3978 - val_accuracy: 0.6435\n",
      "Epoch 775/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1022 - accuracy: 0.9945 - val_loss: 1.3978 - val_accuracy: 0.6435\n",
      "Epoch 776/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1032 - accuracy: 0.9945 - val_loss: 1.3980 - val_accuracy: 0.6435\n",
      "Epoch 777/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1008 - accuracy: 0.9982 - val_loss: 1.3980 - val_accuracy: 0.6435\n",
      "Epoch 778/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.6435\n",
      "Epoch 779/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0875 - accuracy: 0.9982 - val_loss: 1.3977 - val_accuracy: 0.6435\n",
      "Epoch 780/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1032 - accuracy: 0.9945 - val_loss: 1.3975 - val_accuracy: 0.6435\n",
      "Epoch 781/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0991 - accuracy: 0.9982 - val_loss: 1.3972 - val_accuracy: 0.6435\n",
      "Epoch 782/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0951 - accuracy: 0.9982 - val_loss: 1.3970 - val_accuracy: 0.6435\n",
      "Epoch 783/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0939 - accuracy: 0.9982 - val_loss: 1.3971 - val_accuracy: 0.6435\n",
      "Epoch 784/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1084 - accuracy: 0.9963 - val_loss: 1.3971 - val_accuracy: 0.6435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1007 - accuracy: 0.9982 - val_loss: 1.3972 - val_accuracy: 0.6435\n",
      "Epoch 786/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.3971 - val_accuracy: 0.6435\n",
      "Epoch 787/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0919 - accuracy: 0.9927 - val_loss: 1.3968 - val_accuracy: 0.6435\n",
      "Epoch 788/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1029 - accuracy: 0.9982 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 789/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1177 - accuracy: 0.9890 - val_loss: 1.3966 - val_accuracy: 0.6435\n",
      "Epoch 790/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0838 - accuracy: 0.9982 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 791/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1073 - accuracy: 0.9982 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 792/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1061 - accuracy: 0.9908 - val_loss: 1.3968 - val_accuracy: 0.6435\n",
      "Epoch 793/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1077 - accuracy: 0.9927 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 794/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1039 - accuracy: 0.9927 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 795/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1047 - accuracy: 0.9982 - val_loss: 1.3967 - val_accuracy: 0.6435\n",
      "Epoch 796/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1073 - accuracy: 0.9927 - val_loss: 1.3965 - val_accuracy: 0.6435\n",
      "Epoch 797/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1110 - accuracy: 0.9945 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 798/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 799/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.3964 - val_accuracy: 0.6435\n",
      "Epoch 800/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1118 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 801/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1181 - accuracy: 0.9908 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 802/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1145 - accuracy: 0.9908 - val_loss: 1.3963 - val_accuracy: 0.6435\n",
      "Epoch 803/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0984 - accuracy: 0.9963 - val_loss: 1.3964 - val_accuracy: 0.6435\n",
      "Epoch 804/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0857 - accuracy: 0.9982 - val_loss: 1.3964 - val_accuracy: 0.6481\n",
      "Epoch 805/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1051 - accuracy: 0.9945 - val_loss: 1.3963 - val_accuracy: 0.6481\n",
      "Epoch 806/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1164 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6481\n",
      "Epoch 807/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0806 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6481\n",
      "Epoch 808/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1130 - accuracy: 0.9963 - val_loss: 1.3962 - val_accuracy: 0.6481\n",
      "Epoch 809/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1039 - accuracy: 0.9982 - val_loss: 1.3961 - val_accuracy: 0.6481\n",
      "Epoch 810/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0938 - accuracy: 0.9963 - val_loss: 1.3960 - val_accuracy: 0.6481\n",
      "Epoch 811/1000\n",
      "546/546 [==============================] - 0s 179us/step - loss: 0.1026 - accuracy: 0.9982 - val_loss: 1.3960 - val_accuracy: 0.6481\n",
      "Epoch 812/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1134 - accuracy: 0.9963 - val_loss: 1.3958 - val_accuracy: 0.6481\n",
      "Epoch 813/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1104 - accuracy: 0.9908 - val_loss: 1.3957 - val_accuracy: 0.6481\n",
      "Epoch 814/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1240 - accuracy: 0.9908 - val_loss: 1.3956 - val_accuracy: 0.6481\n",
      "Epoch 815/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1013 - accuracy: 0.9945 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 816/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0805 - accuracy: 0.9963 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 817/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1022 - accuracy: 0.9945 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 818/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1053 - accuracy: 0.9982 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 819/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0779 - accuracy: 0.9963 - val_loss: 1.3954 - val_accuracy: 0.6481\n",
      "Epoch 820/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1025 - accuracy: 0.9982 - val_loss: 1.3953 - val_accuracy: 0.6481\n",
      "Epoch 821/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0888 - accuracy: 0.9982 - val_loss: 1.3952 - val_accuracy: 0.6481\n",
      "Epoch 822/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0988 - accuracy: 0.9963 - val_loss: 1.3952 - val_accuracy: 0.6481\n",
      "Epoch 823/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0988 - accuracy: 0.9982 - val_loss: 1.3950 - val_accuracy: 0.6481\n",
      "Epoch 824/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1233 - accuracy: 0.9963 - val_loss: 1.3947 - val_accuracy: 0.6481\n",
      "Epoch 825/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.6481\n",
      "Epoch 826/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 1.3944 - val_accuracy: 0.6481\n",
      "Epoch 827/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0770 - accuracy: 0.9982 - val_loss: 1.3945 - val_accuracy: 0.6481\n",
      "Epoch 828/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.6481\n",
      "Epoch 829/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1002 - accuracy: 0.9927 - val_loss: 1.3946 - val_accuracy: 0.6481\n",
      "Epoch 830/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1143 - accuracy: 0.9963 - val_loss: 1.3946 - val_accuracy: 0.6481\n",
      "Epoch 831/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0871 - accuracy: 0.9982 - val_loss: 1.3946 - val_accuracy: 0.6481\n",
      "Epoch 832/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1036 - accuracy: 0.9982 - val_loss: 1.3948 - val_accuracy: 0.6481\n",
      "Epoch 833/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1017 - accuracy: 0.9945 - val_loss: 1.3949 - val_accuracy: 0.6481\n",
      "Epoch 834/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 1.3948 - val_accuracy: 0.6528\n",
      "Epoch 835/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1014 - accuracy: 0.9945 - val_loss: 1.3948 - val_accuracy: 0.6528\n",
      "Epoch 836/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0943 - accuracy: 0.9945 - val_loss: 1.3948 - val_accuracy: 0.6528\n",
      "Epoch 837/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0988 - accuracy: 0.9963 - val_loss: 1.3949 - val_accuracy: 0.6528\n",
      "Epoch 838/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1153 - accuracy: 0.9927 - val_loss: 1.3949 - val_accuracy: 0.6528\n",
      "Epoch 839/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1140 - accuracy: 0.9890 - val_loss: 1.3947 - val_accuracy: 0.6528\n",
      "Epoch 840/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0987 - accuracy: 0.9982 - val_loss: 1.3944 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1013 - accuracy: 0.9945 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 842/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 1.3938 - val_accuracy: 0.6528\n",
      "Epoch 843/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1156 - accuracy: 0.9927 - val_loss: 1.3940 - val_accuracy: 0.6528\n",
      "Epoch 844/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1138 - accuracy: 0.9945 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 845/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0990 - accuracy: 0.9927 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 846/1000\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.0935 - accuracy: 0.9945 - val_loss: 1.3942 - val_accuracy: 0.6528\n",
      "Epoch 847/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1093 - accuracy: 0.9945 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 848/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0944 - accuracy: 0.9963 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 849/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0844 - accuracy: 0.9982 - val_loss: 1.3940 - val_accuracy: 0.6528\n",
      "Epoch 850/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0937 - accuracy: 0.9982 - val_loss: 1.3941 - val_accuracy: 0.6528\n",
      "Epoch 851/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0834 - accuracy: 0.9963 - val_loss: 1.3945 - val_accuracy: 0.6528\n",
      "Epoch 852/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1041 - accuracy: 0.9945 - val_loss: 1.3946 - val_accuracy: 0.6528\n",
      "Epoch 853/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1127 - accuracy: 0.9890 - val_loss: 1.3948 - val_accuracy: 0.6528\n",
      "Epoch 854/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0917 - accuracy: 0.9945 - val_loss: 1.3948 - val_accuracy: 0.6528\n",
      "Epoch 855/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0952 - accuracy: 0.9982 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 856/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0963 - accuracy: 0.9927 - val_loss: 1.3955 - val_accuracy: 0.6528\n",
      "Epoch 857/1000\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 0.6528\n",
      "Epoch 858/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0928 - accuracy: 0.9982 - val_loss: 1.3960 - val_accuracy: 0.6528\n",
      "Epoch 859/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0942 - accuracy: 0.9982 - val_loss: 1.3961 - val_accuracy: 0.6528\n",
      "Epoch 860/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0954 - accuracy: 0.9927 - val_loss: 1.3961 - val_accuracy: 0.6528\n",
      "Epoch 861/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0983 - accuracy: 0.9945 - val_loss: 1.3962 - val_accuracy: 0.6528\n",
      "Epoch 862/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1043 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6528\n",
      "Epoch 863/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0932 - accuracy: 0.9908 - val_loss: 1.3964 - val_accuracy: 0.6528\n",
      "Epoch 864/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1005 - accuracy: 0.9963 - val_loss: 1.3962 - val_accuracy: 0.6528\n",
      "Epoch 865/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1039 - accuracy: 0.9927 - val_loss: 1.3962 - val_accuracy: 0.6528\n",
      "Epoch 866/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1048 - accuracy: 0.9945 - val_loss: 1.3964 - val_accuracy: 0.6528\n",
      "Epoch 867/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0928 - accuracy: 0.9982 - val_loss: 1.3965 - val_accuracy: 0.6528\n",
      "Epoch 868/1000\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.0933 - accuracy: 0.9963 - val_loss: 1.3968 - val_accuracy: 0.6528\n",
      "Epoch 869/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1130 - accuracy: 0.9945 - val_loss: 1.3969 - val_accuracy: 0.6528\n",
      "Epoch 870/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0970 - accuracy: 0.9945 - val_loss: 1.3966 - val_accuracy: 0.6528\n",
      "Epoch 871/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0991 - accuracy: 0.9963 - val_loss: 1.3966 - val_accuracy: 0.6528\n",
      "Epoch 872/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1003 - accuracy: 0.9963 - val_loss: 1.3966 - val_accuracy: 0.6574\n",
      "Epoch 873/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1005 - accuracy: 0.9963 - val_loss: 1.3965 - val_accuracy: 0.6574\n",
      "Epoch 874/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0914 - accuracy: 0.9963 - val_loss: 1.3964 - val_accuracy: 0.6574\n",
      "Epoch 875/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0964 - accuracy: 0.9945 - val_loss: 1.3965 - val_accuracy: 0.6574\n",
      "Epoch 876/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.3967 - val_accuracy: 0.6528\n",
      "Epoch 877/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1198 - accuracy: 0.9908 - val_loss: 1.3966 - val_accuracy: 0.6528\n",
      "Epoch 878/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1009 - accuracy: 0.9963 - val_loss: 1.3965 - val_accuracy: 0.6528\n",
      "Epoch 879/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1059 - accuracy: 0.9908 - val_loss: 1.3963 - val_accuracy: 0.6528\n",
      "Epoch 880/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 1.3959 - val_accuracy: 0.6528\n",
      "Epoch 881/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.6528\n",
      "Epoch 882/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1044 - accuracy: 0.9963 - val_loss: 1.3956 - val_accuracy: 0.6528\n",
      "Epoch 883/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1036 - accuracy: 0.9982 - val_loss: 1.3955 - val_accuracy: 0.6528\n",
      "Epoch 884/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0997 - accuracy: 0.9963 - val_loss: 1.3954 - val_accuracy: 0.6528\n",
      "Epoch 885/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0919 - accuracy: 0.9963 - val_loss: 1.3954 - val_accuracy: 0.6528\n",
      "Epoch 886/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1102 - accuracy: 0.9945 - val_loss: 1.3955 - val_accuracy: 0.6528\n",
      "Epoch 887/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0976 - accuracy: 0.9963 - val_loss: 1.3954 - val_accuracy: 0.6528\n",
      "Epoch 888/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0873 - accuracy: 0.9982 - val_loss: 1.3955 - val_accuracy: 0.6528\n",
      "Epoch 889/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0896 - accuracy: 0.9963 - val_loss: 1.3956 - val_accuracy: 0.6528\n",
      "Epoch 890/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.3958 - val_accuracy: 0.6528\n",
      "Epoch 891/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0843 - accuracy: 0.9982 - val_loss: 1.3958 - val_accuracy: 0.6528\n",
      "Epoch 892/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0927 - accuracy: 0.9982 - val_loss: 1.3958 - val_accuracy: 0.6528\n",
      "Epoch 893/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0936 - accuracy: 0.9982 - val_loss: 1.3957 - val_accuracy: 0.6528\n",
      "Epoch 894/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0945 - accuracy: 0.9945 - val_loss: 1.3956 - val_accuracy: 0.6528\n",
      "Epoch 895/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1138 - accuracy: 0.9963 - val_loss: 1.3955 - val_accuracy: 0.6528\n",
      "Epoch 896/1000\n",
      "546/546 [==============================] - 0s 181us/step - loss: 0.0957 - accuracy: 0.9982 - val_loss: 1.3954 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1110 - accuracy: 0.9963 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 898/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0909 - accuracy: 0.9945 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 899/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 900/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0940 - accuracy: 0.9945 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 901/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.3951 - val_accuracy: 0.6528\n",
      "Epoch 902/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0892 - accuracy: 0.9963 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 903/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1022 - accuracy: 0.9982 - val_loss: 1.3952 - val_accuracy: 0.6528\n",
      "Epoch 904/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0943 - accuracy: 0.9963 - val_loss: 1.3953 - val_accuracy: 0.6528\n",
      "Epoch 905/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0902 - accuracy: 0.9963 - val_loss: 1.3957 - val_accuracy: 0.6528\n",
      "Epoch 906/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0839 - accuracy: 0.9982 - val_loss: 1.3957 - val_accuracy: 0.6528\n",
      "Epoch 907/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1060 - accuracy: 0.9945 - val_loss: 1.3958 - val_accuracy: 0.6528\n",
      "Epoch 908/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0996 - accuracy: 0.9982 - val_loss: 1.3960 - val_accuracy: 0.6528\n",
      "Epoch 909/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1088 - accuracy: 0.9963 - val_loss: 1.3963 - val_accuracy: 0.6528\n",
      "Epoch 910/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0812 - accuracy: 0.9982 - val_loss: 1.3965 - val_accuracy: 0.6528\n",
      "Epoch 911/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0935 - accuracy: 0.9982 - val_loss: 1.3966 - val_accuracy: 0.6528\n",
      "Epoch 912/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1068 - accuracy: 0.9927 - val_loss: 1.3967 - val_accuracy: 0.6528\n",
      "Epoch 913/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0917 - accuracy: 0.9982 - val_loss: 1.3969 - val_accuracy: 0.6528\n",
      "Epoch 914/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0932 - accuracy: 0.9982 - val_loss: 1.3970 - val_accuracy: 0.6528\n",
      "Epoch 915/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0775 - accuracy: 0.9982 - val_loss: 1.3971 - val_accuracy: 0.6528\n",
      "Epoch 916/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0858 - accuracy: 0.9982 - val_loss: 1.3974 - val_accuracy: 0.6528\n",
      "Epoch 917/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0888 - accuracy: 0.9945 - val_loss: 1.3976 - val_accuracy: 0.6528\n",
      "Epoch 918/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1020 - accuracy: 0.9963 - val_loss: 1.3975 - val_accuracy: 0.6528\n",
      "Epoch 919/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0973 - accuracy: 0.9982 - val_loss: 1.3978 - val_accuracy: 0.6528\n",
      "Epoch 920/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1120 - accuracy: 0.9963 - val_loss: 1.3977 - val_accuracy: 0.6528\n",
      "Epoch 921/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1006 - accuracy: 0.9982 - val_loss: 1.3980 - val_accuracy: 0.6528\n",
      "Epoch 922/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1031 - accuracy: 0.9927 - val_loss: 1.3983 - val_accuracy: 0.6528\n",
      "Epoch 923/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1058 - accuracy: 0.9927 - val_loss: 1.3983 - val_accuracy: 0.6528\n",
      "Epoch 924/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.0991 - accuracy: 0.9927 - val_loss: 1.3984 - val_accuracy: 0.6528\n",
      "Epoch 925/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0922 - accuracy: 0.9945 - val_loss: 1.3986 - val_accuracy: 0.6528\n",
      "Epoch 926/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0983 - accuracy: 0.9908 - val_loss: 1.3985 - val_accuracy: 0.6528\n",
      "Epoch 927/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0774 - accuracy: 0.9963 - val_loss: 1.3987 - val_accuracy: 0.6528\n",
      "Epoch 928/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.6528\n",
      "Epoch 929/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0992 - accuracy: 0.9982 - val_loss: 1.3991 - val_accuracy: 0.6528\n",
      "Epoch 930/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1083 - accuracy: 0.9963 - val_loss: 1.3994 - val_accuracy: 0.6528\n",
      "Epoch 931/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0974 - accuracy: 0.9963 - val_loss: 1.3997 - val_accuracy: 0.6528\n",
      "Epoch 932/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0976 - accuracy: 0.9982 - val_loss: 1.4000 - val_accuracy: 0.6574\n",
      "Epoch 933/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0861 - accuracy: 0.9982 - val_loss: 1.4002 - val_accuracy: 0.6574\n",
      "Epoch 934/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1257 - accuracy: 0.9890 - val_loss: 1.4005 - val_accuracy: 0.6574\n",
      "Epoch 935/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0966 - accuracy: 0.9945 - val_loss: 1.4009 - val_accuracy: 0.6574\n",
      "Epoch 936/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.6574\n",
      "Epoch 937/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0853 - accuracy: 0.9963 - val_loss: 1.4013 - val_accuracy: 0.6574\n",
      "Epoch 938/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1365 - accuracy: 0.9890 - val_loss: 1.4015 - val_accuracy: 0.6574\n",
      "Epoch 939/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.6528\n",
      "Epoch 940/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0878 - accuracy: 0.9982 - val_loss: 1.4015 - val_accuracy: 0.6528\n",
      "Epoch 941/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1122 - accuracy: 0.9872 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 942/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0853 - accuracy: 0.9945 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 943/1000\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1099 - accuracy: 0.9927 - val_loss: 1.4013 - val_accuracy: 0.6528\n",
      "Epoch 944/1000\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0832 - accuracy: 0.9982 - val_loss: 1.4013 - val_accuracy: 0.6528\n",
      "Epoch 945/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.6528\n",
      "Epoch 946/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1067 - accuracy: 0.9982 - val_loss: 1.4012 - val_accuracy: 0.6528\n",
      "Epoch 947/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0958 - accuracy: 0.9963 - val_loss: 1.4013 - val_accuracy: 0.6528\n",
      "Epoch 948/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0807 - accuracy: 0.9945 - val_loss: 1.4016 - val_accuracy: 0.6528\n",
      "Epoch 949/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.6528\n",
      "Epoch 950/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0955 - accuracy: 0.9945 - val_loss: 1.4022 - val_accuracy: 0.6528\n",
      "Epoch 951/1000\n",
      "546/546 [==============================] - 0s 180us/step - loss: 0.1198 - accuracy: 0.9872 - val_loss: 1.4022 - val_accuracy: 0.6528\n",
      "Epoch 952/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0990 - accuracy: 0.9963 - val_loss: 1.4022 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1012 - accuracy: 0.9945 - val_loss: 1.4023 - val_accuracy: 0.6528\n",
      "Epoch 954/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0987 - accuracy: 0.9908 - val_loss: 1.4025 - val_accuracy: 0.6528\n",
      "Epoch 955/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0928 - accuracy: 0.9963 - val_loss: 1.4028 - val_accuracy: 0.6528\n",
      "Epoch 956/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.6528\n",
      "Epoch 957/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0986 - accuracy: 0.9982 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 958/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0863 - accuracy: 0.9982 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 959/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1100 - accuracy: 0.9908 - val_loss: 1.4035 - val_accuracy: 0.6528\n",
      "Epoch 960/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1024 - accuracy: 0.9963 - val_loss: 1.4036 - val_accuracy: 0.6528\n",
      "Epoch 961/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1034 - accuracy: 0.9982 - val_loss: 1.4038 - val_accuracy: 0.6528\n",
      "Epoch 962/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1026 - accuracy: 0.9927 - val_loss: 1.4038 - val_accuracy: 0.6528\n",
      "Epoch 963/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1107 - accuracy: 0.9982 - val_loss: 1.4037 - val_accuracy: 0.6528\n",
      "Epoch 964/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1055 - accuracy: 0.9945 - val_loss: 1.4036 - val_accuracy: 0.6528\n",
      "Epoch 965/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0997 - accuracy: 0.9945 - val_loss: 1.4035 - val_accuracy: 0.6528\n",
      "Epoch 966/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0914 - accuracy: 0.9982 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 967/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 968/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1108 - accuracy: 0.9945 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 969/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0842 - accuracy: 0.9982 - val_loss: 1.4030 - val_accuracy: 0.6528\n",
      "Epoch 970/1000\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0870 - accuracy: 0.9982 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 971/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0846 - accuracy: 0.9982 - val_loss: 1.4025 - val_accuracy: 0.6528\n",
      "Epoch 972/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0839 - accuracy: 0.9945 - val_loss: 1.4021 - val_accuracy: 0.6528\n",
      "Epoch 973/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.6481\n",
      "Epoch 974/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0948 - accuracy: 0.9963 - val_loss: 1.4016 - val_accuracy: 0.6481\n",
      "Epoch 975/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0790 - accuracy: 0.9982 - val_loss: 1.4011 - val_accuracy: 0.6481\n",
      "Epoch 976/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0875 - accuracy: 0.9982 - val_loss: 1.4009 - val_accuracy: 0.6481\n",
      "Epoch 977/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0832 - accuracy: 0.9982 - val_loss: 1.4008 - val_accuracy: 0.6481\n",
      "Epoch 978/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1046 - accuracy: 0.9945 - val_loss: 1.4006 - val_accuracy: 0.6481\n",
      "Epoch 979/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0845 - accuracy: 0.9963 - val_loss: 1.4005 - val_accuracy: 0.6481\n",
      "Epoch 980/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1004 - accuracy: 0.9927 - val_loss: 1.4004 - val_accuracy: 0.6481\n",
      "Epoch 981/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.6481\n",
      "Epoch 982/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0944 - accuracy: 0.9963 - val_loss: 1.3999 - val_accuracy: 0.6481\n",
      "Epoch 983/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0989 - accuracy: 0.9963 - val_loss: 1.3996 - val_accuracy: 0.6481\n",
      "Epoch 984/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0899 - accuracy: 0.9982 - val_loss: 1.3995 - val_accuracy: 0.6481\n",
      "Epoch 985/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0987 - accuracy: 0.9945 - val_loss: 1.3995 - val_accuracy: 0.6481\n",
      "Epoch 986/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0902 - accuracy: 0.9982 - val_loss: 1.3995 - val_accuracy: 0.6481\n",
      "Epoch 987/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0920 - accuracy: 0.9963 - val_loss: 1.3994 - val_accuracy: 0.6481\n",
      "Epoch 988/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.0916 - accuracy: 0.9963 - val_loss: 1.3991 - val_accuracy: 0.6481\n",
      "Epoch 989/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1122 - accuracy: 0.9927 - val_loss: 1.3990 - val_accuracy: 0.6481\n",
      "Epoch 990/1000\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.1065 - accuracy: 0.9982 - val_loss: 1.3988 - val_accuracy: 0.6481\n",
      "Epoch 991/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1032 - accuracy: 0.9963 - val_loss: 1.3987 - val_accuracy: 0.6481\n",
      "Epoch 992/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 1.3984 - val_accuracy: 0.6528\n",
      "Epoch 993/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0910 - accuracy: 0.9963 - val_loss: 1.3983 - val_accuracy: 0.6528\n",
      "Epoch 994/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0902 - accuracy: 0.9982 - val_loss: 1.3981 - val_accuracy: 0.6528\n",
      "Epoch 995/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0995 - accuracy: 0.9908 - val_loss: 1.3981 - val_accuracy: 0.6528\n",
      "Epoch 996/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1082 - accuracy: 0.9982 - val_loss: 1.3983 - val_accuracy: 0.6528\n",
      "Epoch 997/1000\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1061 - accuracy: 0.9963 - val_loss: 1.3982 - val_accuracy: 0.6528\n",
      "Epoch 998/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0932 - accuracy: 0.9982 - val_loss: 1.3984 - val_accuracy: 0.6528\n",
      "Epoch 999/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0870 - accuracy: 0.9963 - val_loss: 1.3984 - val_accuracy: 0.6528\n",
      "Epoch 1000/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1209 - accuracy: 0.9963 - val_loss: 1.3985 - val_accuracy: 0.6528\n",
      "Train on 546 samples, validate on 216 samples\n",
      "Epoch 1/400\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 0.1007 - accuracy: 0.9945 - val_loss: 1.3898 - val_accuracy: 0.6574\n",
      "Epoch 2/400\n",
      "546/546 [==============================] - 0s 195us/step - loss: 0.0770 - accuracy: 0.9982 - val_loss: 1.3914 - val_accuracy: 0.6528\n",
      "Epoch 3/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1072 - accuracy: 0.9927 - val_loss: 1.3893 - val_accuracy: 0.6528\n",
      "Epoch 4/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1087 - accuracy: 0.9945 - val_loss: 1.3899 - val_accuracy: 0.6528\n",
      "Epoch 5/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0821 - accuracy: 0.9963 - val_loss: 1.3898 - val_accuracy: 0.6528\n",
      "Epoch 6/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0804 - accuracy: 0.9945 - val_loss: 1.3939 - val_accuracy: 0.6481\n",
      "Epoch 7/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1070 - accuracy: 0.9927 - val_loss: 1.3956 - val_accuracy: 0.6481\n",
      "Epoch 8/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1059 - accuracy: 0.9963 - val_loss: 1.3959 - val_accuracy: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0804 - accuracy: 0.9963 - val_loss: 1.3962 - val_accuracy: 0.6389\n",
      "Epoch 10/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0802 - accuracy: 0.9963 - val_loss: 1.3962 - val_accuracy: 0.6389\n",
      "Epoch 11/400\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.1018 - accuracy: 0.9908 - val_loss: 1.3934 - val_accuracy: 0.6343\n",
      "Epoch 12/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0898 - accuracy: 0.9982 - val_loss: 1.3914 - val_accuracy: 0.6296\n",
      "Epoch 13/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0921 - accuracy: 0.9945 - val_loss: 1.3895 - val_accuracy: 0.6296\n",
      "Epoch 14/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1014 - accuracy: 0.9945 - val_loss: 1.3874 - val_accuracy: 0.6296\n",
      "Epoch 15/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.3862 - val_accuracy: 0.6343\n",
      "Epoch 16/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1005 - accuracy: 0.9982 - val_loss: 1.3850 - val_accuracy: 0.6296\n",
      "Epoch 17/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0769 - accuracy: 0.9982 - val_loss: 1.3840 - val_accuracy: 0.6296\n",
      "Epoch 18/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0851 - accuracy: 0.9982 - val_loss: 1.3833 - val_accuracy: 0.6296\n",
      "Epoch 19/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0860 - accuracy: 0.9963 - val_loss: 1.3824 - val_accuracy: 0.6296\n",
      "Epoch 20/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.3819 - val_accuracy: 0.6296\n",
      "Epoch 21/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1047 - accuracy: 0.9945 - val_loss: 1.3821 - val_accuracy: 0.6296\n",
      "Epoch 22/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0911 - accuracy: 0.9963 - val_loss: 1.3825 - val_accuracy: 0.6296\n",
      "Epoch 23/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0963 - accuracy: 0.9945 - val_loss: 1.3835 - val_accuracy: 0.6296\n",
      "Epoch 24/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1027 - accuracy: 0.9945 - val_loss: 1.3853 - val_accuracy: 0.6296\n",
      "Epoch 25/400\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.0968 - accuracy: 0.9963 - val_loss: 1.3874 - val_accuracy: 0.6296\n",
      "Epoch 26/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0898 - accuracy: 0.9963 - val_loss: 1.3886 - val_accuracy: 0.6296\n",
      "Epoch 27/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0760 - accuracy: 0.9982 - val_loss: 1.3895 - val_accuracy: 0.6296\n",
      "Epoch 28/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0828 - accuracy: 0.9982 - val_loss: 1.3905 - val_accuracy: 0.6296\n",
      "Epoch 29/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0929 - accuracy: 0.9963 - val_loss: 1.3912 - val_accuracy: 0.6296\n",
      "Epoch 30/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0978 - accuracy: 0.9945 - val_loss: 1.3921 - val_accuracy: 0.6296\n",
      "Epoch 31/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.3933 - val_accuracy: 0.6296\n",
      "Epoch 32/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0878 - accuracy: 0.9945 - val_loss: 1.3943 - val_accuracy: 0.6296\n",
      "Epoch 33/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.0859 - accuracy: 0.9945 - val_loss: 1.3954 - val_accuracy: 0.6296\n",
      "Epoch 34/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1005 - accuracy: 0.9963 - val_loss: 1.3962 - val_accuracy: 0.6296\n",
      "Epoch 35/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0932 - accuracy: 0.9982 - val_loss: 1.3965 - val_accuracy: 0.6296\n",
      "Epoch 36/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0948 - accuracy: 0.9945 - val_loss: 1.3968 - val_accuracy: 0.6296\n",
      "Epoch 37/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 1.3970 - val_accuracy: 0.6296\n",
      "Epoch 38/400\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 1.3971 - val_accuracy: 0.6296\n",
      "Epoch 39/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0841 - accuracy: 0.9982 - val_loss: 1.3973 - val_accuracy: 0.6296\n",
      "Epoch 40/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1002 - accuracy: 0.9963 - val_loss: 1.3974 - val_accuracy: 0.6296\n",
      "Epoch 41/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0875 - accuracy: 0.9908 - val_loss: 1.3975 - val_accuracy: 0.6296\n",
      "Epoch 42/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 1.3974 - val_accuracy: 0.6296\n",
      "Epoch 43/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0812 - accuracy: 0.9982 - val_loss: 1.3974 - val_accuracy: 0.6296\n",
      "Epoch 44/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1149 - accuracy: 0.9945 - val_loss: 1.3974 - val_accuracy: 0.6343\n",
      "Epoch 45/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0926 - accuracy: 0.9982 - val_loss: 1.3972 - val_accuracy: 0.6343\n",
      "Epoch 46/400\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.0783 - accuracy: 0.9982 - val_loss: 1.3970 - val_accuracy: 0.6343\n",
      "Epoch 47/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0894 - accuracy: 0.9963 - val_loss: 1.3968 - val_accuracy: 0.6343\n",
      "Epoch 48/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1052 - accuracy: 0.9908 - val_loss: 1.3967 - val_accuracy: 0.6343\n",
      "Epoch 49/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0932 - accuracy: 0.9927 - val_loss: 1.3964 - val_accuracy: 0.6343\n",
      "Epoch 50/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.6343\n",
      "Epoch 51/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0954 - accuracy: 0.9945 - val_loss: 1.3960 - val_accuracy: 0.6343\n",
      "Epoch 52/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.6343\n",
      "Epoch 53/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0924 - accuracy: 0.9963 - val_loss: 1.3957 - val_accuracy: 0.6389\n",
      "Epoch 54/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0832 - accuracy: 0.9963 - val_loss: 1.3955 - val_accuracy: 0.6389\n",
      "Epoch 55/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0975 - accuracy: 0.9927 - val_loss: 1.3955 - val_accuracy: 0.6389\n",
      "Epoch 56/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0916 - accuracy: 0.9982 - val_loss: 1.3954 - val_accuracy: 0.6389\n",
      "Epoch 57/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.6389\n",
      "Epoch 58/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0739 - accuracy: 0.9982 - val_loss: 1.3954 - val_accuracy: 0.6389\n",
      "Epoch 59/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0795 - accuracy: 0.9963 - val_loss: 1.3952 - val_accuracy: 0.6389\n",
      "Epoch 60/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.6389\n",
      "Epoch 61/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1053 - accuracy: 0.9945 - val_loss: 1.3953 - val_accuracy: 0.6389\n",
      "Epoch 62/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1057 - accuracy: 0.9927 - val_loss: 1.3952 - val_accuracy: 0.6389\n",
      "Epoch 63/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0946 - accuracy: 0.9963 - val_loss: 1.3953 - val_accuracy: 0.6389\n",
      "Epoch 64/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.6389\n",
      "Epoch 65/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0912 - accuracy: 0.9963 - val_loss: 1.3953 - val_accuracy: 0.6389\n",
      "Epoch 67/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0912 - accuracy: 0.9982 - val_loss: 1.3953 - val_accuracy: 0.6435\n",
      "Epoch 68/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0873 - accuracy: 0.9945 - val_loss: 1.3953 - val_accuracy: 0.6435\n",
      "Epoch 69/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1094 - accuracy: 0.9927 - val_loss: 1.3955 - val_accuracy: 0.6435\n",
      "Epoch 70/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0765 - accuracy: 0.9963 - val_loss: 1.3955 - val_accuracy: 0.6435\n",
      "Epoch 71/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0888 - accuracy: 0.9982 - val_loss: 1.3955 - val_accuracy: 0.6435\n",
      "Epoch 72/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0813 - accuracy: 0.9982 - val_loss: 1.3956 - val_accuracy: 0.6435\n",
      "Epoch 73/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0899 - accuracy: 0.9927 - val_loss: 1.3956 - val_accuracy: 0.6435\n",
      "Epoch 74/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0836 - accuracy: 0.9963 - val_loss: 1.3957 - val_accuracy: 0.6435\n",
      "Epoch 75/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.6435\n",
      "Epoch 76/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0729 - accuracy: 0.9963 - val_loss: 1.3959 - val_accuracy: 0.6435\n",
      "Epoch 77/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0992 - accuracy: 0.9945 - val_loss: 1.3961 - val_accuracy: 0.6435\n",
      "Epoch 78/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0843 - accuracy: 0.9945 - val_loss: 1.3964 - val_accuracy: 0.6481\n",
      "Epoch 79/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.6481\n",
      "Epoch 80/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0778 - accuracy: 0.9927 - val_loss: 1.3967 - val_accuracy: 0.6481\n",
      "Epoch 81/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0796 - accuracy: 0.9982 - val_loss: 1.3971 - val_accuracy: 0.6481\n",
      "Epoch 82/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1040 - accuracy: 0.9908 - val_loss: 1.3975 - val_accuracy: 0.6481\n",
      "Epoch 83/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0805 - accuracy: 0.9982 - val_loss: 1.3977 - val_accuracy: 0.6481\n",
      "Epoch 84/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0817 - accuracy: 0.9982 - val_loss: 1.3981 - val_accuracy: 0.6481\n",
      "Epoch 85/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.3984 - val_accuracy: 0.6481\n",
      "Epoch 86/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0877 - accuracy: 0.9963 - val_loss: 1.3988 - val_accuracy: 0.6435\n",
      "Epoch 87/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1049 - accuracy: 0.9945 - val_loss: 1.3990 - val_accuracy: 0.6435\n",
      "Epoch 88/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0879 - accuracy: 0.9927 - val_loss: 1.3990 - val_accuracy: 0.6435\n",
      "Epoch 89/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0895 - accuracy: 0.9963 - val_loss: 1.3992 - val_accuracy: 0.6435\n",
      "Epoch 90/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0957 - accuracy: 0.9963 - val_loss: 1.3994 - val_accuracy: 0.6435\n",
      "Epoch 91/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.6435\n",
      "Epoch 92/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0802 - accuracy: 0.9945 - val_loss: 1.3995 - val_accuracy: 0.6435\n",
      "Epoch 93/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0894 - accuracy: 0.9963 - val_loss: 1.3995 - val_accuracy: 0.6435\n",
      "Epoch 94/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1027 - accuracy: 0.9963 - val_loss: 1.3995 - val_accuracy: 0.6435\n",
      "Epoch 95/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.6435\n",
      "Epoch 96/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0896 - accuracy: 0.9982 - val_loss: 1.3992 - val_accuracy: 0.6435\n",
      "Epoch 97/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0830 - accuracy: 0.9982 - val_loss: 1.3990 - val_accuracy: 0.6435\n",
      "Epoch 98/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0853 - accuracy: 0.9982 - val_loss: 1.3988 - val_accuracy: 0.6435\n",
      "Epoch 99/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 1.3988 - val_accuracy: 0.6435\n",
      "Epoch 100/400\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.0904 - accuracy: 0.9963 - val_loss: 1.3986 - val_accuracy: 0.6435\n",
      "Epoch 101/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0763 - accuracy: 0.9963 - val_loss: 1.3985 - val_accuracy: 0.6435\n",
      "Epoch 102/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0860 - accuracy: 0.9963 - val_loss: 1.3984 - val_accuracy: 0.6435\n",
      "Epoch 103/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0906 - accuracy: 0.9927 - val_loss: 1.3982 - val_accuracy: 0.6435\n",
      "Epoch 104/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0954 - accuracy: 0.9963 - val_loss: 1.3981 - val_accuracy: 0.6435\n",
      "Epoch 105/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0839 - accuracy: 0.9963 - val_loss: 1.3979 - val_accuracy: 0.6435\n",
      "Epoch 106/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1121 - accuracy: 0.9945 - val_loss: 1.3978 - val_accuracy: 0.6435\n",
      "Epoch 107/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0868 - accuracy: 0.9927 - val_loss: 1.3978 - val_accuracy: 0.6435\n",
      "Epoch 108/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0923 - accuracy: 0.9982 - val_loss: 1.3975 - val_accuracy: 0.6435\n",
      "Epoch 109/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 110/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 111/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.6435\n",
      "Epoch 112/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0934 - accuracy: 0.9963 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 113/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0791 - accuracy: 0.9982 - val_loss: 1.3974 - val_accuracy: 0.6435\n",
      "Epoch 114/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0997 - accuracy: 0.9963 - val_loss: 1.3975 - val_accuracy: 0.6435\n",
      "Epoch 115/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1033 - accuracy: 0.9908 - val_loss: 1.3976 - val_accuracy: 0.6435\n",
      "Epoch 116/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0787 - accuracy: 0.9982 - val_loss: 1.3977 - val_accuracy: 0.6435\n",
      "Epoch 117/400\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.0899 - accuracy: 0.9963 - val_loss: 1.3978 - val_accuracy: 0.6435\n",
      "Epoch 118/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0799 - accuracy: 0.9963 - val_loss: 1.3980 - val_accuracy: 0.6435\n",
      "Epoch 119/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.6435\n",
      "Epoch 120/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0991 - accuracy: 0.9963 - val_loss: 1.3983 - val_accuracy: 0.6435\n",
      "Epoch 121/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1069 - accuracy: 0.9945 - val_loss: 1.3987 - val_accuracy: 0.6435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0946 - accuracy: 0.9982 - val_loss: 1.3990 - val_accuracy: 0.6435\n",
      "Epoch 123/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0820 - accuracy: 0.9982 - val_loss: 1.3989 - val_accuracy: 0.6435\n",
      "Epoch 124/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0902 - accuracy: 0.9927 - val_loss: 1.3990 - val_accuracy: 0.6435\n",
      "Epoch 125/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0938 - accuracy: 0.9982 - val_loss: 1.3991 - val_accuracy: 0.6435\n",
      "Epoch 126/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1029 - accuracy: 0.9945 - val_loss: 1.3992 - val_accuracy: 0.6435\n",
      "Epoch 127/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0849 - accuracy: 0.9982 - val_loss: 1.3992 - val_accuracy: 0.6435\n",
      "Epoch 128/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0879 - accuracy: 0.9982 - val_loss: 1.3993 - val_accuracy: 0.6435\n",
      "Epoch 129/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.6435\n",
      "Epoch 130/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0884 - accuracy: 0.9927 - val_loss: 1.3996 - val_accuracy: 0.6435\n",
      "Epoch 131/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0821 - accuracy: 0.9982 - val_loss: 1.3998 - val_accuracy: 0.6435\n",
      "Epoch 132/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0873 - accuracy: 0.9945 - val_loss: 1.3998 - val_accuracy: 0.6435\n",
      "Epoch 133/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0838 - accuracy: 0.9982 - val_loss: 1.3999 - val_accuracy: 0.6435\n",
      "Epoch 134/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0711 - accuracy: 0.9963 - val_loss: 1.3999 - val_accuracy: 0.6435\n",
      "Epoch 135/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0986 - accuracy: 0.9963 - val_loss: 1.4002 - val_accuracy: 0.6435\n",
      "Epoch 136/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.4003 - val_accuracy: 0.6435\n",
      "Epoch 137/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0907 - accuracy: 0.9982 - val_loss: 1.4003 - val_accuracy: 0.6435\n",
      "Epoch 138/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0791 - accuracy: 0.9982 - val_loss: 1.4005 - val_accuracy: 0.6435\n",
      "Epoch 139/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0885 - accuracy: 0.9963 - val_loss: 1.4006 - val_accuracy: 0.6435\n",
      "Epoch 140/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1042 - accuracy: 0.9945 - val_loss: 1.4008 - val_accuracy: 0.6481\n",
      "Epoch 141/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0751 - accuracy: 0.9982 - val_loss: 1.4010 - val_accuracy: 0.6481\n",
      "Epoch 142/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0744 - accuracy: 0.9982 - val_loss: 1.4011 - val_accuracy: 0.6481\n",
      "Epoch 143/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0722 - accuracy: 0.9945 - val_loss: 1.4012 - val_accuracy: 0.6481\n",
      "Epoch 144/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0873 - accuracy: 0.9963 - val_loss: 1.4010 - val_accuracy: 0.6528\n",
      "Epoch 145/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.1009 - accuracy: 0.9945 - val_loss: 1.4012 - val_accuracy: 0.6528\n",
      "Epoch 146/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0793 - accuracy: 0.9982 - val_loss: 1.4013 - val_accuracy: 0.6481\n",
      "Epoch 147/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 148/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0894 - accuracy: 0.9945 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 149/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1004 - accuracy: 0.9963 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 150/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0841 - accuracy: 0.9963 - val_loss: 1.4014 - val_accuracy: 0.6528\n",
      "Epoch 151/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0896 - accuracy: 0.9982 - val_loss: 1.4015 - val_accuracy: 0.6528\n",
      "Epoch 152/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.6528\n",
      "Epoch 153/400\n",
      "546/546 [==============================] - 0s 179us/step - loss: 0.0768 - accuracy: 0.9982 - val_loss: 1.4015 - val_accuracy: 0.6574\n",
      "Epoch 154/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0905 - accuracy: 0.9963 - val_loss: 1.4014 - val_accuracy: 0.6574\n",
      "Epoch 155/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0842 - accuracy: 0.9982 - val_loss: 1.4015 - val_accuracy: 0.6574\n",
      "Epoch 156/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0826 - accuracy: 0.9963 - val_loss: 1.4019 - val_accuracy: 0.6528\n",
      "Epoch 157/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.4021 - val_accuracy: 0.6528\n",
      "Epoch 158/400\n",
      "546/546 [==============================] - 0s 178us/step - loss: 0.0889 - accuracy: 0.9945 - val_loss: 1.4025 - val_accuracy: 0.6528\n",
      "Epoch 159/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.1090 - accuracy: 0.9945 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 160/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.6528\n",
      "Epoch 161/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0950 - accuracy: 0.9963 - val_loss: 1.4029 - val_accuracy: 0.6528\n",
      "Epoch 162/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0774 - accuracy: 0.9963 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 163/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1031 - accuracy: 0.9927 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 164/400\n",
      "546/546 [==============================] - 0s 180us/step - loss: 0.0760 - accuracy: 0.9982 - val_loss: 1.4034 - val_accuracy: 0.6528\n",
      "Epoch 165/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0800 - accuracy: 0.9982 - val_loss: 1.4035 - val_accuracy: 0.6528\n",
      "Epoch 166/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0975 - accuracy: 0.9908 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 167/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0911 - accuracy: 0.9945 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 168/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.0905 - accuracy: 0.9963 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 169/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0975 - accuracy: 0.9927 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 170/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0764 - accuracy: 0.9982 - val_loss: 1.4029 - val_accuracy: 0.6528\n",
      "Epoch 171/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0850 - accuracy: 0.9963 - val_loss: 1.4029 - val_accuracy: 0.6528\n",
      "Epoch 172/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0915 - accuracy: 0.9982 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 173/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0874 - accuracy: 0.9982 - val_loss: 1.4026 - val_accuracy: 0.6528\n",
      "Epoch 174/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0984 - accuracy: 0.9982 - val_loss: 1.4026 - val_accuracy: 0.6528\n",
      "Epoch 175/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1001 - accuracy: 0.9927 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 176/400\n",
      "546/546 [==============================] - 0s 184us/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 177/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0872 - accuracy: 0.9982 - val_loss: 1.4030 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0976 - accuracy: 0.9927 - val_loss: 1.4030 - val_accuracy: 0.6528\n",
      "Epoch 179/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0923 - accuracy: 0.9963 - val_loss: 1.4030 - val_accuracy: 0.6528\n",
      "Epoch 180/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0892 - accuracy: 0.9982 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 181/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0826 - accuracy: 0.9982 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 182/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0969 - accuracy: 0.9945 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 183/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0924 - accuracy: 0.9982 - val_loss: 1.4028 - val_accuracy: 0.6528\n",
      "Epoch 184/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.6528\n",
      "Epoch 185/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0924 - accuracy: 0.9963 - val_loss: 1.4023 - val_accuracy: 0.6528\n",
      "Epoch 186/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0704 - accuracy: 0.9963 - val_loss: 1.4020 - val_accuracy: 0.6528\n",
      "Epoch 187/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0809 - accuracy: 0.9963 - val_loss: 1.4019 - val_accuracy: 0.6528\n",
      "Epoch 188/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0837 - accuracy: 0.9945 - val_loss: 1.4017 - val_accuracy: 0.6528\n",
      "Epoch 189/400\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.0938 - accuracy: 0.9945 - val_loss: 1.4018 - val_accuracy: 0.6528\n",
      "Epoch 190/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0854 - accuracy: 0.9982 - val_loss: 1.4016 - val_accuracy: 0.6528\n",
      "Epoch 191/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0906 - accuracy: 0.9982 - val_loss: 1.4016 - val_accuracy: 0.6528\n",
      "Epoch 192/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.6528\n",
      "Epoch 193/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0904 - accuracy: 0.9945 - val_loss: 1.4016 - val_accuracy: 0.6528\n",
      "Epoch 194/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0868 - accuracy: 0.9982 - val_loss: 1.4015 - val_accuracy: 0.6528\n",
      "Epoch 195/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0909 - accuracy: 0.9963 - val_loss: 1.4019 - val_accuracy: 0.6528\n",
      "Epoch 196/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0919 - accuracy: 0.9945 - val_loss: 1.4022 - val_accuracy: 0.6528\n",
      "Epoch 197/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0862 - accuracy: 0.9982 - val_loss: 1.4024 - val_accuracy: 0.6528\n",
      "Epoch 198/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1031 - accuracy: 0.9945 - val_loss: 1.4026 - val_accuracy: 0.6528\n",
      "Epoch 199/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0774 - accuracy: 0.9963 - val_loss: 1.4027 - val_accuracy: 0.6528\n",
      "Epoch 200/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0934 - accuracy: 0.9982 - val_loss: 1.4030 - val_accuracy: 0.6528\n",
      "Epoch 201/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0879 - accuracy: 0.9963 - val_loss: 1.4031 - val_accuracy: 0.6528\n",
      "Epoch 202/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 203/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 204/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0848 - accuracy: 0.9982 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 205/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0996 - accuracy: 0.9927 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 206/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0816 - accuracy: 0.9963 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 207/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0932 - accuracy: 0.9945 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 208/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.6528\n",
      "Epoch 209/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0843 - accuracy: 0.9982 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 210/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0857 - accuracy: 0.9945 - val_loss: 1.4033 - val_accuracy: 0.6528\n",
      "Epoch 211/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1040 - accuracy: 0.9908 - val_loss: 1.4034 - val_accuracy: 0.6528\n",
      "Epoch 212/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0961 - accuracy: 0.9945 - val_loss: 1.4037 - val_accuracy: 0.6528\n",
      "Epoch 213/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0839 - accuracy: 0.9982 - val_loss: 1.4038 - val_accuracy: 0.6528\n",
      "Epoch 214/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0915 - accuracy: 0.9927 - val_loss: 1.4039 - val_accuracy: 0.6528\n",
      "Epoch 215/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0712 - accuracy: 0.9982 - val_loss: 1.4039 - val_accuracy: 0.6528\n",
      "Epoch 216/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.6528\n",
      "Epoch 217/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0904 - accuracy: 0.9945 - val_loss: 1.4040 - val_accuracy: 0.6528\n",
      "Epoch 218/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.6528\n",
      "Epoch 219/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0800 - accuracy: 0.9982 - val_loss: 1.4040 - val_accuracy: 0.6481\n",
      "Epoch 220/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0877 - accuracy: 0.9927 - val_loss: 1.4040 - val_accuracy: 0.6481\n",
      "Epoch 221/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0841 - accuracy: 0.9982 - val_loss: 1.4039 - val_accuracy: 0.6481\n",
      "Epoch 222/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0855 - accuracy: 0.9982 - val_loss: 1.4041 - val_accuracy: 0.6481\n",
      "Epoch 223/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0860 - accuracy: 0.9945 - val_loss: 1.4043 - val_accuracy: 0.6481\n",
      "Epoch 224/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0834 - accuracy: 0.9963 - val_loss: 1.4043 - val_accuracy: 0.6481\n",
      "Epoch 225/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0907 - accuracy: 0.9963 - val_loss: 1.4044 - val_accuracy: 0.6481\n",
      "Epoch 226/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0950 - accuracy: 0.9945 - val_loss: 1.4043 - val_accuracy: 0.6481\n",
      "Epoch 227/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0894 - accuracy: 0.9982 - val_loss: 1.4043 - val_accuracy: 0.6481\n",
      "Epoch 228/400\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.6481\n",
      "Epoch 229/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0824 - accuracy: 0.9963 - val_loss: 1.4045 - val_accuracy: 0.6481\n",
      "Epoch 230/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0738 - accuracy: 0.9982 - val_loss: 1.4046 - val_accuracy: 0.6481\n",
      "Epoch 231/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0910 - accuracy: 0.9963 - val_loss: 1.4048 - val_accuracy: 0.6481\n",
      "Epoch 232/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0918 - accuracy: 0.9945 - val_loss: 1.4051 - val_accuracy: 0.6481\n",
      "Epoch 233/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1079 - accuracy: 0.9927 - val_loss: 1.4053 - val_accuracy: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/400\n",
      "546/546 [==============================] - 0s 182us/step - loss: 0.0854 - accuracy: 0.9963 - val_loss: 1.4055 - val_accuracy: 0.6481\n",
      "Epoch 235/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0793 - accuracy: 0.9982 - val_loss: 1.4057 - val_accuracy: 0.6481\n",
      "Epoch 236/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.4059 - val_accuracy: 0.6481\n",
      "Epoch 237/400\n",
      "546/546 [==============================] - 0s 176us/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 1.4061 - val_accuracy: 0.6481\n",
      "Epoch 238/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.6481\n",
      "Epoch 239/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0770 - accuracy: 0.9982 - val_loss: 1.4063 - val_accuracy: 0.6481\n",
      "Epoch 240/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0826 - accuracy: 0.9963 - val_loss: 1.4067 - val_accuracy: 0.6435\n",
      "Epoch 241/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.6435\n",
      "Epoch 242/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.6435\n",
      "Epoch 243/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0916 - accuracy: 0.9945 - val_loss: 1.4076 - val_accuracy: 0.6435\n",
      "Epoch 244/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0854 - accuracy: 0.9945 - val_loss: 1.4079 - val_accuracy: 0.6435\n",
      "Epoch 245/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0793 - accuracy: 0.9982 - val_loss: 1.4082 - val_accuracy: 0.6435\n",
      "Epoch 246/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0775 - accuracy: 0.9963 - val_loss: 1.4085 - val_accuracy: 0.6435\n",
      "Epoch 247/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.4090 - val_accuracy: 0.6435\n",
      "Epoch 248/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0770 - accuracy: 0.9982 - val_loss: 1.4092 - val_accuracy: 0.6435\n",
      "Epoch 249/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0728 - accuracy: 0.9982 - val_loss: 1.4095 - val_accuracy: 0.6435\n",
      "Epoch 250/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1013 - accuracy: 0.9963 - val_loss: 1.4099 - val_accuracy: 0.6435\n",
      "Epoch 251/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0823 - accuracy: 0.9963 - val_loss: 1.4101 - val_accuracy: 0.6435\n",
      "Epoch 252/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 1.4102 - val_accuracy: 0.6435\n",
      "Epoch 253/400\n",
      "546/546 [==============================] - 0s 190us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.6435\n",
      "Epoch 254/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0914 - accuracy: 0.9945 - val_loss: 1.4109 - val_accuracy: 0.6435\n",
      "Epoch 255/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0909 - accuracy: 0.9963 - val_loss: 1.4112 - val_accuracy: 0.6435\n",
      "Epoch 256/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.4116 - val_accuracy: 0.6435\n",
      "Epoch 257/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0943 - accuracy: 0.9963 - val_loss: 1.4119 - val_accuracy: 0.6435\n",
      "Epoch 258/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.0849 - accuracy: 0.9963 - val_loss: 1.4122 - val_accuracy: 0.6435\n",
      "Epoch 259/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0878 - accuracy: 0.9945 - val_loss: 1.4126 - val_accuracy: 0.6435\n",
      "Epoch 260/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0736 - accuracy: 0.9982 - val_loss: 1.4129 - val_accuracy: 0.6435\n",
      "Epoch 261/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0800 - accuracy: 0.9982 - val_loss: 1.4131 - val_accuracy: 0.6435\n",
      "Epoch 262/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.6435\n",
      "Epoch 263/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.0779 - accuracy: 0.9963 - val_loss: 1.4137 - val_accuracy: 0.6435\n",
      "Epoch 264/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0742 - accuracy: 0.9982 - val_loss: 1.4139 - val_accuracy: 0.6435\n",
      "Epoch 265/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.6435\n",
      "Epoch 266/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.4146 - val_accuracy: 0.6435\n",
      "Epoch 267/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0860 - accuracy: 0.9963 - val_loss: 1.4147 - val_accuracy: 0.6435\n",
      "Epoch 268/400\n",
      "546/546 [==============================] - 0s 174us/step - loss: 0.0903 - accuracy: 0.9963 - val_loss: 1.4147 - val_accuracy: 0.6435\n",
      "Epoch 269/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0876 - accuracy: 0.9982 - val_loss: 1.4148 - val_accuracy: 0.6435\n",
      "Epoch 270/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0726 - accuracy: 0.9982 - val_loss: 1.4149 - val_accuracy: 0.6435\n",
      "Epoch 271/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0861 - accuracy: 0.9945 - val_loss: 1.4149 - val_accuracy: 0.6435\n",
      "Epoch 272/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0812 - accuracy: 0.9963 - val_loss: 1.4150 - val_accuracy: 0.6435\n",
      "Epoch 273/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 1.4150 - val_accuracy: 0.6435\n",
      "Epoch 274/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0983 - accuracy: 0.9982 - val_loss: 1.4151 - val_accuracy: 0.6435\n",
      "Epoch 275/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0807 - accuracy: 0.9982 - val_loss: 1.4152 - val_accuracy: 0.6435\n",
      "Epoch 276/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0815 - accuracy: 0.9982 - val_loss: 1.4153 - val_accuracy: 0.6435\n",
      "Epoch 277/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 1.4154 - val_accuracy: 0.6435\n",
      "Epoch 278/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0868 - accuracy: 0.9982 - val_loss: 1.4155 - val_accuracy: 0.6435\n",
      "Epoch 279/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.1124 - accuracy: 0.9927 - val_loss: 1.4156 - val_accuracy: 0.6435\n",
      "Epoch 280/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0908 - accuracy: 0.9963 - val_loss: 1.4157 - val_accuracy: 0.6435\n",
      "Epoch 281/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0817 - accuracy: 0.9982 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 282/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 1.4161 - val_accuracy: 0.6389\n",
      "Epoch 283/400\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.0866 - accuracy: 0.9927 - val_loss: 1.4161 - val_accuracy: 0.6389\n",
      "Epoch 284/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0825 - accuracy: 0.9963 - val_loss: 1.4161 - val_accuracy: 0.6389\n",
      "Epoch 285/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0810 - accuracy: 0.9963 - val_loss: 1.4162 - val_accuracy: 0.6389\n",
      "Epoch 286/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0785 - accuracy: 0.9982 - val_loss: 1.4167 - val_accuracy: 0.6389\n",
      "Epoch 287/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1085 - accuracy: 0.9927 - val_loss: 1.4168 - val_accuracy: 0.6389\n",
      "Epoch 288/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0917 - accuracy: 0.9908 - val_loss: 1.4170 - val_accuracy: 0.6389\n",
      "Epoch 289/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0809 - accuracy: 0.9945 - val_loss: 1.4175 - val_accuracy: 0.6389\n",
      "Epoch 291/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.1002 - accuracy: 0.9945 - val_loss: 1.4178 - val_accuracy: 0.6389\n",
      "Epoch 292/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.4181 - val_accuracy: 0.6389\n",
      "Epoch 293/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.4183 - val_accuracy: 0.6389\n",
      "Epoch 294/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0799 - accuracy: 0.9982 - val_loss: 1.4184 - val_accuracy: 0.6389\n",
      "Epoch 295/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1084 - accuracy: 0.9963 - val_loss: 1.4186 - val_accuracy: 0.6389\n",
      "Epoch 296/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0784 - accuracy: 0.9945 - val_loss: 1.4187 - val_accuracy: 0.6389\n",
      "Epoch 297/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0904 - accuracy: 0.9963 - val_loss: 1.4187 - val_accuracy: 0.6389\n",
      "Epoch 298/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0877 - accuracy: 0.9945 - val_loss: 1.4186 - val_accuracy: 0.6389\n",
      "Epoch 299/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.4184 - val_accuracy: 0.6389\n",
      "Epoch 300/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0869 - accuracy: 0.9963 - val_loss: 1.4180 - val_accuracy: 0.6389\n",
      "Epoch 301/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0832 - accuracy: 0.9982 - val_loss: 1.4178 - val_accuracy: 0.6389\n",
      "Epoch 302/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0794 - accuracy: 0.9963 - val_loss: 1.4176 - val_accuracy: 0.6389\n",
      "Epoch 303/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0893 - accuracy: 0.9945 - val_loss: 1.4176 - val_accuracy: 0.6389\n",
      "Epoch 304/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0727 - accuracy: 0.9982 - val_loss: 1.4176 - val_accuracy: 0.6389\n",
      "Epoch 305/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0889 - accuracy: 0.9945 - val_loss: 1.4175 - val_accuracy: 0.6389\n",
      "Epoch 306/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.6389\n",
      "Epoch 307/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0768 - accuracy: 0.9982 - val_loss: 1.4172 - val_accuracy: 0.6389\n",
      "Epoch 308/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0871 - accuracy: 0.9927 - val_loss: 1.4170 - val_accuracy: 0.6389\n",
      "Epoch 309/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0959 - accuracy: 0.9963 - val_loss: 1.4167 - val_accuracy: 0.6435\n",
      "Epoch 310/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0795 - accuracy: 0.9982 - val_loss: 1.4166 - val_accuracy: 0.6435\n",
      "Epoch 311/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0920 - accuracy: 0.9927 - val_loss: 1.4165 - val_accuracy: 0.6435\n",
      "Epoch 312/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0883 - accuracy: 0.9927 - val_loss: 1.4163 - val_accuracy: 0.6435\n",
      "Epoch 313/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0838 - accuracy: 0.9963 - val_loss: 1.4162 - val_accuracy: 0.6435\n",
      "Epoch 314/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 1.4162 - val_accuracy: 0.6435\n",
      "Epoch 315/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0811 - accuracy: 0.9982 - val_loss: 1.4160 - val_accuracy: 0.6435\n",
      "Epoch 316/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0741 - accuracy: 0.9982 - val_loss: 1.4158 - val_accuracy: 0.6435\n",
      "Epoch 317/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0755 - accuracy: 0.9963 - val_loss: 1.4156 - val_accuracy: 0.6435\n",
      "Epoch 318/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0878 - accuracy: 0.9982 - val_loss: 1.4153 - val_accuracy: 0.6435\n",
      "Epoch 319/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.6435\n",
      "Epoch 320/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0938 - accuracy: 0.9963 - val_loss: 1.4148 - val_accuracy: 0.6435\n",
      "Epoch 321/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0734 - accuracy: 0.9982 - val_loss: 1.4146 - val_accuracy: 0.6435\n",
      "Epoch 322/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.6435\n",
      "Epoch 323/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0878 - accuracy: 0.9945 - val_loss: 1.4143 - val_accuracy: 0.6435\n",
      "Epoch 324/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0846 - accuracy: 0.9982 - val_loss: 1.4142 - val_accuracy: 0.6435\n",
      "Epoch 325/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0865 - accuracy: 0.9945 - val_loss: 1.4142 - val_accuracy: 0.6435\n",
      "Epoch 326/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0924 - accuracy: 0.9963 - val_loss: 1.4141 - val_accuracy: 0.6481\n",
      "Epoch 327/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0714 - accuracy: 0.9963 - val_loss: 1.4139 - val_accuracy: 0.6481\n",
      "Epoch 328/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0784 - accuracy: 0.9945 - val_loss: 1.4138 - val_accuracy: 0.6435\n",
      "Epoch 329/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0750 - accuracy: 0.9982 - val_loss: 1.4137 - val_accuracy: 0.6435\n",
      "Epoch 330/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 1.4135 - val_accuracy: 0.6435\n",
      "Epoch 331/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0785 - accuracy: 0.9982 - val_loss: 1.4134 - val_accuracy: 0.6435\n",
      "Epoch 332/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0772 - accuracy: 0.9982 - val_loss: 1.4132 - val_accuracy: 0.6435\n",
      "Epoch 333/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0862 - accuracy: 0.9982 - val_loss: 1.4130 - val_accuracy: 0.6435\n",
      "Epoch 334/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0601 - accuracy: 0.9982 - val_loss: 1.4127 - val_accuracy: 0.6435\n",
      "Epoch 335/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0867 - accuracy: 0.9945 - val_loss: 1.4125 - val_accuracy: 0.6435\n",
      "Epoch 336/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.4121 - val_accuracy: 0.6435\n",
      "Epoch 337/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0671 - accuracy: 0.9982 - val_loss: 1.4119 - val_accuracy: 0.6435\n",
      "Epoch 338/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0859 - accuracy: 0.9982 - val_loss: 1.4118 - val_accuracy: 0.6435\n",
      "Epoch 339/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0898 - accuracy: 0.9982 - val_loss: 1.4117 - val_accuracy: 0.6435\n",
      "Epoch 340/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0777 - accuracy: 0.9982 - val_loss: 1.4116 - val_accuracy: 0.6435\n",
      "Epoch 341/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1064 - accuracy: 0.9927 - val_loss: 1.4116 - val_accuracy: 0.6435\n",
      "Epoch 342/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.4115 - val_accuracy: 0.6435\n",
      "Epoch 343/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0845 - accuracy: 0.9982 - val_loss: 1.4115 - val_accuracy: 0.6435\n",
      "Epoch 344/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 1.4117 - val_accuracy: 0.6435\n",
      "Epoch 345/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0925 - accuracy: 0.9945 - val_loss: 1.4116 - val_accuracy: 0.6435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0867 - accuracy: 0.9945 - val_loss: 1.4116 - val_accuracy: 0.6435\n",
      "Epoch 347/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0871 - accuracy: 0.9963 - val_loss: 1.4117 - val_accuracy: 0.6435\n",
      "Epoch 348/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 1.4121 - val_accuracy: 0.6435\n",
      "Epoch 349/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0716 - accuracy: 0.9982 - val_loss: 1.4122 - val_accuracy: 0.6435\n",
      "Epoch 350/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0957 - accuracy: 0.9963 - val_loss: 1.4124 - val_accuracy: 0.6435\n",
      "Epoch 351/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0814 - accuracy: 0.9982 - val_loss: 1.4126 - val_accuracy: 0.6435\n",
      "Epoch 352/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0744 - accuracy: 0.9982 - val_loss: 1.4129 - val_accuracy: 0.6389\n",
      "Epoch 353/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1036 - accuracy: 0.9908 - val_loss: 1.4130 - val_accuracy: 0.6389\n",
      "Epoch 354/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.6389\n",
      "Epoch 355/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0697 - accuracy: 0.9982 - val_loss: 1.4136 - val_accuracy: 0.6389\n",
      "Epoch 356/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0726 - accuracy: 0.9982 - val_loss: 1.4137 - val_accuracy: 0.6389\n",
      "Epoch 357/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0723 - accuracy: 0.9982 - val_loss: 1.4138 - val_accuracy: 0.6389\n",
      "Epoch 358/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0730 - accuracy: 0.9982 - val_loss: 1.4139 - val_accuracy: 0.6389\n",
      "Epoch 359/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0844 - accuracy: 0.9945 - val_loss: 1.4141 - val_accuracy: 0.6389\n",
      "Epoch 360/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.6389\n",
      "Epoch 361/400\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.0800 - accuracy: 0.9963 - val_loss: 1.4141 - val_accuracy: 0.6389\n",
      "Epoch 362/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1121 - accuracy: 0.9945 - val_loss: 1.4142 - val_accuracy: 0.6389\n",
      "Epoch 363/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0746 - accuracy: 0.9982 - val_loss: 1.4141 - val_accuracy: 0.6389\n",
      "Epoch 364/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0876 - accuracy: 0.9963 - val_loss: 1.4141 - val_accuracy: 0.6389\n",
      "Epoch 365/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0894 - accuracy: 0.9982 - val_loss: 1.4142 - val_accuracy: 0.6389\n",
      "Epoch 366/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0823 - accuracy: 0.9982 - val_loss: 1.4140 - val_accuracy: 0.6389\n",
      "Epoch 367/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0719 - accuracy: 0.9982 - val_loss: 1.4139 - val_accuracy: 0.6389\n",
      "Epoch 368/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0879 - accuracy: 0.9963 - val_loss: 1.4137 - val_accuracy: 0.6389\n",
      "Epoch 369/400\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.4136 - val_accuracy: 0.6389\n",
      "Epoch 370/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1130 - accuracy: 0.9927 - val_loss: 1.4135 - val_accuracy: 0.6389\n",
      "Epoch 371/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0735 - accuracy: 0.9982 - val_loss: 1.4133 - val_accuracy: 0.6389\n",
      "Epoch 372/400\n",
      "546/546 [==============================] - 0s 171us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.6389\n",
      "Epoch 373/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.6389\n",
      "Epoch 374/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0842 - accuracy: 0.9963 - val_loss: 1.4135 - val_accuracy: 0.6389\n",
      "Epoch 375/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0713 - accuracy: 0.9982 - val_loss: 1.4136 - val_accuracy: 0.6389\n",
      "Epoch 376/400\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 1.4137 - val_accuracy: 0.6389\n",
      "Epoch 377/400\n",
      "546/546 [==============================] - 0s 172us/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 1.4138 - val_accuracy: 0.6389\n",
      "Epoch 378/400\n",
      "546/546 [==============================] - 0s 173us/step - loss: 0.0884 - accuracy: 0.9982 - val_loss: 1.4140 - val_accuracy: 0.6389\n",
      "Epoch 379/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0737 - accuracy: 0.9982 - val_loss: 1.4140 - val_accuracy: 0.6389\n",
      "Epoch 380/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0735 - accuracy: 0.9982 - val_loss: 1.4142 - val_accuracy: 0.6389\n",
      "Epoch 381/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0708 - accuracy: 0.9982 - val_loss: 1.4143 - val_accuracy: 0.6389\n",
      "Epoch 382/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0948 - accuracy: 0.9927 - val_loss: 1.4143 - val_accuracy: 0.6389\n",
      "Epoch 383/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0777 - accuracy: 0.9963 - val_loss: 1.4143 - val_accuracy: 0.6389\n",
      "Epoch 384/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0748 - accuracy: 0.9982 - val_loss: 1.4146 - val_accuracy: 0.6389\n",
      "Epoch 385/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0827 - accuracy: 0.9982 - val_loss: 1.4149 - val_accuracy: 0.6389\n",
      "Epoch 386/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0935 - accuracy: 0.9982 - val_loss: 1.4153 - val_accuracy: 0.6389\n",
      "Epoch 387/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0967 - accuracy: 0.9963 - val_loss: 1.4155 - val_accuracy: 0.6389\n",
      "Epoch 388/400\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.0848 - accuracy: 0.9963 - val_loss: 1.4158 - val_accuracy: 0.6389\n",
      "Epoch 389/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1006 - accuracy: 0.9945 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 390/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0770 - accuracy: 0.9963 - val_loss: 1.4160 - val_accuracy: 0.6389\n",
      "Epoch 391/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0879 - accuracy: 0.9982 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 392/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0940 - accuracy: 0.9963 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 393/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0895 - accuracy: 0.9963 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 394/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.0932 - accuracy: 0.9945 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 395/400\n",
      "546/546 [==============================] - 0s 169us/step - loss: 0.0668 - accuracy: 0.9982 - val_loss: 1.4160 - val_accuracy: 0.6389\n",
      "Epoch 396/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0676 - accuracy: 0.9963 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 397/400\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.0795 - accuracy: 0.9890 - val_loss: 1.4159 - val_accuracy: 0.6389\n",
      "Epoch 398/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.0765 - accuracy: 0.9982 - val_loss: 1.4160 - val_accuracy: 0.6389\n",
      "Epoch 399/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0800 - accuracy: 0.9982 - val_loss: 1.4158 - val_accuracy: 0.6389\n",
      "Epoch 400/400\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.0945 - accuracy: 0.9963 - val_loss: 1.4158 - val_accuracy: 0.6389\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "\n",
    "history1 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=1000,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input),\n",
    "                    sample_weight=sample_weight\n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history2 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=400,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input),\n",
    "                    sample_weight=sample_weight\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# the first 600 epochs\n",
    "plot_accuracy(history1)\n",
    "plot_loss(history1)\n",
    "# the next 500 epochs\n",
    "plot_accuracy(history2)\n",
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = DD_Net.predict([X_test_0, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  2  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  1  0  2  0  1  0  0  0  2  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  3  0  1  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  1  0  3  0  1  0  0  0  0  0  0  0  1  1  0  1  0  0]\n",
      " [ 0  0  0  0  0  2  2  0  0  1  0  2  0  0  0  0  0  0  1  2  0]\n",
      " [ 0  0  0  1  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  8  0  0  0  0  0  1  0  0  1  0]\n",
      " [ 0  0  0  3  0  0  1  0  0  0  0  2  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0  0  1  0  0  7  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0 13  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  2  0  0  0 10  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  8  0  0  0  1]\n",
      " [ 0  9  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  4  0  0  0]\n",
      " [ 0  1  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  4  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  8  0]\n",
      " [ 0  1  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  1  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb2711ffeb8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_pred_cls = np.argmax(Y_test_pred, axis=1)\n",
    "Y_test_cls = np.argmax(Y_test_input, axis=1)\n",
    "Y_test_cls[:10], Y_test_pred_cls[:10]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "normalize= None # 'true'\n",
    "cm = confusion_matrix(Y_test_cls, Y_test_pred_cls, normalize=normalize)\n",
    "print(cm)\n",
    "# print(np.sum(np.diagonal(cm)) / np.sum(cm)) # accuracy\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=le.classes_) #sorted(set(le.inverse_transform(Y_test_cls))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(xticks_rotation=90, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-vs-all AP      class_name  precision  recall  test_size  train_size\n",
      "0         0.459      brush_hair       0.67    0.33        6.0        19.0\n",
      "1         0.260           catch       0.22    0.40       10.0        34.0\n",
      "2         0.940            clap       0.77    0.91       11.0        24.0\n",
      "3         0.352    climb_stairs       0.33    0.43        7.0        27.0\n",
      "4         0.994            golf       0.92    1.00       12.0        30.0\n",
      "5         0.463            jump       0.43    0.33        9.0        19.0\n",
      "6         0.441       kick_ball       0.50    0.20       10.0        22.0\n",
      "7         0.899            pick       0.77    0.91       11.0        20.0\n",
      "8         0.837            pour       0.64    0.82       11.0        36.0\n",
      "9         0.991          pullup       0.88    1.00       14.0        38.0\n",
      "10        0.753            push       0.73    0.73       11.0        19.0\n",
      "11        0.207             run       0.22    0.22        9.0        27.0\n",
      "12        0.848      shoot_ball       0.78    0.78        9.0        18.0\n",
      "13        0.986       shoot_bow       0.93    0.87       15.0        35.0\n",
      "14        0.847       shoot_gun       0.83    0.77       13.0        24.0\n",
      "15        0.789             sit       0.62    0.71        7.0        19.0\n",
      "16        0.783           stand       0.80    0.73       11.0        16.0\n",
      "17        0.679  swing_baseball       0.50    0.27       15.0        39.0\n",
      "18        0.287           throw       0.25    0.22        9.0        31.0\n",
      "19        0.894            walk       0.67    0.89        9.0        26.0\n",
      "20        0.250            wave       0.40    0.29        7.0        23.0\n"
     ]
    }
   ],
   "source": [
    "# other statistics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, cls_name in enumerate(le.classes_):\n",
    "    precision = np.round(cm[i, i] / np.sum(cm[:, i]), 2)\n",
    "    recall = np.round(cm[i, i] / np.sum(cm[i, :]), 2)\n",
    "    train_size =  list(le.inverse_transform(np.argmax(Y_input, axis=1))).count(cls_name)\n",
    "    test_size =  list(le.inverse_transform(np.argmax(Y_test_input, axis=1))).count(cls_name)\n",
    "\n",
    "    ap = average_precision_score(Y_test_input[:, i], Y_test_pred[:, i])\n",
    "        \n",
    "    df = df.append({\n",
    "        'class_name': cls_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'train_size': train_size,\n",
    "        'test_size': test_size,\n",
    "        '1-vs-all AP': ap \n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'jhmdb_openpose_model_15.h5'\n",
    "ddnet.save_DDNet(DD_Net, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_labels(Y_true, Y_pred, le, filenames, labels=['wave']):\n",
    "    assert Y_true.shape[0] == Y_pred.shape[0] == len(filenames)\n",
    "    for yt, yp, fn in zip(Y_true, Y_pred, filenames):\n",
    "        cls_true = np.argmax(yt)\n",
    "        cls_pred = np.argmax(yp)\n",
    "        if le.inverse_transform([cls_true])[0] in labels:\n",
    "            correct = (cls_true == cls_pred)\n",
    "            print(\"{} \\t{}={:.2f} \\t{}={:.2f} \\t{}\".format(\n",
    "                correct,\n",
    "                le.inverse_transform([cls_pred])[0],\n",
    "                np.max(yp),\n",
    "                labels[0],\n",
    "                yp[cls_true],\n",
    "                fn\n",
    "            ))\n",
    "            \n",
    "check_labels(Y_test_input, Y_test_pred, le, Test_undoctored['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit using Training + Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 21) (216, 21)\n",
      "Refit using 762 samples\n",
      "[25 44 35 34 42 28 32 31 47 52 30 36 27 50 37 26 27 54 40 35 30]\n",
      "[2.16       1.22727273 1.54285714 1.58823529 1.28571429 1.92857143\n",
      " 1.6875     1.74193548 1.14893617 1.03846154 1.8        1.5\n",
      " 2.         1.08       1.45945946 2.07692308 2.         1.\n",
      " 1.35       1.54285714 1.8       ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_input.shape, Y_test_input.shape)\n",
    "X_rf_0 = np.concatenate([X_0, X_test_0])\n",
    "X_rf_1 = np.concatenate([X_1, X_test_1])\n",
    "Y_rf = np.concatenate([Y_input, Y_test_input])\n",
    "assert X_rf_0.shape[0] == X_rf_1.shape[0] == Y_rf.shape[0]\n",
    "print(\"Refit using {} samples\".format(Y_rf.shape[0]))\n",
    "rf_sample_weight = get_sample_weight(Y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "762/762 [==============================] - 5s 7ms/step - loss: 5.5851 - accuracy: 0.0564\n",
      "Epoch 2/800\n",
      "762/762 [==============================] - 0s 114us/step - loss: 5.0997 - accuracy: 0.0748\n",
      "Epoch 3/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 4.7201 - accuracy: 0.1168\n",
      "Epoch 4/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 4.4563 - accuracy: 0.1575\n",
      "Epoch 5/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 4.2628 - accuracy: 0.1693\n",
      "Epoch 6/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 4.1836 - accuracy: 0.1903\n",
      "Epoch 7/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 3.9911 - accuracy: 0.1982\n",
      "Epoch 8/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 3.9079 - accuracy: 0.2165\n",
      "Epoch 9/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 3.6456 - accuracy: 0.2612\n",
      "Epoch 10/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 3.5769 - accuracy: 0.2612\n",
      "Epoch 11/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 3.5566 - accuracy: 0.2690\n",
      "Epoch 12/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 3.2733 - accuracy: 0.3360\n",
      "Epoch 13/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 3.2238 - accuracy: 0.3609\n",
      "Epoch 14/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 3.1022 - accuracy: 0.3858\n",
      "Epoch 15/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 2.9167 - accuracy: 0.4068\n",
      "Epoch 16/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 2.8921 - accuracy: 0.4357\n",
      "Epoch 17/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 2.7948 - accuracy: 0.4751\n",
      "Epoch 18/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 2.8151 - accuracy: 0.4501\n",
      "Epoch 19/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 2.6337 - accuracy: 0.4869\n",
      "Epoch 20/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 2.5822 - accuracy: 0.5026\n",
      "Epoch 21/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 2.5990 - accuracy: 0.4974\n",
      "Epoch 22/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 2.4839 - accuracy: 0.5354\n",
      "Epoch 23/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 2.4325 - accuracy: 0.5328\n",
      "Epoch 24/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 2.3416 - accuracy: 0.5538\n",
      "Epoch 25/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 2.2071 - accuracy: 0.5866\n",
      "Epoch 26/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 2.1656 - accuracy: 0.5801\n",
      "Epoch 27/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 2.1285 - accuracy: 0.6050\n",
      "Epoch 28/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 2.0679 - accuracy: 0.6194\n",
      "Epoch 29/800\n",
      "762/762 [==============================] - 0s 87us/step - loss: 1.9732 - accuracy: 0.6339\n",
      "Epoch 30/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 1.9534 - accuracy: 0.6299\n",
      "Epoch 31/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 1.9016 - accuracy: 0.6509\n",
      "Epoch 32/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 1.8839 - accuracy: 0.6535\n",
      "Epoch 33/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 1.7680 - accuracy: 0.6811\n",
      "Epoch 34/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 1.7013 - accuracy: 0.7113\n",
      "Epoch 35/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 1.7633 - accuracy: 0.6890\n",
      "Epoch 36/800\n",
      "762/762 [==============================] - 0s 114us/step - loss: 1.6289 - accuracy: 0.7178\n",
      "Epoch 37/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 1.6539 - accuracy: 0.6982\n",
      "Epoch 38/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 1.5414 - accuracy: 0.7441\n",
      "Epoch 39/800\n",
      "762/762 [==============================] - 0s 122us/step - loss: 1.4964 - accuracy: 0.7362\n",
      "Epoch 40/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 1.3855 - accuracy: 0.7690\n",
      "Epoch 41/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 1.3429 - accuracy: 0.7677\n",
      "Epoch 42/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 1.3704 - accuracy: 0.7559\n",
      "Epoch 43/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 1.3152 - accuracy: 0.7598\n",
      "Epoch 44/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 1.3230 - accuracy: 0.7651\n",
      "Epoch 45/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 1.2808 - accuracy: 0.7822\n",
      "Epoch 46/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 1.2472 - accuracy: 0.7717\n",
      "Epoch 47/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 1.1892 - accuracy: 0.8005\n",
      "Epoch 48/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 1.0885 - accuracy: 0.8281\n",
      "Epoch 49/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 1.1452 - accuracy: 0.8045\n",
      "Epoch 50/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 1.0436 - accuracy: 0.8202\n",
      "Epoch 51/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 1.0493 - accuracy: 0.8268\n",
      "Epoch 52/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.9457 - accuracy: 0.8451\n",
      "Epoch 53/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.9637 - accuracy: 0.8543\n",
      "Epoch 54/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.9341 - accuracy: 0.8609\n",
      "Epoch 55/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.8570 - accuracy: 0.8714\n",
      "Epoch 56/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.8919 - accuracy: 0.8701\n",
      "Epoch 57/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.9141 - accuracy: 0.8412\n",
      "Epoch 58/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.8215 - accuracy: 0.8740\n",
      "Epoch 59/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.7924 - accuracy: 0.8832\n",
      "Epoch 60/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.8131 - accuracy: 0.8661\n",
      "Epoch 61/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.8291 - accuracy: 0.8701\n",
      "Epoch 62/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.7483 - accuracy: 0.8963\n",
      "Epoch 63/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.7177 - accuracy: 0.9003\n",
      "Epoch 64/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.6690 - accuracy: 0.9003\n",
      "Epoch 65/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.7124 - accuracy: 0.8845\n",
      "Epoch 66/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.6751 - accuracy: 0.9173\n",
      "Epoch 67/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.6168 - accuracy: 0.9173\n",
      "Epoch 68/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.6343 - accuracy: 0.9121\n",
      "Epoch 69/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.6163 - accuracy: 0.9016\n",
      "Epoch 70/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.5805 - accuracy: 0.9147\n",
      "Epoch 71/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.5933 - accuracy: 0.9068\n",
      "Epoch 72/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.5963 - accuracy: 0.9252\n",
      "Epoch 73/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.5454 - accuracy: 0.9199\n",
      "Epoch 74/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.4998 - accuracy: 0.9370\n",
      "Epoch 75/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.5185 - accuracy: 0.9304\n",
      "Epoch 76/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.5089 - accuracy: 0.9291\n",
      "Epoch 77/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.4863 - accuracy: 0.9423\n",
      "Epoch 78/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.4939 - accuracy: 0.9396\n",
      "Epoch 79/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.4496 - accuracy: 0.9475\n",
      "Epoch 80/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.3908 - accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.4471 - accuracy: 0.9514\n",
      "Epoch 82/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.3996 - accuracy: 0.9619\n",
      "Epoch 83/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.3832 - accuracy: 0.9659\n",
      "Epoch 84/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.3988 - accuracy: 0.9514\n",
      "Epoch 85/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.4040 - accuracy: 0.9488\n",
      "Epoch 86/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.3785 - accuracy: 0.9646\n",
      "Epoch 87/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.3394 - accuracy: 0.9685\n",
      "Epoch 88/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.3307 - accuracy: 0.9659\n",
      "Epoch 89/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.3849 - accuracy: 0.9554\n",
      "Epoch 90/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.3392 - accuracy: 0.9672\n",
      "Epoch 91/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.2900 - accuracy: 0.9764\n",
      "Epoch 92/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.3180 - accuracy: 0.9698\n",
      "Epoch 93/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.2947 - accuracy: 0.9659\n",
      "Epoch 94/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.3295 - accuracy: 0.9672\n",
      "Epoch 95/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.2726 - accuracy: 0.9751\n",
      "Epoch 96/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.2773 - accuracy: 0.9724\n",
      "Epoch 97/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.3047 - accuracy: 0.9646\n",
      "Epoch 98/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.2687 - accuracy: 0.9685\n",
      "Epoch 99/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.2517 - accuracy: 0.9790\n",
      "Epoch 100/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.2818 - accuracy: 0.9751\n",
      "Epoch 101/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.2519 - accuracy: 0.9751\n",
      "Epoch 102/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.2491 - accuracy: 0.9803\n",
      "Epoch 103/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.2374 - accuracy: 0.9829\n",
      "Epoch 104/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.2478 - accuracy: 0.9764\n",
      "Epoch 105/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.2322 - accuracy: 0.9738\n",
      "Epoch 106/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.2354 - accuracy: 0.9738\n",
      "Epoch 107/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.2143 - accuracy: 0.9856\n",
      "Epoch 108/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.2275 - accuracy: 0.9816\n",
      "Epoch 109/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1879 - accuracy: 0.9908\n",
      "Epoch 110/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1984 - accuracy: 0.9829\n",
      "Epoch 111/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1926 - accuracy: 0.9856\n",
      "Epoch 112/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.2065 - accuracy: 0.9816\n",
      "Epoch 113/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1694 - accuracy: 0.9869\n",
      "Epoch 114/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.2043 - accuracy: 0.9816\n",
      "Epoch 115/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1892 - accuracy: 0.9816\n",
      "Epoch 116/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1745 - accuracy: 0.9934\n",
      "Epoch 117/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1764 - accuracy: 0.9908\n",
      "Epoch 118/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1948 - accuracy: 0.9869\n",
      "Epoch 119/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1820 - accuracy: 0.9843\n",
      "Epoch 120/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1544 - accuracy: 0.9908\n",
      "Epoch 121/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1658 - accuracy: 0.9856\n",
      "Epoch 122/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1776 - accuracy: 0.9843\n",
      "Epoch 123/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1805 - accuracy: 0.9869\n",
      "Epoch 124/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1553 - accuracy: 0.9895\n",
      "Epoch 125/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1666 - accuracy: 0.9882\n",
      "Epoch 126/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1682 - accuracy: 0.9843\n",
      "Epoch 127/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1670 - accuracy: 0.9908\n",
      "Epoch 128/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1560 - accuracy: 0.9908\n",
      "Epoch 129/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1362 - accuracy: 0.9921\n",
      "Epoch 130/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1703 - accuracy: 0.9803\n",
      "Epoch 131/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1465 - accuracy: 0.9869\n",
      "Epoch 132/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1481 - accuracy: 0.9882\n",
      "Epoch 133/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1405 - accuracy: 0.9908\n",
      "Epoch 134/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1409 - accuracy: 0.9908\n",
      "Epoch 135/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1366 - accuracy: 0.9921\n",
      "Epoch 136/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1629 - accuracy: 0.9843\n",
      "Epoch 137/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1424 - accuracy: 0.9934\n",
      "Epoch 138/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1398 - accuracy: 0.9908\n",
      "Epoch 139/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1497 - accuracy: 0.9948\n",
      "Epoch 140/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1563 - accuracy: 0.9908\n",
      "Epoch 141/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1513 - accuracy: 0.9934\n",
      "Epoch 142/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1242 - accuracy: 0.9961\n",
      "Epoch 143/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1268 - accuracy: 0.9921\n",
      "Epoch 144/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1369 - accuracy: 0.9908\n",
      "Epoch 145/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1436 - accuracy: 0.9882\n",
      "Epoch 146/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1181 - accuracy: 0.9934\n",
      "Epoch 147/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1259 - accuracy: 0.9882\n",
      "Epoch 148/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1319 - accuracy: 0.9948\n",
      "Epoch 149/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1350 - accuracy: 0.9921\n",
      "Epoch 150/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1508 - accuracy: 0.9882\n",
      "Epoch 151/800\n",
      "762/762 [==============================] - 0s 131us/step - loss: 0.1364 - accuracy: 0.9908\n",
      "Epoch 152/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1304 - accuracy: 0.9921\n",
      "Epoch 153/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1298 - accuracy: 0.9948\n",
      "Epoch 154/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1350 - accuracy: 0.9895\n",
      "Epoch 155/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1246 - accuracy: 0.9908\n",
      "Epoch 156/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1408 - accuracy: 0.9908\n",
      "Epoch 157/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1396 - accuracy: 0.9908\n",
      "Epoch 158/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1491 - accuracy: 0.9856\n",
      "Epoch 159/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1294 - accuracy: 0.9908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1382 - accuracy: 0.9869\n",
      "Epoch 161/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1312 - accuracy: 0.9948\n",
      "Epoch 162/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1479 - accuracy: 0.9921\n",
      "Epoch 163/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1182 - accuracy: 0.9921\n",
      "Epoch 164/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1355 - accuracy: 0.9908\n",
      "Epoch 165/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1328 - accuracy: 0.9908\n",
      "Epoch 166/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1137 - accuracy: 0.9974\n",
      "Epoch 167/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1187 - accuracy: 0.9974\n",
      "Epoch 168/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1328 - accuracy: 0.9934\n",
      "Epoch 169/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1368 - accuracy: 0.9921\n",
      "Epoch 170/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1366 - accuracy: 0.9908\n",
      "Epoch 171/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1318 - accuracy: 0.9869\n",
      "Epoch 172/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1273 - accuracy: 0.9948\n",
      "Epoch 173/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1374 - accuracy: 0.9856\n",
      "Epoch 174/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1281 - accuracy: 0.9921\n",
      "Epoch 175/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1118 - accuracy: 0.9987\n",
      "Epoch 176/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1379 - accuracy: 0.9921\n",
      "Epoch 177/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1217 - accuracy: 0.9934\n",
      "Epoch 178/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1306 - accuracy: 0.9948\n",
      "Epoch 179/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1300 - accuracy: 0.9948\n",
      "Epoch 180/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1154 - accuracy: 0.9961\n",
      "Epoch 181/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1222 - accuracy: 0.9921\n",
      "Epoch 182/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1308 - accuracy: 0.9948\n",
      "Epoch 183/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1202 - accuracy: 0.9974\n",
      "Epoch 184/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1394 - accuracy: 0.9895\n",
      "Epoch 185/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1247 - accuracy: 0.9934\n",
      "Epoch 186/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1227 - accuracy: 0.9961\n",
      "Epoch 187/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1299 - accuracy: 0.9921\n",
      "Epoch 188/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1396 - accuracy: 0.9908\n",
      "Epoch 189/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1183 - accuracy: 0.9934\n",
      "Epoch 190/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1358 - accuracy: 0.9908\n",
      "Epoch 191/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1308 - accuracy: 0.9908\n",
      "Epoch 192/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1264 - accuracy: 0.9908\n",
      "Epoch 193/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1545 - accuracy: 0.9869\n",
      "Epoch 194/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1336 - accuracy: 0.9961\n",
      "Epoch 195/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1338 - accuracy: 0.9961\n",
      "Epoch 196/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1208 - accuracy: 0.9948\n",
      "Epoch 197/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1363 - accuracy: 0.9921\n",
      "Epoch 198/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1313 - accuracy: 0.9948\n",
      "Epoch 199/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1322 - accuracy: 0.9908\n",
      "Epoch 200/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1253 - accuracy: 0.9934\n",
      "Epoch 201/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1323 - accuracy: 0.9895\n",
      "Epoch 202/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1300 - accuracy: 0.9882\n",
      "Epoch 203/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1488 - accuracy: 0.9869\n",
      "Epoch 204/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1328 - accuracy: 0.9908\n",
      "Epoch 205/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1129 - accuracy: 0.9934\n",
      "Epoch 206/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1330 - accuracy: 0.9948\n",
      "Epoch 207/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1274 - accuracy: 0.9948\n",
      "Epoch 208/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1295 - accuracy: 0.9869\n",
      "Epoch 209/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1225 - accuracy: 0.9961\n",
      "Epoch 210/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1363 - accuracy: 0.9921\n",
      "Epoch 211/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1074 - accuracy: 0.9948\n",
      "Epoch 212/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1369 - accuracy: 0.9934\n",
      "Epoch 213/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1101 - accuracy: 0.9974\n",
      "Epoch 214/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1406 - accuracy: 0.9934\n",
      "Epoch 215/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1082 - accuracy: 0.9948\n",
      "Epoch 216/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1376 - accuracy: 0.9974\n",
      "Epoch 217/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1327 - accuracy: 0.9934\n",
      "Epoch 218/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1486 - accuracy: 0.9895\n",
      "Epoch 219/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1199 - accuracy: 1.0000\n",
      "Epoch 220/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1244 - accuracy: 0.9948\n",
      "Epoch 221/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1210 - accuracy: 0.9921\n",
      "Epoch 222/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1247 - accuracy: 0.9934\n",
      "Epoch 223/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1306 - accuracy: 0.9934\n",
      "Epoch 224/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1113 - accuracy: 0.9948\n",
      "Epoch 225/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1272 - accuracy: 0.9934\n",
      "Epoch 226/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1193 - accuracy: 0.9948\n",
      "Epoch 227/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1434 - accuracy: 0.9882\n",
      "Epoch 228/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1476 - accuracy: 0.9882\n",
      "Epoch 229/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1304 - accuracy: 0.9921\n",
      "Epoch 230/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1415 - accuracy: 0.9921\n",
      "Epoch 231/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1334 - accuracy: 0.9961\n",
      "Epoch 232/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1294 - accuracy: 0.9908\n",
      "Epoch 233/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1231 - accuracy: 0.9934\n",
      "Epoch 234/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1143 - accuracy: 0.9974\n",
      "Epoch 235/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1173 - accuracy: 0.9921\n",
      "Epoch 236/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1364 - accuracy: 0.9921\n",
      "Epoch 237/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1453 - accuracy: 0.9921\n",
      "Epoch 238/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1105 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1276 - accuracy: 0.9934\n",
      "Epoch 240/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1411 - accuracy: 0.9882\n",
      "Epoch 241/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1290 - accuracy: 0.9921\n",
      "Epoch 242/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1280 - accuracy: 0.9921\n",
      "Epoch 243/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1230 - accuracy: 0.9948\n",
      "Epoch 244/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1276 - accuracy: 0.9961\n",
      "Epoch 245/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1116 - accuracy: 0.9974\n",
      "Epoch 246/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1161 - accuracy: 0.9974\n",
      "Epoch 247/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1074 - accuracy: 0.9987\n",
      "Epoch 248/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1262 - accuracy: 0.9921\n",
      "Epoch 249/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1338 - accuracy: 0.9948\n",
      "Epoch 250/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1126 - accuracy: 0.9921\n",
      "Epoch 251/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1137 - accuracy: 0.9961\n",
      "Epoch 252/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1238 - accuracy: 0.9934\n",
      "Epoch 253/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1423 - accuracy: 0.9895\n",
      "Epoch 254/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1250 - accuracy: 0.9921\n",
      "Epoch 255/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1439 - accuracy: 0.9934\n",
      "Epoch 256/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1366 - accuracy: 0.9921\n",
      "Epoch 257/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1237 - accuracy: 0.9908\n",
      "Epoch 258/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1485 - accuracy: 0.9882\n",
      "Epoch 259/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1426 - accuracy: 0.9895\n",
      "Epoch 260/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1453 - accuracy: 0.9908\n",
      "Epoch 261/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1147 - accuracy: 0.9882\n",
      "Epoch 262/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1309 - accuracy: 0.9934\n",
      "Epoch 263/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1425 - accuracy: 0.9921\n",
      "Epoch 264/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1417 - accuracy: 0.9829\n",
      "Epoch 265/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1389 - accuracy: 0.9934\n",
      "Epoch 266/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1234 - accuracy: 0.9948\n",
      "Epoch 267/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1144 - accuracy: 0.9948\n",
      "Epoch 268/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1397 - accuracy: 0.9948\n",
      "Epoch 269/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1293 - accuracy: 0.9948\n",
      "Epoch 270/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1206 - accuracy: 0.9974\n",
      "Epoch 271/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1395 - accuracy: 0.9934\n",
      "Epoch 272/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1343 - accuracy: 0.9908\n",
      "Epoch 273/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1362 - accuracy: 0.9895\n",
      "Epoch 274/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1175 - accuracy: 0.9934\n",
      "Epoch 275/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1280 - accuracy: 0.9921\n",
      "Epoch 276/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1379 - accuracy: 0.9948\n",
      "Epoch 277/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1254 - accuracy: 0.9921\n",
      "Epoch 278/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1355 - accuracy: 0.9908\n",
      "Epoch 279/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1264 - accuracy: 0.9948\n",
      "Epoch 280/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1152 - accuracy: 0.9921\n",
      "Epoch 281/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1351 - accuracy: 0.9934\n",
      "Epoch 282/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1238 - accuracy: 0.9921\n",
      "Epoch 283/800\n",
      "762/762 [==============================] - 0s 87us/step - loss: 0.1305 - accuracy: 0.9934\n",
      "Epoch 284/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1408 - accuracy: 0.9934\n",
      "Epoch 285/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1463 - accuracy: 0.9856\n",
      "Epoch 286/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1192 - accuracy: 0.9934\n",
      "Epoch 287/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1382 - accuracy: 0.9882\n",
      "Epoch 288/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1171 - accuracy: 0.9908\n",
      "Epoch 289/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1253 - accuracy: 0.9908\n",
      "Epoch 290/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1196 - accuracy: 0.9961\n",
      "Epoch 291/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1038 - accuracy: 0.9974\n",
      "Epoch 292/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1187 - accuracy: 0.9934\n",
      "Epoch 293/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1401 - accuracy: 0.9882\n",
      "Epoch 294/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1215 - accuracy: 0.9921\n",
      "Epoch 295/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1355 - accuracy: 0.9921\n",
      "Epoch 296/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1201 - accuracy: 0.9974\n",
      "Epoch 297/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1236 - accuracy: 0.9974\n",
      "Epoch 298/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1387 - accuracy: 0.9908\n",
      "Epoch 299/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1230 - accuracy: 0.9961\n",
      "Epoch 300/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1284 - accuracy: 0.9921\n",
      "Epoch 301/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1296 - accuracy: 0.9961\n",
      "Epoch 302/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1360 - accuracy: 0.9921\n",
      "Epoch 303/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1339 - accuracy: 0.9934\n",
      "Epoch 304/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1269 - accuracy: 0.9869\n",
      "Epoch 305/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1247 - accuracy: 0.9974\n",
      "Epoch 306/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1125 - accuracy: 0.9961\n",
      "Epoch 307/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1206 - accuracy: 0.9961\n",
      "Epoch 308/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1133 - accuracy: 0.9948\n",
      "Epoch 309/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1253 - accuracy: 0.9921\n",
      "Epoch 310/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1169 - accuracy: 0.9934\n",
      "Epoch 311/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1549 - accuracy: 0.9869\n",
      "Epoch 312/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1107 - accuracy: 0.9961\n",
      "Epoch 313/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1166 - accuracy: 0.9974\n",
      "Epoch 314/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1322 - accuracy: 0.9895\n",
      "Epoch 315/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1344 - accuracy: 0.9908\n",
      "Epoch 316/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1213 - accuracy: 0.9921\n",
      "Epoch 317/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1167 - accuracy: 0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1262 - accuracy: 0.9948\n",
      "Epoch 319/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1038 - accuracy: 0.9974\n",
      "Epoch 320/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1097 - accuracy: 0.9961\n",
      "Epoch 321/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1260 - accuracy: 0.9908\n",
      "Epoch 322/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1264 - accuracy: 0.9948\n",
      "Epoch 323/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1235 - accuracy: 0.9934\n",
      "Epoch 324/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1149 - accuracy: 0.9921\n",
      "Epoch 325/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1404 - accuracy: 0.9948\n",
      "Epoch 326/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1317 - accuracy: 0.9908\n",
      "Epoch 327/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1322 - accuracy: 0.9882\n",
      "Epoch 328/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1432 - accuracy: 0.9921\n",
      "Epoch 329/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1212 - accuracy: 0.9921\n",
      "Epoch 330/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1136 - accuracy: 0.9934\n",
      "Epoch 331/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1343 - accuracy: 0.9829\n",
      "Epoch 332/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1275 - accuracy: 0.9934\n",
      "Epoch 333/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1278 - accuracy: 0.9948\n",
      "Epoch 334/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1282 - accuracy: 0.9948\n",
      "Epoch 335/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1234 - accuracy: 0.9948\n",
      "Epoch 336/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0976 - accuracy: 0.9987\n",
      "Epoch 337/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1280 - accuracy: 0.9934\n",
      "Epoch 338/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1337 - accuracy: 0.9882\n",
      "Epoch 339/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1476 - accuracy: 0.9921\n",
      "Epoch 340/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1334 - accuracy: 0.9908\n",
      "Epoch 341/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1260 - accuracy: 0.9948\n",
      "Epoch 342/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1150 - accuracy: 0.9974\n",
      "Epoch 343/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1224 - accuracy: 0.9948\n",
      "Epoch 344/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1445 - accuracy: 0.9856\n",
      "Epoch 345/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1325 - accuracy: 0.9934\n",
      "Epoch 346/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1340 - accuracy: 0.9882\n",
      "Epoch 347/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1300 - accuracy: 0.9921\n",
      "Epoch 348/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1232 - accuracy: 0.9974\n",
      "Epoch 349/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1421 - accuracy: 0.9895\n",
      "Epoch 350/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1144 - accuracy: 0.9974\n",
      "Epoch 351/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1302 - accuracy: 0.9934\n",
      "Epoch 352/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1175 - accuracy: 0.9948\n",
      "Epoch 353/800\n",
      "762/762 [==============================] - 0s 118us/step - loss: 0.1204 - accuracy: 0.9934\n",
      "Epoch 354/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1183 - accuracy: 0.9948\n",
      "Epoch 355/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1199 - accuracy: 0.9921\n",
      "Epoch 356/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1259 - accuracy: 0.9948\n",
      "Epoch 357/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1188 - accuracy: 0.9921\n",
      "Epoch 358/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1246 - accuracy: 0.9961\n",
      "Epoch 359/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1274 - accuracy: 0.9948\n",
      "Epoch 360/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1309 - accuracy: 0.9908\n",
      "Epoch 361/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1240 - accuracy: 0.9921\n",
      "Epoch 362/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1269 - accuracy: 0.9908\n",
      "Epoch 363/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1175 - accuracy: 0.9948\n",
      "Epoch 364/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1187 - accuracy: 0.9908\n",
      "Epoch 365/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1309 - accuracy: 0.9908\n",
      "Epoch 366/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1266 - accuracy: 0.9921\n",
      "Epoch 367/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1125 - accuracy: 0.9948\n",
      "Epoch 368/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1076 - accuracy: 0.9934\n",
      "Epoch 369/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1272 - accuracy: 0.9869\n",
      "Epoch 370/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1120 - accuracy: 0.9961\n",
      "Epoch 371/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1429 - accuracy: 0.9882\n",
      "Epoch 372/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1273 - accuracy: 0.9921\n",
      "Epoch 373/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1240 - accuracy: 0.9948\n",
      "Epoch 374/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1331 - accuracy: 0.9895\n",
      "Epoch 375/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1234 - accuracy: 0.9921\n",
      "Epoch 376/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1236 - accuracy: 0.9934\n",
      "Epoch 377/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1030 - accuracy: 0.9987\n",
      "Epoch 378/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1195 - accuracy: 0.9908\n",
      "Epoch 379/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1169 - accuracy: 0.9974\n",
      "Epoch 380/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1114 - accuracy: 0.9974\n",
      "Epoch 381/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1073 - accuracy: 0.9948\n",
      "Epoch 382/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1322 - accuracy: 0.9882\n",
      "Epoch 383/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1306 - accuracy: 0.9948\n",
      "Epoch 384/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1345 - accuracy: 0.9948\n",
      "Epoch 385/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1103 - accuracy: 0.9974\n",
      "Epoch 386/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1201 - accuracy: 0.9948\n",
      "Epoch 387/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1053 - accuracy: 0.9948\n",
      "Epoch 388/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1365 - accuracy: 0.9908\n",
      "Epoch 389/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1195 - accuracy: 0.9961\n",
      "Epoch 390/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1415 - accuracy: 0.9934\n",
      "Epoch 391/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1310 - accuracy: 0.9961\n",
      "Epoch 392/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1184 - accuracy: 0.9895\n",
      "Epoch 393/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1300 - accuracy: 0.9908\n",
      "Epoch 394/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1123 - accuracy: 0.9934\n",
      "Epoch 395/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1291 - accuracy: 0.9934\n",
      "Epoch 396/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1219 - accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1132 - accuracy: 0.9961\n",
      "Epoch 398/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1079 - accuracy: 0.9921\n",
      "Epoch 399/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1278 - accuracy: 0.9882\n",
      "Epoch 400/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1194 - accuracy: 0.9869\n",
      "Epoch 401/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1213 - accuracy: 0.9895\n",
      "Epoch 402/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1251 - accuracy: 0.9948\n",
      "Epoch 403/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1314 - accuracy: 0.9934\n",
      "Epoch 404/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1369 - accuracy: 0.9908\n",
      "Epoch 405/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.0996 - accuracy: 0.9961\n",
      "Epoch 406/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1257 - accuracy: 0.9921\n",
      "Epoch 407/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1028 - accuracy: 0.9974\n",
      "Epoch 408/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1221 - accuracy: 0.9948\n",
      "Epoch 409/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1326 - accuracy: 0.9961\n",
      "Epoch 410/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1082 - accuracy: 0.9987\n",
      "Epoch 411/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1191 - accuracy: 0.9934\n",
      "Epoch 412/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1089 - accuracy: 0.9961\n",
      "Epoch 413/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1385 - accuracy: 0.9961\n",
      "Epoch 414/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1171 - accuracy: 0.9895\n",
      "Epoch 415/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1188 - accuracy: 0.9934\n",
      "Epoch 416/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1354 - accuracy: 0.9934\n",
      "Epoch 417/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1181 - accuracy: 0.9948\n",
      "Epoch 418/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1412 - accuracy: 0.9921\n",
      "Epoch 419/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1449 - accuracy: 0.9882\n",
      "Epoch 420/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1254 - accuracy: 0.9934\n",
      "Epoch 421/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1221 - accuracy: 0.9908\n",
      "Epoch 422/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1101 - accuracy: 0.9974\n",
      "Epoch 423/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1183 - accuracy: 0.9948\n",
      "Epoch 424/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1230 - accuracy: 0.9921\n",
      "Epoch 425/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1244 - accuracy: 0.9934\n",
      "Epoch 426/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1229 - accuracy: 0.9934\n",
      "Epoch 427/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1203 - accuracy: 0.9974\n",
      "Epoch 428/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1264 - accuracy: 0.9934\n",
      "Epoch 429/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1269 - accuracy: 0.9921\n",
      "Epoch 430/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1159 - accuracy: 0.9921\n",
      "Epoch 431/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1283 - accuracy: 0.9934\n",
      "Epoch 432/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1264 - accuracy: 0.9961\n",
      "Epoch 433/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1333 - accuracy: 0.9921\n",
      "Epoch 434/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1147 - accuracy: 1.0000\n",
      "Epoch 435/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1250 - accuracy: 0.9934\n",
      "Epoch 436/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1294 - accuracy: 0.9895\n",
      "Epoch 437/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1236 - accuracy: 0.9921\n",
      "Epoch 438/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1174 - accuracy: 0.9974\n",
      "Epoch 439/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1340 - accuracy: 0.9908\n",
      "Epoch 440/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1131 - accuracy: 0.9934\n",
      "Epoch 441/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1161 - accuracy: 0.9921\n",
      "Epoch 442/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1251 - accuracy: 0.9908\n",
      "Epoch 443/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1266 - accuracy: 0.9908\n",
      "Epoch 444/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1364 - accuracy: 0.9908\n",
      "Epoch 445/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1141 - accuracy: 0.9934\n",
      "Epoch 446/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1300 - accuracy: 0.9948\n",
      "Epoch 447/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1313 - accuracy: 0.9948\n",
      "Epoch 448/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1102 - accuracy: 0.9961\n",
      "Epoch 449/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1460 - accuracy: 0.9948\n",
      "Epoch 450/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1082 - accuracy: 0.9934\n",
      "Epoch 451/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1150 - accuracy: 0.9934\n",
      "Epoch 452/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1306 - accuracy: 0.9908\n",
      "Epoch 453/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1264 - accuracy: 0.9921\n",
      "Epoch 454/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1241 - accuracy: 0.9948\n",
      "Epoch 455/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1080 - accuracy: 0.9948\n",
      "Epoch 456/800\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1206 - accuracy: 0.9908\n",
      "Epoch 457/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1129 - accuracy: 0.9934\n",
      "Epoch 458/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1354 - accuracy: 0.9882\n",
      "Epoch 459/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1068 - accuracy: 0.9948\n",
      "Epoch 460/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1348 - accuracy: 0.9921\n",
      "Epoch 461/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1324 - accuracy: 0.9948\n",
      "Epoch 462/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1311 - accuracy: 0.9908\n",
      "Epoch 463/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1114 - accuracy: 0.9948\n",
      "Epoch 464/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1136 - accuracy: 0.9948\n",
      "Epoch 465/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1066 - accuracy: 0.9987\n",
      "Epoch 466/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1228 - accuracy: 0.9921\n",
      "Epoch 467/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1154 - accuracy: 0.9961\n",
      "Epoch 468/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1442 - accuracy: 0.9882\n",
      "Epoch 469/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1019 - accuracy: 0.9974\n",
      "Epoch 470/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1362 - accuracy: 0.9948\n",
      "Epoch 471/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1253 - accuracy: 0.9934\n",
      "Epoch 472/800\n",
      "762/762 [==============================] - 0s 118us/step - loss: 0.1355 - accuracy: 0.9974\n",
      "Epoch 473/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1184 - accuracy: 0.9948\n",
      "Epoch 474/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1178 - accuracy: 0.9948\n",
      "Epoch 475/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1067 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1231 - accuracy: 0.9921\n",
      "Epoch 477/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1184 - accuracy: 0.9921\n",
      "Epoch 478/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1251 - accuracy: 0.9961\n",
      "Epoch 479/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1285 - accuracy: 0.9948\n",
      "Epoch 480/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1136 - accuracy: 0.9921\n",
      "Epoch 481/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1155 - accuracy: 0.9948\n",
      "Epoch 482/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1255 - accuracy: 0.9934\n",
      "Epoch 483/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1281 - accuracy: 0.9934\n",
      "Epoch 484/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1102 - accuracy: 0.9948\n",
      "Epoch 485/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1234 - accuracy: 0.9948\n",
      "Epoch 486/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1190 - accuracy: 0.9934\n",
      "Epoch 487/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1299 - accuracy: 0.9934\n",
      "Epoch 488/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1192 - accuracy: 0.9934\n",
      "Epoch 489/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1183 - accuracy: 0.9961\n",
      "Epoch 490/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1269 - accuracy: 0.9895\n",
      "Epoch 491/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1316 - accuracy: 0.9908\n",
      "Epoch 492/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1317 - accuracy: 0.9934\n",
      "Epoch 493/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1140 - accuracy: 0.9921\n",
      "Epoch 494/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1037 - accuracy: 0.9948\n",
      "Epoch 495/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1007 - accuracy: 0.9974\n",
      "Epoch 496/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1067 - accuracy: 0.9921\n",
      "Epoch 497/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1364 - accuracy: 0.9895\n",
      "Epoch 498/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1132 - accuracy: 0.9961\n",
      "Epoch 499/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1112 - accuracy: 0.9961\n",
      "Epoch 500/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1268 - accuracy: 0.9882\n",
      "Epoch 501/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1252 - accuracy: 0.9934\n",
      "Epoch 502/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1170 - accuracy: 0.9908\n",
      "Epoch 503/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1204 - accuracy: 0.9908\n",
      "Epoch 504/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1069 - accuracy: 0.9961\n",
      "Epoch 505/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1236 - accuracy: 0.9882\n",
      "Epoch 506/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1488 - accuracy: 0.9869\n",
      "Epoch 507/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1258 - accuracy: 0.9948\n",
      "Epoch 508/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1059 - accuracy: 0.9934\n",
      "Epoch 509/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1133 - accuracy: 0.9948\n",
      "Epoch 510/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1332 - accuracy: 0.9869\n",
      "Epoch 511/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1087 - accuracy: 0.9974\n",
      "Epoch 512/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1132 - accuracy: 0.9921\n",
      "Epoch 513/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1149 - accuracy: 0.9974\n",
      "Epoch 514/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1320 - accuracy: 0.9961\n",
      "Epoch 515/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1353 - accuracy: 0.9895\n",
      "Epoch 516/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1148 - accuracy: 0.9961\n",
      "Epoch 517/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1167 - accuracy: 0.9948\n",
      "Epoch 518/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1171 - accuracy: 0.9921\n",
      "Epoch 519/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1043 - accuracy: 0.9961\n",
      "Epoch 520/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1168 - accuracy: 0.9934\n",
      "Epoch 521/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1283 - accuracy: 0.9882\n",
      "Epoch 522/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1069 - accuracy: 0.9974\n",
      "Epoch 523/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1234 - accuracy: 0.9921\n",
      "Epoch 524/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1195 - accuracy: 0.9934\n",
      "Epoch 525/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1214 - accuracy: 0.9934\n",
      "Epoch 526/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1203 - accuracy: 0.9934\n",
      "Epoch 527/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1165 - accuracy: 0.9882\n",
      "Epoch 528/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1140 - accuracy: 0.9934\n",
      "Epoch 529/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1194 - accuracy: 0.9921\n",
      "Epoch 530/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1194 - accuracy: 0.9934\n",
      "Epoch 531/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1009 - accuracy: 0.9961\n",
      "Epoch 532/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1326 - accuracy: 0.9895\n",
      "Epoch 533/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0948 - accuracy: 0.9974\n",
      "Epoch 534/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1019 - accuracy: 1.0000\n",
      "Epoch 535/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1364 - accuracy: 0.9882\n",
      "Epoch 536/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1086 - accuracy: 0.9974\n",
      "Epoch 537/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1299 - accuracy: 0.9961\n",
      "Epoch 538/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1159 - accuracy: 0.9934\n",
      "Epoch 539/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1175 - accuracy: 0.9961\n",
      "Epoch 540/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1209 - accuracy: 0.9948\n",
      "Epoch 541/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1505 - accuracy: 0.9895\n",
      "Epoch 542/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1159 - accuracy: 0.9895\n",
      "Epoch 543/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1282 - accuracy: 0.9908\n",
      "Epoch 544/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1155 - accuracy: 0.9921\n",
      "Epoch 545/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1310 - accuracy: 0.9948\n",
      "Epoch 546/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1224 - accuracy: 0.9948\n",
      "Epoch 547/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1117 - accuracy: 0.9934\n",
      "Epoch 548/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1129 - accuracy: 0.9961\n",
      "Epoch 549/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1317 - accuracy: 0.9921\n",
      "Epoch 550/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1127 - accuracy: 0.9882\n",
      "Epoch 551/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1094 - accuracy: 0.9948\n",
      "Epoch 552/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1379 - accuracy: 0.9882\n",
      "Epoch 553/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1216 - accuracy: 0.9921\n",
      "Epoch 554/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1110 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1186 - accuracy: 0.9948\n",
      "Epoch 556/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1212 - accuracy: 0.9934\n",
      "Epoch 557/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1279 - accuracy: 0.9895\n",
      "Epoch 558/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1075 - accuracy: 0.9934\n",
      "Epoch 559/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1389 - accuracy: 0.9921\n",
      "Epoch 560/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1127 - accuracy: 0.9934\n",
      "Epoch 561/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1112 - accuracy: 0.9948\n",
      "Epoch 562/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1240 - accuracy: 0.9934\n",
      "Epoch 563/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1236 - accuracy: 0.9961\n",
      "Epoch 564/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1197 - accuracy: 0.9948\n",
      "Epoch 565/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1124 - accuracy: 0.9974\n",
      "Epoch 566/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1108 - accuracy: 0.9948\n",
      "Epoch 567/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1323 - accuracy: 0.9882\n",
      "Epoch 568/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1255 - accuracy: 0.9948\n",
      "Epoch 569/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1180 - accuracy: 0.9908\n",
      "Epoch 570/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1197 - accuracy: 0.9948\n",
      "Epoch 571/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1303 - accuracy: 0.9961\n",
      "Epoch 572/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1279 - accuracy: 0.9934\n",
      "Epoch 573/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0929 - accuracy: 0.9974\n",
      "Epoch 574/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1104 - accuracy: 0.9961\n",
      "Epoch 575/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1330 - accuracy: 0.9895\n",
      "Epoch 576/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1115 - accuracy: 0.9961\n",
      "Epoch 577/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1029 - accuracy: 0.9895\n",
      "Epoch 578/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1112 - accuracy: 0.9974\n",
      "Epoch 579/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1280 - accuracy: 0.9961\n",
      "Epoch 580/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1120 - accuracy: 0.9987\n",
      "Epoch 581/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1081 - accuracy: 0.9987\n",
      "Epoch 582/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1153 - accuracy: 0.9948\n",
      "Epoch 583/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0951 - accuracy: 1.0000\n",
      "Epoch 584/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1164 - accuracy: 0.9934\n",
      "Epoch 585/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1039 - accuracy: 0.9961\n",
      "Epoch 586/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1054 - accuracy: 0.9961\n",
      "Epoch 587/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1174 - accuracy: 0.9882\n",
      "Epoch 588/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1221 - accuracy: 0.9869\n",
      "Epoch 589/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1162 - accuracy: 0.9934\n",
      "Epoch 590/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1218 - accuracy: 0.9934\n",
      "Epoch 591/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1159 - accuracy: 0.9921\n",
      "Epoch 592/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1134 - accuracy: 0.9948\n",
      "Epoch 593/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1197 - accuracy: 0.9948\n",
      "Epoch 594/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1169 - accuracy: 0.9934\n",
      "Epoch 595/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1160 - accuracy: 0.9921\n",
      "Epoch 596/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1039 - accuracy: 0.9961\n",
      "Epoch 597/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1161 - accuracy: 0.9948\n",
      "Epoch 598/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1040 - accuracy: 0.9934\n",
      "Epoch 599/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1131 - accuracy: 0.9908\n",
      "Epoch 600/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0987 - accuracy: 0.9974\n",
      "Epoch 601/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1092 - accuracy: 0.9961\n",
      "Epoch 602/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1243 - accuracy: 0.9934\n",
      "Epoch 603/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1117 - accuracy: 0.9961\n",
      "Epoch 604/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1131 - accuracy: 0.9948\n",
      "Epoch 605/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1195 - accuracy: 0.9948\n",
      "Epoch 606/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1255 - accuracy: 0.9921\n",
      "Epoch 607/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1219 - accuracy: 0.9948\n",
      "Epoch 608/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1231 - accuracy: 0.9934\n",
      "Epoch 609/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1178 - accuracy: 0.9921\n",
      "Epoch 610/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1111 - accuracy: 0.9948\n",
      "Epoch 611/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1041 - accuracy: 0.9948\n",
      "Epoch 612/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1078 - accuracy: 0.9921\n",
      "Epoch 613/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1128 - accuracy: 0.9934\n",
      "Epoch 614/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1524 - accuracy: 0.9869\n",
      "Epoch 615/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1131 - accuracy: 0.9974\n",
      "Epoch 616/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1170 - accuracy: 0.9948\n",
      "Epoch 617/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1174 - accuracy: 0.9908\n",
      "Epoch 618/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1025 - accuracy: 0.9948\n",
      "Epoch 619/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1255 - accuracy: 0.9934\n",
      "Epoch 620/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1076 - accuracy: 0.9961\n",
      "Epoch 621/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1184 - accuracy: 0.9948\n",
      "Epoch 622/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1023 - accuracy: 0.9934\n",
      "Epoch 623/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1202 - accuracy: 0.9908\n",
      "Epoch 624/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1233 - accuracy: 0.9921\n",
      "Epoch 625/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1192 - accuracy: 0.9934\n",
      "Epoch 626/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1034 - accuracy: 1.0000\n",
      "Epoch 627/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1129 - accuracy: 0.9934\n",
      "Epoch 628/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1217 - accuracy: 0.9934\n",
      "Epoch 629/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1269 - accuracy: 0.9934\n",
      "Epoch 630/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1129 - accuracy: 0.9974\n",
      "Epoch 631/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1099 - accuracy: 0.9948\n",
      "Epoch 632/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1066 - accuracy: 0.9974\n",
      "Epoch 633/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1169 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1091 - accuracy: 0.9974\n",
      "Epoch 635/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1264 - accuracy: 0.9974\n",
      "Epoch 636/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1208 - accuracy: 0.9948\n",
      "Epoch 637/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1073 - accuracy: 0.9921\n",
      "Epoch 638/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1083 - accuracy: 0.9948\n",
      "Epoch 639/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1183 - accuracy: 0.9895\n",
      "Epoch 640/800\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1105 - accuracy: 0.9934\n",
      "Epoch 641/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1374 - accuracy: 0.9882\n",
      "Epoch 642/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1195 - accuracy: 0.9908\n",
      "Epoch 643/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1265 - accuracy: 0.9908\n",
      "Epoch 644/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1103 - accuracy: 0.9934\n",
      "Epoch 645/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0997 - accuracy: 0.9948\n",
      "Epoch 646/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1068 - accuracy: 0.9921\n",
      "Epoch 647/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1076 - accuracy: 0.9921\n",
      "Epoch 648/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1128 - accuracy: 0.9948\n",
      "Epoch 649/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1293 - accuracy: 0.9895\n",
      "Epoch 650/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1161 - accuracy: 0.9934\n",
      "Epoch 651/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1156 - accuracy: 0.9948\n",
      "Epoch 652/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1219 - accuracy: 0.9934\n",
      "Epoch 653/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1099 - accuracy: 0.9961\n",
      "Epoch 654/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1151 - accuracy: 0.9921\n",
      "Epoch 655/800\n",
      "762/762 [==============================] - 0s 86us/step - loss: 0.0972 - accuracy: 0.9974\n",
      "Epoch 656/800\n",
      "762/762 [==============================] - 0s 85us/step - loss: 0.1137 - accuracy: 0.9908\n",
      "Epoch 657/800\n",
      "762/762 [==============================] - 0s 85us/step - loss: 0.1172 - accuracy: 0.9974\n",
      "Epoch 658/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1195 - accuracy: 0.9934\n",
      "Epoch 659/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1133 - accuracy: 0.9934\n",
      "Epoch 660/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1110 - accuracy: 0.9948\n",
      "Epoch 661/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1145 - accuracy: 0.9921\n",
      "Epoch 662/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1140 - accuracy: 0.9934\n",
      "Epoch 663/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1023 - accuracy: 0.9934\n",
      "Epoch 664/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1123 - accuracy: 0.9974\n",
      "Epoch 665/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1147 - accuracy: 0.9921\n",
      "Epoch 666/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1081 - accuracy: 0.9961\n",
      "Epoch 667/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1218 - accuracy: 0.9908\n",
      "Epoch 668/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1147 - accuracy: 0.9974\n",
      "Epoch 669/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1231 - accuracy: 0.9948\n",
      "Epoch 670/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1300 - accuracy: 0.9974\n",
      "Epoch 671/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1254 - accuracy: 0.9948\n",
      "Epoch 672/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0973 - accuracy: 0.9974\n",
      "Epoch 673/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1361 - accuracy: 0.9895\n",
      "Epoch 674/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1155 - accuracy: 0.9934\n",
      "Epoch 675/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1022 - accuracy: 0.9974\n",
      "Epoch 676/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1131 - accuracy: 0.9987\n",
      "Epoch 677/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1124 - accuracy: 0.9934\n",
      "Epoch 678/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1098 - accuracy: 0.9948\n",
      "Epoch 679/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1277 - accuracy: 0.9934\n",
      "Epoch 680/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1100 - accuracy: 0.9921\n",
      "Epoch 681/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1311 - accuracy: 0.9934\n",
      "Epoch 682/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.0987 - accuracy: 1.0000\n",
      "Epoch 683/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1153 - accuracy: 0.9974\n",
      "Epoch 684/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1081 - accuracy: 0.9921\n",
      "Epoch 685/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1127 - accuracy: 0.9934\n",
      "Epoch 686/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1161 - accuracy: 0.9908\n",
      "Epoch 687/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1085 - accuracy: 0.9987\n",
      "Epoch 688/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1171 - accuracy: 0.9948\n",
      "Epoch 689/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1135 - accuracy: 0.9934\n",
      "Epoch 690/800\n",
      "762/762 [==============================] - 0s 86us/step - loss: 0.0944 - accuracy: 0.9987\n",
      "Epoch 691/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.0989 - accuracy: 0.9961\n",
      "Epoch 692/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1123 - accuracy: 0.9921\n",
      "Epoch 693/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1083 - accuracy: 0.9948\n",
      "Epoch 694/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1098 - accuracy: 0.9974\n",
      "Epoch 695/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1106 - accuracy: 0.9987\n",
      "Epoch 696/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1200 - accuracy: 0.9921\n",
      "Epoch 697/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1047 - accuracy: 0.9948\n",
      "Epoch 698/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1148 - accuracy: 0.9921\n",
      "Epoch 699/800\n",
      "762/762 [==============================] - 0s 87us/step - loss: 0.1169 - accuracy: 0.9961\n",
      "Epoch 700/800\n",
      "762/762 [==============================] - 0s 87us/step - loss: 0.1094 - accuracy: 0.9948\n",
      "Epoch 701/800\n",
      "762/762 [==============================] - 0s 85us/step - loss: 0.1086 - accuracy: 0.9974\n",
      "Epoch 702/800\n",
      "762/762 [==============================] - 0s 88us/step - loss: 0.1159 - accuracy: 0.9961\n",
      "Epoch 703/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1124 - accuracy: 0.9974\n",
      "Epoch 704/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0982 - accuracy: 0.9974\n",
      "Epoch 705/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1054 - accuracy: 0.9948\n",
      "Epoch 706/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1132 - accuracy: 0.9961\n",
      "Epoch 707/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1145 - accuracy: 0.9948\n",
      "Epoch 708/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1174 - accuracy: 0.9948\n",
      "Epoch 709/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1228 - accuracy: 0.9934\n",
      "Epoch 710/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0974 - accuracy: 0.9934\n",
      "Epoch 711/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0954 - accuracy: 0.9948\n",
      "Epoch 712/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1131 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1073 - accuracy: 0.9974\n",
      "Epoch 714/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0996 - accuracy: 0.9961\n",
      "Epoch 715/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1004 - accuracy: 0.9974\n",
      "Epoch 716/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1298 - accuracy: 0.9948\n",
      "Epoch 717/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1050 - accuracy: 0.9974\n",
      "Epoch 718/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1128 - accuracy: 0.9921\n",
      "Epoch 719/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1059 - accuracy: 0.9987\n",
      "Epoch 720/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1094 - accuracy: 0.9934\n",
      "Epoch 721/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1142 - accuracy: 0.9934\n",
      "Epoch 722/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1145 - accuracy: 0.9908\n",
      "Epoch 723/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1107 - accuracy: 0.9934\n",
      "Epoch 724/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0983 - accuracy: 0.9974\n",
      "Epoch 725/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1149 - accuracy: 0.9895\n",
      "Epoch 726/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1174 - accuracy: 0.9934\n",
      "Epoch 727/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1060 - accuracy: 0.9987\n",
      "Epoch 728/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1221 - accuracy: 0.9895\n",
      "Epoch 729/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0946 - accuracy: 0.9961\n",
      "Epoch 730/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1100 - accuracy: 0.9921\n",
      "Epoch 731/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1271 - accuracy: 0.9948\n",
      "Epoch 732/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1008 - accuracy: 0.9961\n",
      "Epoch 733/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0993 - accuracy: 0.9987\n",
      "Epoch 734/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1187 - accuracy: 0.9961\n",
      "Epoch 735/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1243 - accuracy: 0.9882\n",
      "Epoch 736/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1121 - accuracy: 0.9948\n",
      "Epoch 737/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0966 - accuracy: 0.9948\n",
      "Epoch 738/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1109 - accuracy: 0.9948\n",
      "Epoch 739/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1028 - accuracy: 0.9948\n",
      "Epoch 740/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0950 - accuracy: 0.9921\n",
      "Epoch 741/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1106 - accuracy: 0.9961\n",
      "Epoch 742/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0967 - accuracy: 0.9987\n",
      "Epoch 743/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1036 - accuracy: 0.9961\n",
      "Epoch 744/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1051 - accuracy: 0.9948\n",
      "Epoch 745/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1037 - accuracy: 0.9987\n",
      "Epoch 746/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1181 - accuracy: 0.9895\n",
      "Epoch 747/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0950 - accuracy: 0.9948\n",
      "Epoch 748/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 749/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0997 - accuracy: 0.9961\n",
      "Epoch 750/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1097 - accuracy: 0.9961\n",
      "Epoch 751/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0887 - accuracy: 0.9987\n",
      "Epoch 752/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1113 - accuracy: 0.9934\n",
      "Epoch 753/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1033 - accuracy: 0.9987\n",
      "Epoch 754/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0940 - accuracy: 0.9974\n",
      "Epoch 755/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1240 - accuracy: 0.9934\n",
      "Epoch 756/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1079 - accuracy: 0.9948\n",
      "Epoch 757/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1062 - accuracy: 0.9934\n",
      "Epoch 758/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1041 - accuracy: 0.9934\n",
      "Epoch 759/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1087 - accuracy: 0.9921\n",
      "Epoch 760/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1045 - accuracy: 0.9934\n",
      "Epoch 761/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1103 - accuracy: 0.9948\n",
      "Epoch 762/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1079 - accuracy: 0.9948\n",
      "Epoch 763/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1151 - accuracy: 0.9895\n",
      "Epoch 764/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1156 - accuracy: 0.9934\n",
      "Epoch 765/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1157 - accuracy: 0.9961\n",
      "Epoch 766/800\n",
      "762/762 [==============================] - 0s 85us/step - loss: 0.1019 - accuracy: 0.9948\n",
      "Epoch 767/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.1034 - accuracy: 0.9948\n",
      "Epoch 768/800\n",
      "762/762 [==============================] - 0s 122us/step - loss: 0.0987 - accuracy: 0.9948\n",
      "Epoch 769/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1063 - accuracy: 0.9961\n",
      "Epoch 770/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1093 - accuracy: 0.9961\n",
      "Epoch 771/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1181 - accuracy: 0.9921\n",
      "Epoch 772/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1129 - accuracy: 0.9961\n",
      "Epoch 773/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1097 - accuracy: 0.9961\n",
      "Epoch 774/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1072 - accuracy: 0.9948\n",
      "Epoch 775/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1050 - accuracy: 0.9961\n",
      "Epoch 776/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0906 - accuracy: 0.9961\n",
      "Epoch 777/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1049 - accuracy: 0.9974\n",
      "Epoch 778/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1071 - accuracy: 0.9908\n",
      "Epoch 779/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1043 - accuracy: 0.9961\n",
      "Epoch 780/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1218 - accuracy: 0.9934\n",
      "Epoch 781/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1160 - accuracy: 0.9934\n",
      "Epoch 782/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1054 - accuracy: 0.9948\n",
      "Epoch 783/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1144 - accuracy: 0.9987\n",
      "Epoch 784/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1124 - accuracy: 0.9961\n",
      "Epoch 785/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1159 - accuracy: 0.9948\n",
      "Epoch 786/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1098 - accuracy: 0.9934\n",
      "Epoch 787/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1141 - accuracy: 0.9921\n",
      "Epoch 788/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1083 - accuracy: 0.9921\n",
      "Epoch 789/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1148 - accuracy: 0.9934\n",
      "Epoch 790/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1016 - accuracy: 0.9961\n",
      "Epoch 791/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1015 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1144 - accuracy: 0.9961\n",
      "Epoch 793/800\n",
      "762/762 [==============================] - 0s 89us/step - loss: 0.1176 - accuracy: 0.9934\n",
      "Epoch 794/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.0990 - accuracy: 0.9961\n",
      "Epoch 795/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1004 - accuracy: 0.9948\n",
      "Epoch 796/800\n",
      "762/762 [==============================] - 0s 91us/step - loss: 0.1162 - accuracy: 0.9948\n",
      "Epoch 797/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1178 - accuracy: 0.9948\n",
      "Epoch 798/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0955 - accuracy: 1.0000\n",
      "Epoch 799/800\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1036 - accuracy: 0.9987\n",
      "Epoch 800/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1079 - accuracy: 0.9961\n",
      "Epoch 1/500\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 0.1175 - accuracy: 0.9934\n",
      "Epoch 2/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1107 - accuracy: 0.9961\n",
      "Epoch 3/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1112 - accuracy: 0.9948\n",
      "Epoch 4/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1059 - accuracy: 0.9948\n",
      "Epoch 5/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1184 - accuracy: 0.9934\n",
      "Epoch 6/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1138 - accuracy: 0.9948\n",
      "Epoch 7/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1024 - accuracy: 0.9974\n",
      "Epoch 8/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0956 - accuracy: 0.9974\n",
      "Epoch 9/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1108 - accuracy: 0.9908\n",
      "Epoch 10/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1080 - accuracy: 0.9948\n",
      "Epoch 11/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1052 - accuracy: 0.9921\n",
      "Epoch 12/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1229 - accuracy: 0.9895\n",
      "Epoch 13/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "762/762 [==============================] - 0s 125us/step - loss: 0.1102 - accuracy: 0.9921\n",
      "Epoch 15/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1066 - accuracy: 0.9948\n",
      "Epoch 16/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1042 - accuracy: 0.9895\n",
      "Epoch 17/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0776 - accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0950 - accuracy: 0.9921\n",
      "Epoch 19/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1140 - accuracy: 0.9934\n",
      "Epoch 20/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1085 - accuracy: 0.9974\n",
      "Epoch 21/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1057 - accuracy: 0.9948\n",
      "Epoch 22/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1086 - accuracy: 0.9948\n",
      "Epoch 23/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0957 - accuracy: 0.9987\n",
      "Epoch 24/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0972 - accuracy: 0.9961\n",
      "Epoch 25/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1165 - accuracy: 0.9934\n",
      "Epoch 26/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1169 - accuracy: 0.9921\n",
      "Epoch 27/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1004 - accuracy: 0.9974\n",
      "Epoch 28/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0943 - accuracy: 0.9974\n",
      "Epoch 29/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0862 - accuracy: 0.9948\n",
      "Epoch 30/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1147 - accuracy: 0.9948\n",
      "Epoch 31/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1135 - accuracy: 0.9895\n",
      "Epoch 32/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1094 - accuracy: 0.9948\n",
      "Epoch 33/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1083 - accuracy: 0.9961\n",
      "Epoch 34/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0980 - accuracy: 0.9974\n",
      "Epoch 35/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0952 - accuracy: 0.9961\n",
      "Epoch 36/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0885 - accuracy: 0.9948\n",
      "Epoch 37/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0978 - accuracy: 0.9921\n",
      "Epoch 38/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0997 - accuracy: 0.9948\n",
      "Epoch 40/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0986 - accuracy: 0.9961\n",
      "Epoch 41/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1074 - accuracy: 0.9908\n",
      "Epoch 42/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1312 - accuracy: 0.9921\n",
      "Epoch 43/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0989 - accuracy: 0.9987\n",
      "Epoch 44/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1022 - accuracy: 0.9934\n",
      "Epoch 45/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0927 - accuracy: 0.9948\n",
      "Epoch 46/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1199 - accuracy: 0.9934\n",
      "Epoch 47/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1022 - accuracy: 0.9934\n",
      "Epoch 48/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0872 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0999 - accuracy: 0.9934\n",
      "Epoch 50/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1003 - accuracy: 0.9948\n",
      "Epoch 51/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1098 - accuracy: 0.9895\n",
      "Epoch 52/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1076 - accuracy: 0.9921\n",
      "Epoch 53/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0952 - accuracy: 0.9934\n",
      "Epoch 54/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0914 - accuracy: 0.9987\n",
      "Epoch 55/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0926 - accuracy: 0.9974\n",
      "Epoch 56/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0997 - accuracy: 0.9974\n",
      "Epoch 58/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0916 - accuracy: 0.9961\n",
      "Epoch 59/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0932 - accuracy: 0.9974\n",
      "Epoch 60/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1129 - accuracy: 0.9934\n",
      "Epoch 61/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0878 - accuracy: 0.9987\n",
      "Epoch 62/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0991 - accuracy: 0.9921\n",
      "Epoch 63/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0945 - accuracy: 0.9974\n",
      "Epoch 64/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0884 - accuracy: 0.9974\n",
      "Epoch 65/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0929 - accuracy: 0.9974\n",
      "Epoch 66/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1030 - accuracy: 0.9948\n",
      "Epoch 67/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1024 - accuracy: 0.9948\n",
      "Epoch 68/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0905 - accuracy: 0.9961\n",
      "Epoch 69/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1038 - accuracy: 0.9921\n",
      "Epoch 70/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1120 - accuracy: 0.9934\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 103us/step - loss: 0.0958 - accuracy: 0.9948\n",
      "Epoch 72/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0952 - accuracy: 0.9961\n",
      "Epoch 73/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1204 - accuracy: 0.9934\n",
      "Epoch 74/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0901 - accuracy: 0.9987\n",
      "Epoch 75/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1031 - accuracy: 0.9974\n",
      "Epoch 76/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1053 - accuracy: 0.9921\n",
      "Epoch 77/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0824 - accuracy: 0.9987\n",
      "Epoch 78/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1053 - accuracy: 0.9934\n",
      "Epoch 79/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0915 - accuracy: 0.9948\n",
      "Epoch 80/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0967 - accuracy: 0.9948\n",
      "Epoch 81/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0969 - accuracy: 0.9961\n",
      "Epoch 82/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0898 - accuracy: 0.9961\n",
      "Epoch 83/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0985 - accuracy: 0.9934\n",
      "Epoch 84/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1028 - accuracy: 0.9908\n",
      "Epoch 85/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0928 - accuracy: 0.9961\n",
      "Epoch 86/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0903 - accuracy: 0.9948\n",
      "Epoch 87/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1128 - accuracy: 0.9921\n",
      "Epoch 88/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0830 - accuracy: 0.9987\n",
      "Epoch 89/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1067 - accuracy: 0.9934\n",
      "Epoch 90/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1051 - accuracy: 0.9961\n",
      "Epoch 91/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0945 - accuracy: 0.9961\n",
      "Epoch 92/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0937 - accuracy: 0.9974\n",
      "Epoch 93/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1033 - accuracy: 0.9948\n",
      "Epoch 94/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0992 - accuracy: 0.9908\n",
      "Epoch 95/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1088 - accuracy: 0.9948\n",
      "Epoch 96/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0836 - accuracy: 0.9987\n",
      "Epoch 97/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0991 - accuracy: 0.9934\n",
      "Epoch 98/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1004 - accuracy: 0.9961\n",
      "Epoch 99/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1009 - accuracy: 0.9934\n",
      "Epoch 100/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1052 - accuracy: 0.9961\n",
      "Epoch 101/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0986 - accuracy: 0.9974\n",
      "Epoch 102/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0868 - accuracy: 0.9974\n",
      "Epoch 103/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1117 - accuracy: 0.9961\n",
      "Epoch 104/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1090 - accuracy: 0.9934\n",
      "Epoch 105/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1064 - accuracy: 0.9921\n",
      "Epoch 106/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1039 - accuracy: 0.9948\n",
      "Epoch 107/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1064 - accuracy: 0.9921\n",
      "Epoch 108/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0944 - accuracy: 0.9921\n",
      "Epoch 109/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0969 - accuracy: 0.9974\n",
      "Epoch 110/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1087 - accuracy: 0.9921\n",
      "Epoch 111/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1032 - accuracy: 0.9987\n",
      "Epoch 112/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0829 - accuracy: 0.9987\n",
      "Epoch 113/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0953 - accuracy: 0.9987\n",
      "Epoch 114/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0945 - accuracy: 0.9961\n",
      "Epoch 115/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1027 - accuracy: 0.9934\n",
      "Epoch 116/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1017 - accuracy: 0.9974\n",
      "Epoch 117/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1037 - accuracy: 0.9961\n",
      "Epoch 118/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1243 - accuracy: 0.9921\n",
      "Epoch 119/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1000 - accuracy: 0.9948\n",
      "Epoch 120/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0992 - accuracy: 0.9948\n",
      "Epoch 121/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0859 - accuracy: 0.9961\n",
      "Epoch 122/500\n",
      "762/762 [==============================] - 0s 118us/step - loss: 0.0928 - accuracy: 0.9961\n",
      "Epoch 123/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1216 - accuracy: 0.9895\n",
      "Epoch 124/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0924 - accuracy: 0.9961\n",
      "Epoch 125/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0953 - accuracy: 0.9934\n",
      "Epoch 126/500\n",
      "762/762 [==============================] - 0s 114us/step - loss: 0.0936 - accuracy: 0.9961\n",
      "Epoch 127/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0872 - accuracy: 0.9974\n",
      "Epoch 128/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0932 - accuracy: 0.9921\n",
      "Epoch 129/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0966 - accuracy: 0.9934\n",
      "Epoch 130/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0836 - accuracy: 0.9961\n",
      "Epoch 131/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1025 - accuracy: 0.9974\n",
      "Epoch 132/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1035 - accuracy: 0.9934\n",
      "Epoch 133/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0834 - accuracy: 0.9987\n",
      "Epoch 134/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0866 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0977 - accuracy: 0.9948\n",
      "Epoch 136/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0849 - accuracy: 0.9974\n",
      "Epoch 137/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0827 - accuracy: 0.9987\n",
      "Epoch 138/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1058 - accuracy: 0.9948\n",
      "Epoch 139/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1126 - accuracy: 0.9961\n",
      "Epoch 140/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0908 - accuracy: 0.9961\n",
      "Epoch 141/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1107 - accuracy: 0.9934\n",
      "Epoch 142/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0951 - accuracy: 0.9921\n",
      "Epoch 143/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0886 - accuracy: 0.9974\n",
      "Epoch 144/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1051 - accuracy: 0.9921\n",
      "Epoch 145/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0949 - accuracy: 0.9934\n",
      "Epoch 146/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0906 - accuracy: 0.9961\n",
      "Epoch 147/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1049 - accuracy: 0.9961\n",
      "Epoch 148/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1005 - accuracy: 0.9974\n",
      "Epoch 149/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0840 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0857 - accuracy: 0.9987\n",
      "Epoch 151/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0881 - accuracy: 0.9948\n",
      "Epoch 152/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1043 - accuracy: 0.9974\n",
      "Epoch 153/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0978 - accuracy: 0.9934\n",
      "Epoch 154/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0932 - accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0994 - accuracy: 0.9961\n",
      "Epoch 156/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1073 - accuracy: 0.9948\n",
      "Epoch 157/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0980 - accuracy: 0.9974\n",
      "Epoch 158/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0954 - accuracy: 0.9974\n",
      "Epoch 159/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1074 - accuracy: 0.9921\n",
      "Epoch 160/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0994 - accuracy: 0.9974\n",
      "Epoch 161/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1072 - accuracy: 0.9921\n",
      "Epoch 162/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1012 - accuracy: 0.9921\n",
      "Epoch 163/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0980 - accuracy: 0.9934\n",
      "Epoch 164/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1114 - accuracy: 0.9948\n",
      "Epoch 165/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0911 - accuracy: 0.9961\n",
      "Epoch 166/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0940 - accuracy: 0.9974\n",
      "Epoch 167/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1115 - accuracy: 0.9921\n",
      "Epoch 168/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0895 - accuracy: 0.9961\n",
      "Epoch 169/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0946 - accuracy: 0.9934\n",
      "Epoch 170/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0961 - accuracy: 0.9987\n",
      "Epoch 171/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1014 - accuracy: 0.9948\n",
      "Epoch 172/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0977 - accuracy: 0.9961\n",
      "Epoch 173/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0755 - accuracy: 0.9974\n",
      "Epoch 174/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0871 - accuracy: 0.9987\n",
      "Epoch 175/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0795 - accuracy: 0.9974\n",
      "Epoch 176/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0903 - accuracy: 0.9948\n",
      "Epoch 177/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1055 - accuracy: 0.9961\n",
      "Epoch 178/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0890 - accuracy: 0.9987\n",
      "Epoch 179/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0905 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0898 - accuracy: 0.9974\n",
      "Epoch 181/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1276 - accuracy: 0.9948\n",
      "Epoch 182/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1052 - accuracy: 0.9961\n",
      "Epoch 183/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0890 - accuracy: 0.9987\n",
      "Epoch 184/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0869 - accuracy: 0.9948\n",
      "Epoch 185/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1039 - accuracy: 0.9948\n",
      "Epoch 186/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1063 - accuracy: 0.9908\n",
      "Epoch 187/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1068 - accuracy: 0.9961\n",
      "Epoch 188/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1127 - accuracy: 0.9961\n",
      "Epoch 189/500\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1100 - accuracy: 0.9961\n",
      "Epoch 190/500\n",
      "762/762 [==============================] - 0s 126us/step - loss: 0.0992 - accuracy: 0.9961\n",
      "Epoch 191/500\n",
      "762/762 [==============================] - 0s 116us/step - loss: 0.0883 - accuracy: 0.9961\n",
      "Epoch 192/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0860 - accuracy: 0.9987\n",
      "Epoch 193/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0920 - accuracy: 0.9987\n",
      "Epoch 194/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0798 - accuracy: 0.9974\n",
      "Epoch 195/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0906 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0886 - accuracy: 0.9974\n",
      "Epoch 197/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0865 - accuracy: 0.9987\n",
      "Epoch 198/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0851 - accuracy: 0.9987\n",
      "Epoch 199/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.1002 - accuracy: 0.9961\n",
      "Epoch 200/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0877 - accuracy: 0.9987\n",
      "Epoch 201/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0953 - accuracy: 0.9921\n",
      "Epoch 202/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0915 - accuracy: 0.9961\n",
      "Epoch 203/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0919 - accuracy: 0.9961\n",
      "Epoch 204/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0820 - accuracy: 0.9974\n",
      "Epoch 205/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0804 - accuracy: 0.9974\n",
      "Epoch 206/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1046 - accuracy: 0.9934\n",
      "Epoch 207/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1059 - accuracy: 0.9921\n",
      "Epoch 208/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0861 - accuracy: 0.9987\n",
      "Epoch 209/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1084 - accuracy: 0.9934\n",
      "Epoch 210/500\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.0943 - accuracy: 0.9961\n",
      "Epoch 211/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0912 - accuracy: 0.9974\n",
      "Epoch 212/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0903 - accuracy: 0.9987\n",
      "Epoch 213/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.1014 - accuracy: 0.9961\n",
      "Epoch 214/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0886 - accuracy: 0.9974\n",
      "Epoch 215/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0987 - accuracy: 0.9934\n",
      "Epoch 216/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0886 - accuracy: 0.9961\n",
      "Epoch 217/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0962 - accuracy: 0.9961\n",
      "Epoch 218/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0825 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0907 - accuracy: 0.9987\n",
      "Epoch 220/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0927 - accuracy: 0.9921\n",
      "Epoch 221/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0874 - accuracy: 0.9961\n",
      "Epoch 222/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1185 - accuracy: 0.9921\n",
      "Epoch 223/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0869 - accuracy: 0.9987\n",
      "Epoch 224/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1004 - accuracy: 0.9974\n",
      "Epoch 225/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0955 - accuracy: 0.9987\n",
      "Epoch 226/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1025 - accuracy: 0.9961\n",
      "Epoch 227/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0929 - accuracy: 0.9934\n",
      "Epoch 228/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0975 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0972 - accuracy: 0.9921\n",
      "Epoch 230/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0983 - accuracy: 0.9961\n",
      "Epoch 231/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0969 - accuracy: 0.9961\n",
      "Epoch 232/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1054 - accuracy: 0.9948\n",
      "Epoch 233/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0906 - accuracy: 0.9987\n",
      "Epoch 234/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0962 - accuracy: 0.9961\n",
      "Epoch 235/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0996 - accuracy: 0.9921\n",
      "Epoch 236/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 237/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0965 - accuracy: 0.9987\n",
      "Epoch 238/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0966 - accuracy: 0.9921\n",
      "Epoch 239/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0817 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0948 - accuracy: 0.9948\n",
      "Epoch 241/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0832 - accuracy: 0.9974\n",
      "Epoch 242/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0980 - accuracy: 0.9961\n",
      "Epoch 243/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1001 - accuracy: 0.9934\n",
      "Epoch 244/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0792 - accuracy: 0.9987\n",
      "Epoch 245/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0956 - accuracy: 0.9934\n",
      "Epoch 246/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0912 - accuracy: 0.9934\n",
      "Epoch 247/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0896 - accuracy: 0.9961\n",
      "Epoch 248/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0863 - accuracy: 0.9961\n",
      "Epoch 249/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0964 - accuracy: 0.9948\n",
      "Epoch 250/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0891 - accuracy: 0.9934\n",
      "Epoch 251/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0850 - accuracy: 0.9974\n",
      "Epoch 252/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1047 - accuracy: 0.9934\n",
      "Epoch 253/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0898 - accuracy: 0.9987\n",
      "Epoch 254/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0915 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0941 - accuracy: 0.9948\n",
      "Epoch 256/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 257/500\n",
      "762/762 [==============================] - 0s 114us/step - loss: 0.0898 - accuracy: 0.9961\n",
      "Epoch 258/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0822 - accuracy: 0.9974\n",
      "Epoch 259/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0932 - accuracy: 0.9921\n",
      "Epoch 260/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0781 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0970 - accuracy: 0.9921\n",
      "Epoch 262/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0949 - accuracy: 0.9987\n",
      "Epoch 263/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1038 - accuracy: 0.9948\n",
      "Epoch 264/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0942 - accuracy: 0.9934\n",
      "Epoch 265/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0853 - accuracy: 0.9974\n",
      "Epoch 266/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1131 - accuracy: 0.9921\n",
      "Epoch 267/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0917 - accuracy: 0.9948\n",
      "Epoch 268/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1049 - accuracy: 0.9948\n",
      "Epoch 269/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0859 - accuracy: 0.9948\n",
      "Epoch 270/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1017 - accuracy: 0.9934\n",
      "Epoch 271/500\n",
      "762/762 [==============================] - 0s 118us/step - loss: 0.0886 - accuracy: 0.9974\n",
      "Epoch 272/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0936 - accuracy: 0.9948\n",
      "Epoch 273/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0905 - accuracy: 0.9948\n",
      "Epoch 274/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0941 - accuracy: 0.9974\n",
      "Epoch 275/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1046 - accuracy: 0.9895\n",
      "Epoch 276/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0906 - accuracy: 0.9974\n",
      "Epoch 277/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0833 - accuracy: 0.9987\n",
      "Epoch 278/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0920 - accuracy: 0.9948\n",
      "Epoch 279/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0939 - accuracy: 0.9934\n",
      "Epoch 280/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0819 - accuracy: 0.9974\n",
      "Epoch 281/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1048 - accuracy: 0.9961\n",
      "Epoch 282/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0978 - accuracy: 0.9934\n",
      "Epoch 283/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1053 - accuracy: 0.9908\n",
      "Epoch 284/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.0915 - accuracy: 0.9948\n",
      "Epoch 285/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0942 - accuracy: 0.9974\n",
      "Epoch 286/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0881 - accuracy: 0.9921\n",
      "Epoch 287/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0987 - accuracy: 0.9974\n",
      "Epoch 288/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0869 - accuracy: 0.9974\n",
      "Epoch 289/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0897 - accuracy: 0.9934\n",
      "Epoch 290/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0810 - accuracy: 0.9974\n",
      "Epoch 291/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0930 - accuracy: 0.9921\n",
      "Epoch 292/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0753 - accuracy: 0.9987\n",
      "Epoch 293/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0917 - accuracy: 0.9961\n",
      "Epoch 294/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0939 - accuracy: 0.9961\n",
      "Epoch 295/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0827 - accuracy: 0.9961\n",
      "Epoch 296/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0877 - accuracy: 0.9974\n",
      "Epoch 297/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1064 - accuracy: 0.9908\n",
      "Epoch 298/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0866 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0969 - accuracy: 0.9974\n",
      "Epoch 300/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1004 - accuracy: 0.9948\n",
      "Epoch 301/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0896 - accuracy: 0.9974\n",
      "Epoch 302/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0943 - accuracy: 0.9961\n",
      "Epoch 303/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0892 - accuracy: 0.9948\n",
      "Epoch 304/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1051 - accuracy: 0.9948\n",
      "Epoch 305/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1044 - accuracy: 0.9934\n",
      "Epoch 306/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0852 - accuracy: 0.9974\n",
      "Epoch 307/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0805 - accuracy: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0727 - accuracy: 0.9987\n",
      "Epoch 309/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1065 - accuracy: 0.9921\n",
      "Epoch 310/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0922 - accuracy: 0.9921\n",
      "Epoch 312/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0933 - accuracy: 0.9974\n",
      "Epoch 313/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0828 - accuracy: 0.9974\n",
      "Epoch 314/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0894 - accuracy: 0.9987\n",
      "Epoch 315/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0967 - accuracy: 0.9934\n",
      "Epoch 316/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0917 - accuracy: 0.9948\n",
      "Epoch 317/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0997 - accuracy: 0.9934\n",
      "Epoch 318/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0948 - accuracy: 0.9934\n",
      "Epoch 319/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0767 - accuracy: 0.9987\n",
      "Epoch 320/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0911 - accuracy: 0.9908\n",
      "Epoch 321/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0954 - accuracy: 0.9934\n",
      "Epoch 322/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0933 - accuracy: 0.9987\n",
      "Epoch 323/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0857 - accuracy: 0.9961\n",
      "Epoch 324/500\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.0913 - accuracy: 0.9961\n",
      "Epoch 325/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1205 - accuracy: 0.9882\n",
      "Epoch 326/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0879 - accuracy: 0.9961\n",
      "Epoch 327/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0771 - accuracy: 0.9961\n",
      "Epoch 328/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1042 - accuracy: 0.9921\n",
      "Epoch 329/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0798 - accuracy: 0.9948\n",
      "Epoch 330/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0931 - accuracy: 0.9921\n",
      "Epoch 331/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0899 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0948 - accuracy: 0.9948\n",
      "Epoch 333/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1122 - accuracy: 0.9934\n",
      "Epoch 334/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1062 - accuracy: 0.9948\n",
      "Epoch 335/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0796 - accuracy: 0.9961\n",
      "Epoch 336/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0926 - accuracy: 0.9974\n",
      "Epoch 337/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0998 - accuracy: 0.9908\n",
      "Epoch 339/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1127 - accuracy: 0.9934\n",
      "Epoch 340/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1060 - accuracy: 0.9895\n",
      "Epoch 341/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0973 - accuracy: 0.9921\n",
      "Epoch 342/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0889 - accuracy: 0.9974\n",
      "Epoch 343/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0989 - accuracy: 0.9948\n",
      "Epoch 344/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0947 - accuracy: 0.9961\n",
      "Epoch 345/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0909 - accuracy: 0.9961\n",
      "Epoch 346/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0768 - accuracy: 0.9961\n",
      "Epoch 347/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 348/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0788 - accuracy: 0.9974\n",
      "Epoch 349/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0910 - accuracy: 0.9961\n",
      "Epoch 350/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1029 - accuracy: 0.9961\n",
      "Epoch 351/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0963 - accuracy: 0.9921\n",
      "Epoch 352/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0900 - accuracy: 0.9961\n",
      "Epoch 353/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0959 - accuracy: 0.9948\n",
      "Epoch 354/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1023 - accuracy: 0.9948\n",
      "Epoch 355/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0999 - accuracy: 0.9948\n",
      "Epoch 356/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0880 - accuracy: 0.9987\n",
      "Epoch 357/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0920 - accuracy: 0.9934\n",
      "Epoch 358/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1113 - accuracy: 0.9869\n",
      "Epoch 359/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0752 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0840 - accuracy: 0.9987\n",
      "Epoch 361/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1010 - accuracy: 0.9934\n",
      "Epoch 362/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0990 - accuracy: 0.9921\n",
      "Epoch 363/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1022 - accuracy: 0.9948\n",
      "Epoch 364/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0979 - accuracy: 0.9987\n",
      "Epoch 365/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0950 - accuracy: 0.9961\n",
      "Epoch 366/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1001 - accuracy: 0.9934\n",
      "Epoch 367/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1065 - accuracy: 0.9934\n",
      "Epoch 368/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1192 - accuracy: 0.9908\n",
      "Epoch 369/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1040 - accuracy: 0.9948\n",
      "Epoch 370/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1005 - accuracy: 0.9921\n",
      "Epoch 371/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1022 - accuracy: 0.9934\n",
      "Epoch 372/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0951 - accuracy: 0.9974\n",
      "Epoch 373/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0853 - accuracy: 0.9948\n",
      "Epoch 374/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1093 - accuracy: 0.9948\n",
      "Epoch 375/500\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.0867 - accuracy: 0.9974\n",
      "Epoch 376/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0807 - accuracy: 0.9974\n",
      "Epoch 377/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1043 - accuracy: 0.9908\n",
      "Epoch 378/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0884 - accuracy: 0.9921\n",
      "Epoch 379/500\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.0955 - accuracy: 0.9908\n",
      "Epoch 380/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0951 - accuracy: 0.9974\n",
      "Epoch 381/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0902 - accuracy: 0.9934\n",
      "Epoch 382/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0929 - accuracy: 0.9961\n",
      "Epoch 383/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1120 - accuracy: 0.9869\n",
      "Epoch 384/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0903 - accuracy: 0.9961\n",
      "Epoch 385/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0859 - accuracy: 0.9974\n",
      "Epoch 386/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0864 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0813 - accuracy: 0.9987\n",
      "Epoch 388/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0920 - accuracy: 0.9934\n",
      "Epoch 389/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0911 - accuracy: 0.9948\n",
      "Epoch 390/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0823 - accuracy: 0.9961\n",
      "Epoch 391/500\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.0842 - accuracy: 0.9974\n",
      "Epoch 392/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 393/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0881 - accuracy: 0.9948\n",
      "Epoch 394/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0856 - accuracy: 0.9974\n",
      "Epoch 395/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0867 - accuracy: 0.9961\n",
      "Epoch 396/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0941 - accuracy: 0.9948\n",
      "Epoch 397/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0777 - accuracy: 0.9987\n",
      "Epoch 398/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0955 - accuracy: 0.9934\n",
      "Epoch 399/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0851 - accuracy: 0.9987\n",
      "Epoch 400/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0870 - accuracy: 0.9961\n",
      "Epoch 401/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1056 - accuracy: 0.9948\n",
      "Epoch 402/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 403/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0908 - accuracy: 0.9961\n",
      "Epoch 404/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1106 - accuracy: 0.9895\n",
      "Epoch 405/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0797 - accuracy: 0.9961\n",
      "Epoch 406/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0869 - accuracy: 0.9974\n",
      "Epoch 407/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0947 - accuracy: 0.9961\n",
      "Epoch 408/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0911 - accuracy: 0.9921\n",
      "Epoch 409/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0745 - accuracy: 0.9961\n",
      "Epoch 410/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0921 - accuracy: 0.9934\n",
      "Epoch 411/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0902 - accuracy: 0.9948\n",
      "Epoch 412/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0887 - accuracy: 0.9987\n",
      "Epoch 413/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0799 - accuracy: 0.9974\n",
      "Epoch 414/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1097 - accuracy: 0.9921\n",
      "Epoch 415/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0992 - accuracy: 0.9948\n",
      "Epoch 416/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0887 - accuracy: 0.9974\n",
      "Epoch 417/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0841 - accuracy: 0.9921\n",
      "Epoch 418/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1140 - accuracy: 0.9934\n",
      "Epoch 419/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0855 - accuracy: 0.9961\n",
      "Epoch 420/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0906 - accuracy: 0.9948\n",
      "Epoch 421/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0931 - accuracy: 0.9961\n",
      "Epoch 422/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1030 - accuracy: 0.9948\n",
      "Epoch 423/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0900 - accuracy: 0.9948\n",
      "Epoch 424/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0913 - accuracy: 0.9948\n",
      "Epoch 425/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0919 - accuracy: 0.9961\n",
      "Epoch 426/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0896 - accuracy: 0.9987\n",
      "Epoch 427/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0867 - accuracy: 0.9974\n",
      "Epoch 428/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0863 - accuracy: 0.9974\n",
      "Epoch 429/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0791 - accuracy: 0.9948\n",
      "Epoch 430/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0769 - accuracy: 0.9987\n",
      "Epoch 431/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0821 - accuracy: 0.9987\n",
      "Epoch 432/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1071 - accuracy: 0.9934\n",
      "Epoch 433/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0896 - accuracy: 0.9934\n",
      "Epoch 434/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0883 - accuracy: 0.9987\n",
      "Epoch 435/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0836 - accuracy: 0.9987\n",
      "Epoch 436/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0931 - accuracy: 0.9934\n",
      "Epoch 437/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1143 - accuracy: 0.9921\n",
      "Epoch 438/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0891 - accuracy: 0.9974\n",
      "Epoch 439/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0886 - accuracy: 0.9961\n",
      "Epoch 440/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 441/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0970 - accuracy: 0.9987\n",
      "Epoch 442/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1033 - accuracy: 0.9974\n",
      "Epoch 443/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0956 - accuracy: 0.9961\n",
      "Epoch 444/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0860 - accuracy: 0.9974\n",
      "Epoch 445/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0917 - accuracy: 0.9974\n",
      "Epoch 446/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0956 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0804 - accuracy: 0.9974\n",
      "Epoch 448/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0830 - accuracy: 0.9948\n",
      "Epoch 449/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0796 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0987 - accuracy: 0.9934\n",
      "Epoch 451/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0832 - accuracy: 0.9987\n",
      "Epoch 452/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0752 - accuracy: 0.9974\n",
      "Epoch 453/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1022 - accuracy: 0.9961\n",
      "Epoch 454/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0898 - accuracy: 0.9987\n",
      "Epoch 455/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0872 - accuracy: 0.9961\n",
      "Epoch 456/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0840 - accuracy: 0.9961\n",
      "Epoch 457/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0865 - accuracy: 0.9987\n",
      "Epoch 458/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0852 - accuracy: 0.9921\n",
      "Epoch 459/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0900 - accuracy: 0.9934\n",
      "Epoch 460/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1088 - accuracy: 0.9882\n",
      "Epoch 461/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0942 - accuracy: 0.9974\n",
      "Epoch 462/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0717 - accuracy: 0.9974\n",
      "Epoch 463/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0922 - accuracy: 0.9948\n",
      "Epoch 464/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0979 - accuracy: 0.9934\n",
      "Epoch 465/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0852 - accuracy: 0.9934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0922 - accuracy: 0.9948\n",
      "Epoch 467/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0825 - accuracy: 0.9974\n",
      "Epoch 468/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0822 - accuracy: 0.9974\n",
      "Epoch 469/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0829 - accuracy: 0.9987\n",
      "Epoch 470/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0902 - accuracy: 0.9948\n",
      "Epoch 471/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1077 - accuracy: 0.9948\n",
      "Epoch 472/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0974 - accuracy: 0.9948\n",
      "Epoch 473/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0902 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0826 - accuracy: 0.9948\n",
      "Epoch 475/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0935 - accuracy: 0.9921\n",
      "Epoch 476/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0977 - accuracy: 0.9948\n",
      "Epoch 477/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1137 - accuracy: 0.9921\n",
      "Epoch 478/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0902 - accuracy: 0.9948\n",
      "Epoch 479/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0865 - accuracy: 0.9974\n",
      "Epoch 480/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0843 - accuracy: 0.9961\n",
      "Epoch 481/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0966 - accuracy: 0.9961\n",
      "Epoch 482/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0746 - accuracy: 0.9974\n",
      "Epoch 483/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0896 - accuracy: 0.9974\n",
      "Epoch 484/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0877 - accuracy: 0.9961\n",
      "Epoch 485/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0909 - accuracy: 0.9974\n",
      "Epoch 486/500\n",
      "762/762 [==============================] - 0s 92us/step - loss: 0.0723 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1094 - accuracy: 0.9895\n",
      "Epoch 488/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0904 - accuracy: 0.9974\n",
      "Epoch 489/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0866 - accuracy: 0.9987\n",
      "Epoch 490/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0927 - accuracy: 0.9921\n",
      "Epoch 491/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1087 - accuracy: 0.9895\n",
      "Epoch 492/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0768 - accuracy: 0.9987\n",
      "Epoch 493/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0887 - accuracy: 0.9934\n",
      "Epoch 494/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1035 - accuracy: 0.9961\n",
      "Epoch 495/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0931 - accuracy: 0.9974\n",
      "Epoch 496/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1024 - accuracy: 0.9921\n",
      "Epoch 497/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.0852 - accuracy: 0.9974\n",
      "Epoch 498/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0941 - accuracy: 0.9948\n",
      "Epoch 499/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0755 - accuracy: 0.9974\n",
      "Epoch 500/500\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.0931 - accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "# create a new net\n",
    "rf_net = ddnet.create_DDNet(C)\n",
    "\n",
    "lr = 1e-3\n",
    "rf_net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "\n",
    "history1 = rf_net.fit([X_rf_0,X_rf_1],Y_rf,\n",
    "                    batch_size=len(Y_rf),\n",
    "                    epochs=800,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    sample_weight=rf_sample_weight\n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "rf_net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "\n",
    "history2 = rf_net.fit([X_rf_0,X_rf_1],Y_rf,\n",
    "                    batch_size=len(Y_rf),\n",
    "                    epochs=500,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    sample_weight=rf_sample_weight\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # the first 600 epochs\n",
    "    plot_accuracy(history1)\n",
    "    plot_loss(history1)\n",
    "    # the next 500 epochs\n",
    "    plot_accuracy(history2)\n",
    "    plot_loss(history2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brush_hair',\n",
       " 'catch',\n",
       " 'clap',\n",
       " 'climb_stairs',\n",
       " 'golf',\n",
       " 'jump',\n",
       " 'kick_ball',\n",
       " 'pick',\n",
       " 'pour',\n",
       " 'pullup',\n",
       " 'push',\n",
       " 'run',\n",
       " 'shoot_ball',\n",
       " 'shoot_bow',\n",
       " 'shoot_gun',\n",
       " 'sit',\n",
       " 'stand',\n",
       " 'swing_baseball',\n",
       " 'throw',\n",
       " 'walk',\n",
       " 'wave']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('jhmdb_le.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'jhmdb_openpose_model_15_refit.h5'\n",
    "ddnet.save_DDNet(rf_net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back from disk\n",
    "new_net = ddnet.load_DDNet(model_path)\n",
    "# Evaluate against test set, you should get the same accuracy\n",
    "new_net.evaluate([X_test_0,X_test_1],Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
