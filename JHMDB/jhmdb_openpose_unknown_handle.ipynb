{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# <project_root>/ddnet/ddnet.py\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(''), '..', 'ddnet'))\n",
    "import ddnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(T, C, le, exclude_labels=[], max_per_class=None):\n",
    "    \"\"\"\n",
    "    Generate X (list of arrays) and Y (array) from a dict \n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    labels = []\n",
    "    counter = collections.Counter()\n",
    "    for p, L in zip(T['pose'], T['label']):\n",
    "        if L not in exclude_labels and (max_per_class is None or counter[L] < max_per_class):\n",
    "            poses.append(p)\n",
    "            labels.append(L)\n",
    "            counter[L] += 1\n",
    "    \n",
    "    X = poses # list of arrays\n",
    "    Y = np.zeros(shape=(len(labels), C.clc_num)) # 2D array one-hot encoding of labels\n",
    "    Y[range(Y.shape[0]), le.transform(labels)] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for plotting\n",
    "# history is a history object from keras\n",
    "def plot_accuracy(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_nan(X):\n",
    "    return sum([np.count_nonzero(np.isnan(x)) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory that contains pickle files\n",
    "undoctored_data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'JHMDB_openpose_pkl')\n",
    "doctored_data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'JHMDB_openpose_doctored_pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classses:  21 ['brush_hair' 'catch' 'clap' 'climb_stairs' 'golf' 'jump' 'kick_ball'\n",
      " 'pick' 'pour' 'pullup' 'push' 'run' 'shoot_ball' 'shoot_bow' 'shoot_gun'\n",
      " 'sit' 'stand' 'swing_baseball' 'throw' 'walk' 'wave']\n"
     ]
    }
   ],
   "source": [
    "# Load pickle files\n",
    "Train_undoctored = pickle.load(open(os.path.join(undoctored_data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test_undoctored = pickle.load(open(os.path.join(undoctored_data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "Train_doctored = pickle.load(open(os.path.join(doctored_data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test_doctored = pickle.load(open(os.path.join(doctored_data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train_undoctored['label'])\n",
    "print(\"Classses: \", len(le.classes_), le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pose', 'label', 'filename'])\n",
      "wave wave/Maddin_winkt_wave_h_cm_np1_fr_med_1\n",
      "float64\n",
      "Nose\n",
      " [[217.41  111.526]\n",
      " [216.107 107.003]\n",
      " [205.713 106.334]\n",
      " [196.635 106.364]\n",
      " [197.279 106.35 ]\n",
      " [197.935 106.334]\n",
      " [198.586 106.337]\n",
      " [194.704 102.465]\n",
      " [193.385 102.465]\n",
      " [190.808 104.415]\n",
      " [190.808 104.416]\n",
      " [189.483  96.63 ]\n",
      " [193.388  95.314]\n",
      " [203.14   95.949]\n",
      " [217.418  94.665]\n",
      " [224.554  92.069]\n",
      " [225.851  92.065]\n",
      " [222.612  86.869]\n",
      " [221.977  92.076]\n",
      " [228.466  95.981]\n",
      " [231.706  96.606]\n",
      " [231.693  96.649]\n",
      " [231.06   96.64 ]\n",
      " [227.174 101.836]\n",
      " [227.805 106.336]\n",
      " [231.69  109.607]\n",
      " [232.365 110.902]\n",
      " [233.658 112.221]\n",
      " [234.944 112.222]\n",
      " [235.604 117.402]\n",
      " [234.309 117.38 ]\n",
      " [226.535 117.387]\n",
      " [221.956 121.958]\n",
      " [221.33  121.967]\n",
      " [226.492 119.36 ]\n",
      " [226.526 121.307]\n",
      " [226.538 120.659]\n",
      " [225.867 118.05 ]]\n",
      "RElbow\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "RWrist\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "LElbow\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "RWrist\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# examine some known strange videos\n",
    "print(Train_undoctored.keys())\n",
    "for p, L, filename in zip(Train_undoctored['pose'], Train_undoctored['label'], Train_undoctored['filename']):\n",
    "    if 'Maddin_winkt_wave_h_cm_np1_fr_med_1' in filename:\n",
    "        print(L, filename)\n",
    "        print(p.dtype)\n",
    "        print('Nose\\n', p[:, 0, :])\n",
    "        print('RElbow\\n', p[:, 3, :])\n",
    "        print('RWrist\\n', p[:, 4, :])\n",
    "        print('LElbow\\n', p[:, 6, :])\n",
    "        print('RWrist\\n', p[:, 7, :])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally Combine doctored and undoctored train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 (30, 25, 2) (630, 21)\n",
      "251 (31, 25, 2) (251, 21)\n"
     ]
    }
   ],
   "source": [
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=15, joint_dim=2, num_classes=21, num_filters=64)\n",
    "\n",
    "X_doctored, Y_doctored = data_generator(Train_doctored,C,le)\n",
    "X_undoctored, Y_undoctored = data_generator(Train_undoctored,C,le)\n",
    "\n",
    "# print(\"Combine doctored and undoctored training sets!\")\n",
    "# X = X_doctored + X_undoctored\n",
    "# Y = np.concatenate([Y_doctored, Y_undoctored])\n",
    "\n",
    "X = X_undoctored\n",
    "Y = Y_undoctored\n",
    "\n",
    "# X = X_doctored\n",
    "# Y = Y_doctored\n",
    "\n",
    "X_test,Y_test = data_generator(Test_undoctored,C,le) #, exclude_labels=['climb_stairs', 'jump', 'kick_ball', 'run', 'sit', 'stand', 'walk'])\n",
    "# X_test,Y_test = data_generator(Test_doctored,C,le) #, exclude_labels=['climb_stairs', 'jump', 'kick_ball', 'run', 'sit', 'stand', 'walk'])\n",
    "\n",
    "print(len(X), X[0].shape, Y.shape)\n",
    "print(len(X_test), X_test[0].shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with undetected joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NANify undetection joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ddnet.OpenPoseDataCleaner(copy=True)\n",
    "\n",
    "X_nan = list(map(cleaner.make_nan, X))\n",
    "X_test_nan = list(map(cleaner.make_nan, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter on visible subset of joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RWrist, LWrist = 4, 7\n",
    "RElbow, LElbow = 3, 6\n",
    "RShoulder, LShoulder = 2, 5\n",
    "MidHip = 8\n",
    "\n",
    "def has_joint(p, joint, thresh=3):\n",
    "    return np.count_nonzero(~np.isnan(p[:,joint, 0])) >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 -> 546\n",
      "251 -> 216\n"
     ]
    }
   ],
   "source": [
    "# Now let's filter the points with both hands visible\n",
    "\n",
    "X_subset, Y_subset = zip(*[(x, y) for x,y in zip(X_nan, Y) \\\n",
    "                           if has_joint(x, RWrist) and has_joint(x, LWrist) \\\n",
    "                            and has_joint(x, RElbow) and has_joint(x, LElbow) \\\n",
    "                            and has_joint(x, RShoulder) and has_joint(x, LShoulder)])\n",
    "Y_subset=np.array(Y_subset)\n",
    "\n",
    "X_test_subset, Y_test_subset = zip(*[(x, y) for x,y in zip(X_test_nan, Y_test) \\\n",
    "                                     if has_joint(x, RWrist) and has_joint(x, LWrist) \\\n",
    "                                     and has_joint(x, RShoulder) and has_joint(x, LShoulder)])\n",
    "Y_test_subset=np.array(Y_test_subset)\n",
    "\n",
    "print(len(X), '->', len(X_subset))\n",
    "print(len(X_test), '->', len(X_test_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter good joints, temporal interpolation and normalize (still have NANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = list(map(cleaner.transform_point, X_subset))\n",
    "X_test_clean = list(map(cleaner.transform_point, X_test_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 105) (32, 15, 2)\n",
      "49176\n",
      "17142\n",
      "302624 46656\n",
      "106496 16448\n"
     ]
    }
   ],
   "source": [
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=X_clean[0].shape[1], joint_dim=2, num_classes=21, num_filters=64)\n",
    "\n",
    "X_0_nan, X_1_nan = ddnet.preprocess_batch(X_clean, C)\n",
    "X_test_0_nan, X_test_1_nan = ddnet.preprocess_batch(X_test_clean, C)\n",
    "print(X_0_nan[0].shape, X_1_nan[0].shape)\n",
    "\n",
    "print(count_all_nan(X_clean))\n",
    "print(count_all_nan(X_test_clean))\n",
    "print(count_all_nan(X_0_nan), count_all_nan(X_1_nan))\n",
    "print(count_all_nan(X_test_0_nan), count_all_nan(X_test_1_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -0.65950087 -0.12642284  0.35559673 -0.64442366\n",
      " -0.12598109  0.2508891   0.29156327  0.3293937   1.06008882  0.31034416\n",
      "  1.08756844         nan         nan -0.28515897  0.25663624 -0.30404791\n",
      "  0.0985716   0.3805516   0.33617743  0.31488398  1.05251784  0.41360095\n",
      "  1.14400971         nan         nan -0.44713877  0.13668593  0.02164037\n",
      "  0.01469042 -0.18725831 -0.30180534  0.40056135 -0.01250218  0.56892368\n",
      "         nan         nan  0.54531851  0.14884868 -0.11876332 -0.4457569\n",
      " -0.66906255 -0.12419867 -0.20589118  0.11359826         nan         nan\n",
      " -0.24591002  0.21999861  0.35196385  0.44562351  1.1398      0.30590762\n",
      "  1.10043431         nan         nan -0.50103164 -0.26257918 -0.08592249\n",
      "  0.49095518 -0.39417049  0.38234921         nan         nan -0.66026607\n",
      " -0.43308903  0.00425622 -0.88018957 -0.11376807         nan         nan\n",
      " -0.77077073 -0.21210259 -0.75909936 -0.1918349          nan         nan\n",
      " -0.26112762 -0.53011107 -0.12919287         nan         nan -0.11135829\n",
      " -0.6023527          nan         nan -0.20545829         nan         nan\n",
      "         nan         nan         nan]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.65950087 -0.12642284  0.35559673 -0.64442366\n",
      " -0.12598109  0.2508891   0.29156327  0.3293937   1.06008882  0.31034416\n",
      "  1.08756844  0.          0.         -0.28515897  0.25663624 -0.30404791\n",
      "  0.0985716   0.3805516   0.33617743  0.31488398  1.05251784  0.41360095\n",
      "  1.14400971  0.          0.         -0.44713877  0.13668593  0.02164037\n",
      "  0.01469042 -0.18725831 -0.30180534  0.40056135 -0.01250218  0.56892368\n",
      "  0.          0.          0.54531851  0.14884868 -0.11876332 -0.4457569\n",
      " -0.66906255 -0.12419867 -0.20589118  0.11359826  0.          0.\n",
      " -0.24591002  0.21999861  0.35196385  0.44562351  1.1398      0.30590762\n",
      "  1.10043431  0.          0.         -0.50103164 -0.26257918 -0.08592249\n",
      "  0.49095518 -0.39417049  0.38234921  0.          0.         -0.66026607\n",
      " -0.43308903  0.00425622 -0.88018957 -0.11376807  0.          0.\n",
      " -0.77077073 -0.21210259 -0.75909936 -0.1918349   0.          0.\n",
      " -0.26112762 -0.53011107 -0.12919287  0.          0.         -0.11135829\n",
      " -0.6023527   0.          0.         -0.20545829  0.          0.\n",
      "  0.          0.          0.        ]\n",
      "[[        nan         nan]\n",
      " [-0.09975051 -0.4194388 ]\n",
      " [ 0.14022362 -0.40908951]\n",
      " [ 0.26031849  0.08066901]\n",
      " [ 0.25010781  0.47053841]\n",
      " [-0.34976591 -0.43967535]\n",
      " [-0.46037393  0.08065361]\n",
      " [-0.36954044  0.42071706]\n",
      " [-0.14034682  0.49075956]\n",
      " [ 0.02012875  0.5106573 ]\n",
      " [-0.00981026  1.03101706]\n",
      " [-0.30998583  0.48068749]\n",
      " [-0.2901497   1.04082733]\n",
      " [        nan         nan]\n",
      " [        nan         nan]]\n",
      "[[ 0.          0.        ]\n",
      " [-0.09975051 -0.4194388 ]\n",
      " [ 0.14022362 -0.40908951]\n",
      " [ 0.26031849  0.08066901]\n",
      " [ 0.25010781  0.47053841]\n",
      " [-0.34976591 -0.43967535]\n",
      " [-0.46037393  0.08065361]\n",
      " [-0.36954044  0.42071706]\n",
      " [-0.14034682  0.49075956]\n",
      " [ 0.02012875  0.5106573 ]\n",
      " [-0.00981026  1.03101706]\n",
      " [-0.30998583  0.48068749]\n",
      " [-0.2901497   1.04082733]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Impute JCD with 0\n",
    "X_0_imp = X_0_nan.copy()\n",
    "X_0_imp[np.isnan(X_0_imp)] = 0.\n",
    "X_test_0_imp = X_test_0_nan.copy()\n",
    "X_test_0_imp[np.isnan(X_test_0_imp)] = 0.\n",
    "print(X_0_nan[0][0])\n",
    "print(X_0_imp[0][0])\n",
    "\n",
    "# Impute Cartessian with 0\n",
    "X_1_imp = X_1_nan.copy()\n",
    "X_1_imp[np.isnan(X_1_imp)] = 0.\n",
    "X_test_1_imp = X_test_1_nan.copy()\n",
    "X_test_1_imp[np.isnan(X_test_1_imp)] = 0.\n",
    "print(X_1_nan[0][0])\n",
    "print(X_1_imp[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 32, 105) (546, 32, 15, 2)\n",
      "(216, 32, 105) (216, 32, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_input = Y_subset\n",
    "Y_test_input = Y_test_subset\n",
    "X_0, X_1 = X_0_imp, X_1_imp\n",
    "X_test_0, X_test_1 = X_test_0_imp, X_test_1_imp\n",
    "print(X_0.shape, X_1.shape)\n",
    "print(X_test_0.shape, X_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale sample weight to balance classes\n",
    "def get_sample_weight(Y):\n",
    "    cls_ids = np.argmax(Y, axis=1)\n",
    "    assert cls_ids.shape[0] == Y.shape[0]\n",
    "    cls_histo = np.array([np.count_nonzero(cls_ids==i) for i in range(Y.shape[1])])\n",
    "    cls_weight = np.max(cls_histo) / cls_histo # balanced\n",
    "    print(cls_histo)\n",
    "    print(cls_weight)\n",
    "    sample_weight = cls_weight[cls_ids]\n",
    "    assert sample_weight.shape[0] == Y.shape[0]\n",
    "    return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 34 24 27 30 19 22 20 36 38 19 27 18 35 24 19 16 39 31 26 23]\n",
      "[2.05263158 1.14705882 1.625      1.44444444 1.3        2.05263158\n",
      " 1.77272727 1.95       1.08333333 1.02631579 2.05263158 1.44444444\n",
      " 2.16666667 1.11428571 1.625      2.05263158 2.4375     1.\n",
      " 1.25806452 1.5        1.69565217]\n",
      "(546,)\n",
      "[1.77272727 2.16666667 2.05263158 1.08333333 2.05263158 1.11428571]\n"
     ]
    }
   ],
   "source": [
    "sample_weight = get_sample_weight(Y_input)\n",
    "print(sample_weight.shape)\n",
    "print(sample_weight[::100][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Net, Train and plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 105)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 15, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 4, 512)       1714816     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 512)          0           model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          65536       global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 128)          0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16384       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 128)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 128)          0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 21)           2709        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,800,469\n",
      "Trainable params: 1,794,837\n",
      "Non-trainable params: 5,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random.seed(456)\n",
    "\n",
    "DD_Net = ddnet.build_DD_Net(C)\n",
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 546 samples, validate on 216 samples\n",
      "Epoch 1/1000\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 5.7330 - accuracy: 0.0440 - val_loss: 3.0422 - val_accuracy: 0.0463\n",
      "Epoch 2/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 5.3218 - accuracy: 0.0678 - val_loss: 3.0401 - val_accuracy: 0.0556\n",
      "Epoch 3/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 5.0114 - accuracy: 0.1081 - val_loss: 3.0379 - val_accuracy: 0.0694\n",
      "Epoch 4/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 4.8336 - accuracy: 0.1172 - val_loss: 3.0360 - val_accuracy: 0.0833\n",
      "Epoch 5/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 4.5686 - accuracy: 0.1502 - val_loss: 3.0333 - val_accuracy: 0.1343\n",
      "Epoch 6/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 4.7127 - accuracy: 0.1465 - val_loss: 3.0299 - val_accuracy: 0.1574\n",
      "Epoch 7/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 4.4413 - accuracy: 0.1484 - val_loss: 3.0253 - val_accuracy: 0.1574\n",
      "Epoch 8/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 4.2905 - accuracy: 0.1813 - val_loss: 3.0196 - val_accuracy: 0.1574\n",
      "Epoch 9/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 4.1403 - accuracy: 0.2198 - val_loss: 3.0126 - val_accuracy: 0.1435\n",
      "Epoch 10/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 3.8989 - accuracy: 0.2179 - val_loss: 3.0039 - val_accuracy: 0.1389\n",
      "Epoch 11/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 3.8370 - accuracy: 0.2399 - val_loss: 2.9932 - val_accuracy: 0.1574\n",
      "Epoch 12/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 3.6969 - accuracy: 0.2747 - val_loss: 2.9820 - val_accuracy: 0.1481\n",
      "Epoch 13/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 3.7497 - accuracy: 0.2656 - val_loss: 2.9704 - val_accuracy: 0.1296\n",
      "Epoch 14/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 3.4928 - accuracy: 0.3095 - val_loss: 2.9586 - val_accuracy: 0.1111\n",
      "Epoch 15/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 3.2908 - accuracy: 0.3297 - val_loss: 2.9463 - val_accuracy: 0.1157\n",
      "Epoch 16/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 3.3279 - accuracy: 0.3645 - val_loss: 2.9352 - val_accuracy: 0.1157\n",
      "Epoch 17/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 3.2557 - accuracy: 0.3535 - val_loss: 2.9251 - val_accuracy: 0.1250\n",
      "Epoch 18/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 3.0579 - accuracy: 0.3681 - val_loss: 2.9143 - val_accuracy: 0.1296\n",
      "Epoch 19/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 3.1563 - accuracy: 0.3993 - val_loss: 2.9008 - val_accuracy: 0.1389\n",
      "Epoch 20/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 3.0087 - accuracy: 0.3956 - val_loss: 2.8852 - val_accuracy: 0.1528\n",
      "Epoch 21/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 2.7660 - accuracy: 0.4560 - val_loss: 2.8688 - val_accuracy: 0.1667\n",
      "Epoch 22/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 2.6536 - accuracy: 0.4908 - val_loss: 2.8518 - val_accuracy: 0.1667\n",
      "Epoch 23/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 2.6357 - accuracy: 0.4890 - val_loss: 2.8358 - val_accuracy: 0.1759\n",
      "Epoch 24/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 2.5543 - accuracy: 0.4853 - val_loss: 2.8214 - val_accuracy: 0.1852\n",
      "Epoch 25/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 2.5617 - accuracy: 0.5128 - val_loss: 2.8097 - val_accuracy: 0.1898\n",
      "Epoch 26/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 2.5070 - accuracy: 0.5110 - val_loss: 2.7989 - val_accuracy: 0.1991\n",
      "Epoch 27/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 2.3522 - accuracy: 0.5513 - val_loss: 2.7865 - val_accuracy: 0.2083\n",
      "Epoch 28/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 2.3803 - accuracy: 0.5440 - val_loss: 2.7739 - val_accuracy: 0.2083\n",
      "Epoch 29/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 2.2552 - accuracy: 0.5458 - val_loss: 2.7604 - val_accuracy: 0.2083\n",
      "Epoch 30/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 2.1092 - accuracy: 0.6026 - val_loss: 2.7475 - val_accuracy: 0.2130\n",
      "Epoch 31/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 2.1545 - accuracy: 0.5733 - val_loss: 2.7379 - val_accuracy: 0.2083\n",
      "Epoch 32/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 2.0740 - accuracy: 0.6227 - val_loss: 2.7302 - val_accuracy: 0.1944\n",
      "Epoch 33/1000\n",
      "546/546 [==============================] - 0s 179us/step - loss: 2.0596 - accuracy: 0.6136 - val_loss: 2.7198 - val_accuracy: 0.1852\n",
      "Epoch 34/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 2.0357 - accuracy: 0.6062 - val_loss: 2.7093 - val_accuracy: 0.1944\n",
      "Epoch 35/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 1.7815 - accuracy: 0.6722 - val_loss: 2.6978 - val_accuracy: 0.2037\n",
      "Epoch 36/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 1.8513 - accuracy: 0.6410 - val_loss: 2.6835 - val_accuracy: 0.2130\n",
      "Epoch 37/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 1.8249 - accuracy: 0.6557 - val_loss: 2.6681 - val_accuracy: 0.2130\n",
      "Epoch 38/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 1.5959 - accuracy: 0.7051 - val_loss: 2.6522 - val_accuracy: 0.2361\n",
      "Epoch 39/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 1.5740 - accuracy: 0.7271 - val_loss: 2.6361 - val_accuracy: 0.2454\n",
      "Epoch 40/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 1.6705 - accuracy: 0.6886 - val_loss: 2.6201 - val_accuracy: 0.2593\n",
      "Epoch 41/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 1.5954 - accuracy: 0.6978 - val_loss: 2.5996 - val_accuracy: 0.2639\n",
      "Epoch 42/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 1.4586 - accuracy: 0.7363 - val_loss: 2.5843 - val_accuracy: 0.2639\n",
      "Epoch 43/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 1.5075 - accuracy: 0.7253 - val_loss: 2.5744 - val_accuracy: 0.2731\n",
      "Epoch 44/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 1.4028 - accuracy: 0.7509 - val_loss: 2.5699 - val_accuracy: 0.2685\n",
      "Epoch 45/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 1.4087 - accuracy: 0.7473 - val_loss: 2.5632 - val_accuracy: 0.2778\n",
      "Epoch 46/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 1.3381 - accuracy: 0.7527 - val_loss: 2.5580 - val_accuracy: 0.2824\n",
      "Epoch 47/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 1.3185 - accuracy: 0.7747 - val_loss: 2.5553 - val_accuracy: 0.2870\n",
      "Epoch 48/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 1.3162 - accuracy: 0.7637 - val_loss: 2.5594 - val_accuracy: 0.2778\n",
      "Epoch 49/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 1.2294 - accuracy: 0.7839 - val_loss: 2.5646 - val_accuracy: 0.2593\n",
      "Epoch 50/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 1.1958 - accuracy: 0.7930 - val_loss: 2.5682 - val_accuracy: 0.2546\n",
      "Epoch 51/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 1.1400 - accuracy: 0.7930 - val_loss: 2.5730 - val_accuracy: 0.2407\n",
      "Epoch 52/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 1.1053 - accuracy: 0.8114 - val_loss: 2.5784 - val_accuracy: 0.2407\n",
      "Epoch 53/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 1.0959 - accuracy: 0.7821 - val_loss: 2.5833 - val_accuracy: 0.2361\n",
      "Epoch 54/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.0800 - accuracy: 0.8333 - val_loss: 2.5907 - val_accuracy: 0.2454\n",
      "Epoch 55/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 1.0355 - accuracy: 0.8315 - val_loss: 2.5968 - val_accuracy: 0.2361\n",
      "Epoch 56/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.9994 - accuracy: 0.8462 - val_loss: 2.6023 - val_accuracy: 0.2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.9127 - accuracy: 0.8553 - val_loss: 2.6075 - val_accuracy: 0.2222\n",
      "Epoch 58/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.8895 - accuracy: 0.8571 - val_loss: 2.6157 - val_accuracy: 0.2269\n",
      "Epoch 59/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.9682 - accuracy: 0.8425 - val_loss: 2.6172 - val_accuracy: 0.2176\n",
      "Epoch 60/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.8850 - accuracy: 0.8608 - val_loss: 2.6181 - val_accuracy: 0.2315\n",
      "Epoch 61/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.8230 - accuracy: 0.8864 - val_loss: 2.6154 - val_accuracy: 0.2361\n",
      "Epoch 62/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.8249 - accuracy: 0.8590 - val_loss: 2.6069 - val_accuracy: 0.2407\n",
      "Epoch 63/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.8133 - accuracy: 0.8755 - val_loss: 2.6101 - val_accuracy: 0.2315\n",
      "Epoch 64/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.7611 - accuracy: 0.8974 - val_loss: 2.6079 - val_accuracy: 0.2454\n",
      "Epoch 65/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.7595 - accuracy: 0.8810 - val_loss: 2.6001 - val_accuracy: 0.2454\n",
      "Epoch 66/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.7410 - accuracy: 0.8938 - val_loss: 2.5988 - val_accuracy: 0.2454\n",
      "Epoch 67/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.7594 - accuracy: 0.8828 - val_loss: 2.6025 - val_accuracy: 0.2500\n",
      "Epoch 68/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.7548 - accuracy: 0.8919 - val_loss: 2.6121 - val_accuracy: 0.2500\n",
      "Epoch 69/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.6905 - accuracy: 0.9011 - val_loss: 2.6269 - val_accuracy: 0.2500\n",
      "Epoch 70/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.6405 - accuracy: 0.9231 - val_loss: 2.6535 - val_accuracy: 0.2454\n",
      "Epoch 71/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.6423 - accuracy: 0.9212 - val_loss: 2.6772 - val_accuracy: 0.2407\n",
      "Epoch 72/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.6395 - accuracy: 0.9176 - val_loss: 2.6994 - val_accuracy: 0.2407\n",
      "Epoch 73/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.6730 - accuracy: 0.8883 - val_loss: 2.7220 - val_accuracy: 0.2269\n",
      "Epoch 74/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.6180 - accuracy: 0.9103 - val_loss: 2.7318 - val_accuracy: 0.2315\n",
      "Epoch 75/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.5861 - accuracy: 0.9176 - val_loss: 2.7336 - val_accuracy: 0.2222\n",
      "Epoch 76/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.5180 - accuracy: 0.9414 - val_loss: 2.7208 - val_accuracy: 0.2361\n",
      "Epoch 77/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.5455 - accuracy: 0.9396 - val_loss: 2.6992 - val_accuracy: 0.2407\n",
      "Epoch 78/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.5341 - accuracy: 0.9231 - val_loss: 2.6800 - val_accuracy: 0.2407\n",
      "Epoch 79/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.5667 - accuracy: 0.9249 - val_loss: 2.6718 - val_accuracy: 0.2500\n",
      "Epoch 80/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.5075 - accuracy: 0.9286 - val_loss: 2.6664 - val_accuracy: 0.2546\n",
      "Epoch 81/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.4301 - accuracy: 0.9469 - val_loss: 2.6637 - val_accuracy: 0.2593\n",
      "Epoch 82/1000\n",
      "546/546 [==============================] - 0s 175us/step - loss: 0.4515 - accuracy: 0.9377 - val_loss: 2.6676 - val_accuracy: 0.2546\n",
      "Epoch 83/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.4132 - accuracy: 0.9579 - val_loss: 2.6836 - val_accuracy: 0.2546\n",
      "Epoch 84/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.4537 - accuracy: 0.9377 - val_loss: 2.6973 - val_accuracy: 0.2546\n",
      "Epoch 85/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.4225 - accuracy: 0.9487 - val_loss: 2.6999 - val_accuracy: 0.2500\n",
      "Epoch 86/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.4240 - accuracy: 0.9487 - val_loss: 2.7129 - val_accuracy: 0.2315\n",
      "Epoch 87/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.4369 - accuracy: 0.9359 - val_loss: 2.7211 - val_accuracy: 0.2222\n",
      "Epoch 88/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.3983 - accuracy: 0.9542 - val_loss: 2.7142 - val_accuracy: 0.2176\n",
      "Epoch 89/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.3559 - accuracy: 0.9707 - val_loss: 2.6934 - val_accuracy: 0.2269\n",
      "Epoch 90/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.3519 - accuracy: 0.9597 - val_loss: 2.6722 - val_accuracy: 0.2315\n",
      "Epoch 91/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.3990 - accuracy: 0.9524 - val_loss: 2.6569 - val_accuracy: 0.2454\n",
      "Epoch 92/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.3949 - accuracy: 0.9542 - val_loss: 2.6446 - val_accuracy: 0.2500\n",
      "Epoch 93/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.3549 - accuracy: 0.9670 - val_loss: 2.6442 - val_accuracy: 0.2639\n",
      "Epoch 94/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.3529 - accuracy: 0.9689 - val_loss: 2.6609 - val_accuracy: 0.2685\n",
      "Epoch 95/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.3187 - accuracy: 0.9615 - val_loss: 2.6824 - val_accuracy: 0.2731\n",
      "Epoch 96/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.3407 - accuracy: 0.9634 - val_loss: 2.7150 - val_accuracy: 0.2639\n",
      "Epoch 97/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.3257 - accuracy: 0.9670 - val_loss: 2.7530 - val_accuracy: 0.2593\n",
      "Epoch 98/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.3117 - accuracy: 0.9652 - val_loss: 2.7891 - val_accuracy: 0.2407\n",
      "Epoch 99/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.2873 - accuracy: 0.9725 - val_loss: 2.8244 - val_accuracy: 0.2315\n",
      "Epoch 100/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.2936 - accuracy: 0.9707 - val_loss: 2.8480 - val_accuracy: 0.2315\n",
      "Epoch 101/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.2747 - accuracy: 0.9670 - val_loss: 2.8592 - val_accuracy: 0.2315\n",
      "Epoch 102/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.2873 - accuracy: 0.9780 - val_loss: 2.8693 - val_accuracy: 0.2315\n",
      "Epoch 103/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.2720 - accuracy: 0.9799 - val_loss: 2.8598 - val_accuracy: 0.2361\n",
      "Epoch 104/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.2716 - accuracy: 0.9707 - val_loss: 2.8385 - val_accuracy: 0.2407\n",
      "Epoch 105/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.2266 - accuracy: 0.9780 - val_loss: 2.8150 - val_accuracy: 0.2361\n",
      "Epoch 106/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.2445 - accuracy: 0.9780 - val_loss: 2.7923 - val_accuracy: 0.2361\n",
      "Epoch 107/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.2565 - accuracy: 0.9780 - val_loss: 2.7847 - val_accuracy: 0.2407\n",
      "Epoch 108/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.2270 - accuracy: 0.9817 - val_loss: 2.7834 - val_accuracy: 0.2454\n",
      "Epoch 109/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.2635 - accuracy: 0.9799 - val_loss: 2.8068 - val_accuracy: 0.2454\n",
      "Epoch 110/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.2489 - accuracy: 0.9744 - val_loss: 2.8500 - val_accuracy: 0.2454\n",
      "Epoch 111/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.2273 - accuracy: 0.9872 - val_loss: 2.8834 - val_accuracy: 0.2361\n",
      "Epoch 112/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.2143 - accuracy: 0.9762 - val_loss: 2.9219 - val_accuracy: 0.2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.2126 - accuracy: 0.9927 - val_loss: 2.9634 - val_accuracy: 0.2407\n",
      "Epoch 114/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.2326 - accuracy: 0.9835 - val_loss: 2.9926 - val_accuracy: 0.2315\n",
      "Epoch 115/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.2301 - accuracy: 0.9817 - val_loss: 3.0162 - val_accuracy: 0.2361\n",
      "Epoch 116/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.2342 - accuracy: 0.9872 - val_loss: 3.0267 - val_accuracy: 0.2361\n",
      "Epoch 117/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.2150 - accuracy: 0.9890 - val_loss: 3.0315 - val_accuracy: 0.2361\n",
      "Epoch 118/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.2078 - accuracy: 0.9872 - val_loss: 3.0290 - val_accuracy: 0.2361\n",
      "Epoch 119/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.2018 - accuracy: 0.9908 - val_loss: 3.0147 - val_accuracy: 0.2361\n",
      "Epoch 120/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.2126 - accuracy: 0.9762 - val_loss: 3.0000 - val_accuracy: 0.2361\n",
      "Epoch 121/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.2099 - accuracy: 0.9908 - val_loss: 2.9945 - val_accuracy: 0.2361\n",
      "Epoch 122/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.2157 - accuracy: 0.9799 - val_loss: 2.9888 - val_accuracy: 0.2361\n",
      "Epoch 123/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.2111 - accuracy: 0.9762 - val_loss: 2.9767 - val_accuracy: 0.2407\n",
      "Epoch 124/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1756 - accuracy: 0.9817 - val_loss: 2.9661 - val_accuracy: 0.2407\n",
      "Epoch 125/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.2077 - accuracy: 0.9872 - val_loss: 2.9599 - val_accuracy: 0.2593\n",
      "Epoch 126/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.2214 - accuracy: 0.9853 - val_loss: 2.9683 - val_accuracy: 0.2546\n",
      "Epoch 127/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1673 - accuracy: 0.9872 - val_loss: 2.9800 - val_accuracy: 0.2500\n",
      "Epoch 128/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1793 - accuracy: 0.9853 - val_loss: 2.9934 - val_accuracy: 0.2454\n",
      "Epoch 129/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1842 - accuracy: 0.9835 - val_loss: 3.0131 - val_accuracy: 0.2407\n",
      "Epoch 130/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1845 - accuracy: 0.9853 - val_loss: 3.0314 - val_accuracy: 0.2454\n",
      "Epoch 131/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1512 - accuracy: 0.9872 - val_loss: 3.0500 - val_accuracy: 0.2500\n",
      "Epoch 132/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1746 - accuracy: 0.9872 - val_loss: 3.0588 - val_accuracy: 0.2546\n",
      "Epoch 133/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1840 - accuracy: 0.9908 - val_loss: 3.0586 - val_accuracy: 0.2546\n",
      "Epoch 134/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1885 - accuracy: 0.9799 - val_loss: 3.0393 - val_accuracy: 0.2546\n",
      "Epoch 135/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1800 - accuracy: 0.9908 - val_loss: 3.0030 - val_accuracy: 0.2731\n",
      "Epoch 136/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1843 - accuracy: 0.9835 - val_loss: 2.9658 - val_accuracy: 0.2824\n",
      "Epoch 137/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1468 - accuracy: 0.9890 - val_loss: 2.9477 - val_accuracy: 0.2824\n",
      "Epoch 138/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1771 - accuracy: 0.9872 - val_loss: 2.9275 - val_accuracy: 0.2824\n",
      "Epoch 139/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1799 - accuracy: 0.9853 - val_loss: 2.9120 - val_accuracy: 0.2824\n",
      "Epoch 140/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1870 - accuracy: 0.9817 - val_loss: 2.9073 - val_accuracy: 0.2870\n",
      "Epoch 141/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1876 - accuracy: 0.9817 - val_loss: 2.9023 - val_accuracy: 0.2870\n",
      "Epoch 142/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1762 - accuracy: 0.9890 - val_loss: 2.9028 - val_accuracy: 0.2870\n",
      "Epoch 143/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1598 - accuracy: 0.9927 - val_loss: 2.9035 - val_accuracy: 0.2963\n",
      "Epoch 144/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1668 - accuracy: 0.9853 - val_loss: 2.9065 - val_accuracy: 0.2963\n",
      "Epoch 145/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1529 - accuracy: 0.9908 - val_loss: 2.9144 - val_accuracy: 0.2963\n",
      "Epoch 146/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1621 - accuracy: 0.9908 - val_loss: 2.9190 - val_accuracy: 0.2963\n",
      "Epoch 147/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1498 - accuracy: 0.9945 - val_loss: 2.9217 - val_accuracy: 0.2963\n",
      "Epoch 148/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1534 - accuracy: 0.9908 - val_loss: 2.9258 - val_accuracy: 0.2963\n",
      "Epoch 149/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1705 - accuracy: 0.9908 - val_loss: 2.9294 - val_accuracy: 0.2963\n",
      "Epoch 150/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1431 - accuracy: 0.9890 - val_loss: 2.9319 - val_accuracy: 0.2963\n",
      "Epoch 151/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1614 - accuracy: 0.9872 - val_loss: 2.9336 - val_accuracy: 0.2963\n",
      "Epoch 152/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1604 - accuracy: 0.9890 - val_loss: 2.9341 - val_accuracy: 0.2963\n",
      "Epoch 153/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1759 - accuracy: 0.9908 - val_loss: 2.9363 - val_accuracy: 0.2963\n",
      "Epoch 154/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1447 - accuracy: 0.9927 - val_loss: 2.9380 - val_accuracy: 0.2963\n",
      "Epoch 155/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1517 - accuracy: 0.9945 - val_loss: 2.9395 - val_accuracy: 0.2963\n",
      "Epoch 156/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1519 - accuracy: 0.9890 - val_loss: 2.9385 - val_accuracy: 0.2963\n",
      "Epoch 157/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1767 - accuracy: 0.9908 - val_loss: 2.9372 - val_accuracy: 0.2917\n",
      "Epoch 158/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1600 - accuracy: 0.9927 - val_loss: 2.9355 - val_accuracy: 0.2917\n",
      "Epoch 159/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1307 - accuracy: 0.9963 - val_loss: 2.9342 - val_accuracy: 0.2917\n",
      "Epoch 160/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1477 - accuracy: 0.9945 - val_loss: 2.9335 - val_accuracy: 0.2963\n",
      "Epoch 161/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1490 - accuracy: 0.9982 - val_loss: 2.9314 - val_accuracy: 0.2963\n",
      "Epoch 162/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1818 - accuracy: 0.9890 - val_loss: 2.9295 - val_accuracy: 0.2963\n",
      "Epoch 163/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1787 - accuracy: 0.9853 - val_loss: 2.9281 - val_accuracy: 0.2963\n",
      "Epoch 164/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1668 - accuracy: 0.9872 - val_loss: 2.9261 - val_accuracy: 0.3009\n",
      "Epoch 165/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1509 - accuracy: 0.9945 - val_loss: 2.9233 - val_accuracy: 0.3056\n",
      "Epoch 166/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1675 - accuracy: 0.9853 - val_loss: 2.9201 - val_accuracy: 0.3102\n",
      "Epoch 167/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1363 - accuracy: 0.9945 - val_loss: 2.9173 - val_accuracy: 0.3102\n",
      "Epoch 168/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1376 - accuracy: 0.9963 - val_loss: 2.9145 - val_accuracy: 0.3102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1447 - accuracy: 0.9963 - val_loss: 2.9114 - val_accuracy: 0.3102\n",
      "Epoch 170/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1643 - accuracy: 0.9872 - val_loss: 2.9083 - val_accuracy: 0.3056\n",
      "Epoch 171/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1719 - accuracy: 0.9872 - val_loss: 2.9059 - val_accuracy: 0.3056\n",
      "Epoch 172/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1391 - accuracy: 0.9927 - val_loss: 2.9032 - val_accuracy: 0.3056\n",
      "Epoch 173/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1597 - accuracy: 0.9872 - val_loss: 2.9013 - val_accuracy: 0.3056\n",
      "Epoch 174/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1458 - accuracy: 0.9945 - val_loss: 2.8982 - val_accuracy: 0.3056\n",
      "Epoch 175/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1597 - accuracy: 0.9927 - val_loss: 2.8951 - val_accuracy: 0.3056\n",
      "Epoch 176/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1366 - accuracy: 0.9872 - val_loss: 2.8916 - val_accuracy: 0.3056\n",
      "Epoch 177/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1808 - accuracy: 0.9817 - val_loss: 2.8886 - val_accuracy: 0.3056\n",
      "Epoch 178/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1738 - accuracy: 0.9890 - val_loss: 2.8838 - val_accuracy: 0.3102\n",
      "Epoch 179/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1426 - accuracy: 0.9908 - val_loss: 2.8792 - val_accuracy: 0.3102\n",
      "Epoch 180/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1616 - accuracy: 0.9872 - val_loss: 2.8749 - val_accuracy: 0.3148\n",
      "Epoch 181/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1438 - accuracy: 0.9890 - val_loss: 2.8700 - val_accuracy: 0.3148\n",
      "Epoch 182/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1288 - accuracy: 0.9982 - val_loss: 2.8656 - val_accuracy: 0.3148\n",
      "Epoch 183/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1466 - accuracy: 0.9927 - val_loss: 2.8616 - val_accuracy: 0.3148\n",
      "Epoch 184/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1427 - accuracy: 0.9945 - val_loss: 2.8563 - val_accuracy: 0.3148\n",
      "Epoch 185/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1680 - accuracy: 0.9890 - val_loss: 2.8509 - val_accuracy: 0.3148\n",
      "Epoch 186/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1541 - accuracy: 0.9908 - val_loss: 2.8463 - val_accuracy: 0.3148\n",
      "Epoch 187/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1552 - accuracy: 0.9853 - val_loss: 2.8411 - val_accuracy: 0.3148\n",
      "Epoch 188/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1393 - accuracy: 0.9963 - val_loss: 2.8354 - val_accuracy: 0.3148\n",
      "Epoch 189/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1366 - accuracy: 0.9945 - val_loss: 2.8299 - val_accuracy: 0.3148\n",
      "Epoch 190/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1504 - accuracy: 0.9927 - val_loss: 2.8246 - val_accuracy: 0.3148\n",
      "Epoch 191/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1740 - accuracy: 0.9853 - val_loss: 2.8189 - val_accuracy: 0.3148\n",
      "Epoch 192/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1502 - accuracy: 0.9908 - val_loss: 2.8137 - val_accuracy: 0.3148\n",
      "Epoch 193/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1261 - accuracy: 0.9963 - val_loss: 2.8084 - val_accuracy: 0.3148\n",
      "Epoch 194/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1421 - accuracy: 0.9945 - val_loss: 2.8030 - val_accuracy: 0.3194\n",
      "Epoch 195/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1682 - accuracy: 0.9908 - val_loss: 2.7983 - val_accuracy: 0.3194\n",
      "Epoch 196/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1551 - accuracy: 0.9872 - val_loss: 2.7928 - val_accuracy: 0.3194\n",
      "Epoch 197/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1592 - accuracy: 0.9872 - val_loss: 2.7867 - val_accuracy: 0.3241\n",
      "Epoch 198/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1509 - accuracy: 0.9890 - val_loss: 2.7809 - val_accuracy: 0.3287\n",
      "Epoch 199/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1713 - accuracy: 0.9890 - val_loss: 2.7745 - val_accuracy: 0.3287\n",
      "Epoch 200/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1515 - accuracy: 0.9945 - val_loss: 2.7686 - val_accuracy: 0.3287\n",
      "Epoch 201/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1563 - accuracy: 0.9945 - val_loss: 2.7629 - val_accuracy: 0.3333\n",
      "Epoch 202/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1445 - accuracy: 0.9945 - val_loss: 2.7571 - val_accuracy: 0.3380\n",
      "Epoch 203/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1475 - accuracy: 0.9927 - val_loss: 2.7513 - val_accuracy: 0.3426\n",
      "Epoch 204/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1578 - accuracy: 0.9945 - val_loss: 2.7452 - val_accuracy: 0.3426\n",
      "Epoch 205/1000\n",
      "546/546 [==============================] - 0s 128us/step - loss: 0.1786 - accuracy: 0.9927 - val_loss: 2.7391 - val_accuracy: 0.3426\n",
      "Epoch 206/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1619 - accuracy: 0.9872 - val_loss: 2.7330 - val_accuracy: 0.3426\n",
      "Epoch 207/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1691 - accuracy: 0.9927 - val_loss: 2.7272 - val_accuracy: 0.3472\n",
      "Epoch 208/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1502 - accuracy: 0.9872 - val_loss: 2.7210 - val_accuracy: 0.3472\n",
      "Epoch 209/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1536 - accuracy: 0.9927 - val_loss: 2.7151 - val_accuracy: 0.3472\n",
      "Epoch 210/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1553 - accuracy: 0.9945 - val_loss: 2.7096 - val_accuracy: 0.3472\n",
      "Epoch 211/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1571 - accuracy: 0.9963 - val_loss: 2.7036 - val_accuracy: 0.3472\n",
      "Epoch 212/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1547 - accuracy: 0.9890 - val_loss: 2.6980 - val_accuracy: 0.3519\n",
      "Epoch 213/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1619 - accuracy: 0.9927 - val_loss: 2.6918 - val_accuracy: 0.3519\n",
      "Epoch 214/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1580 - accuracy: 0.9890 - val_loss: 2.6863 - val_accuracy: 0.3565\n",
      "Epoch 215/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1818 - accuracy: 0.9890 - val_loss: 2.6803 - val_accuracy: 0.3565\n",
      "Epoch 216/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1568 - accuracy: 0.9890 - val_loss: 2.6742 - val_accuracy: 0.3565\n",
      "Epoch 217/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1469 - accuracy: 0.9963 - val_loss: 2.6687 - val_accuracy: 0.3611\n",
      "Epoch 218/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1400 - accuracy: 0.9963 - val_loss: 2.6626 - val_accuracy: 0.3611\n",
      "Epoch 219/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1653 - accuracy: 0.9890 - val_loss: 2.6571 - val_accuracy: 0.3611\n",
      "Epoch 220/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1422 - accuracy: 0.9945 - val_loss: 2.6512 - val_accuracy: 0.3657\n",
      "Epoch 221/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1705 - accuracy: 0.9927 - val_loss: 2.6450 - val_accuracy: 0.3657\n",
      "Epoch 222/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1829 - accuracy: 0.9835 - val_loss: 2.6397 - val_accuracy: 0.3657\n",
      "Epoch 223/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1506 - accuracy: 0.9927 - val_loss: 2.6338 - val_accuracy: 0.3657\n",
      "Epoch 224/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1621 - accuracy: 0.9853 - val_loss: 2.6275 - val_accuracy: 0.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1661 - accuracy: 0.9853 - val_loss: 2.6216 - val_accuracy: 0.3657\n",
      "Epoch 226/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1387 - accuracy: 0.9927 - val_loss: 2.6153 - val_accuracy: 0.3657\n",
      "Epoch 227/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1409 - accuracy: 0.9927 - val_loss: 2.6093 - val_accuracy: 0.3657\n",
      "Epoch 228/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1691 - accuracy: 0.9908 - val_loss: 2.6032 - val_accuracy: 0.3657\n",
      "Epoch 229/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1429 - accuracy: 0.9908 - val_loss: 2.5968 - val_accuracy: 0.3657\n",
      "Epoch 230/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1725 - accuracy: 0.9890 - val_loss: 2.5906 - val_accuracy: 0.3704\n",
      "Epoch 231/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1553 - accuracy: 0.9908 - val_loss: 2.5844 - val_accuracy: 0.3704\n",
      "Epoch 232/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1640 - accuracy: 0.9890 - val_loss: 2.5778 - val_accuracy: 0.3750\n",
      "Epoch 233/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1591 - accuracy: 0.9890 - val_loss: 2.5715 - val_accuracy: 0.3750\n",
      "Epoch 234/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1537 - accuracy: 0.9853 - val_loss: 2.5644 - val_accuracy: 0.3750\n",
      "Epoch 235/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1496 - accuracy: 0.9963 - val_loss: 2.5578 - val_accuracy: 0.3750\n",
      "Epoch 236/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1599 - accuracy: 0.9908 - val_loss: 2.5509 - val_accuracy: 0.3750\n",
      "Epoch 237/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1920 - accuracy: 0.9780 - val_loss: 2.5438 - val_accuracy: 0.3750\n",
      "Epoch 238/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1673 - accuracy: 0.9908 - val_loss: 2.5370 - val_accuracy: 0.3750\n",
      "Epoch 239/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1329 - accuracy: 0.9908 - val_loss: 2.5306 - val_accuracy: 0.3750\n",
      "Epoch 240/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1305 - accuracy: 0.9927 - val_loss: 2.5234 - val_accuracy: 0.3750\n",
      "Epoch 241/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1286 - accuracy: 0.9963 - val_loss: 2.5167 - val_accuracy: 0.3750\n",
      "Epoch 242/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1569 - accuracy: 0.9853 - val_loss: 2.5104 - val_accuracy: 0.3704\n",
      "Epoch 243/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1515 - accuracy: 0.9927 - val_loss: 2.5046 - val_accuracy: 0.3704\n",
      "Epoch 244/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1617 - accuracy: 0.9890 - val_loss: 2.4982 - val_accuracy: 0.3704\n",
      "Epoch 245/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1503 - accuracy: 0.9908 - val_loss: 2.4916 - val_accuracy: 0.3750\n",
      "Epoch 246/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1733 - accuracy: 0.9853 - val_loss: 2.4855 - val_accuracy: 0.3796\n",
      "Epoch 247/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1301 - accuracy: 0.9945 - val_loss: 2.4791 - val_accuracy: 0.3796\n",
      "Epoch 248/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1509 - accuracy: 0.9890 - val_loss: 2.4724 - val_accuracy: 0.3796\n",
      "Epoch 249/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1797 - accuracy: 0.9927 - val_loss: 2.4658 - val_accuracy: 0.3796\n",
      "Epoch 250/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1642 - accuracy: 0.9963 - val_loss: 2.4591 - val_accuracy: 0.3796\n",
      "Epoch 251/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1379 - accuracy: 0.9963 - val_loss: 2.4523 - val_accuracy: 0.3796\n",
      "Epoch 252/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1727 - accuracy: 0.9890 - val_loss: 2.4463 - val_accuracy: 0.3843\n",
      "Epoch 253/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1474 - accuracy: 0.9927 - val_loss: 2.4398 - val_accuracy: 0.3889\n",
      "Epoch 254/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1376 - accuracy: 0.9963 - val_loss: 2.4336 - val_accuracy: 0.3981\n",
      "Epoch 255/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1414 - accuracy: 0.9908 - val_loss: 2.4268 - val_accuracy: 0.3981\n",
      "Epoch 256/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1530 - accuracy: 0.9817 - val_loss: 2.4205 - val_accuracy: 0.3981\n",
      "Epoch 257/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1708 - accuracy: 0.9817 - val_loss: 2.4139 - val_accuracy: 0.3981\n",
      "Epoch 258/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1301 - accuracy: 0.9963 - val_loss: 2.4078 - val_accuracy: 0.3981\n",
      "Epoch 259/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1594 - accuracy: 0.9927 - val_loss: 2.4016 - val_accuracy: 0.4028\n",
      "Epoch 260/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1588 - accuracy: 0.9853 - val_loss: 2.3952 - val_accuracy: 0.4028\n",
      "Epoch 261/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1422 - accuracy: 0.9908 - val_loss: 2.3889 - val_accuracy: 0.4028\n",
      "Epoch 262/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1487 - accuracy: 0.9908 - val_loss: 2.3827 - val_accuracy: 0.4028\n",
      "Epoch 263/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1669 - accuracy: 0.9872 - val_loss: 2.3759 - val_accuracy: 0.4074\n",
      "Epoch 264/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1416 - accuracy: 0.9853 - val_loss: 2.3693 - val_accuracy: 0.4074\n",
      "Epoch 265/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1466 - accuracy: 0.9872 - val_loss: 2.3630 - val_accuracy: 0.4074\n",
      "Epoch 266/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1368 - accuracy: 0.9927 - val_loss: 2.3563 - val_accuracy: 0.4074\n",
      "Epoch 267/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1297 - accuracy: 0.9963 - val_loss: 2.3500 - val_accuracy: 0.4074\n",
      "Epoch 268/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1450 - accuracy: 0.9927 - val_loss: 2.3437 - val_accuracy: 0.4074\n",
      "Epoch 269/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1737 - accuracy: 0.9890 - val_loss: 2.3370 - val_accuracy: 0.4074\n",
      "Epoch 270/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1465 - accuracy: 0.9853 - val_loss: 2.3303 - val_accuracy: 0.4074\n",
      "Epoch 271/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1141 - accuracy: 0.9945 - val_loss: 2.3236 - val_accuracy: 0.4120\n",
      "Epoch 272/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1506 - accuracy: 0.9927 - val_loss: 2.3169 - val_accuracy: 0.4120\n",
      "Epoch 273/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1644 - accuracy: 0.9872 - val_loss: 2.3104 - val_accuracy: 0.4120\n",
      "Epoch 274/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1508 - accuracy: 0.9945 - val_loss: 2.3042 - val_accuracy: 0.4167\n",
      "Epoch 275/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1315 - accuracy: 0.9927 - val_loss: 2.2982 - val_accuracy: 0.4213\n",
      "Epoch 276/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1573 - accuracy: 0.9945 - val_loss: 2.2924 - val_accuracy: 0.4213\n",
      "Epoch 277/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1647 - accuracy: 0.9853 - val_loss: 2.2868 - val_accuracy: 0.4213\n",
      "Epoch 278/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1509 - accuracy: 0.9927 - val_loss: 2.2812 - val_accuracy: 0.4213\n",
      "Epoch 279/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1294 - accuracy: 0.9945 - val_loss: 2.2752 - val_accuracy: 0.4213\n",
      "Epoch 280/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1405 - accuracy: 0.9927 - val_loss: 2.2694 - val_accuracy: 0.4259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1341 - accuracy: 0.9945 - val_loss: 2.2636 - val_accuracy: 0.4352\n",
      "Epoch 282/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1432 - accuracy: 0.9927 - val_loss: 2.2574 - val_accuracy: 0.4352\n",
      "Epoch 283/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1587 - accuracy: 0.9872 - val_loss: 2.2516 - val_accuracy: 0.4352\n",
      "Epoch 284/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1343 - accuracy: 0.9963 - val_loss: 2.2453 - val_accuracy: 0.4398\n",
      "Epoch 285/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1522 - accuracy: 0.9890 - val_loss: 2.2395 - val_accuracy: 0.4398\n",
      "Epoch 286/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1266 - accuracy: 0.9963 - val_loss: 2.2339 - val_accuracy: 0.4398\n",
      "Epoch 287/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1388 - accuracy: 0.9927 - val_loss: 2.2280 - val_accuracy: 0.4398\n",
      "Epoch 288/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1354 - accuracy: 0.9982 - val_loss: 2.2217 - val_accuracy: 0.4398\n",
      "Epoch 289/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1527 - accuracy: 0.9890 - val_loss: 2.2161 - val_accuracy: 0.4398\n",
      "Epoch 290/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1408 - accuracy: 0.9927 - val_loss: 2.2103 - val_accuracy: 0.4398\n",
      "Epoch 291/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1657 - accuracy: 0.9872 - val_loss: 2.2042 - val_accuracy: 0.4398\n",
      "Epoch 292/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1607 - accuracy: 0.9927 - val_loss: 2.1981 - val_accuracy: 0.4398\n",
      "Epoch 293/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1313 - accuracy: 0.9963 - val_loss: 2.1920 - val_accuracy: 0.4398\n",
      "Epoch 294/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1200 - accuracy: 0.9982 - val_loss: 2.1858 - val_accuracy: 0.4398\n",
      "Epoch 295/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1524 - accuracy: 0.9890 - val_loss: 2.1796 - val_accuracy: 0.4398\n",
      "Epoch 296/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1490 - accuracy: 0.9963 - val_loss: 2.1736 - val_accuracy: 0.4398\n",
      "Epoch 297/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1262 - accuracy: 0.9963 - val_loss: 2.1677 - val_accuracy: 0.4398\n",
      "Epoch 298/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1708 - accuracy: 0.9890 - val_loss: 2.1621 - val_accuracy: 0.4444\n",
      "Epoch 299/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1556 - accuracy: 0.9853 - val_loss: 2.1561 - val_accuracy: 0.4444\n",
      "Epoch 300/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1440 - accuracy: 0.9963 - val_loss: 2.1503 - val_accuracy: 0.4444\n",
      "Epoch 301/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1511 - accuracy: 0.9908 - val_loss: 2.1445 - val_accuracy: 0.4444\n",
      "Epoch 302/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1574 - accuracy: 0.9963 - val_loss: 2.1381 - val_accuracy: 0.4444\n",
      "Epoch 303/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1416 - accuracy: 0.9872 - val_loss: 2.1315 - val_accuracy: 0.4491\n",
      "Epoch 304/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1334 - accuracy: 0.9890 - val_loss: 2.1249 - val_accuracy: 0.4537\n",
      "Epoch 305/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1359 - accuracy: 1.0000 - val_loss: 2.1186 - val_accuracy: 0.4537\n",
      "Epoch 306/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1478 - accuracy: 0.9945 - val_loss: 2.1125 - val_accuracy: 0.4583\n",
      "Epoch 307/1000\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1442 - accuracy: 0.9963 - val_loss: 2.1056 - val_accuracy: 0.4630\n",
      "Epoch 308/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1535 - accuracy: 0.9927 - val_loss: 2.0992 - val_accuracy: 0.4630\n",
      "Epoch 309/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1529 - accuracy: 0.9963 - val_loss: 2.0928 - val_accuracy: 0.4630\n",
      "Epoch 310/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1655 - accuracy: 0.9872 - val_loss: 2.0863 - val_accuracy: 0.4676\n",
      "Epoch 311/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1503 - accuracy: 0.9908 - val_loss: 2.0799 - val_accuracy: 0.4676\n",
      "Epoch 312/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1320 - accuracy: 0.9908 - val_loss: 2.0738 - val_accuracy: 0.4722\n",
      "Epoch 313/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1566 - accuracy: 0.9945 - val_loss: 2.0673 - val_accuracy: 0.4769\n",
      "Epoch 314/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1448 - accuracy: 0.9945 - val_loss: 2.0613 - val_accuracy: 0.4769\n",
      "Epoch 315/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1646 - accuracy: 0.9890 - val_loss: 2.0552 - val_accuracy: 0.4769\n",
      "Epoch 316/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1536 - accuracy: 0.9945 - val_loss: 2.0493 - val_accuracy: 0.4815\n",
      "Epoch 317/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1442 - accuracy: 0.9890 - val_loss: 2.0431 - val_accuracy: 0.4815\n",
      "Epoch 318/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1523 - accuracy: 0.9945 - val_loss: 2.0372 - val_accuracy: 0.4815\n",
      "Epoch 319/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1425 - accuracy: 0.9945 - val_loss: 2.0309 - val_accuracy: 0.4815\n",
      "Epoch 320/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1253 - accuracy: 0.9927 - val_loss: 2.0247 - val_accuracy: 0.4815\n",
      "Epoch 321/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1279 - accuracy: 0.9945 - val_loss: 2.0188 - val_accuracy: 0.4815\n",
      "Epoch 322/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1709 - accuracy: 0.9835 - val_loss: 2.0128 - val_accuracy: 0.4861\n",
      "Epoch 323/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1272 - accuracy: 0.9963 - val_loss: 2.0069 - val_accuracy: 0.4861\n",
      "Epoch 324/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1531 - accuracy: 0.9908 - val_loss: 2.0010 - val_accuracy: 0.4907\n",
      "Epoch 325/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1522 - accuracy: 0.9963 - val_loss: 1.9951 - val_accuracy: 0.4907\n",
      "Epoch 326/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1477 - accuracy: 0.9927 - val_loss: 1.9889 - val_accuracy: 0.4954\n",
      "Epoch 327/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1231 - accuracy: 0.9982 - val_loss: 1.9825 - val_accuracy: 0.4954\n",
      "Epoch 328/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1252 - accuracy: 0.9963 - val_loss: 1.9768 - val_accuracy: 0.4954\n",
      "Epoch 329/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1328 - accuracy: 0.9908 - val_loss: 1.9708 - val_accuracy: 0.4954\n",
      "Epoch 330/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1826 - accuracy: 0.9799 - val_loss: 1.9651 - val_accuracy: 0.4954\n",
      "Epoch 331/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1538 - accuracy: 0.9872 - val_loss: 1.9596 - val_accuracy: 0.4954\n",
      "Epoch 332/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1301 - accuracy: 0.9927 - val_loss: 1.9537 - val_accuracy: 0.4954\n",
      "Epoch 333/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1443 - accuracy: 0.9927 - val_loss: 1.9480 - val_accuracy: 0.4954\n",
      "Epoch 334/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1356 - accuracy: 0.9927 - val_loss: 1.9426 - val_accuracy: 0.4954\n",
      "Epoch 335/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1582 - accuracy: 0.9872 - val_loss: 1.9367 - val_accuracy: 0.4954\n",
      "Epoch 336/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1486 - accuracy: 0.9890 - val_loss: 1.9311 - val_accuracy: 0.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1674 - accuracy: 0.9872 - val_loss: 1.9253 - val_accuracy: 0.4954\n",
      "Epoch 338/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1474 - accuracy: 0.9872 - val_loss: 1.9199 - val_accuracy: 0.4954\n",
      "Epoch 339/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1618 - accuracy: 0.9890 - val_loss: 1.9139 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1294 - accuracy: 0.9982 - val_loss: 1.9086 - val_accuracy: 0.5000\n",
      "Epoch 341/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1524 - accuracy: 0.9908 - val_loss: 1.9029 - val_accuracy: 0.5000\n",
      "Epoch 342/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1610 - accuracy: 0.9890 - val_loss: 1.8975 - val_accuracy: 0.5000\n",
      "Epoch 343/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1353 - accuracy: 0.9963 - val_loss: 1.8921 - val_accuracy: 0.5000\n",
      "Epoch 344/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1538 - accuracy: 0.9945 - val_loss: 1.8870 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1467 - accuracy: 0.9927 - val_loss: 1.8816 - val_accuracy: 0.5046\n",
      "Epoch 346/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1352 - accuracy: 0.9945 - val_loss: 1.8761 - val_accuracy: 0.5046\n",
      "Epoch 347/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1302 - accuracy: 0.9963 - val_loss: 1.8705 - val_accuracy: 0.5046\n",
      "Epoch 348/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1510 - accuracy: 0.9908 - val_loss: 1.8651 - val_accuracy: 0.5093\n",
      "Epoch 349/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1721 - accuracy: 0.9817 - val_loss: 1.8601 - val_accuracy: 0.5093\n",
      "Epoch 350/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1406 - accuracy: 0.9945 - val_loss: 1.8549 - val_accuracy: 0.5139\n",
      "Epoch 351/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1674 - accuracy: 0.9872 - val_loss: 1.8494 - val_accuracy: 0.5139\n",
      "Epoch 352/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1599 - accuracy: 0.9908 - val_loss: 1.8439 - val_accuracy: 0.5185\n",
      "Epoch 353/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1576 - accuracy: 0.9963 - val_loss: 1.8384 - val_accuracy: 0.5185\n",
      "Epoch 354/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1476 - accuracy: 1.0000 - val_loss: 1.8332 - val_accuracy: 0.5185\n",
      "Epoch 355/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1534 - accuracy: 0.9890 - val_loss: 1.8279 - val_accuracy: 0.5185\n",
      "Epoch 356/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1622 - accuracy: 0.9963 - val_loss: 1.8224 - val_accuracy: 0.5231\n",
      "Epoch 357/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1398 - accuracy: 0.9872 - val_loss: 1.8170 - val_accuracy: 0.5231\n",
      "Epoch 358/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1386 - accuracy: 0.9945 - val_loss: 1.8115 - val_accuracy: 0.5231\n",
      "Epoch 359/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1641 - accuracy: 0.9817 - val_loss: 1.8059 - val_accuracy: 0.5231\n",
      "Epoch 360/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1501 - accuracy: 0.9853 - val_loss: 1.7998 - val_accuracy: 0.5231\n",
      "Epoch 361/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1622 - accuracy: 0.9908 - val_loss: 1.7939 - val_accuracy: 0.5278\n",
      "Epoch 362/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 1.7879 - val_accuracy: 0.5278\n",
      "Epoch 363/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1630 - accuracy: 0.9927 - val_loss: 1.7820 - val_accuracy: 0.5324\n",
      "Epoch 364/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1375 - accuracy: 0.9945 - val_loss: 1.7760 - val_accuracy: 0.5324\n",
      "Epoch 365/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1168 - accuracy: 0.9982 - val_loss: 1.7704 - val_accuracy: 0.5370\n",
      "Epoch 366/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1452 - accuracy: 0.9945 - val_loss: 1.7648 - val_accuracy: 0.5370\n",
      "Epoch 367/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1358 - accuracy: 0.9908 - val_loss: 1.7593 - val_accuracy: 0.5370\n",
      "Epoch 368/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1491 - accuracy: 0.9853 - val_loss: 1.7535 - val_accuracy: 0.5370\n",
      "Epoch 369/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1357 - accuracy: 0.9945 - val_loss: 1.7484 - val_accuracy: 0.5370\n",
      "Epoch 370/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1463 - accuracy: 0.9945 - val_loss: 1.7432 - val_accuracy: 0.5417\n",
      "Epoch 371/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1254 - accuracy: 0.9927 - val_loss: 1.7378 - val_accuracy: 0.5417\n",
      "Epoch 372/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1371 - accuracy: 0.9945 - val_loss: 1.7328 - val_accuracy: 0.5417\n",
      "Epoch 373/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1262 - accuracy: 0.9945 - val_loss: 1.7275 - val_accuracy: 0.5417\n",
      "Epoch 374/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1072 - accuracy: 0.9982 - val_loss: 1.7229 - val_accuracy: 0.5417\n",
      "Epoch 375/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1535 - accuracy: 0.9927 - val_loss: 1.7183 - val_accuracy: 0.5417\n",
      "Epoch 376/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1465 - accuracy: 0.9945 - val_loss: 1.7129 - val_accuracy: 0.5417\n",
      "Epoch 377/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1521 - accuracy: 0.9963 - val_loss: 1.7081 - val_accuracy: 0.5417\n",
      "Epoch 378/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1284 - accuracy: 0.9982 - val_loss: 1.7032 - val_accuracy: 0.5417\n",
      "Epoch 379/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1353 - accuracy: 0.9908 - val_loss: 1.6982 - val_accuracy: 0.5463\n",
      "Epoch 380/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1565 - accuracy: 0.9872 - val_loss: 1.6933 - val_accuracy: 0.5509\n",
      "Epoch 381/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1370 - accuracy: 0.9963 - val_loss: 1.6885 - val_accuracy: 0.5556\n",
      "Epoch 382/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1409 - accuracy: 0.9927 - val_loss: 1.6840 - val_accuracy: 0.5556\n",
      "Epoch 383/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1285 - accuracy: 0.9963 - val_loss: 1.6791 - val_accuracy: 0.5556\n",
      "Epoch 384/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1157 - accuracy: 0.9963 - val_loss: 1.6744 - val_accuracy: 0.5602\n",
      "Epoch 385/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1594 - accuracy: 0.9835 - val_loss: 1.6696 - val_accuracy: 0.5602\n",
      "Epoch 386/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1521 - accuracy: 0.9927 - val_loss: 1.6647 - val_accuracy: 0.5602\n",
      "Epoch 387/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1267 - accuracy: 0.9927 - val_loss: 1.6603 - val_accuracy: 0.5602\n",
      "Epoch 388/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1461 - accuracy: 0.9982 - val_loss: 1.6558 - val_accuracy: 0.5602\n",
      "Epoch 389/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1438 - accuracy: 0.9963 - val_loss: 1.6513 - val_accuracy: 0.5602\n",
      "Epoch 390/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1372 - accuracy: 0.9908 - val_loss: 1.6468 - val_accuracy: 0.5602\n",
      "Epoch 391/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1505 - accuracy: 0.9927 - val_loss: 1.6421 - val_accuracy: 0.5602\n",
      "Epoch 392/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1541 - accuracy: 0.9927 - val_loss: 1.6377 - val_accuracy: 0.5602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1492 - accuracy: 0.9890 - val_loss: 1.6333 - val_accuracy: 0.5602\n",
      "Epoch 394/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1446 - accuracy: 0.9890 - val_loss: 1.6288 - val_accuracy: 0.5602\n",
      "Epoch 395/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1583 - accuracy: 0.9908 - val_loss: 1.6243 - val_accuracy: 0.5602\n",
      "Epoch 396/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1568 - accuracy: 0.9890 - val_loss: 1.6197 - val_accuracy: 0.5602\n",
      "Epoch 397/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1503 - accuracy: 0.9945 - val_loss: 1.6151 - val_accuracy: 0.5602\n",
      "Epoch 398/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1198 - accuracy: 0.9982 - val_loss: 1.6105 - val_accuracy: 0.5602\n",
      "Epoch 399/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1238 - accuracy: 0.9963 - val_loss: 1.6056 - val_accuracy: 0.5602\n",
      "Epoch 400/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1431 - accuracy: 0.9963 - val_loss: 1.6010 - val_accuracy: 0.5602\n",
      "Epoch 401/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1595 - accuracy: 0.9908 - val_loss: 1.5966 - val_accuracy: 0.5602\n",
      "Epoch 402/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1462 - accuracy: 0.9945 - val_loss: 1.5919 - val_accuracy: 0.5602\n",
      "Epoch 403/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1388 - accuracy: 0.9927 - val_loss: 1.5873 - val_accuracy: 0.5602\n",
      "Epoch 404/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1444 - accuracy: 0.9963 - val_loss: 1.5829 - val_accuracy: 0.5602\n",
      "Epoch 405/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1510 - accuracy: 0.9908 - val_loss: 1.5784 - val_accuracy: 0.5602\n",
      "Epoch 406/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1554 - accuracy: 0.9927 - val_loss: 1.5736 - val_accuracy: 0.5602\n",
      "Epoch 407/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1406 - accuracy: 0.9945 - val_loss: 1.5691 - val_accuracy: 0.5602\n",
      "Epoch 408/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1223 - accuracy: 0.9945 - val_loss: 1.5645 - val_accuracy: 0.5602\n",
      "Epoch 409/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1514 - accuracy: 0.9945 - val_loss: 1.5598 - val_accuracy: 0.5602\n",
      "Epoch 410/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1665 - accuracy: 0.9890 - val_loss: 1.5554 - val_accuracy: 0.5648\n",
      "Epoch 411/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1387 - accuracy: 0.9890 - val_loss: 1.5509 - val_accuracy: 0.5648\n",
      "Epoch 412/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1374 - accuracy: 0.9908 - val_loss: 1.5462 - val_accuracy: 0.5694\n",
      "Epoch 413/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1517 - accuracy: 0.9927 - val_loss: 1.5416 - val_accuracy: 0.5694\n",
      "Epoch 414/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1559 - accuracy: 0.9945 - val_loss: 1.5373 - val_accuracy: 0.5694\n",
      "Epoch 415/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1502 - accuracy: 0.9872 - val_loss: 1.5328 - val_accuracy: 0.5694\n",
      "Epoch 416/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1788 - accuracy: 0.9890 - val_loss: 1.5286 - val_accuracy: 0.5694\n",
      "Epoch 417/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1293 - accuracy: 0.9945 - val_loss: 1.5243 - val_accuracy: 0.5694\n",
      "Epoch 418/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1295 - accuracy: 0.9982 - val_loss: 1.5201 - val_accuracy: 0.5694\n",
      "Epoch 419/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1286 - accuracy: 0.9945 - val_loss: 1.5161 - val_accuracy: 0.5741\n",
      "Epoch 420/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1256 - accuracy: 0.9982 - val_loss: 1.5119 - val_accuracy: 0.5741\n",
      "Epoch 421/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1453 - accuracy: 0.9908 - val_loss: 1.5077 - val_accuracy: 0.5787\n",
      "Epoch 422/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1680 - accuracy: 0.9890 - val_loss: 1.5033 - val_accuracy: 0.5787\n",
      "Epoch 423/1000\n",
      "546/546 [==============================] - 0s 128us/step - loss: 0.1396 - accuracy: 0.9908 - val_loss: 1.4996 - val_accuracy: 0.5787\n",
      "Epoch 424/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1640 - accuracy: 0.9890 - val_loss: 1.4955 - val_accuracy: 0.5787\n",
      "Epoch 425/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 0.5833\n",
      "Epoch 426/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1477 - accuracy: 0.9927 - val_loss: 1.4872 - val_accuracy: 0.5880\n",
      "Epoch 427/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1279 - accuracy: 0.9945 - val_loss: 1.4829 - val_accuracy: 0.5880\n",
      "Epoch 428/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1304 - accuracy: 0.9945 - val_loss: 1.4784 - val_accuracy: 0.5880\n",
      "Epoch 429/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1376 - accuracy: 0.9963 - val_loss: 1.4742 - val_accuracy: 0.5926\n",
      "Epoch 430/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1359 - accuracy: 0.9945 - val_loss: 1.4700 - val_accuracy: 0.5926\n",
      "Epoch 431/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1329 - accuracy: 0.9908 - val_loss: 1.4656 - val_accuracy: 0.5880\n",
      "Epoch 432/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1488 - accuracy: 0.9982 - val_loss: 1.4613 - val_accuracy: 0.5880\n",
      "Epoch 433/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1477 - accuracy: 0.9927 - val_loss: 1.4571 - val_accuracy: 0.5880\n",
      "Epoch 434/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1235 - accuracy: 0.9927 - val_loss: 1.4528 - val_accuracy: 0.5880\n",
      "Epoch 435/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1364 - accuracy: 0.9945 - val_loss: 1.4484 - val_accuracy: 0.5926\n",
      "Epoch 436/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1472 - accuracy: 0.9908 - val_loss: 1.4442 - val_accuracy: 0.5926\n",
      "Epoch 437/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1440 - accuracy: 0.9908 - val_loss: 1.4401 - val_accuracy: 0.5926\n",
      "Epoch 438/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1401 - accuracy: 0.9982 - val_loss: 1.4360 - val_accuracy: 0.5972\n",
      "Epoch 439/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1542 - accuracy: 0.9927 - val_loss: 1.4322 - val_accuracy: 0.5972\n",
      "Epoch 440/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1282 - accuracy: 0.9945 - val_loss: 1.4285 - val_accuracy: 0.6065\n",
      "Epoch 441/1000\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.1306 - accuracy: 0.9982 - val_loss: 1.4248 - val_accuracy: 0.6065\n",
      "Epoch 442/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1324 - accuracy: 0.9945 - val_loss: 1.4213 - val_accuracy: 0.6065\n",
      "Epoch 443/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1579 - accuracy: 0.9853 - val_loss: 1.4178 - val_accuracy: 0.6065\n",
      "Epoch 444/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1637 - accuracy: 0.9817 - val_loss: 1.4144 - val_accuracy: 0.6065\n",
      "Epoch 445/1000\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1399 - accuracy: 0.9927 - val_loss: 1.4109 - val_accuracy: 0.6065\n",
      "Epoch 446/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1322 - accuracy: 0.9982 - val_loss: 1.4073 - val_accuracy: 0.6065\n",
      "Epoch 447/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1264 - accuracy: 0.9945 - val_loss: 1.4042 - val_accuracy: 0.6111\n",
      "Epoch 448/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1530 - accuracy: 0.9908 - val_loss: 1.4007 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1297 - accuracy: 0.9945 - val_loss: 1.3969 - val_accuracy: 0.6111\n",
      "Epoch 450/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1475 - accuracy: 0.9945 - val_loss: 1.3933 - val_accuracy: 0.6111\n",
      "Epoch 451/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1475 - accuracy: 0.9963 - val_loss: 1.3898 - val_accuracy: 0.6111\n",
      "Epoch 452/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1486 - accuracy: 0.9853 - val_loss: 1.3865 - val_accuracy: 0.6111\n",
      "Epoch 453/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1316 - accuracy: 0.9982 - val_loss: 1.3834 - val_accuracy: 0.6111\n",
      "Epoch 454/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1230 - accuracy: 0.9982 - val_loss: 1.3803 - val_accuracy: 0.6157\n",
      "Epoch 455/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1260 - accuracy: 0.9982 - val_loss: 1.3771 - val_accuracy: 0.6204\n",
      "Epoch 456/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1502 - accuracy: 0.9945 - val_loss: 1.3740 - val_accuracy: 0.6204\n",
      "Epoch 457/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1451 - accuracy: 0.9908 - val_loss: 1.3711 - val_accuracy: 0.6204\n",
      "Epoch 458/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1353 - accuracy: 0.9890 - val_loss: 1.3684 - val_accuracy: 0.6204\n",
      "Epoch 459/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1288 - accuracy: 0.9982 - val_loss: 1.3658 - val_accuracy: 0.6204\n",
      "Epoch 460/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1555 - accuracy: 0.9963 - val_loss: 1.3629 - val_accuracy: 0.6204\n",
      "Epoch 461/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1591 - accuracy: 0.9927 - val_loss: 1.3603 - val_accuracy: 0.6204\n",
      "Epoch 462/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1737 - accuracy: 0.9835 - val_loss: 1.3572 - val_accuracy: 0.6204\n",
      "Epoch 463/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1448 - accuracy: 0.9927 - val_loss: 1.3545 - val_accuracy: 0.6204\n",
      "Epoch 464/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1659 - accuracy: 0.9872 - val_loss: 1.3517 - val_accuracy: 0.6204\n",
      "Epoch 465/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1192 - accuracy: 0.9982 - val_loss: 1.3488 - val_accuracy: 0.6204\n",
      "Epoch 466/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1730 - accuracy: 0.9890 - val_loss: 1.3460 - val_accuracy: 0.6204\n",
      "Epoch 467/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1221 - accuracy: 0.9963 - val_loss: 1.3432 - val_accuracy: 0.6204\n",
      "Epoch 468/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1314 - accuracy: 1.0000 - val_loss: 1.3400 - val_accuracy: 0.6204\n",
      "Epoch 469/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 1.3371 - val_accuracy: 0.6204\n",
      "Epoch 470/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1466 - accuracy: 0.9853 - val_loss: 1.3343 - val_accuracy: 0.6204\n",
      "Epoch 471/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1481 - accuracy: 0.9890 - val_loss: 1.3316 - val_accuracy: 0.6250\n",
      "Epoch 472/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1567 - accuracy: 0.9908 - val_loss: 1.3287 - val_accuracy: 0.6296\n",
      "Epoch 473/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1409 - accuracy: 0.9908 - val_loss: 1.3259 - val_accuracy: 0.6296\n",
      "Epoch 474/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1330 - accuracy: 0.9963 - val_loss: 1.3230 - val_accuracy: 0.6296\n",
      "Epoch 475/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1381 - accuracy: 0.9927 - val_loss: 1.3203 - val_accuracy: 0.6296\n",
      "Epoch 476/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1473 - accuracy: 0.9872 - val_loss: 1.3176 - val_accuracy: 0.6296\n",
      "Epoch 477/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1475 - accuracy: 0.9982 - val_loss: 1.3149 - val_accuracy: 0.6343\n",
      "Epoch 478/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1234 - accuracy: 0.9945 - val_loss: 1.3123 - val_accuracy: 0.6343\n",
      "Epoch 479/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1279 - accuracy: 0.9963 - val_loss: 1.3097 - val_accuracy: 0.6343\n",
      "Epoch 480/1000\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1316 - accuracy: 0.9927 - val_loss: 1.3070 - val_accuracy: 0.6343\n",
      "Epoch 481/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1281 - accuracy: 0.9982 - val_loss: 1.3044 - val_accuracy: 0.6343\n",
      "Epoch 482/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1535 - accuracy: 0.9927 - val_loss: 1.3020 - val_accuracy: 0.6343\n",
      "Epoch 483/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1374 - accuracy: 0.9872 - val_loss: 1.2998 - val_accuracy: 0.6389\n",
      "Epoch 484/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1439 - accuracy: 0.9908 - val_loss: 1.2975 - val_accuracy: 0.6481\n",
      "Epoch 485/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1425 - accuracy: 0.9945 - val_loss: 1.2949 - val_accuracy: 0.6528\n",
      "Epoch 486/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1630 - accuracy: 0.9817 - val_loss: 1.2929 - val_accuracy: 0.6528\n",
      "Epoch 487/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1385 - accuracy: 0.9945 - val_loss: 1.2907 - val_accuracy: 0.6528\n",
      "Epoch 488/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1487 - accuracy: 0.9945 - val_loss: 1.2886 - val_accuracy: 0.6528\n",
      "Epoch 489/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1375 - accuracy: 0.9872 - val_loss: 1.2864 - val_accuracy: 0.6481\n",
      "Epoch 490/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1376 - accuracy: 0.9908 - val_loss: 1.2842 - val_accuracy: 0.6481\n",
      "Epoch 491/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1572 - accuracy: 0.9890 - val_loss: 1.2822 - val_accuracy: 0.6481\n",
      "Epoch 492/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1258 - accuracy: 0.9945 - val_loss: 1.2803 - val_accuracy: 0.6481\n",
      "Epoch 493/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1487 - accuracy: 0.9927 - val_loss: 1.2781 - val_accuracy: 0.6528\n",
      "Epoch 494/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1297 - accuracy: 0.9927 - val_loss: 1.2757 - val_accuracy: 0.6528\n",
      "Epoch 495/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1144 - accuracy: 0.9963 - val_loss: 1.2736 - val_accuracy: 0.6528\n",
      "Epoch 496/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1200 - accuracy: 0.9927 - val_loss: 1.2715 - val_accuracy: 0.6528\n",
      "Epoch 497/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1572 - accuracy: 0.9963 - val_loss: 1.2694 - val_accuracy: 0.6528\n",
      "Epoch 498/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1347 - accuracy: 0.9927 - val_loss: 1.2673 - val_accuracy: 0.6528\n",
      "Epoch 499/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1194 - accuracy: 0.9963 - val_loss: 1.2651 - val_accuracy: 0.6574\n",
      "Epoch 500/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1406 - accuracy: 0.9927 - val_loss: 1.2630 - val_accuracy: 0.6574\n",
      "Epoch 501/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1189 - accuracy: 0.9963 - val_loss: 1.2612 - val_accuracy: 0.6574\n",
      "Epoch 502/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1372 - accuracy: 0.9927 - val_loss: 1.2592 - val_accuracy: 0.6574\n",
      "Epoch 503/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1338 - accuracy: 0.9945 - val_loss: 1.2573 - val_accuracy: 0.6574\n",
      "Epoch 504/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1522 - accuracy: 0.9872 - val_loss: 1.2552 - val_accuracy: 0.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1555 - accuracy: 0.9890 - val_loss: 1.2534 - val_accuracy: 0.6574\n",
      "Epoch 506/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1384 - accuracy: 0.9927 - val_loss: 1.2514 - val_accuracy: 0.6620\n",
      "Epoch 507/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1302 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.6620\n",
      "Epoch 508/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1365 - accuracy: 0.9890 - val_loss: 1.2476 - val_accuracy: 0.6620\n",
      "Epoch 509/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1251 - accuracy: 0.9982 - val_loss: 1.2458 - val_accuracy: 0.6620\n",
      "Epoch 510/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1298 - accuracy: 0.9945 - val_loss: 1.2440 - val_accuracy: 0.6620\n",
      "Epoch 511/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 1.2420 - val_accuracy: 0.6620\n",
      "Epoch 512/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1173 - accuracy: 0.9982 - val_loss: 1.2399 - val_accuracy: 0.6620\n",
      "Epoch 513/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1313 - accuracy: 0.9982 - val_loss: 1.2382 - val_accuracy: 0.6620\n",
      "Epoch 514/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1094 - accuracy: 0.9963 - val_loss: 1.2364 - val_accuracy: 0.6667\n",
      "Epoch 515/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1210 - accuracy: 0.9963 - val_loss: 1.2345 - val_accuracy: 0.6759\n",
      "Epoch 516/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1269 - accuracy: 0.9945 - val_loss: 1.2327 - val_accuracy: 0.6759\n",
      "Epoch 517/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1274 - accuracy: 0.9945 - val_loss: 1.2308 - val_accuracy: 0.6806\n",
      "Epoch 518/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1372 - accuracy: 0.9945 - val_loss: 1.2290 - val_accuracy: 0.6806\n",
      "Epoch 519/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1437 - accuracy: 0.9908 - val_loss: 1.2273 - val_accuracy: 0.6806\n",
      "Epoch 520/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1346 - accuracy: 0.9890 - val_loss: 1.2256 - val_accuracy: 0.6806\n",
      "Epoch 521/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1595 - accuracy: 0.9872 - val_loss: 1.2239 - val_accuracy: 0.6806\n",
      "Epoch 522/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1363 - accuracy: 0.9945 - val_loss: 1.2220 - val_accuracy: 0.6806\n",
      "Epoch 523/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1316 - accuracy: 0.9908 - val_loss: 1.2204 - val_accuracy: 0.6806\n",
      "Epoch 524/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1701 - accuracy: 0.9835 - val_loss: 1.2187 - val_accuracy: 0.6806\n",
      "Epoch 525/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1287 - accuracy: 0.9945 - val_loss: 1.2168 - val_accuracy: 0.6759\n",
      "Epoch 526/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1617 - accuracy: 0.9872 - val_loss: 1.2151 - val_accuracy: 0.6759\n",
      "Epoch 527/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1499 - accuracy: 0.9927 - val_loss: 1.2135 - val_accuracy: 0.6759\n",
      "Epoch 528/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1191 - accuracy: 0.9963 - val_loss: 1.2120 - val_accuracy: 0.6806\n",
      "Epoch 529/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1422 - accuracy: 0.9963 - val_loss: 1.2105 - val_accuracy: 0.6806\n",
      "Epoch 530/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1100 - accuracy: 0.9982 - val_loss: 1.2090 - val_accuracy: 0.6806\n",
      "Epoch 531/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1319 - accuracy: 0.9908 - val_loss: 1.2075 - val_accuracy: 0.6806\n",
      "Epoch 532/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 1.2059 - val_accuracy: 0.6759\n",
      "Epoch 533/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1213 - accuracy: 0.9945 - val_loss: 1.2045 - val_accuracy: 0.6759\n",
      "Epoch 534/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1321 - accuracy: 0.9963 - val_loss: 1.2033 - val_accuracy: 0.6759\n",
      "Epoch 535/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1360 - accuracy: 0.9945 - val_loss: 1.2016 - val_accuracy: 0.6759\n",
      "Epoch 536/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1350 - accuracy: 0.9945 - val_loss: 1.2003 - val_accuracy: 0.6759\n",
      "Epoch 537/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1439 - accuracy: 0.9945 - val_loss: 1.1989 - val_accuracy: 0.6759\n",
      "Epoch 538/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1307 - accuracy: 0.9963 - val_loss: 1.1976 - val_accuracy: 0.6759\n",
      "Epoch 539/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1407 - accuracy: 0.9908 - val_loss: 1.1964 - val_accuracy: 0.6759\n",
      "Epoch 540/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1264 - accuracy: 0.9945 - val_loss: 1.1954 - val_accuracy: 0.6759\n",
      "Epoch 541/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1278 - accuracy: 0.9982 - val_loss: 1.1943 - val_accuracy: 0.6759\n",
      "Epoch 542/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 1.1929 - val_accuracy: 0.6759\n",
      "Epoch 543/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1369 - accuracy: 0.9908 - val_loss: 1.1917 - val_accuracy: 0.6759\n",
      "Epoch 544/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1646 - accuracy: 0.9853 - val_loss: 1.1905 - val_accuracy: 0.6806\n",
      "Epoch 545/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1288 - accuracy: 0.9963 - val_loss: 1.1893 - val_accuracy: 0.6806\n",
      "Epoch 546/1000\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1441 - accuracy: 0.9927 - val_loss: 1.1881 - val_accuracy: 0.6852\n",
      "Epoch 547/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1403 - accuracy: 0.9908 - val_loss: 1.1870 - val_accuracy: 0.6852\n",
      "Epoch 548/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1290 - accuracy: 0.9945 - val_loss: 1.1859 - val_accuracy: 0.6852\n",
      "Epoch 549/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 1.1851 - val_accuracy: 0.6898\n",
      "Epoch 550/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1405 - accuracy: 0.9945 - val_loss: 1.1841 - val_accuracy: 0.6898\n",
      "Epoch 551/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1415 - accuracy: 0.9963 - val_loss: 1.1832 - val_accuracy: 0.6898\n",
      "Epoch 552/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1211 - accuracy: 0.9963 - val_loss: 1.1821 - val_accuracy: 0.6852\n",
      "Epoch 553/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1295 - accuracy: 0.9927 - val_loss: 1.1811 - val_accuracy: 0.6852\n",
      "Epoch 554/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1329 - accuracy: 0.9945 - val_loss: 1.1801 - val_accuracy: 0.6852\n",
      "Epoch 555/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1349 - accuracy: 0.9927 - val_loss: 1.1791 - val_accuracy: 0.6852\n",
      "Epoch 556/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.6852\n",
      "Epoch 557/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1407 - accuracy: 0.9945 - val_loss: 1.1773 - val_accuracy: 0.6852\n",
      "Epoch 558/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1246 - accuracy: 0.9963 - val_loss: 1.1764 - val_accuracy: 0.6852\n",
      "Epoch 559/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1426 - accuracy: 0.9945 - val_loss: 1.1755 - val_accuracy: 0.6852\n",
      "Epoch 560/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1388 - accuracy: 0.9945 - val_loss: 1.1746 - val_accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1360 - accuracy: 0.9945 - val_loss: 1.1739 - val_accuracy: 0.6852\n",
      "Epoch 562/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1342 - accuracy: 0.9945 - val_loss: 1.1730 - val_accuracy: 0.6852\n",
      "Epoch 563/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1232 - accuracy: 0.9927 - val_loss: 1.1721 - val_accuracy: 0.6852\n",
      "Epoch 564/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1348 - accuracy: 0.9963 - val_loss: 1.1714 - val_accuracy: 0.6852\n",
      "Epoch 565/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1320 - accuracy: 0.9963 - val_loss: 1.1704 - val_accuracy: 0.6852\n",
      "Epoch 566/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1314 - accuracy: 0.9963 - val_loss: 1.1695 - val_accuracy: 0.6898\n",
      "Epoch 567/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1292 - accuracy: 0.9963 - val_loss: 1.1686 - val_accuracy: 0.6898\n",
      "Epoch 568/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1293 - accuracy: 0.9963 - val_loss: 1.1678 - val_accuracy: 0.6898\n",
      "Epoch 569/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1178 - accuracy: 0.9927 - val_loss: 1.1666 - val_accuracy: 0.6898\n",
      "Epoch 570/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1507 - accuracy: 0.9908 - val_loss: 1.1657 - val_accuracy: 0.6898\n",
      "Epoch 571/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1164 - accuracy: 0.9927 - val_loss: 1.1647 - val_accuracy: 0.6898\n",
      "Epoch 572/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1196 - accuracy: 0.9982 - val_loss: 1.1639 - val_accuracy: 0.6898\n",
      "Epoch 573/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1319 - accuracy: 0.9927 - val_loss: 1.1628 - val_accuracy: 0.6898\n",
      "Epoch 574/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1525 - accuracy: 0.9890 - val_loss: 1.1616 - val_accuracy: 0.6898\n",
      "Epoch 575/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1486 - accuracy: 0.9908 - val_loss: 1.1606 - val_accuracy: 0.6991\n",
      "Epoch 576/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1115 - accuracy: 0.9982 - val_loss: 1.1594 - val_accuracy: 0.6991\n",
      "Epoch 577/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1200 - accuracy: 1.0000 - val_loss: 1.1586 - val_accuracy: 0.6991\n",
      "Epoch 578/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1387 - accuracy: 0.9927 - val_loss: 1.1577 - val_accuracy: 0.6991\n",
      "Epoch 579/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1356 - accuracy: 0.9963 - val_loss: 1.1569 - val_accuracy: 0.6991\n",
      "Epoch 580/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1410 - accuracy: 0.9890 - val_loss: 1.1564 - val_accuracy: 0.6991\n",
      "Epoch 581/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1300 - accuracy: 0.9963 - val_loss: 1.1557 - val_accuracy: 0.6991\n",
      "Epoch 582/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1253 - accuracy: 0.9945 - val_loss: 1.1553 - val_accuracy: 0.6991\n",
      "Epoch 583/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1531 - accuracy: 0.9945 - val_loss: 1.1548 - val_accuracy: 0.6991\n",
      "Epoch 584/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1571 - accuracy: 0.9963 - val_loss: 1.1543 - val_accuracy: 0.6991\n",
      "Epoch 585/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1498 - accuracy: 0.9890 - val_loss: 1.1539 - val_accuracy: 0.6991\n",
      "Epoch 586/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1512 - accuracy: 0.9908 - val_loss: 1.1533 - val_accuracy: 0.6991\n",
      "Epoch 587/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.0945 - accuracy: 0.9982 - val_loss: 1.1525 - val_accuracy: 0.6991\n",
      "Epoch 588/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1286 - accuracy: 0.9982 - val_loss: 1.1521 - val_accuracy: 0.6991\n",
      "Epoch 589/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1341 - accuracy: 0.9963 - val_loss: 1.1514 - val_accuracy: 0.6991\n",
      "Epoch 590/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1198 - accuracy: 0.9963 - val_loss: 1.1508 - val_accuracy: 0.6991\n",
      "Epoch 591/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1462 - accuracy: 0.9945 - val_loss: 1.1500 - val_accuracy: 0.6991\n",
      "Epoch 592/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1364 - accuracy: 0.9945 - val_loss: 1.1494 - val_accuracy: 0.6991\n",
      "Epoch 593/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1535 - accuracy: 0.9908 - val_loss: 1.1488 - val_accuracy: 0.6991\n",
      "Epoch 594/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1306 - accuracy: 0.9945 - val_loss: 1.1483 - val_accuracy: 0.6991\n",
      "Epoch 595/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1361 - accuracy: 0.9982 - val_loss: 1.1477 - val_accuracy: 0.6991\n",
      "Epoch 596/1000\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1683 - accuracy: 0.9853 - val_loss: 1.1473 - val_accuracy: 0.6991\n",
      "Epoch 597/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1314 - accuracy: 0.9963 - val_loss: 1.1468 - val_accuracy: 0.6991\n",
      "Epoch 598/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1324 - accuracy: 0.9927 - val_loss: 1.1464 - val_accuracy: 0.6991\n",
      "Epoch 599/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1440 - accuracy: 0.9872 - val_loss: 1.1460 - val_accuracy: 0.6991\n",
      "Epoch 600/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1402 - accuracy: 0.9890 - val_loss: 1.1456 - val_accuracy: 0.7037\n",
      "Epoch 601/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1256 - accuracy: 0.9982 - val_loss: 1.1452 - val_accuracy: 0.7037\n",
      "Epoch 602/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1534 - accuracy: 0.9890 - val_loss: 1.1450 - val_accuracy: 0.7037\n",
      "Epoch 603/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1292 - accuracy: 0.9890 - val_loss: 1.1447 - val_accuracy: 0.7037\n",
      "Epoch 604/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1417 - accuracy: 0.9945 - val_loss: 1.1442 - val_accuracy: 0.7037\n",
      "Epoch 605/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1404 - accuracy: 0.9908 - val_loss: 1.1438 - val_accuracy: 0.7037\n",
      "Epoch 606/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1499 - accuracy: 0.9945 - val_loss: 1.1433 - val_accuracy: 0.7037\n",
      "Epoch 607/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1406 - accuracy: 0.9945 - val_loss: 1.1428 - val_accuracy: 0.7037\n",
      "Epoch 608/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1412 - accuracy: 0.9890 - val_loss: 1.1424 - val_accuracy: 0.7083\n",
      "Epoch 609/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1737 - accuracy: 0.9890 - val_loss: 1.1419 - val_accuracy: 0.7083\n",
      "Epoch 610/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1282 - accuracy: 0.9963 - val_loss: 1.1414 - val_accuracy: 0.7083\n",
      "Epoch 611/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1401 - accuracy: 0.9945 - val_loss: 1.1409 - val_accuracy: 0.7130\n",
      "Epoch 612/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1521 - accuracy: 0.9908 - val_loss: 1.1405 - val_accuracy: 0.7130\n",
      "Epoch 613/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1378 - accuracy: 0.9927 - val_loss: 1.1401 - val_accuracy: 0.7130\n",
      "Epoch 614/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1452 - accuracy: 0.9890 - val_loss: 1.1396 - val_accuracy: 0.7130\n",
      "Epoch 615/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1120 - accuracy: 0.9927 - val_loss: 1.1390 - val_accuracy: 0.7130\n",
      "Epoch 616/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1324 - accuracy: 0.9945 - val_loss: 1.1385 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1538 - accuracy: 0.9908 - val_loss: 1.1379 - val_accuracy: 0.7083\n",
      "Epoch 618/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1486 - accuracy: 0.9963 - val_loss: 1.1373 - val_accuracy: 0.7083\n",
      "Epoch 619/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1394 - accuracy: 0.9872 - val_loss: 1.1369 - val_accuracy: 0.7083\n",
      "Epoch 620/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1439 - accuracy: 0.9927 - val_loss: 1.1364 - val_accuracy: 0.7083\n",
      "Epoch 621/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1251 - accuracy: 0.9927 - val_loss: 1.1360 - val_accuracy: 0.7083\n",
      "Epoch 622/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1466 - accuracy: 0.9927 - val_loss: 1.1356 - val_accuracy: 0.7083\n",
      "Epoch 623/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1335 - accuracy: 0.9927 - val_loss: 1.1352 - val_accuracy: 0.7130\n",
      "Epoch 624/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1614 - accuracy: 0.9908 - val_loss: 1.1348 - val_accuracy: 0.7083\n",
      "Epoch 625/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1236 - accuracy: 0.9945 - val_loss: 1.1347 - val_accuracy: 0.7083\n",
      "Epoch 626/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1534 - accuracy: 0.9908 - val_loss: 1.1343 - val_accuracy: 0.7083\n",
      "Epoch 627/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1369 - accuracy: 0.9927 - val_loss: 1.1339 - val_accuracy: 0.7083\n",
      "Epoch 628/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1430 - accuracy: 0.9963 - val_loss: 1.1335 - val_accuracy: 0.7083\n",
      "Epoch 629/1000\n",
      "546/546 [==============================] - 0s 129us/step - loss: 0.1308 - accuracy: 0.9945 - val_loss: 1.1331 - val_accuracy: 0.7083\n",
      "Epoch 630/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1407 - accuracy: 0.9963 - val_loss: 1.1327 - val_accuracy: 0.7083\n",
      "Epoch 631/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1302 - accuracy: 0.9982 - val_loss: 1.1325 - val_accuracy: 0.7083\n",
      "Epoch 632/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1457 - accuracy: 0.9945 - val_loss: 1.1320 - val_accuracy: 0.7083\n",
      "Epoch 633/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1290 - accuracy: 0.9945 - val_loss: 1.1314 - val_accuracy: 0.7083\n",
      "Epoch 634/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1207 - accuracy: 0.9945 - val_loss: 1.1308 - val_accuracy: 0.7083\n",
      "Epoch 635/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1378 - accuracy: 0.9982 - val_loss: 1.1301 - val_accuracy: 0.7083\n",
      "Epoch 636/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1497 - accuracy: 0.9927 - val_loss: 1.1296 - val_accuracy: 0.7083\n",
      "Epoch 637/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1376 - accuracy: 0.9945 - val_loss: 1.1291 - val_accuracy: 0.7083\n",
      "Epoch 638/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1477 - accuracy: 0.9945 - val_loss: 1.1286 - val_accuracy: 0.7083\n",
      "Epoch 639/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1335 - accuracy: 0.9982 - val_loss: 1.1281 - val_accuracy: 0.7083\n",
      "Epoch 640/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1307 - accuracy: 0.9927 - val_loss: 1.1276 - val_accuracy: 0.7083\n",
      "Epoch 641/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1331 - accuracy: 0.9945 - val_loss: 1.1270 - val_accuracy: 0.7083\n",
      "Epoch 642/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1291 - accuracy: 0.9963 - val_loss: 1.1266 - val_accuracy: 0.7083\n",
      "Epoch 643/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1487 - accuracy: 0.9908 - val_loss: 1.1261 - val_accuracy: 0.7083\n",
      "Epoch 644/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1204 - accuracy: 0.9945 - val_loss: 1.1256 - val_accuracy: 0.7083\n",
      "Epoch 645/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.7083\n",
      "Epoch 646/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1398 - accuracy: 0.9908 - val_loss: 1.1244 - val_accuracy: 0.7083\n",
      "Epoch 647/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1536 - accuracy: 0.9908 - val_loss: 1.1238 - val_accuracy: 0.7083\n",
      "Epoch 648/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1458 - accuracy: 0.9927 - val_loss: 1.1233 - val_accuracy: 0.7083\n",
      "Epoch 649/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1460 - accuracy: 0.9872 - val_loss: 1.1227 - val_accuracy: 0.7083\n",
      "Epoch 650/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1476 - accuracy: 0.9927 - val_loss: 1.1221 - val_accuracy: 0.7083\n",
      "Epoch 651/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1174 - accuracy: 0.9963 - val_loss: 1.1217 - val_accuracy: 0.7083\n",
      "Epoch 652/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1242 - accuracy: 0.9945 - val_loss: 1.1211 - val_accuracy: 0.7083\n",
      "Epoch 653/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.7083\n",
      "Epoch 654/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1264 - accuracy: 0.9927 - val_loss: 1.1203 - val_accuracy: 0.7083\n",
      "Epoch 655/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1130 - accuracy: 0.9945 - val_loss: 1.1200 - val_accuracy: 0.7083\n",
      "Epoch 656/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1399 - accuracy: 0.9908 - val_loss: 1.1199 - val_accuracy: 0.7083\n",
      "Epoch 657/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1652 - accuracy: 0.9853 - val_loss: 1.1196 - val_accuracy: 0.7083\n",
      "Epoch 658/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1106 - accuracy: 0.9963 - val_loss: 1.1194 - val_accuracy: 0.7083\n",
      "Epoch 659/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1418 - accuracy: 0.9945 - val_loss: 1.1193 - val_accuracy: 0.7083\n",
      "Epoch 660/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1532 - accuracy: 0.9908 - val_loss: 1.1191 - val_accuracy: 0.7130\n",
      "Epoch 661/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1227 - accuracy: 0.9982 - val_loss: 1.1189 - val_accuracy: 0.7130\n",
      "Epoch 662/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1182 - accuracy: 0.9963 - val_loss: 1.1185 - val_accuracy: 0.7130\n",
      "Epoch 663/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1325 - accuracy: 0.9927 - val_loss: 1.1181 - val_accuracy: 0.7130\n",
      "Epoch 664/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1214 - accuracy: 0.9945 - val_loss: 1.1180 - val_accuracy: 0.7083\n",
      "Epoch 665/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1791 - accuracy: 0.9908 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 666/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1458 - accuracy: 0.9927 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 667/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1268 - accuracy: 0.9908 - val_loss: 1.1181 - val_accuracy: 0.7083\n",
      "Epoch 668/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1506 - accuracy: 0.9872 - val_loss: 1.1182 - val_accuracy: 0.7083\n",
      "Epoch 669/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1253 - accuracy: 0.9963 - val_loss: 1.1184 - val_accuracy: 0.7083\n",
      "Epoch 670/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1317 - accuracy: 0.9890 - val_loss: 1.1185 - val_accuracy: 0.7083\n",
      "Epoch 671/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1315 - accuracy: 0.9945 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
      "Epoch 672/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1454 - accuracy: 0.9945 - val_loss: 1.1186 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1273 - accuracy: 0.9963 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
      "Epoch 674/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1562 - accuracy: 0.9908 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 675/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1398 - accuracy: 0.9927 - val_loss: 1.1187 - val_accuracy: 0.7037\n",
      "Epoch 676/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1223 - accuracy: 0.9963 - val_loss: 1.1186 - val_accuracy: 0.7037\n",
      "Epoch 677/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1258 - accuracy: 0.9945 - val_loss: 1.1186 - val_accuracy: 0.7037\n",
      "Epoch 678/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1229 - accuracy: 0.9945 - val_loss: 1.1185 - val_accuracy: 0.7037\n",
      "Epoch 679/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1358 - accuracy: 0.9982 - val_loss: 1.1186 - val_accuracy: 0.7037\n",
      "Epoch 680/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1178 - accuracy: 0.9982 - val_loss: 1.1188 - val_accuracy: 0.7037\n",
      "Epoch 681/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1272 - accuracy: 0.9963 - val_loss: 1.1190 - val_accuracy: 0.7037\n",
      "Epoch 682/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1131 - accuracy: 0.9927 - val_loss: 1.1191 - val_accuracy: 0.7083\n",
      "Epoch 683/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1388 - accuracy: 0.9945 - val_loss: 1.1190 - val_accuracy: 0.7083\n",
      "Epoch 684/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1283 - accuracy: 0.9945 - val_loss: 1.1191 - val_accuracy: 0.7130\n",
      "Epoch 685/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1154 - accuracy: 0.9963 - val_loss: 1.1190 - val_accuracy: 0.7130\n",
      "Epoch 686/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1156 - accuracy: 0.9908 - val_loss: 1.1190 - val_accuracy: 0.7130\n",
      "Epoch 687/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1256 - accuracy: 0.9963 - val_loss: 1.1189 - val_accuracy: 0.7130\n",
      "Epoch 688/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1225 - accuracy: 0.9908 - val_loss: 1.1190 - val_accuracy: 0.7083\n",
      "Epoch 689/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1137 - accuracy: 0.9927 - val_loss: 1.1189 - val_accuracy: 0.7130\n",
      "Epoch 690/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1202 - accuracy: 0.9927 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 691/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1292 - accuracy: 0.9927 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 692/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1260 - accuracy: 0.9963 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 693/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1409 - accuracy: 0.9890 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
      "Epoch 694/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1241 - accuracy: 0.9982 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 695/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1344 - accuracy: 0.9927 - val_loss: 1.1184 - val_accuracy: 0.7083\n",
      "Epoch 696/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1271 - accuracy: 0.9963 - val_loss: 1.1181 - val_accuracy: 0.7083\n",
      "Epoch 697/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1259 - accuracy: 0.9982 - val_loss: 1.1180 - val_accuracy: 0.7083\n",
      "Epoch 698/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1340 - accuracy: 0.9927 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 699/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1128 - accuracy: 0.9963 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 700/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1145 - accuracy: 0.9982 - val_loss: 1.1173 - val_accuracy: 0.7083\n",
      "Epoch 701/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1217 - accuracy: 0.9945 - val_loss: 1.1169 - val_accuracy: 0.7083\n",
      "Epoch 702/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1424 - accuracy: 0.9927 - val_loss: 1.1167 - val_accuracy: 0.7083\n",
      "Epoch 703/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1224 - accuracy: 0.9945 - val_loss: 1.1164 - val_accuracy: 0.7083\n",
      "Epoch 704/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1248 - accuracy: 1.0000 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 705/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1173 - accuracy: 0.9927 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 706/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1223 - accuracy: 0.9982 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 707/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1364 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 708/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1627 - accuracy: 0.9890 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 709/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1331 - accuracy: 0.9927 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 710/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1418 - accuracy: 0.9927 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 711/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1263 - accuracy: 0.9963 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 712/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1628 - accuracy: 0.9890 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 713/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1392 - accuracy: 0.9908 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 714/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1442 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 715/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1166 - accuracy: 0.9963 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 716/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1392 - accuracy: 0.9945 - val_loss: 1.1162 - val_accuracy: 0.7083\n",
      "Epoch 717/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1382 - accuracy: 0.9908 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 718/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1187 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 719/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1344 - accuracy: 0.9908 - val_loss: 1.1163 - val_accuracy: 0.7083\n",
      "Epoch 720/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1315 - accuracy: 0.9927 - val_loss: 1.1164 - val_accuracy: 0.7083\n",
      "Epoch 721/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1038 - accuracy: 0.9963 - val_loss: 1.1164 - val_accuracy: 0.7083\n",
      "Epoch 722/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1167 - accuracy: 0.9908 - val_loss: 1.1163 - val_accuracy: 0.7083\n",
      "Epoch 723/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1138 - accuracy: 0.9963 - val_loss: 1.1162 - val_accuracy: 0.7083\n",
      "Epoch 724/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1136 - accuracy: 0.9982 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 725/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1350 - accuracy: 0.9982 - val_loss: 1.1158 - val_accuracy: 0.7083\n",
      "Epoch 726/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1285 - accuracy: 0.9982 - val_loss: 1.1158 - val_accuracy: 0.7083\n",
      "Epoch 727/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1416 - accuracy: 0.9982 - val_loss: 1.1157 - val_accuracy: 0.7083\n",
      "Epoch 728/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1140 - accuracy: 0.9982 - val_loss: 1.1158 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1204 - accuracy: 0.9927 - val_loss: 1.1156 - val_accuracy: 0.7083\n",
      "Epoch 730/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1403 - accuracy: 0.9890 - val_loss: 1.1154 - val_accuracy: 0.7083\n",
      "Epoch 731/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1248 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7083\n",
      "Epoch 732/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1636 - accuracy: 0.9872 - val_loss: 1.1148 - val_accuracy: 0.7130\n",
      "Epoch 733/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1288 - accuracy: 0.9963 - val_loss: 1.1145 - val_accuracy: 0.7130\n",
      "Epoch 734/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1261 - accuracy: 0.9945 - val_loss: 1.1142 - val_accuracy: 0.7130\n",
      "Epoch 735/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1352 - accuracy: 0.9963 - val_loss: 1.1139 - val_accuracy: 0.7130\n",
      "Epoch 736/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1178 - accuracy: 0.9963 - val_loss: 1.1136 - val_accuracy: 0.7130\n",
      "Epoch 737/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1272 - accuracy: 0.9945 - val_loss: 1.1135 - val_accuracy: 0.7130\n",
      "Epoch 738/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1399 - accuracy: 0.9945 - val_loss: 1.1134 - val_accuracy: 0.7130\n",
      "Epoch 739/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1267 - accuracy: 0.9963 - val_loss: 1.1134 - val_accuracy: 0.7130\n",
      "Epoch 740/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1283 - accuracy: 0.9963 - val_loss: 1.1135 - val_accuracy: 0.7130\n",
      "Epoch 741/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1181 - accuracy: 0.9945 - val_loss: 1.1135 - val_accuracy: 0.7130\n",
      "Epoch 742/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1165 - accuracy: 0.9982 - val_loss: 1.1133 - val_accuracy: 0.7130\n",
      "Epoch 743/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1126 - accuracy: 0.9982 - val_loss: 1.1132 - val_accuracy: 0.7130\n",
      "Epoch 744/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1242 - accuracy: 0.9963 - val_loss: 1.1131 - val_accuracy: 0.7130\n",
      "Epoch 745/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1363 - accuracy: 0.9908 - val_loss: 1.1128 - val_accuracy: 0.7130\n",
      "Epoch 746/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1339 - accuracy: 0.9927 - val_loss: 1.1125 - val_accuracy: 0.7130\n",
      "Epoch 747/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1257 - accuracy: 0.9945 - val_loss: 1.1124 - val_accuracy: 0.7130\n",
      "Epoch 748/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1265 - accuracy: 0.9945 - val_loss: 1.1121 - val_accuracy: 0.7130\n",
      "Epoch 749/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1311 - accuracy: 0.9927 - val_loss: 1.1124 - val_accuracy: 0.7130\n",
      "Epoch 750/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1454 - accuracy: 0.9908 - val_loss: 1.1126 - val_accuracy: 0.7130\n",
      "Epoch 751/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1264 - accuracy: 0.9963 - val_loss: 1.1128 - val_accuracy: 0.7130\n",
      "Epoch 752/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1247 - accuracy: 0.9927 - val_loss: 1.1129 - val_accuracy: 0.7130\n",
      "Epoch 753/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1192 - accuracy: 0.9963 - val_loss: 1.1129 - val_accuracy: 0.7130\n",
      "Epoch 754/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1176 - accuracy: 0.9963 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 755/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1244 - accuracy: 0.9963 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 756/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1171 - accuracy: 0.9945 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 757/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1372 - accuracy: 0.9908 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 758/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1404 - accuracy: 0.9927 - val_loss: 1.1132 - val_accuracy: 0.7130\n",
      "Epoch 759/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1147 - accuracy: 0.9945 - val_loss: 1.1134 - val_accuracy: 0.7130\n",
      "Epoch 760/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1190 - accuracy: 0.9982 - val_loss: 1.1134 - val_accuracy: 0.7130\n",
      "Epoch 761/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1338 - accuracy: 0.9890 - val_loss: 1.1134 - val_accuracy: 0.7130\n",
      "Epoch 762/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1390 - accuracy: 0.9945 - val_loss: 1.1136 - val_accuracy: 0.7130\n",
      "Epoch 763/1000\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.1311 - accuracy: 0.9963 - val_loss: 1.1138 - val_accuracy: 0.7130\n",
      "Epoch 764/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1475 - accuracy: 0.9908 - val_loss: 1.1138 - val_accuracy: 0.7130\n",
      "Epoch 765/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1288 - accuracy: 0.9927 - val_loss: 1.1139 - val_accuracy: 0.7130\n",
      "Epoch 766/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1139 - accuracy: 0.9963 - val_loss: 1.1141 - val_accuracy: 0.7130\n",
      "Epoch 767/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1315 - accuracy: 0.9927 - val_loss: 1.1143 - val_accuracy: 0.7130\n",
      "Epoch 768/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1331 - accuracy: 0.9963 - val_loss: 1.1146 - val_accuracy: 0.7130\n",
      "Epoch 769/1000\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.1165 - accuracy: 0.9908 - val_loss: 1.1148 - val_accuracy: 0.7130\n",
      "Epoch 770/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1241 - accuracy: 0.9963 - val_loss: 1.1151 - val_accuracy: 0.7130\n",
      "Epoch 771/1000\n",
      "546/546 [==============================] - 0s 123us/step - loss: 0.1203 - accuracy: 0.9945 - val_loss: 1.1151 - val_accuracy: 0.7130\n",
      "Epoch 772/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7130\n",
      "Epoch 773/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1507 - accuracy: 0.9835 - val_loss: 1.1154 - val_accuracy: 0.7130\n",
      "Epoch 774/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1230 - accuracy: 0.9963 - val_loss: 1.1155 - val_accuracy: 0.7130\n",
      "Epoch 775/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1166 - accuracy: 0.9963 - val_loss: 1.1156 - val_accuracy: 0.7130\n",
      "Epoch 776/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1068 - accuracy: 0.9982 - val_loss: 1.1155 - val_accuracy: 0.7130\n",
      "Epoch 777/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1282 - accuracy: 0.9927 - val_loss: 1.1154 - val_accuracy: 0.7130\n",
      "Epoch 778/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1114 - accuracy: 0.9982 - val_loss: 1.1153 - val_accuracy: 0.7130\n",
      "Epoch 779/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1208 - accuracy: 0.9945 - val_loss: 1.1152 - val_accuracy: 0.7130\n",
      "Epoch 780/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1333 - accuracy: 0.9927 - val_loss: 1.1151 - val_accuracy: 0.7130\n",
      "Epoch 781/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1354 - accuracy: 0.9908 - val_loss: 1.1152 - val_accuracy: 0.7130\n",
      "Epoch 782/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1314 - accuracy: 0.9927 - val_loss: 1.1153 - val_accuracy: 0.7176\n",
      "Epoch 783/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1282 - accuracy: 0.9908 - val_loss: 1.1154 - val_accuracy: 0.7176\n",
      "Epoch 784/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1327 - accuracy: 0.9982 - val_loss: 1.1157 - val_accuracy: 0.7176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1580 - accuracy: 0.9908 - val_loss: 1.1159 - val_accuracy: 0.7176\n",
      "Epoch 786/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1202 - accuracy: 0.9963 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 787/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1301 - accuracy: 0.9890 - val_loss: 1.1161 - val_accuracy: 0.7130\n",
      "Epoch 788/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1212 - accuracy: 0.9963 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 789/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1548 - accuracy: 0.9908 - val_loss: 1.1161 - val_accuracy: 0.7130\n",
      "Epoch 790/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1309 - accuracy: 0.9927 - val_loss: 1.1160 - val_accuracy: 0.7130\n",
      "Epoch 791/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1268 - accuracy: 0.9945 - val_loss: 1.1159 - val_accuracy: 0.7130\n",
      "Epoch 792/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1206 - accuracy: 0.9927 - val_loss: 1.1159 - val_accuracy: 0.7130\n",
      "Epoch 793/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1207 - accuracy: 0.9982 - val_loss: 1.1160 - val_accuracy: 0.7130\n",
      "Epoch 794/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1343 - accuracy: 0.9890 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 795/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1169 - accuracy: 0.9927 - val_loss: 1.1163 - val_accuracy: 0.7130\n",
      "Epoch 796/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1383 - accuracy: 0.9908 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 797/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1320 - accuracy: 0.9945 - val_loss: 1.1164 - val_accuracy: 0.7176\n",
      "Epoch 798/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1364 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.7176\n",
      "Epoch 799/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1279 - accuracy: 0.9982 - val_loss: 1.1168 - val_accuracy: 0.7176\n",
      "Epoch 800/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1374 - accuracy: 0.9908 - val_loss: 1.1171 - val_accuracy: 0.7176\n",
      "Epoch 801/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1145 - accuracy: 0.9982 - val_loss: 1.1173 - val_accuracy: 0.7176\n",
      "Epoch 802/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1453 - accuracy: 0.9890 - val_loss: 1.1176 - val_accuracy: 0.7176\n",
      "Epoch 803/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1343 - accuracy: 0.9853 - val_loss: 1.1178 - val_accuracy: 0.7176\n",
      "Epoch 804/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1256 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7176\n",
      "Epoch 805/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1172 - accuracy: 0.9982 - val_loss: 1.1181 - val_accuracy: 0.7176\n",
      "Epoch 806/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1191 - accuracy: 0.9945 - val_loss: 1.1184 - val_accuracy: 0.7176\n",
      "Epoch 807/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.7176\n",
      "Epoch 808/1000\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.1329 - accuracy: 0.9927 - val_loss: 1.1189 - val_accuracy: 0.7176\n",
      "Epoch 809/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1211 - accuracy: 0.9945 - val_loss: 1.1192 - val_accuracy: 0.7130\n",
      "Epoch 810/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1186 - accuracy: 0.9945 - val_loss: 1.1194 - val_accuracy: 0.7130\n",
      "Epoch 811/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1203 - accuracy: 0.9890 - val_loss: 1.1197 - val_accuracy: 0.7083\n",
      "Epoch 812/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1221 - accuracy: 0.9945 - val_loss: 1.1198 - val_accuracy: 0.7083\n",
      "Epoch 813/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1260 - accuracy: 0.9963 - val_loss: 1.1200 - val_accuracy: 0.7083\n",
      "Epoch 814/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1332 - accuracy: 0.9890 - val_loss: 1.1201 - val_accuracy: 0.7130\n",
      "Epoch 815/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1143 - accuracy: 0.9927 - val_loss: 1.1202 - val_accuracy: 0.7130\n",
      "Epoch 816/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1116 - accuracy: 0.9963 - val_loss: 1.1201 - val_accuracy: 0.7130\n",
      "Epoch 817/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1370 - accuracy: 0.9963 - val_loss: 1.1201 - val_accuracy: 0.7130\n",
      "Epoch 818/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1208 - accuracy: 0.9963 - val_loss: 1.1202 - val_accuracy: 0.7130\n",
      "Epoch 819/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1363 - accuracy: 0.9890 - val_loss: 1.1202 - val_accuracy: 0.7130\n",
      "Epoch 820/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1283 - accuracy: 0.9963 - val_loss: 1.1203 - val_accuracy: 0.7130\n",
      "Epoch 821/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1220 - accuracy: 0.9927 - val_loss: 1.1204 - val_accuracy: 0.7130\n",
      "Epoch 822/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1347 - accuracy: 0.9963 - val_loss: 1.1205 - val_accuracy: 0.7083\n",
      "Epoch 823/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1100 - accuracy: 0.9945 - val_loss: 1.1207 - val_accuracy: 0.7083\n",
      "Epoch 824/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1296 - accuracy: 0.9945 - val_loss: 1.1209 - val_accuracy: 0.7083\n",
      "Epoch 825/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1322 - accuracy: 0.9963 - val_loss: 1.1211 - val_accuracy: 0.7083\n",
      "Epoch 826/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1392 - accuracy: 0.9908 - val_loss: 1.1213 - val_accuracy: 0.7083\n",
      "Epoch 827/1000\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1286 - accuracy: 0.9872 - val_loss: 1.1214 - val_accuracy: 0.7083\n",
      "Epoch 828/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1108 - accuracy: 0.9982 - val_loss: 1.1214 - val_accuracy: 0.7083\n",
      "Epoch 829/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1179 - accuracy: 0.9945 - val_loss: 1.1213 - val_accuracy: 0.7083\n",
      "Epoch 830/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1285 - accuracy: 0.9945 - val_loss: 1.1210 - val_accuracy: 0.7083\n",
      "Epoch 831/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1416 - accuracy: 0.9945 - val_loss: 1.1208 - val_accuracy: 0.7083\n",
      "Epoch 832/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.7083\n",
      "Epoch 833/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1272 - accuracy: 0.9963 - val_loss: 1.1203 - val_accuracy: 0.7083\n",
      "Epoch 834/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1167 - accuracy: 0.9908 - val_loss: 1.1200 - val_accuracy: 0.7083\n",
      "Epoch 835/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1320 - accuracy: 0.9945 - val_loss: 1.1197 - val_accuracy: 0.7083\n",
      "Epoch 836/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1362 - accuracy: 0.9908 - val_loss: 1.1195 - val_accuracy: 0.7083\n",
      "Epoch 837/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1085 - accuracy: 0.9927 - val_loss: 1.1193 - val_accuracy: 0.7083\n",
      "Epoch 838/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1263 - accuracy: 0.9945 - val_loss: 1.1192 - val_accuracy: 0.7083\n",
      "Epoch 839/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1180 - accuracy: 0.9963 - val_loss: 1.1190 - val_accuracy: 0.7083\n",
      "Epoch 840/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1144 - accuracy: 0.9927 - val_loss: 1.1188 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1229 - accuracy: 0.9890 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 842/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1267 - accuracy: 0.9908 - val_loss: 1.1184 - val_accuracy: 0.7083\n",
      "Epoch 843/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1399 - accuracy: 0.9945 - val_loss: 1.1182 - val_accuracy: 0.7083\n",
      "Epoch 844/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1317 - accuracy: 0.9945 - val_loss: 1.1181 - val_accuracy: 0.7083\n",
      "Epoch 845/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1138 - accuracy: 0.9927 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 846/1000\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1155 - accuracy: 0.9982 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 847/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1234 - accuracy: 0.9927 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 848/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1161 - accuracy: 0.9982 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 849/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1149 - accuracy: 0.9963 - val_loss: 1.1175 - val_accuracy: 0.7083\n",
      "Epoch 850/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1390 - accuracy: 0.9908 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 851/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1221 - accuracy: 0.9982 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 852/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1299 - accuracy: 0.9963 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 853/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1090 - accuracy: 0.9982 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 854/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1239 - accuracy: 0.9945 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 855/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1110 - accuracy: 0.9982 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 856/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1194 - accuracy: 0.9927 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 857/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1471 - accuracy: 0.9872 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 858/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1122 - accuracy: 0.9982 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 859/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1320 - accuracy: 0.9945 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 860/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1296 - accuracy: 0.9927 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 861/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1278 - accuracy: 0.9908 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 862/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1394 - accuracy: 0.9945 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 863/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1273 - accuracy: 0.9908 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 864/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 865/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1111 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 866/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1325 - accuracy: 0.9927 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 867/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1114 - accuracy: 0.9945 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 868/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 869/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1063 - accuracy: 0.9982 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 870/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1411 - accuracy: 0.9853 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 871/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1218 - accuracy: 0.9945 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 872/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1282 - accuracy: 0.9890 - val_loss: 1.1176 - val_accuracy: 0.7083\n",
      "Epoch 873/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1147 - accuracy: 0.9945 - val_loss: 1.1175 - val_accuracy: 0.7083\n",
      "Epoch 874/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1209 - accuracy: 0.9945 - val_loss: 1.1173 - val_accuracy: 0.7083\n",
      "Epoch 875/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1149 - accuracy: 0.9982 - val_loss: 1.1172 - val_accuracy: 0.7083\n",
      "Epoch 876/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1224 - accuracy: 0.9963 - val_loss: 1.1170 - val_accuracy: 0.7083\n",
      "Epoch 877/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1250 - accuracy: 0.9890 - val_loss: 1.1168 - val_accuracy: 0.7083\n",
      "Epoch 878/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1315 - accuracy: 0.9908 - val_loss: 1.1167 - val_accuracy: 0.7130\n",
      "Epoch 879/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1091 - accuracy: 0.9927 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 880/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1286 - accuracy: 0.9963 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 881/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1207 - accuracy: 0.9927 - val_loss: 1.1163 - val_accuracy: 0.7130\n",
      "Epoch 882/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 883/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1116 - accuracy: 0.9963 - val_loss: 1.1163 - val_accuracy: 0.7130\n",
      "Epoch 884/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1246 - accuracy: 0.9927 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 885/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1255 - accuracy: 0.9945 - val_loss: 1.1163 - val_accuracy: 0.7130\n",
      "Epoch 886/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1179 - accuracy: 0.9982 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 887/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1102 - accuracy: 0.9945 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 888/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1242 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7130\n",
      "Epoch 889/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1284 - accuracy: 0.9908 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 890/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1191 - accuracy: 0.9927 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 891/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1177 - accuracy: 0.9982 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 892/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1253 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 893/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1066 - accuracy: 0.9982 - val_loss: 1.1166 - val_accuracy: 0.7130\n",
      "Epoch 894/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1233 - accuracy: 0.9945 - val_loss: 1.1167 - val_accuracy: 0.7130\n",
      "Epoch 895/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.7130\n",
      "Epoch 896/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1233 - accuracy: 0.9945 - val_loss: 1.1170 - val_accuracy: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0963 - accuracy: 0.9963 - val_loss: 1.1171 - val_accuracy: 0.7130\n",
      "Epoch 898/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1448 - accuracy: 0.9908 - val_loss: 1.1173 - val_accuracy: 0.7130\n",
      "Epoch 899/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1245 - accuracy: 0.9963 - val_loss: 1.1174 - val_accuracy: 0.7130\n",
      "Epoch 900/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1304 - accuracy: 0.9908 - val_loss: 1.1177 - val_accuracy: 0.7130\n",
      "Epoch 901/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1533 - accuracy: 0.9890 - val_loss: 1.1177 - val_accuracy: 0.7130\n",
      "Epoch 902/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1205 - accuracy: 0.9927 - val_loss: 1.1177 - val_accuracy: 0.7130\n",
      "Epoch 903/1000\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1253 - accuracy: 0.9963 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 904/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1367 - accuracy: 0.9945 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 905/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1136 - accuracy: 0.9982 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 906/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1400 - accuracy: 0.9945 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 907/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1077 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 908/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1230 - accuracy: 0.9927 - val_loss: 1.1180 - val_accuracy: 0.7083\n",
      "Epoch 909/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1365 - accuracy: 0.9908 - val_loss: 1.1182 - val_accuracy: 0.7083\n",
      "Epoch 910/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1177 - accuracy: 0.9945 - val_loss: 1.1184 - val_accuracy: 0.7083\n",
      "Epoch 911/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1329 - accuracy: 0.9927 - val_loss: 1.1185 - val_accuracy: 0.7083\n",
      "Epoch 912/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1250 - accuracy: 0.9963 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 913/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1033 - accuracy: 0.9945 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 914/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1069 - accuracy: 0.9963 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 915/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1062 - accuracy: 0.9963 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
      "Epoch 916/1000\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1333 - accuracy: 0.9890 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 917/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1220 - accuracy: 0.9945 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 918/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1366 - accuracy: 0.9945 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 919/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1311 - accuracy: 0.9945 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 920/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1154 - accuracy: 0.9945 - val_loss: 1.1188 - val_accuracy: 0.7083\n",
      "Epoch 921/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1229 - accuracy: 0.9945 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
      "Epoch 922/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1160 - accuracy: 0.9963 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 923/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1172 - accuracy: 0.9945 - val_loss: 1.1185 - val_accuracy: 0.7083\n",
      "Epoch 924/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1256 - accuracy: 0.9982 - val_loss: 1.1183 - val_accuracy: 0.7130\n",
      "Epoch 925/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1166 - accuracy: 0.9982 - val_loss: 1.1183 - val_accuracy: 0.7130\n",
      "Epoch 926/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1272 - accuracy: 0.9945 - val_loss: 1.1183 - val_accuracy: 0.7130\n",
      "Epoch 927/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1253 - accuracy: 0.9963 - val_loss: 1.1183 - val_accuracy: 0.7130\n",
      "Epoch 928/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.7130\n",
      "Epoch 929/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1188 - accuracy: 0.9963 - val_loss: 1.1181 - val_accuracy: 0.7130\n",
      "Epoch 930/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1266 - accuracy: 0.9945 - val_loss: 1.1178 - val_accuracy: 0.7130\n",
      "Epoch 931/1000\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1370 - accuracy: 0.9927 - val_loss: 1.1175 - val_accuracy: 0.7130\n",
      "Epoch 932/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1608 - accuracy: 0.9872 - val_loss: 1.1174 - val_accuracy: 0.7130\n",
      "Epoch 933/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1382 - accuracy: 0.9908 - val_loss: 1.1172 - val_accuracy: 0.7130\n",
      "Epoch 934/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1245 - accuracy: 0.9890 - val_loss: 1.1172 - val_accuracy: 0.7130\n",
      "Epoch 935/1000\n",
      "546/546 [==============================] - 0s 126us/step - loss: 0.1198 - accuracy: 0.9982 - val_loss: 1.1170 - val_accuracy: 0.7130\n",
      "Epoch 936/1000\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.1164 - accuracy: 0.9963 - val_loss: 1.1168 - val_accuracy: 0.7130\n",
      "Epoch 937/1000\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.1119 - accuracy: 0.9963 - val_loss: 1.1166 - val_accuracy: 0.7130\n",
      "Epoch 938/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1156 - accuracy: 0.9945 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 939/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1252 - accuracy: 0.9963 - val_loss: 1.1161 - val_accuracy: 0.7130\n",
      "Epoch 940/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1193 - accuracy: 0.9945 - val_loss: 1.1158 - val_accuracy: 0.7130\n",
      "Epoch 941/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1242 - accuracy: 0.9945 - val_loss: 1.1155 - val_accuracy: 0.7130\n",
      "Epoch 942/1000\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1215 - accuracy: 0.9963 - val_loss: 1.1153 - val_accuracy: 0.7130\n",
      "Epoch 943/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1340 - accuracy: 0.9890 - val_loss: 1.1152 - val_accuracy: 0.7130\n",
      "Epoch 944/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1321 - accuracy: 0.9908 - val_loss: 1.1150 - val_accuracy: 0.7130\n",
      "Epoch 945/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1183 - accuracy: 0.9963 - val_loss: 1.1147 - val_accuracy: 0.7130\n",
      "Epoch 946/1000\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 1.1146 - val_accuracy: 0.7130\n",
      "Epoch 947/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1007 - accuracy: 0.9945 - val_loss: 1.1144 - val_accuracy: 0.7130\n",
      "Epoch 948/1000\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1217 - accuracy: 0.9908 - val_loss: 1.1143 - val_accuracy: 0.7130\n",
      "Epoch 949/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.7130\n",
      "Epoch 950/1000\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1064 - accuracy: 0.9945 - val_loss: 1.1141 - val_accuracy: 0.7130\n",
      "Epoch 951/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1282 - accuracy: 0.9908 - val_loss: 1.1139 - val_accuracy: 0.7130\n",
      "Epoch 952/1000\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1243 - accuracy: 0.9945 - val_loss: 1.1139 - val_accuracy: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1319 - accuracy: 0.9927 - val_loss: 1.1137 - val_accuracy: 0.7130\n",
      "Epoch 954/1000\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1219 - accuracy: 0.9945 - val_loss: 1.1136 - val_accuracy: 0.7130\n",
      "Epoch 955/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1101 - accuracy: 0.9945 - val_loss: 1.1136 - val_accuracy: 0.7130\n",
      "Epoch 956/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1090 - accuracy: 0.9945 - val_loss: 1.1133 - val_accuracy: 0.7130\n",
      "Epoch 957/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1264 - accuracy: 0.9963 - val_loss: 1.1132 - val_accuracy: 0.7130\n",
      "Epoch 958/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1324 - accuracy: 0.9982 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 959/1000\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1182 - accuracy: 0.9982 - val_loss: 1.1129 - val_accuracy: 0.7130\n",
      "Epoch 960/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1289 - accuracy: 0.9908 - val_loss: 1.1127 - val_accuracy: 0.7130\n",
      "Epoch 961/1000\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.1240 - accuracy: 0.9927 - val_loss: 1.1126 - val_accuracy: 0.7130\n",
      "Epoch 962/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1166 - accuracy: 0.9963 - val_loss: 1.1126 - val_accuracy: 0.7130\n",
      "Epoch 963/1000\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1145 - accuracy: 0.9927 - val_loss: 1.1124 - val_accuracy: 0.7130\n",
      "Epoch 964/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1170 - accuracy: 0.9945 - val_loss: 1.1122 - val_accuracy: 0.7130\n",
      "Epoch 965/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1414 - accuracy: 0.9890 - val_loss: 1.1121 - val_accuracy: 0.7130\n",
      "Epoch 966/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1049 - accuracy: 0.9963 - val_loss: 1.1122 - val_accuracy: 0.7083\n",
      "Epoch 967/1000\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1441 - accuracy: 0.9927 - val_loss: 1.1123 - val_accuracy: 0.7083\n",
      "Epoch 968/1000\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1230 - accuracy: 0.9963 - val_loss: 1.1124 - val_accuracy: 0.7083\n",
      "Epoch 969/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1218 - accuracy: 0.9982 - val_loss: 1.1125 - val_accuracy: 0.7083\n",
      "Epoch 970/1000\n",
      "546/546 [==============================] - 0s 170us/step - loss: 0.1244 - accuracy: 0.9927 - val_loss: 1.1126 - val_accuracy: 0.7083\n",
      "Epoch 971/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1165 - accuracy: 0.9982 - val_loss: 1.1127 - val_accuracy: 0.7083\n",
      "Epoch 972/1000\n",
      "546/546 [==============================] - 0s 165us/step - loss: 0.1365 - accuracy: 0.9835 - val_loss: 1.1128 - val_accuracy: 0.7083\n",
      "Epoch 973/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1307 - accuracy: 0.9982 - val_loss: 1.1130 - val_accuracy: 0.7083\n",
      "Epoch 974/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1275 - accuracy: 0.9890 - val_loss: 1.1132 - val_accuracy: 0.7083\n",
      "Epoch 975/1000\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1019 - accuracy: 0.9982 - val_loss: 1.1134 - val_accuracy: 0.7083\n",
      "Epoch 976/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1330 - accuracy: 0.9945 - val_loss: 1.1134 - val_accuracy: 0.7083\n",
      "Epoch 977/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1167 - accuracy: 0.9982 - val_loss: 1.1136 - val_accuracy: 0.7083\n",
      "Epoch 978/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1188 - accuracy: 0.9908 - val_loss: 1.1137 - val_accuracy: 0.7083\n",
      "Epoch 979/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1211 - accuracy: 0.9945 - val_loss: 1.1138 - val_accuracy: 0.7083\n",
      "Epoch 980/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1249 - accuracy: 0.9908 - val_loss: 1.1139 - val_accuracy: 0.7037\n",
      "Epoch 981/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1261 - accuracy: 0.9945 - val_loss: 1.1138 - val_accuracy: 0.7037\n",
      "Epoch 982/1000\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1309 - accuracy: 0.9963 - val_loss: 1.1141 - val_accuracy: 0.7083\n",
      "Epoch 983/1000\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1326 - accuracy: 0.9963 - val_loss: 1.1144 - val_accuracy: 0.7083\n",
      "Epoch 984/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1061 - accuracy: 0.9963 - val_loss: 1.1147 - val_accuracy: 0.7083\n",
      "Epoch 985/1000\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1197 - accuracy: 0.9945 - val_loss: 1.1152 - val_accuracy: 0.7083\n",
      "Epoch 986/1000\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1309 - accuracy: 0.9927 - val_loss: 1.1155 - val_accuracy: 0.7083\n",
      "Epoch 987/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1038 - accuracy: 0.9963 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Epoch 988/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1177 - accuracy: 0.9982 - val_loss: 1.1163 - val_accuracy: 0.7083\n",
      "Epoch 989/1000\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1208 - accuracy: 0.9963 - val_loss: 1.1165 - val_accuracy: 0.7083\n",
      "Epoch 990/1000\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1233 - accuracy: 0.9908 - val_loss: 1.1167 - val_accuracy: 0.7083\n",
      "Epoch 991/1000\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1168 - accuracy: 0.9963 - val_loss: 1.1168 - val_accuracy: 0.7083\n",
      "Epoch 992/1000\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1095 - accuracy: 0.9945 - val_loss: 1.1169 - val_accuracy: 0.7083\n",
      "Epoch 993/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1196 - accuracy: 0.9908 - val_loss: 1.1169 - val_accuracy: 0.7083\n",
      "Epoch 994/1000\n",
      "546/546 [==============================] - 0s 166us/step - loss: 0.1283 - accuracy: 0.9908 - val_loss: 1.1170 - val_accuracy: 0.7083\n",
      "Epoch 995/1000\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1098 - accuracy: 0.9945 - val_loss: 1.1169 - val_accuracy: 0.7083\n",
      "Epoch 996/1000\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1348 - accuracy: 0.9963 - val_loss: 1.1167 - val_accuracy: 0.7083\n",
      "Epoch 997/1000\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1183 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.7083\n",
      "Epoch 998/1000\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1235 - accuracy: 0.9908 - val_loss: 1.1163 - val_accuracy: 0.7083\n",
      "Epoch 999/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1212 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 1000/1000\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1246 - accuracy: 0.9945 - val_loss: 1.1160 - val_accuracy: 0.7083\n",
      "Train on 546 samples, validate on 216 samples\n",
      "Epoch 1/400\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.7130\n",
      "Epoch 2/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1375 - accuracy: 0.9908 - val_loss: 1.1364 - val_accuracy: 0.7083\n",
      "Epoch 3/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1032 - accuracy: 0.9982 - val_loss: 1.1423 - val_accuracy: 0.7130\n",
      "Epoch 4/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1180 - accuracy: 0.9963 - val_loss: 1.1455 - val_accuracy: 0.7083\n",
      "Epoch 5/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1228 - accuracy: 0.9945 - val_loss: 1.1492 - val_accuracy: 0.7083\n",
      "Epoch 6/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1144 - accuracy: 0.9982 - val_loss: 1.1447 - val_accuracy: 0.7037\n",
      "Epoch 7/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0930 - accuracy: 0.9963 - val_loss: 1.1410 - val_accuracy: 0.7083\n",
      "Epoch 8/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1119 - accuracy: 0.9963 - val_loss: 1.1385 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1090 - accuracy: 0.9927 - val_loss: 1.1357 - val_accuracy: 0.7037\n",
      "Epoch 10/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1244 - accuracy: 0.9927 - val_loss: 1.1296 - val_accuracy: 0.7083\n",
      "Epoch 11/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.1241 - val_accuracy: 0.7037\n",
      "Epoch 12/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1044 - accuracy: 0.9963 - val_loss: 1.1194 - val_accuracy: 0.7083\n",
      "Epoch 13/400\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1281 - accuracy: 0.9982 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 14/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1276 - accuracy: 0.9908 - val_loss: 1.1130 - val_accuracy: 0.7130\n",
      "Epoch 15/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1300 - accuracy: 0.9908 - val_loss: 1.1115 - val_accuracy: 0.7222\n",
      "Epoch 16/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1258 - accuracy: 0.9945 - val_loss: 1.1115 - val_accuracy: 0.7222\n",
      "Epoch 17/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1058 - accuracy: 0.9982 - val_loss: 1.1118 - val_accuracy: 0.7222\n",
      "Epoch 18/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1215 - accuracy: 0.9908 - val_loss: 1.1120 - val_accuracy: 0.7222\n",
      "Epoch 19/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1092 - accuracy: 0.9982 - val_loss: 1.1133 - val_accuracy: 0.7176\n",
      "Epoch 20/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1294 - accuracy: 0.9945 - val_loss: 1.1147 - val_accuracy: 0.7176\n",
      "Epoch 21/400\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1067 - accuracy: 0.9963 - val_loss: 1.1158 - val_accuracy: 0.7130\n",
      "Epoch 22/400\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.0957 - accuracy: 0.9945 - val_loss: 1.1166 - val_accuracy: 0.7083\n",
      "Epoch 23/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0931 - accuracy: 0.9963 - val_loss: 1.1175 - val_accuracy: 0.7083\n",
      "Epoch 24/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1148 - accuracy: 0.9963 - val_loss: 1.1181 - val_accuracy: 0.7037\n",
      "Epoch 25/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1089 - accuracy: 0.9927 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 26/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0986 - accuracy: 0.9945 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 27/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1123 - accuracy: 0.9963 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 28/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0928 - accuracy: 0.9945 - val_loss: 1.1181 - val_accuracy: 0.7037\n",
      "Epoch 29/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1173 - accuracy: 0.9927 - val_loss: 1.1182 - val_accuracy: 0.7083\n",
      "Epoch 30/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1207 - accuracy: 0.9927 - val_loss: 1.1183 - val_accuracy: 0.7083\n",
      "Epoch 31/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0994 - accuracy: 0.9945 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 32/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1174 - accuracy: 0.9963 - val_loss: 1.1168 - val_accuracy: 0.7083\n",
      "Epoch 33/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0991 - accuracy: 0.9982 - val_loss: 1.1161 - val_accuracy: 0.7083\n",
      "Epoch 34/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1193 - accuracy: 0.9945 - val_loss: 1.1159 - val_accuracy: 0.7083\n",
      "Epoch 35/400\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1176 - accuracy: 0.9945 - val_loss: 1.1158 - val_accuracy: 0.7083\n",
      "Epoch 36/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0991 - accuracy: 0.9982 - val_loss: 1.1159 - val_accuracy: 0.7083\n",
      "Epoch 37/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1181 - accuracy: 0.9963 - val_loss: 1.1162 - val_accuracy: 0.7083\n",
      "Epoch 38/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1172 - accuracy: 0.9927 - val_loss: 1.1163 - val_accuracy: 0.7083\n",
      "Epoch 39/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1054 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 40/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1001 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 41/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1087 - accuracy: 0.9982 - val_loss: 1.1167 - val_accuracy: 0.7130\n",
      "Epoch 42/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1292 - accuracy: 0.9927 - val_loss: 1.1166 - val_accuracy: 0.7130\n",
      "Epoch 43/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1069 - accuracy: 0.9963 - val_loss: 1.1165 - val_accuracy: 0.7130\n",
      "Epoch 44/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1031 - accuracy: 0.9872 - val_loss: 1.1164 - val_accuracy: 0.7130\n",
      "Epoch 45/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1285 - accuracy: 0.9908 - val_loss: 1.1162 - val_accuracy: 0.7130\n",
      "Epoch 46/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1165 - accuracy: 0.9945 - val_loss: 1.1161 - val_accuracy: 0.7130\n",
      "Epoch 47/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1124 - accuracy: 0.9963 - val_loss: 1.1160 - val_accuracy: 0.7130\n",
      "Epoch 48/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0924 - accuracy: 0.9982 - val_loss: 1.1159 - val_accuracy: 0.7130\n",
      "Epoch 49/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1063 - accuracy: 0.9963 - val_loss: 1.1158 - val_accuracy: 0.7130\n",
      "Epoch 50/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1034 - accuracy: 0.9908 - val_loss: 1.1157 - val_accuracy: 0.7130\n",
      "Epoch 51/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0985 - accuracy: 0.9945 - val_loss: 1.1157 - val_accuracy: 0.7130\n",
      "Epoch 52/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.7176\n",
      "Epoch 53/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1018 - accuracy: 0.9963 - val_loss: 1.1156 - val_accuracy: 0.7176\n",
      "Epoch 54/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1177 - accuracy: 0.9890 - val_loss: 1.1155 - val_accuracy: 0.7176\n",
      "Epoch 55/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1111 - accuracy: 0.9927 - val_loss: 1.1156 - val_accuracy: 0.7176\n",
      "Epoch 56/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0963 - accuracy: 0.9982 - val_loss: 1.1156 - val_accuracy: 0.7176\n",
      "Epoch 57/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1000 - accuracy: 0.9982 - val_loss: 1.1156 - val_accuracy: 0.7176\n",
      "Epoch 58/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.7176\n",
      "Epoch 59/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0986 - accuracy: 0.9963 - val_loss: 1.1153 - val_accuracy: 0.7176\n",
      "Epoch 60/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1117 - accuracy: 0.9963 - val_loss: 1.1151 - val_accuracy: 0.7176\n",
      "Epoch 61/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1103 - accuracy: 0.9963 - val_loss: 1.1151 - val_accuracy: 0.7176\n",
      "Epoch 62/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.1151 - val_accuracy: 0.7176\n",
      "Epoch 63/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.1151 - val_accuracy: 0.7176\n",
      "Epoch 64/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1206 - accuracy: 0.9908 - val_loss: 1.1152 - val_accuracy: 0.7176\n",
      "Epoch 65/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.0986 - accuracy: 0.9963 - val_loss: 1.1152 - val_accuracy: 0.7176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1172 - accuracy: 0.9945 - val_loss: 1.1154 - val_accuracy: 0.7176\n",
      "Epoch 67/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 1.1157 - val_accuracy: 0.7176\n",
      "Epoch 68/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1170 - accuracy: 0.9945 - val_loss: 1.1160 - val_accuracy: 0.7176\n",
      "Epoch 69/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1064 - accuracy: 0.9963 - val_loss: 1.1163 - val_accuracy: 0.7176\n",
      "Epoch 70/400\n",
      "546/546 [==============================] - 0s 164us/step - loss: 0.1128 - accuracy: 0.9963 - val_loss: 1.1164 - val_accuracy: 0.7176\n",
      "Epoch 71/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1041 - accuracy: 0.9963 - val_loss: 1.1166 - val_accuracy: 0.7176\n",
      "Epoch 72/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1000 - accuracy: 0.9963 - val_loss: 1.1166 - val_accuracy: 0.7176\n",
      "Epoch 73/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0926 - accuracy: 0.9963 - val_loss: 1.1168 - val_accuracy: 0.7176\n",
      "Epoch 74/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1129 - accuracy: 0.9908 - val_loss: 1.1168 - val_accuracy: 0.7176\n",
      "Epoch 75/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1244 - accuracy: 0.9890 - val_loss: 1.1169 - val_accuracy: 0.7176\n",
      "Epoch 76/400\n",
      "546/546 [==============================] - 0s 162us/step - loss: 0.1180 - accuracy: 0.9963 - val_loss: 1.1171 - val_accuracy: 0.7176\n",
      "Epoch 77/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1118 - accuracy: 0.9945 - val_loss: 1.1174 - val_accuracy: 0.7176\n",
      "Epoch 78/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0923 - accuracy: 0.9945 - val_loss: 1.1176 - val_accuracy: 0.7176\n",
      "Epoch 79/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0952 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7176\n",
      "Epoch 80/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1240 - accuracy: 0.9890 - val_loss: 1.1181 - val_accuracy: 0.7176\n",
      "Epoch 81/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1003 - accuracy: 0.9982 - val_loss: 1.1183 - val_accuracy: 0.7176\n",
      "Epoch 82/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1225 - accuracy: 0.9908 - val_loss: 1.1184 - val_accuracy: 0.7130\n",
      "Epoch 83/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1248 - accuracy: 0.9927 - val_loss: 1.1184 - val_accuracy: 0.7130\n",
      "Epoch 84/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1116 - accuracy: 0.9908 - val_loss: 1.1184 - val_accuracy: 0.7130\n",
      "Epoch 85/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1060 - accuracy: 0.9963 - val_loss: 1.1185 - val_accuracy: 0.7130\n",
      "Epoch 86/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1135 - accuracy: 0.9927 - val_loss: 1.1184 - val_accuracy: 0.7130\n",
      "Epoch 87/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1017 - accuracy: 0.9963 - val_loss: 1.1184 - val_accuracy: 0.7130\n",
      "Epoch 88/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1186 - accuracy: 0.9963 - val_loss: 1.1181 - val_accuracy: 0.7130\n",
      "Epoch 89/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1339 - accuracy: 0.9927 - val_loss: 1.1178 - val_accuracy: 0.7130\n",
      "Epoch 90/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1098 - accuracy: 0.9945 - val_loss: 1.1177 - val_accuracy: 0.7130\n",
      "Epoch 91/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1157 - accuracy: 0.9963 - val_loss: 1.1176 - val_accuracy: 0.7130\n",
      "Epoch 92/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1083 - accuracy: 0.9945 - val_loss: 1.1175 - val_accuracy: 0.7130\n",
      "Epoch 93/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.7083\n",
      "Epoch 94/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1013 - accuracy: 0.9982 - val_loss: 1.1175 - val_accuracy: 0.7083\n",
      "Epoch 95/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1223 - accuracy: 0.9963 - val_loss: 1.1174 - val_accuracy: 0.7083\n",
      "Epoch 96/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1149 - accuracy: 0.9963 - val_loss: 1.1174 - val_accuracy: 0.7083\n",
      "Epoch 97/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0987 - accuracy: 0.9963 - val_loss: 1.1174 - val_accuracy: 0.7083\n",
      "Epoch 98/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1168 - accuracy: 0.9927 - val_loss: 1.1175 - val_accuracy: 0.7083\n",
      "Epoch 99/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1131 - accuracy: 0.9945 - val_loss: 1.1177 - val_accuracy: 0.7083\n",
      "Epoch 100/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0919 - accuracy: 0.9927 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 101/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0974 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 102/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1116 - accuracy: 0.9927 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 103/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1061 - accuracy: 0.9963 - val_loss: 1.1178 - val_accuracy: 0.7083\n",
      "Epoch 104/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1031 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
      "Epoch 105/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1129 - accuracy: 0.9945 - val_loss: 1.1180 - val_accuracy: 0.7083\n",
      "Epoch 106/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1162 - accuracy: 0.9945 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 107/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1004 - accuracy: 0.9890 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 108/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.7037\n",
      "Epoch 109/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1083 - accuracy: 0.9963 - val_loss: 1.1185 - val_accuracy: 0.7083\n",
      "Epoch 110/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1070 - accuracy: 0.9982 - val_loss: 1.1186 - val_accuracy: 0.7083\n",
      "Epoch 111/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1442 - accuracy: 0.9927 - val_loss: 1.1183 - val_accuracy: 0.7083\n",
      "Epoch 112/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1157 - accuracy: 0.9963 - val_loss: 1.1183 - val_accuracy: 0.7083\n",
      "Epoch 113/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1221 - accuracy: 0.9927 - val_loss: 1.1181 - val_accuracy: 0.7083\n",
      "Epoch 114/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1002 - accuracy: 0.9963 - val_loss: 1.1180 - val_accuracy: 0.6991\n",
      "Epoch 115/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1057 - accuracy: 0.9945 - val_loss: 1.1179 - val_accuracy: 0.6991\n",
      "Epoch 116/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1082 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.6991\n",
      "Epoch 117/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1256 - accuracy: 0.9927 - val_loss: 1.1179 - val_accuracy: 0.6991\n",
      "Epoch 118/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.0958 - accuracy: 0.9963 - val_loss: 1.1178 - val_accuracy: 0.7037\n",
      "Epoch 119/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1030 - accuracy: 0.9982 - val_loss: 1.1178 - val_accuracy: 0.7037\n",
      "Epoch 120/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1091 - accuracy: 0.9945 - val_loss: 1.1179 - val_accuracy: 0.7037\n",
      "Epoch 121/400\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1024 - accuracy: 0.9963 - val_loss: 1.1179 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1296 - accuracy: 0.9945 - val_loss: 1.1180 - val_accuracy: 0.7037\n",
      "Epoch 123/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1311 - accuracy: 0.9908 - val_loss: 1.1181 - val_accuracy: 0.7037\n",
      "Epoch 124/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1033 - accuracy: 0.9982 - val_loss: 1.1182 - val_accuracy: 0.7037\n",
      "Epoch 125/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0974 - accuracy: 0.9927 - val_loss: 1.1185 - val_accuracy: 0.7037\n",
      "Epoch 126/400\n",
      "546/546 [==============================] - 0s 177us/step - loss: 0.1167 - accuracy: 0.9945 - val_loss: 1.1185 - val_accuracy: 0.7037\n",
      "Epoch 127/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1160 - accuracy: 0.9908 - val_loss: 1.1188 - val_accuracy: 0.7037\n",
      "Epoch 128/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0935 - accuracy: 0.9963 - val_loss: 1.1190 - val_accuracy: 0.7037\n",
      "Epoch 129/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0951 - accuracy: 0.9963 - val_loss: 1.1192 - val_accuracy: 0.7037\n",
      "Epoch 130/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.7083\n",
      "Epoch 131/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1214 - accuracy: 0.9945 - val_loss: 1.1195 - val_accuracy: 0.7130\n",
      "Epoch 132/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.7130\n",
      "Epoch 133/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1044 - accuracy: 0.9982 - val_loss: 1.1197 - val_accuracy: 0.7130\n",
      "Epoch 134/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1041 - accuracy: 0.9982 - val_loss: 1.1198 - val_accuracy: 0.7130\n",
      "Epoch 135/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1140 - accuracy: 0.9963 - val_loss: 1.1197 - val_accuracy: 0.7130\n",
      "Epoch 136/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1040 - accuracy: 0.9963 - val_loss: 1.1197 - val_accuracy: 0.7130\n",
      "Epoch 137/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.1099 - accuracy: 0.9945 - val_loss: 1.1199 - val_accuracy: 0.7083\n",
      "Epoch 138/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0974 - accuracy: 0.9963 - val_loss: 1.1198 - val_accuracy: 0.7130\n",
      "Epoch 139/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1226 - accuracy: 0.9963 - val_loss: 1.1199 - val_accuracy: 0.7130\n",
      "Epoch 140/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1198 - accuracy: 0.9927 - val_loss: 1.1200 - val_accuracy: 0.7130\n",
      "Epoch 141/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1188 - accuracy: 0.9908 - val_loss: 1.1200 - val_accuracy: 0.7176\n",
      "Epoch 142/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1052 - accuracy: 0.9945 - val_loss: 1.1201 - val_accuracy: 0.7176\n",
      "Epoch 143/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.1201 - val_accuracy: 0.7176\n",
      "Epoch 144/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1116 - accuracy: 0.9982 - val_loss: 1.1204 - val_accuracy: 0.7176\n",
      "Epoch 145/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0986 - accuracy: 0.9982 - val_loss: 1.1206 - val_accuracy: 0.7176\n",
      "Epoch 146/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1041 - accuracy: 0.9963 - val_loss: 1.1209 - val_accuracy: 0.7176\n",
      "Epoch 147/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1139 - accuracy: 0.9927 - val_loss: 1.1212 - val_accuracy: 0.7176\n",
      "Epoch 148/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1109 - accuracy: 0.9945 - val_loss: 1.1213 - val_accuracy: 0.7176\n",
      "Epoch 149/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1003 - accuracy: 0.9945 - val_loss: 1.1216 - val_accuracy: 0.7176\n",
      "Epoch 150/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1393 - accuracy: 0.9927 - val_loss: 1.1216 - val_accuracy: 0.7176\n",
      "Epoch 151/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1132 - accuracy: 0.9963 - val_loss: 1.1216 - val_accuracy: 0.7176\n",
      "Epoch 152/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1091 - accuracy: 0.9927 - val_loss: 1.1219 - val_accuracy: 0.7176\n",
      "Epoch 153/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1062 - accuracy: 0.9963 - val_loss: 1.1222 - val_accuracy: 0.7176\n",
      "Epoch 154/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1056 - accuracy: 0.9927 - val_loss: 1.1224 - val_accuracy: 0.7176\n",
      "Epoch 155/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1095 - accuracy: 0.9908 - val_loss: 1.1227 - val_accuracy: 0.7176\n",
      "Epoch 156/400\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1037 - accuracy: 0.9982 - val_loss: 1.1228 - val_accuracy: 0.7176\n",
      "Epoch 157/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1222 - accuracy: 0.9963 - val_loss: 1.1228 - val_accuracy: 0.7176\n",
      "Epoch 158/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0928 - accuracy: 0.9982 - val_loss: 1.1227 - val_accuracy: 0.7176\n",
      "Epoch 159/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1047 - accuracy: 0.9927 - val_loss: 1.1227 - val_accuracy: 0.7176\n",
      "Epoch 160/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1011 - accuracy: 0.9982 - val_loss: 1.1227 - val_accuracy: 0.7176\n",
      "Epoch 161/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.7176\n",
      "Epoch 162/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1135 - accuracy: 0.9963 - val_loss: 1.1224 - val_accuracy: 0.7176\n",
      "Epoch 163/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.7176\n",
      "Epoch 164/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1002 - accuracy: 0.9982 - val_loss: 1.1227 - val_accuracy: 0.7130\n",
      "Epoch 165/400\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.0997 - accuracy: 0.9945 - val_loss: 1.1227 - val_accuracy: 0.7130\n",
      "Epoch 166/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 1.1227 - val_accuracy: 0.7130\n",
      "Epoch 167/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.7130\n",
      "Epoch 168/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1351 - accuracy: 0.9890 - val_loss: 1.1226 - val_accuracy: 0.7130\n",
      "Epoch 169/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.7130\n",
      "Epoch 170/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1075 - accuracy: 0.9927 - val_loss: 1.1224 - val_accuracy: 0.7130\n",
      "Epoch 171/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1054 - accuracy: 0.9945 - val_loss: 1.1223 - val_accuracy: 0.7083\n",
      "Epoch 172/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1289 - accuracy: 0.9945 - val_loss: 1.1223 - val_accuracy: 0.7083\n",
      "Epoch 173/400\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1103 - accuracy: 0.9963 - val_loss: 1.1221 - val_accuracy: 0.7083\n",
      "Epoch 174/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1051 - accuracy: 0.9982 - val_loss: 1.1222 - val_accuracy: 0.7083\n",
      "Epoch 175/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1232 - accuracy: 0.9927 - val_loss: 1.1222 - val_accuracy: 0.7083\n",
      "Epoch 176/400\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.1159 - accuracy: 0.9908 - val_loss: 1.1222 - val_accuracy: 0.7083\n",
      "Epoch 177/400\n",
      "546/546 [==============================] - 0s 133us/step - loss: 0.0998 - accuracy: 0.9982 - val_loss: 1.1222 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0966 - accuracy: 0.9982 - val_loss: 1.1222 - val_accuracy: 0.7083\n",
      "Epoch 179/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1044 - accuracy: 0.9982 - val_loss: 1.1221 - val_accuracy: 0.7083\n",
      "Epoch 180/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1118 - accuracy: 0.9945 - val_loss: 1.1220 - val_accuracy: 0.7083\n",
      "Epoch 181/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1042 - accuracy: 0.9927 - val_loss: 1.1220 - val_accuracy: 0.7083\n",
      "Epoch 182/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1044 - accuracy: 0.9945 - val_loss: 1.1219 - val_accuracy: 0.7083\n",
      "Epoch 183/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.7083\n",
      "Epoch 184/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1006 - accuracy: 0.9963 - val_loss: 1.1218 - val_accuracy: 0.7083\n",
      "Epoch 185/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0952 - accuracy: 0.9945 - val_loss: 1.1215 - val_accuracy: 0.7083\n",
      "Epoch 186/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1192 - accuracy: 0.9927 - val_loss: 1.1214 - val_accuracy: 0.7083\n",
      "Epoch 187/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1138 - accuracy: 0.9890 - val_loss: 1.1216 - val_accuracy: 0.7083\n",
      "Epoch 188/400\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.0983 - accuracy: 0.9945 - val_loss: 1.1216 - val_accuracy: 0.7083\n",
      "Epoch 189/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1092 - accuracy: 0.9963 - val_loss: 1.1217 - val_accuracy: 0.7083\n",
      "Epoch 190/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1126 - accuracy: 0.9945 - val_loss: 1.1218 - val_accuracy: 0.7083\n",
      "Epoch 191/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1003 - accuracy: 0.9945 - val_loss: 1.1219 - val_accuracy: 0.7083\n",
      "Epoch 192/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1082 - accuracy: 0.9963 - val_loss: 1.1219 - val_accuracy: 0.7083\n",
      "Epoch 193/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1132 - accuracy: 0.9963 - val_loss: 1.1219 - val_accuracy: 0.7083\n",
      "Epoch 194/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0980 - accuracy: 0.9982 - val_loss: 1.1220 - val_accuracy: 0.7083\n",
      "Epoch 195/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.7083\n",
      "Epoch 196/400\n",
      "546/546 [==============================] - 0s 168us/step - loss: 0.1067 - accuracy: 0.9908 - val_loss: 1.1222 - val_accuracy: 0.7083\n",
      "Epoch 197/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1021 - accuracy: 0.9982 - val_loss: 1.1223 - val_accuracy: 0.7083\n",
      "Epoch 198/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1071 - accuracy: 0.9945 - val_loss: 1.1224 - val_accuracy: 0.7083\n",
      "Epoch 199/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1072 - accuracy: 0.9963 - val_loss: 1.1225 - val_accuracy: 0.7083\n",
      "Epoch 200/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1022 - accuracy: 0.9945 - val_loss: 1.1227 - val_accuracy: 0.7083\n",
      "Epoch 201/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0944 - accuracy: 0.9963 - val_loss: 1.1228 - val_accuracy: 0.7083\n",
      "Epoch 202/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1047 - accuracy: 0.9927 - val_loss: 1.1229 - val_accuracy: 0.7083\n",
      "Epoch 203/400\n",
      "546/546 [==============================] - 0s 167us/step - loss: 0.0903 - accuracy: 0.9963 - val_loss: 1.1229 - val_accuracy: 0.7083\n",
      "Epoch 204/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1087 - accuracy: 0.9927 - val_loss: 1.1230 - val_accuracy: 0.7083\n",
      "Epoch 205/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1079 - accuracy: 0.9927 - val_loss: 1.1231 - val_accuracy: 0.7083\n",
      "Epoch 206/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.1169 - accuracy: 0.9908 - val_loss: 1.1233 - val_accuracy: 0.7083\n",
      "Epoch 207/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0956 - accuracy: 0.9963 - val_loss: 1.1235 - val_accuracy: 0.7083\n",
      "Epoch 208/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1037 - accuracy: 0.9982 - val_loss: 1.1235 - val_accuracy: 0.7083\n",
      "Epoch 209/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1024 - accuracy: 0.9927 - val_loss: 1.1235 - val_accuracy: 0.7083\n",
      "Epoch 210/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1026 - accuracy: 0.9963 - val_loss: 1.1236 - val_accuracy: 0.7083\n",
      "Epoch 211/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1001 - accuracy: 0.9982 - val_loss: 1.1234 - val_accuracy: 0.7083\n",
      "Epoch 212/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1142 - accuracy: 0.9963 - val_loss: 1.1233 - val_accuracy: 0.7083\n",
      "Epoch 213/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1021 - accuracy: 0.9982 - val_loss: 1.1233 - val_accuracy: 0.7083\n",
      "Epoch 214/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1100 - accuracy: 0.9945 - val_loss: 1.1234 - val_accuracy: 0.7083\n",
      "Epoch 215/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1081 - accuracy: 0.9927 - val_loss: 1.1235 - val_accuracy: 0.7083\n",
      "Epoch 216/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.7083\n",
      "Epoch 217/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1023 - accuracy: 0.9963 - val_loss: 1.1235 - val_accuracy: 0.7083\n",
      "Epoch 218/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0957 - accuracy: 0.9908 - val_loss: 1.1236 - val_accuracy: 0.7083\n",
      "Epoch 219/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.1024 - accuracy: 0.9945 - val_loss: 1.1236 - val_accuracy: 0.7083\n",
      "Epoch 220/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1242 - accuracy: 0.9945 - val_loss: 1.1238 - val_accuracy: 0.7083\n",
      "Epoch 221/400\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1021 - accuracy: 0.9945 - val_loss: 1.1241 - val_accuracy: 0.7083\n",
      "Epoch 222/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1004 - accuracy: 0.9982 - val_loss: 1.1243 - val_accuracy: 0.7083\n",
      "Epoch 223/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0910 - accuracy: 0.9982 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 224/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1058 - accuracy: 0.9982 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 225/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0993 - accuracy: 0.9963 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 226/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0945 - accuracy: 0.9963 - val_loss: 1.1245 - val_accuracy: 0.7130\n",
      "Epoch 227/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1101 - accuracy: 0.9945 - val_loss: 1.1244 - val_accuracy: 0.7130\n",
      "Epoch 228/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1153 - accuracy: 0.9927 - val_loss: 1.1243 - val_accuracy: 0.7083\n",
      "Epoch 229/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1060 - accuracy: 0.9963 - val_loss: 1.1243 - val_accuracy: 0.7083\n",
      "Epoch 230/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0898 - accuracy: 0.9963 - val_loss: 1.1242 - val_accuracy: 0.7083\n",
      "Epoch 231/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1018 - accuracy: 0.9945 - val_loss: 1.1241 - val_accuracy: 0.7083\n",
      "Epoch 232/400\n",
      "546/546 [==============================] - 0s 163us/step - loss: 0.0928 - accuracy: 0.9945 - val_loss: 1.1241 - val_accuracy: 0.7083\n",
      "Epoch 233/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1059 - accuracy: 0.9945 - val_loss: 1.1241 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 1.1240 - val_accuracy: 0.7083\n",
      "Epoch 235/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0956 - accuracy: 0.9963 - val_loss: 1.1242 - val_accuracy: 0.7083\n",
      "Epoch 236/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1303 - accuracy: 0.9945 - val_loss: 1.1243 - val_accuracy: 0.7083\n",
      "Epoch 237/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1133 - accuracy: 0.9927 - val_loss: 1.1244 - val_accuracy: 0.7083\n",
      "Epoch 238/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1025 - accuracy: 0.9982 - val_loss: 1.1244 - val_accuracy: 0.7083\n",
      "Epoch 239/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1123 - accuracy: 0.9963 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 240/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1047 - accuracy: 0.9963 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 241/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1029 - accuracy: 0.9945 - val_loss: 1.1245 - val_accuracy: 0.7083\n",
      "Epoch 242/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1013 - accuracy: 0.9963 - val_loss: 1.1246 - val_accuracy: 0.7083\n",
      "Epoch 243/400\n",
      "546/546 [==============================] - 0s 131us/step - loss: 0.0957 - accuracy: 0.9982 - val_loss: 1.1247 - val_accuracy: 0.7083\n",
      "Epoch 244/400\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1012 - accuracy: 0.9982 - val_loss: 1.1249 - val_accuracy: 0.7083\n",
      "Epoch 245/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0914 - accuracy: 0.9982 - val_loss: 1.1251 - val_accuracy: 0.7083\n",
      "Epoch 246/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0971 - accuracy: 0.9982 - val_loss: 1.1252 - val_accuracy: 0.7083\n",
      "Epoch 247/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0997 - accuracy: 0.9982 - val_loss: 1.1251 - val_accuracy: 0.7083\n",
      "Epoch 248/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1099 - accuracy: 0.9927 - val_loss: 1.1253 - val_accuracy: 0.7083\n",
      "Epoch 249/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0925 - accuracy: 0.9945 - val_loss: 1.1255 - val_accuracy: 0.7083\n",
      "Epoch 250/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1120 - accuracy: 0.9963 - val_loss: 1.1257 - val_accuracy: 0.7083\n",
      "Epoch 251/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 1.1259 - val_accuracy: 0.7083\n",
      "Epoch 252/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0995 - accuracy: 0.9927 - val_loss: 1.1261 - val_accuracy: 0.7083\n",
      "Epoch 253/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1009 - accuracy: 0.9982 - val_loss: 1.1264 - val_accuracy: 0.7083\n",
      "Epoch 254/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1117 - accuracy: 0.9945 - val_loss: 1.1266 - val_accuracy: 0.7083\n",
      "Epoch 255/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1074 - accuracy: 0.9927 - val_loss: 1.1268 - val_accuracy: 0.7083\n",
      "Epoch 256/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.7083\n",
      "Epoch 257/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1060 - accuracy: 0.9963 - val_loss: 1.1273 - val_accuracy: 0.7083\n",
      "Epoch 258/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0987 - accuracy: 0.9982 - val_loss: 1.1275 - val_accuracy: 0.7083\n",
      "Epoch 259/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.1277 - val_accuracy: 0.7083\n",
      "Epoch 260/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0958 - accuracy: 0.9945 - val_loss: 1.1280 - val_accuracy: 0.7037\n",
      "Epoch 261/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1030 - accuracy: 0.9945 - val_loss: 1.1282 - val_accuracy: 0.7037\n",
      "Epoch 262/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1316 - accuracy: 0.9908 - val_loss: 1.1284 - val_accuracy: 0.7037\n",
      "Epoch 263/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.7037\n",
      "Epoch 264/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1069 - accuracy: 0.9982 - val_loss: 1.1287 - val_accuracy: 0.7037\n",
      "Epoch 265/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0964 - accuracy: 0.9982 - val_loss: 1.1287 - val_accuracy: 0.7037\n",
      "Epoch 266/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0855 - accuracy: 0.9982 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 267/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0993 - accuracy: 0.9982 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 268/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0910 - accuracy: 0.9963 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 269/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1175 - accuracy: 0.9927 - val_loss: 1.1291 - val_accuracy: 0.7037\n",
      "Epoch 270/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.0948 - accuracy: 0.9982 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 271/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.1003 - accuracy: 0.9945 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 272/400\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.0923 - accuracy: 0.9963 - val_loss: 1.1289 - val_accuracy: 0.7037\n",
      "Epoch 273/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.7037\n",
      "Epoch 274/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1177 - accuracy: 0.9908 - val_loss: 1.1292 - val_accuracy: 0.7037\n",
      "Epoch 275/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0968 - accuracy: 0.9982 - val_loss: 1.1292 - val_accuracy: 0.7037\n",
      "Epoch 276/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1181 - accuracy: 0.9945 - val_loss: 1.1295 - val_accuracy: 0.7037\n",
      "Epoch 277/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0925 - accuracy: 0.9963 - val_loss: 1.1298 - val_accuracy: 0.7037\n",
      "Epoch 278/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1127 - accuracy: 0.9945 - val_loss: 1.1301 - val_accuracy: 0.7037\n",
      "Epoch 279/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1343 - accuracy: 0.9890 - val_loss: 1.1306 - val_accuracy: 0.7083\n",
      "Epoch 280/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1015 - accuracy: 0.9945 - val_loss: 1.1309 - val_accuracy: 0.7083\n",
      "Epoch 281/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.7083\n",
      "Epoch 282/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 1.1314 - val_accuracy: 0.7083\n",
      "Epoch 283/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1106 - accuracy: 0.9908 - val_loss: 1.1316 - val_accuracy: 0.7083\n",
      "Epoch 284/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0980 - accuracy: 0.9982 - val_loss: 1.1316 - val_accuracy: 0.7083\n",
      "Epoch 285/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1184 - accuracy: 0.9945 - val_loss: 1.1318 - val_accuracy: 0.7083\n",
      "Epoch 286/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1023 - accuracy: 0.9982 - val_loss: 1.1319 - val_accuracy: 0.7083\n",
      "Epoch 287/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0990 - accuracy: 0.9963 - val_loss: 1.1320 - val_accuracy: 0.7083\n",
      "Epoch 288/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1012 - accuracy: 0.9982 - val_loss: 1.1319 - val_accuracy: 0.7083\n",
      "Epoch 289/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1062 - accuracy: 0.9963 - val_loss: 1.1318 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1170 - accuracy: 0.9853 - val_loss: 1.1317 - val_accuracy: 0.7083\n",
      "Epoch 291/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0932 - accuracy: 0.9982 - val_loss: 1.1317 - val_accuracy: 0.7083\n",
      "Epoch 292/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 1.1316 - val_accuracy: 0.7083\n",
      "Epoch 293/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1090 - accuracy: 0.9927 - val_loss: 1.1315 - val_accuracy: 0.7083\n",
      "Epoch 294/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1095 - accuracy: 0.9945 - val_loss: 1.1314 - val_accuracy: 0.7083\n",
      "Epoch 295/400\n",
      "546/546 [==============================] - 0s 132us/step - loss: 0.1070 - accuracy: 0.9908 - val_loss: 1.1311 - val_accuracy: 0.7083\n",
      "Epoch 296/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1071 - accuracy: 0.9963 - val_loss: 1.1311 - val_accuracy: 0.7083\n",
      "Epoch 297/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0867 - accuracy: 0.9982 - val_loss: 1.1311 - val_accuracy: 0.7083\n",
      "Epoch 298/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.0771 - accuracy: 0.9982 - val_loss: 1.1310 - val_accuracy: 0.7083\n",
      "Epoch 299/400\n",
      "546/546 [==============================] - 0s 138us/step - loss: 0.1098 - accuracy: 0.9927 - val_loss: 1.1309 - val_accuracy: 0.7083\n",
      "Epoch 300/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0892 - accuracy: 0.9982 - val_loss: 1.1309 - val_accuracy: 0.7083\n",
      "Epoch 301/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1196 - accuracy: 0.9945 - val_loss: 1.1308 - val_accuracy: 0.7083\n",
      "Epoch 302/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.1189 - accuracy: 0.9908 - val_loss: 1.1307 - val_accuracy: 0.7083\n",
      "Epoch 303/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1010 - accuracy: 0.9982 - val_loss: 1.1305 - val_accuracy: 0.7083\n",
      "Epoch 304/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1030 - accuracy: 0.9945 - val_loss: 1.1303 - val_accuracy: 0.7083\n",
      "Epoch 305/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0923 - accuracy: 0.9963 - val_loss: 1.1301 - val_accuracy: 0.7083\n",
      "Epoch 306/400\n",
      "546/546 [==============================] - 0s 158us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.7083\n",
      "Epoch 307/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1002 - accuracy: 0.9982 - val_loss: 1.1297 - val_accuracy: 0.7083\n",
      "Epoch 308/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1107 - accuracy: 0.9982 - val_loss: 1.1296 - val_accuracy: 0.7083\n",
      "Epoch 309/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1173 - accuracy: 0.9945 - val_loss: 1.1294 - val_accuracy: 0.7083\n",
      "Epoch 310/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.7083\n",
      "Epoch 311/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1086 - accuracy: 0.9963 - val_loss: 1.1293 - val_accuracy: 0.7083\n",
      "Epoch 312/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0901 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.7083\n",
      "Epoch 313/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1256 - accuracy: 0.9853 - val_loss: 1.1291 - val_accuracy: 0.7083\n",
      "Epoch 314/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.1065 - accuracy: 0.9963 - val_loss: 1.1291 - val_accuracy: 0.7083\n",
      "Epoch 315/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0968 - accuracy: 0.9927 - val_loss: 1.1289 - val_accuracy: 0.7083\n",
      "Epoch 316/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1015 - accuracy: 0.9945 - val_loss: 1.1291 - val_accuracy: 0.7083\n",
      "Epoch 317/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1086 - accuracy: 0.9945 - val_loss: 1.1290 - val_accuracy: 0.7083\n",
      "Epoch 318/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0966 - accuracy: 0.9982 - val_loss: 1.1290 - val_accuracy: 0.7083\n",
      "Epoch 319/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1017 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.7083\n",
      "Epoch 320/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0982 - accuracy: 0.9927 - val_loss: 1.1292 - val_accuracy: 0.7083\n",
      "Epoch 321/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.7083\n",
      "Epoch 322/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.1059 - accuracy: 0.9963 - val_loss: 1.1293 - val_accuracy: 0.7083\n",
      "Epoch 323/400\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.0984 - accuracy: 0.9945 - val_loss: 1.1293 - val_accuracy: 0.7083\n",
      "Epoch 324/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.0984 - accuracy: 0.9982 - val_loss: 1.1294 - val_accuracy: 0.7083\n",
      "Epoch 325/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.1033 - accuracy: 0.9982 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 326/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1046 - accuracy: 0.9963 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 327/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1312 - accuracy: 0.9982 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 328/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0967 - accuracy: 0.9945 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 329/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1188 - accuracy: 0.9890 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 330/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1021 - accuracy: 0.9963 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 331/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1023 - accuracy: 0.9945 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 332/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1011 - accuracy: 0.9927 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 333/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1283 - accuracy: 0.9945 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 334/400\n",
      "546/546 [==============================] - 0s 155us/step - loss: 0.1281 - accuracy: 0.9945 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 335/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1011 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.7130\n",
      "Epoch 336/400\n",
      "546/546 [==============================] - 0s 156us/step - loss: 0.0985 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.7130\n",
      "Epoch 337/400\n",
      "546/546 [==============================] - 0s 134us/step - loss: 0.1013 - accuracy: 0.9963 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 338/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.1123 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.7130\n",
      "Epoch 339/400\n",
      "546/546 [==============================] - 0s 131us/step - loss: 0.1171 - accuracy: 0.9945 - val_loss: 1.1291 - val_accuracy: 0.7130\n",
      "Epoch 340/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0941 - accuracy: 0.9982 - val_loss: 1.1290 - val_accuracy: 0.7130\n",
      "Epoch 341/400\n",
      "546/546 [==============================] - 0s 139us/step - loss: 0.1087 - accuracy: 0.9982 - val_loss: 1.1290 - val_accuracy: 0.7130\n",
      "Epoch 342/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0973 - accuracy: 0.9982 - val_loss: 1.1290 - val_accuracy: 0.7130\n",
      "Epoch 343/400\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1062 - accuracy: 0.9982 - val_loss: 1.1289 - val_accuracy: 0.7130\n",
      "Epoch 344/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1047 - accuracy: 0.9963 - val_loss: 1.1290 - val_accuracy: 0.7130\n",
      "Epoch 345/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0945 - accuracy: 0.9963 - val_loss: 1.1291 - val_accuracy: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.1187 - accuracy: 0.9927 - val_loss: 1.1293 - val_accuracy: 0.7130\n",
      "Epoch 347/400\n",
      "546/546 [==============================] - 0s 137us/step - loss: 0.1012 - accuracy: 0.9927 - val_loss: 1.1294 - val_accuracy: 0.7130\n",
      "Epoch 348/400\n",
      "546/546 [==============================] - 0s 136us/step - loss: 0.1005 - accuracy: 0.9982 - val_loss: 1.1295 - val_accuracy: 0.7130\n",
      "Epoch 349/400\n",
      "546/546 [==============================] - 0s 141us/step - loss: 0.0948 - accuracy: 0.9945 - val_loss: 1.1296 - val_accuracy: 0.7130\n",
      "Epoch 350/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.0865 - accuracy: 0.9963 - val_loss: 1.1297 - val_accuracy: 0.7130\n",
      "Epoch 351/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0840 - accuracy: 0.9963 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 352/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0982 - accuracy: 0.9908 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 353/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1050 - accuracy: 0.9927 - val_loss: 1.1299 - val_accuracy: 0.7130\n",
      "Epoch 354/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.1003 - accuracy: 0.9963 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 355/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1138 - accuracy: 0.9908 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 356/400\n",
      "546/546 [==============================] - 0s 142us/step - loss: 0.0917 - accuracy: 0.9927 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 357/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0861 - accuracy: 0.9982 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 358/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0930 - accuracy: 0.9982 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 359/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1037 - accuracy: 0.9927 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 360/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1355 - accuracy: 0.9945 - val_loss: 1.1297 - val_accuracy: 0.7130\n",
      "Epoch 361/400\n",
      "546/546 [==============================] - 0s 135us/step - loss: 0.1035 - accuracy: 0.9982 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 362/400\n",
      "546/546 [==============================] - 0s 140us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.1297 - val_accuracy: 0.7130\n",
      "Epoch 363/400\n",
      "546/546 [==============================] - 0s 130us/step - loss: 0.0877 - accuracy: 0.9963 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 364/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.1035 - accuracy: 0.9945 - val_loss: 1.1299 - val_accuracy: 0.7130\n",
      "Epoch 365/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0946 - accuracy: 0.9982 - val_loss: 1.1300 - val_accuracy: 0.7130\n",
      "Epoch 366/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1138 - accuracy: 0.9963 - val_loss: 1.1303 - val_accuracy: 0.7130\n",
      "Epoch 367/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.1306 - val_accuracy: 0.7130\n",
      "Epoch 368/400\n",
      "546/546 [==============================] - 0s 161us/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 1.1308 - val_accuracy: 0.7130\n",
      "Epoch 369/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 1.1309 - val_accuracy: 0.7130\n",
      "Epoch 370/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.1039 - accuracy: 0.9963 - val_loss: 1.1311 - val_accuracy: 0.7130\n",
      "Epoch 371/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1109 - accuracy: 0.9982 - val_loss: 1.1310 - val_accuracy: 0.7130\n",
      "Epoch 372/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0957 - accuracy: 0.9963 - val_loss: 1.1312 - val_accuracy: 0.7130\n",
      "Epoch 373/400\n",
      "546/546 [==============================] - 0s 146us/step - loss: 0.1252 - accuracy: 0.9890 - val_loss: 1.1314 - val_accuracy: 0.7083\n",
      "Epoch 374/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0959 - accuracy: 0.9927 - val_loss: 1.1315 - val_accuracy: 0.7083\n",
      "Epoch 375/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.1081 - accuracy: 0.9945 - val_loss: 1.1317 - val_accuracy: 0.7083\n",
      "Epoch 376/400\n",
      "546/546 [==============================] - 0s 153us/step - loss: 0.0980 - accuracy: 0.9945 - val_loss: 1.1317 - val_accuracy: 0.7083\n",
      "Epoch 377/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.1201 - accuracy: 0.9908 - val_loss: 1.1316 - val_accuracy: 0.7037\n",
      "Epoch 378/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.0924 - accuracy: 0.9963 - val_loss: 1.1315 - val_accuracy: 0.7037\n",
      "Epoch 379/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.1013 - accuracy: 0.9982 - val_loss: 1.1315 - val_accuracy: 0.7037\n",
      "Epoch 380/400\n",
      "546/546 [==============================] - 0s 160us/step - loss: 0.1008 - accuracy: 0.9963 - val_loss: 1.1314 - val_accuracy: 0.7037\n",
      "Epoch 381/400\n",
      "546/546 [==============================] - 0s 131us/step - loss: 0.1131 - accuracy: 0.9945 - val_loss: 1.1313 - val_accuracy: 0.7037\n",
      "Epoch 382/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.7037\n",
      "Epoch 383/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.7037\n",
      "Epoch 384/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1150 - accuracy: 0.9963 - val_loss: 1.1308 - val_accuracy: 0.7037\n",
      "Epoch 385/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.0946 - accuracy: 0.9963 - val_loss: 1.1307 - val_accuracy: 0.7037\n",
      "Epoch 386/400\n",
      "546/546 [==============================] - 0s 157us/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 1.1306 - val_accuracy: 0.7037\n",
      "Epoch 387/400\n",
      "546/546 [==============================] - 0s 152us/step - loss: 0.0901 - accuracy: 0.9945 - val_loss: 1.1304 - val_accuracy: 0.7037\n",
      "Epoch 388/400\n",
      "546/546 [==============================] - 0s 149us/step - loss: 0.1104 - accuracy: 0.9927 - val_loss: 1.1303 - val_accuracy: 0.7037\n",
      "Epoch 389/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0878 - accuracy: 0.9963 - val_loss: 1.1302 - val_accuracy: 0.7037\n",
      "Epoch 390/400\n",
      "546/546 [==============================] - 0s 150us/step - loss: 0.0936 - accuracy: 0.9945 - val_loss: 1.1301 - val_accuracy: 0.7037\n",
      "Epoch 391/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0849 - accuracy: 0.9982 - val_loss: 1.1302 - val_accuracy: 0.7037\n",
      "Epoch 392/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0918 - accuracy: 0.9982 - val_loss: 1.1300 - val_accuracy: 0.7037\n",
      "Epoch 393/400\n",
      "546/546 [==============================] - 0s 148us/step - loss: 0.0936 - accuracy: 0.9963 - val_loss: 1.1299 - val_accuracy: 0.7037\n",
      "Epoch 394/400\n",
      "546/546 [==============================] - 0s 159us/step - loss: 0.0963 - accuracy: 0.9963 - val_loss: 1.1299 - val_accuracy: 0.7037\n",
      "Epoch 395/400\n",
      "546/546 [==============================] - 0s 154us/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.1299 - val_accuracy: 0.7037\n",
      "Epoch 396/400\n",
      "546/546 [==============================] - 0s 151us/step - loss: 0.0892 - accuracy: 0.9982 - val_loss: 1.1299 - val_accuracy: 0.7037\n",
      "Epoch 397/400\n",
      "546/546 [==============================] - 0s 147us/step - loss: 0.0905 - accuracy: 0.9945 - val_loss: 1.1300 - val_accuracy: 0.7037\n",
      "Epoch 398/400\n",
      "546/546 [==============================] - 0s 143us/step - loss: 0.0965 - accuracy: 0.9982 - val_loss: 1.1298 - val_accuracy: 0.7037\n",
      "Epoch 399/400\n",
      "546/546 [==============================] - 0s 144us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.1296 - val_accuracy: 0.7037\n",
      "Epoch 400/400\n",
      "546/546 [==============================] - 0s 145us/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.1295 - val_accuracy: 0.7037\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "\n",
    "history1 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=1000,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input),\n",
    "                    sample_weight=sample_weight\n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history2 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=400,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input),\n",
    "                    sample_weight=sample_weight\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xV9f348dc7m4QwE2bYgoKiiKlbcaCCs9bdWi0OvvVna1trW2zdo3VVq+LCiqh14caBC1HZEPYMBAgZjCwSQvbNff/+OCc3NwsC5CbIeT8fj/vI2ed9zz338/58PufkXFFVjDHGeFdYWwdgjDGmbVkiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMbsgYj0FxEVkYhmLPsbEZndGnEZ05IsEZhDhoiki0iliCTUm77ULcz7t01k+5ZQjGltlgjMoWYzcE3NiIgMB2LbLhxjDn6WCMyh5g3guqDx64HXgxcQkY4i8rqI5IrIFhG5S0TC3HnhIvKEiOSJyCbggkbWfUVEtolItog8JCLhBxKwiESLyH9EZKv7+o+IRLvzEkTkMxEpFJECEZkVFOvf3BiKRSRVRM4+kDiMd1kiMIea+UAHERnqFtBXA/+rt8yzQEdgIDAKJ3GMc+fdDFwIHAskA5fXW3cK4AMOc5c5F7jpAGP+B3AiMAI4BjgeuMud92cgC0gEugN/B1REDgd+B/xMVeOB84D0A4zDeJQlAnMoqmkVnAOsBbJrZgQlhztVtVhV04F/A792F7kS+I+qZqpqAfCvoHW7A+cDf1TVElXNAZ5yt3cgfgU8oKo5qpoL3B8UTxXQE+inqlWqOkudB4RVA9HAMBGJVNV0Vd14gHEYj7JEYA5FbwC/BH5DvW4hIAGIBLYETdsC9HaHewGZ9ebV6Oeuu83tqikEXgK6HWC8vRqJp5c7/DiQBnwtIptEZAKAqqYBfwTuA3JE5B0R6YUx+8ESgTnkqOoWnIvG5wMf1pudh1PL7hc0rS+1rYZtQJ9682pkAhVAgqp2cl8dVPXIAwx5ayPxbHXfS7Gq/llVBwIXA7fXXAtQ1bdU9VR3XQUePcA4jEdZIjCHqhuBs1S1JHiiqlYDU4GHRSReRPoBt1N7HWEqcJuIJIlIZ2BC0LrbgK+Bf4tIBxEJE5FBIjJqH+KKFpGYoFcY8DZwl4gkure+3lMTj4hcKCKHiYgARThdQn4ROVxEznIvKpcDZYB/H4+RMYAlAnOIUtWNqprSxOzfAyXAJmA28BYw2Z33MvAVsBxYQsMWxXVAFLAG2Am8j9OH31y7cQrtmtdZwENACrACWOnu9yF3+cHAt+5684DnVXUmzvWBR3BaONtxuqfu3Ic4jAkQ+2EaY4zxNmsRGGOMx1kiMMYYjwtZIhCRySKSIyKrmpj/KxFZISIrRWSuiBwTqliMMcY0LZQtginAmD3M3wyMUtXhwIPApBDGYowxpgkhexKiqv64p6c9qurcoNH5QFJztpuQkKD9+ze5WWOMMY1YvHhxnqomNjbvYHkk7o3A9KZmish4YDxA3759SUlp6q5AY4wxjRGRLU3Na/OLxSJyJk4i+FtTy6jqJFVNVtXkxMRGE5oxxpj91KYtAhE5GvgvMFZV89syFmOM8ao2axGISF+c/9r8taqub6s4jDHG60LWIhCRt4EzgAQRyQLuxXlyI6r6Is7zVLoCzzuPUcGnqsn7s6+qqiqysrIoLy9vidB/EmJiYkhKSiIyMrKtQzHG/MSF8q6ha/Yy/yYO/Ac9AMjKyiI+Pp7+/fvjJpVDmqqSn59PVlYWAwYMaOtwjDE/cW1+sbgllJeX07VrV08kAQARoWvXrp5qARljQueQSASAZ5JADa+9X2NM6BwyiWCfVPugJBf81W0diTHGtDnvJYKqcshLhaIsKNjUIskgPz+fESNGMGLECHr06EHv3r0D45WVlc3axrhx40hNTT3gWIwxZl8dLP9Z3DqqfZCfBijE94Di7ZC3ATr1hajY/d5s165dWbZsGQD33Xcf7du354477qizjKqiqoSFNZ57X3311f3evzHGHAhvJYLd28Hvg4QhTsEfGQuFGU4LocsgiOnQortLS0vj4osv5thjj2Xp0qV888033H///SxZsoSysjKuuuoq7rnnHgBOPfVUJk6cyFFHHUVCQgK//e1vmT59OrGxsXzyySd063agv49uTAvzV0NFccNXZTFIOEREQ3gkhEdBuDscEe2ORzacFhYBP8VrX34/VO523/tuqCqD6iqnrFE/oKAKElbvmEQFHY+a4WhoorIYSodcIrj/09Ws2bqr8ZlVJe4JujxoojofnOa7rYKGJ+KwXh2496L9+33ydevW8frrr5Oc7PyLxCOPPEKXLl3w+XyceeaZXH755QwbNqzOOkVFRYwaNYpHHnmE22+/ncmTJzNhwoTGNm+8ThV8FeArc7o9fWXOeFUZ+Mrdv/XmV5XXzqsqg6rSen/LnOXU7xT2qs6wVjuFW4Vb6FWV7D2+fSIQ2c55RbRzCsyaQtR5sxD4QcWa6Vp7HOoP11mv/nBj6zW17F7Wq64iKLADFxYR9AqvHZZwOP4mOO3PLbcv1yGXCJqkfufDCw+vN0MgIsb9EpQ7J2ELGjRoUCAJALz99tu88sor+Hw+tm7dypo1axokgnbt2jF27FgAjjvuOGbNmtWiMbU51drjXV3pvPw+5wtVXQn+Kne4qnaerxwqS531KkucmldlSW2B56twalxh4c5fqalVBRUeIo18uYRA8g/URpsYbzBN3firat+HrzJoWkXd+aq18ak/aF5Vve1UOcdA/bXxSlDMNZUXn1ug7y8Jc1rFke3cv0HDMZ1q9yth7rFzx6Pj3VeHoOH2tdOi4pzYA8ci6OWrCHqfQcM+dzyQiNxzA2nkM6o3HPh4pO7ns9f16i/b1Hrseb2wSKc3IToeoto7xy88svazrllO/UHvt6L2HPFVBE1z//p9bhJ2k2/Nq8ug/f+89+CQSwRN1tzLi5xuoMQj3JpGPSX5UJQB0R2hc1/3C+fy+6BsZ+1J6vfVXVfE+YJExrqFlEBJHpTkE9cuGnZtA5QNGzfz9FNPsnDmF3Tq1JFrb/4d5YU5sDvHOSnKCqAkj6ioSCjNB4RwXxm+8hJn/4ETSmub5d8/6tTeAgVKhRNDRbFbc9vlnFiBwsR9hUc7TdGIGOcv4BSa/tpaUE1NMLg2FJivjcynbg2quiqohurWRmsK85aoQdUUXBExTtMadZrpNbVX58Op/QKrv/YLpdXOMQzcLNBI/HXGm5gWaNZH1evyiArq9oh0Yq0pDPzV7mfgdoeEB69b8zeyYcz+6tpzr+Z9R8RAZIxTg46MCZrWLuhvdNB8dzyynbOvn2JXjGlxh1wiaFJMR+h+VNMnflxX50u3KxtyU52aTU2trbIEpxAQ50sUFulWGNxaobo1w4pdzivCB0WZzjWJ6irnL7BrRzrxsVF0kN1sS9vCV9/MYMwpI5x9VldCcQ4UxTv7Lcxw4irNc2q/O9Mbxly2E77/pxNPTWEUFunUyGpqah16OTH7q4MKlWr3fe12tu+rcLYXXHtB3JogtdManS8Np+GuExULsV3qFkg1NaaaazQ1hV9YZG0BGCggg+ZFRLnrxbl/27dJX6oxhyLvJALYe+2nfaJTYO3a6hSyNbXn9olOSyEqNqiga4S/GuK6Qfs46H4k7Hb7O3uOABFG9jiGYW9+yRFnXUO/vn055dTToWMf6D7cKdy6DoJuRzo1927DcO5uWukkscQjamviNS2Qwii4Ox/CvfUxGmNalqi2QBO9FSUnJ2v9H6ZZu3YtQ4cObaOI2o5X37cxZt+JyOKmHuxpbWtjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4mgBbTEY6gBJk+ezPbt20MYqTHGNGT/idQCmvMY6uaYPHkyI0eOpEePHi0dojHGNMkSQYi99tprPPfcc1RWVnLyySczceJE/H4/48aNY9myZagq48ePp3v37ixbtoyrrrqKdu3asXDhQqKioto6fGOMBxx6iWD6BNi+smW32WM4jH1kn1dbtWoVH330EXPnziUiIoLx48fzzjvvMGjQIPLy8li50omzsLCQTp068eyzzzJx4kRGjBjRsvEbY8weHHqJ4CDy7bffsmjRosBjqMvKyujTpw/nnXceqamp3HbbbVxwwQWce+65bRypMcbLDr1EsB8191BRVW644QYefPDBBvNWrFjB9OnTee655/jggw+YNGlSG0RojDF211BIjR49mqlTp5KXlwc4dxdlZGSQm5uLqnLFFVfwwAMPsGTJEgDi4+MpLi5uy5CNMR506LUIDiLDhw/n3nvvZfTo0fj9fiIjI3nxxRcJDw/nxhtvRFURER599FEAxo0bx0033WQXi40xrcoeQ/0T5tX3bYzZd/YYamOMMU0KWSIQkckikiMiq5qYLyLyjIikicgKERkZqliMMcY0LZQtginAmD3MHwsMdl/jgRcOZGc/tS6uA+W192uMCZ2QJQJV/REo2MMilwCvq2M+0ElEeu7PvmJiYsjPz/dM4aiq5OfnExMT09ahGGMOAW1511BvIDNoPMudtq3+giIyHqfVQN++fRtsKCkpiaysLHJzc0MT6UEoJiaGpKSktg7DGHMI+EncPqqqk4BJ4Nw1VH9+ZGQkAwYMaPW4jDHmUNCWdw1lA32CxpPcacYYY1pRWyaCacB17t1DJwJFqtqgW8gYY0xohaxrSETeBs4AEkQkC7gXiARQ1ReBL4DzgTSgFBgXqliMMcY0LWSJQFWv2ct8BW4N1f6NMcY0j/1nsTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43EhTQQiMkZEUkUkTUQmNDK/r4jMFJGlIrJCRM4PZTzGGGMaClkiEJFw4DlgLDAMuEZEhtVb7C5gqqoeC1wNPB+qeIwxxjQulC2C44E0Vd2kqpXAO8Al9ZZRoIM73BHYGsJ4jDHGNCIihNvuDWQGjWcBJ9Rb5j7gaxH5PRAHjA5hPMYYYxrR1heLrwGmqGoScD7whog0iElExotIioik5ObmtnqQxhhzKAtlIsgG+gSNJ7nTgt0ITAVQ1XlADJBQf0OqOklVk1U1OTExMUThGmOMN4UyESwCBovIABGJwrkYPK3eMhnA2QAiMhQnEViV3xhjWlHIEoGq+oDfAV8Ba3HuDlotIg+IyMXuYn8GbhaR5cDbwG9UVUMVkzHGmIZCebEYVf0C+KLetHuChtcAp4QyBmOMMXvW1heLjTHGtDFLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj2tWIhCRQSIS7Q6fISK3iUin0IZmjDGmNTS3RfABUC0ihwGTgD7AWyGLyhhjTKtpbiLwq6oPuBR4VlX/AvQMXVjGGGNaS3MTQZWIXANcD3zmTosMTUjGGGNaU3MTwTjgJOBhVd0sIgOAN0IXljHGmNYS0ZyFVHUNcBuAiHQG4lX10VAGZowxpnU0966h70Wkg4h0AZYAL4vIk6ENzRhjTGtobtdQR1XdBfwCeF1VTwBG720lERkjIqkikiYiE5pY5koRWSMiq0XE7kQyxphW1qyuISBCRHoCVwL/aM4KIhIOPAecA2QBi0RkmtvNVLPMYOBO4BRV3Ski3fYpemOMMQesuS2CB4CvgI2qukhEBgIb9rLO8UCaqm5S1UrgHeCSesvcDDynqjsBVDWn+aEbY4xpCc1KBKr6nqoeraq3uOObVPWyvazWG8gMGs9ypwUbAgwRkTkiMl9ExjS2IREZLyIpIpKSm5vbnJCNMcY0U3MvFieJyEcikuO+PhCRpBbYfwQwGDgDuAbnInSDR1eo6iRVTVbV5MTExBbYrTHGmBrN7Rp6FZgG9HJfn7rT9iQb51EUNZLcacGygGmqWqWqm4H1OInBGGNMK2luIkhU1VdV1ee+pgB7q5ovAgaLyAARiQKuxkkmwT7GaQ0gIgk4XUWbmhu8McaYA9fcRJAvIteKSLj7uhbI39MK7rOJfodzkXktMFVVV4vIAyJysbvYV+621wAzgb+o6h63a4wxpmWJqu59IZF+wLM4j5lQYC7we1XN3OOKIZCcnKwpKSmtvVtjjPlJE5HFqprc2Lzm3jW0RVUvVtVEVe2mqj8H9nbXkDHGmJ+AA/mFsttbLApjjDFt5kASgbRYFMYYY9rMgSSCvV9cMMYYc9Db47OGRKSYxgt8AdqFJCJjjDGtao+JQFXjWysQY4wxbeNAuoaMMcYcAiwRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4XEgTgYiMEZFUEUkTkQl7WO4yEVERSQ5lPMYYYxoKWSIQkXDgOWAsMAy4RkSGNbJcPPAHYEGoYjHGGNO0ULYIjgfSVHWTqlYC7wCXNLLcg8CjQHkIYzHGGNOEUCaC3kBm0HiWOy1AREYCfVT18z1tSETGi0iKiKTk5ua2fKTGGONhbXaxWETCgCeBP+9tWVWdpKrJqpqcmJgY+uCMMcZDQpkIsoE+QeNJ7rQa8cBRwPcikg6cCEyzC8bGGNO6QpkIFgGDRWSAiEQBVwPTamaqapGqJqhqf1XtD8wHLlbVlBDGZIwxpp6QJQJV9QG/A74C1gJTVXW1iDwgIheHar/GGGP2TUQoN66qXwBf1Jt2TxPLnhHKWIwxxjTO/rPYGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcSFNBCIyRkRSRSRNRCY0Mv92EVkjIitEZIaI9AtlPMYYYxoKWSIQkXDgOWAsMAy4RkSG1VtsKZCsqkcD7wOPhSoeY4wxjQtli+B4IE1VN6lqJfAOcEnwAqo6U1VL3dH5QFII4zHGGNOIUCaC3kBm0HiWO60pNwLTG5shIuNFJEVEUnJzc1swRGOMMQfFxWIRuRZIBh5vbL6qTlLVZFVNTkxMbN3gjDHmEBcRwm1nA32CxpPcaXWIyGjgH8AoVa0IYTzGGGMaEcoWwSJgsIgMEJEo4GpgWvACInIs8BJwsarmhDAWY4wxTQhZIlBVH/A74CtgLTBVVVeLyAMicrG72ONAe+A9EVkmItOa2JwxxpgQCWXXEKr6BfBFvWn3BA2PDuX+jTHG7N1BcbHYGGNM27FEYIwxHmeJwBhjPM4SgdkvFb5q1m7b1dZhGGNagKcSgaqiqm0dxiHhoc/WMvbpWWwrKmvV/Wbkl7JmqyUgY1qSpxLB3z9axRF3f9nWYbQ5VeXbNTvwVfv3exsLNxcATsHcmk5/fCbnPzNrn9d7Y/4WVmYVhSAib6qq9jN1USbVfm9VrNZs3cUTX6UechVKTyWCtxdmUOHzU1ZZ3eh8VeXH9bk8/e0GnvpmPX73JP9y1TYWbyk4oH1PXZRJzq5y1u8oJi1n9wFt60DNScvnptdT+GbNjv3eRnSkc+qk55c0Ol9VefKb9VzwzCx27Crf7/00pbyq8c+wMX6/cvfHq7ho4mwAZm3IZVNu234GB6Lar9z54YoW65pLyymm/4TPSd1e3Ox1vl69g79+sIJ5G/NbJIaWMPG7Dfzp3WV1ps1MzWHmupwWK7g/WprFxJlpFJRUtsj2DhaeSQQ5QYXRloISFqUXBE6O1O3FPPl1Kquyd3Hd5IU89e16np6xgRd/3EhJhY/f/m8Jl70wb7/3nZ5Xwl8/WMFt7yzl3Kd+ZPSTP4SkRvHK7M3MXOf8g7aq8uqczazfUcyDn63hvZTa5//NTssDYG3QF7+orIrswuZ384gIAAs2F1BS4QPg7o9X8ca8dAByiit4ZsYGVm/dxaL0hkm00td4a2Td9l0Ul1ftdf+b82oTkKrWGa9vZ2llnWV//cpCzvr3D2QWlDJ/U9sXZLsrfPz769RmJ7eMglLeXpjJr19Z0CL7/2TZVgA+W7G12eusyC4EIHNnaFuEaTnFXDJxdrMK3ie+Xs9HS2ufYrNjVznjXl3EuCmLWN1C3YkZBc77zdy55+/KjLU7uP/T1S2yz9bgmUQwa0NeYPjKF+dxxYvzAifN5Nmbeea7tMD4f69L5ti+nXjsy1SOvPerwHqNFd4fL83mtMe+4/vUHFZvLeIv7y3n/cVZzEzN4b0Up+m8aqvTJbExt7awSt3RsPa1cHMBmQWNf7HW7yjm6Pu+Yt7GfLILy1iVXVQnnpxd5Tz8+Rpue2cp24vKySgo5f5P13DuUz/yyuzN3DttdaCFM2+jcyxSt+8KNO1/99YSTnnkOwpLK0lvolDd7Rb4ALluYv1wSTZ3friS0kofb8zfwt2frHbfa22Ne3NuCRn5pYH3lrq9mCF3TWfG2rotkvzdFYz5zyyG3/c1L/2wscH+g5NHcKvqldmbOfOJ75u8dpBTXPsIq6ygL/DNr6dw9aT5TSaR3RU+JnywosnPZG+25JcEkuSefL16O89+l8aP65v3ZN1tbsLO290ytdKaBBQRVrc4WJVdVKcCNWPtDtZu28XMdTmsynbO6aygRJCSXhCoiIDTbVhY2nSMCzcX8OtXFvD+4qw60yt81YHKwwvfb2J5VhGf70OSum/aanbsKq9zjmzIcb5vJRW+BueJr9rPU9+sb1ayySxwjn3GXs6Jj5dtZcrcdMqrqvlmzQ5++8big7o7yTOJYOzwHvzz0uEA7Cp3vpwTZ6axKruIT5a7CWHOZtpFhnPWEd04tk/nBtvILa7g4c/X8PDnaygoqeT71Bz++O4yMgvK+M2ri7jgmdm8tziLO95bzrhXF/GX91fw31mbAn3TuUEF0v3T1lDhq60BVvr8XPnSPE57bCaVPj93fbySKXM2M39TPqWVPt5emMGuch/XvDyfUx75jgufnc1f318RqNFOW74Vv0KFz88/PlrJlnp996WV1by5YAsPfbaGle6X+KvVO7jqpXlU+zWQKC95bg5nPPE9D3++BlVlRVYhqso9n6ziqHu/YvGWnVT7lR1B72XmuhyWZRTW2d+moKS3bkcxo5/8gdMem0lKegFfrtoOOC2Tsspqbn93Get3FNdJjv+avo7swrLA/h/9ch0TZ6bVbnN77Zf585XbgNpuqhVZhUz8bkNgfnAiWBfUCqoZnvids92snaXkFNcWfPM25vPOokxGP/kDpZU+pqZkUlZZzTsLM0hJL9hjl1fe7gpGPf49d364MjBt/Y5ibn1zCaWVdZNDTW11Tb2unuWZhZz1xPcNWlRZQS232Rvy6hyL+ip81XyfmkNVtR+/X1meWdigQNqxyzk++SW1x0lVufDZ2Yx92rkes2brLm58LYWxT89i3JRFgXO6JrGWV1Vz+YvzGDdlEapKeVU1pz8+k+tfXdRkbF+s3MasDXkN+txvmLKIK16cx5b8Ejq2iwT2XvAGF+JT5qYz4YMVdbr/NuaUUF5VzYn/msH5z8yq0z08Z2M+T8/Y0GgNPqe4nAkfrKCkwoeqBioFwZWD57+vm8Tzd1ewOW83qs5yN7+ewpert5O3u5LMglJenbOZbUVljPnPj4Gk1NZJIqSPmDiYxEZFcGVyEn//yPlijjulP6/OSefCZ2fXWW5QtzjCwoRj+nRssI0123bx8qzNAIG/e/PR0uzAyVzjyuQkpqZkMXVRJqcPSSR7ZxnXTV4YmP/6vHT+Nz+jNqbEOE4a1LXBtt9bnMV7i7NYfs+5/LA+l8O7x3PpyN48Mn0dPTrGBJa7ZEQvvli5LVBbBziiRzzrtheTsmUnr81ND0yvSSCT56QzrFcH/vTucs47sjtfrXZq79+u3cGHS7Ko9is3nTqAFVlFLMnYyftLamt17y7K4K6PVxEVHsZx/Trz+YptgXmLt+xkvVs7i40K55Nl2Xy41HnVeOvmE/jlywv4x0cr+T41l8uPS2pQa3z5x83ERkUwb2M+S90kVFNYXPLcHFThkhG96dMltk6t9ubXUxocxx835FJS4ePS5+fSPjqCr/90OpHhYax3E1OFz8+xD3xDhc/PpB831alpPvTzo4iJDGd3eRVXH9+XmMhwUtIL+OXLTrfN3I21LdEHPl3D7LQ8Pl+5jSN7deD5X42kX9e4QGFQ8zc9r4R+XWO59a0lZO0s499fp/LO+JPw+5U123bVKYSudbuH1j04hpjI8MB0v1+59Pk57CytIqOglOP6deaio3ty36druPbEvlx4dC9G9OlETGR4IIF+n5rLiqxCjk7qRL5bsNb8nb6q9jOE2spUZkEpqduLOe8/PwbmbcjZHTh2yzML+WRZNk98ncrh3eM5bXAivzyhL6c/NpNtRc7nsn1XOdmFZSR1jmXDjmLmpDmVm1vfWsL67bvd7RSRWVDK41+lcv/FR+JX5YHP1nBVch9OPiyhTgsUnNZ3v64lxEWFkxgfzaa83Xy8NJtiN+5rXp7PbWcfRsd2UYEWcHDlBZyWwsOfr+WTZVs5aVBXRg1JpNht4dW0hMoqq3nsy1Tnc3vkAlZlF3Hp83OoqnYK9t+/vTSwvc15Jdzx3nIyCkpZnlnIuu3FvPDDRs4+oht/fHcZz9F9EKsAABP8SURBVFxzLBcf04u24JlEABARXtsAumB4T16dkw44Be0vRibx+Fep9OjgFKBHJ3UC4IzDEzllUAKPfLmOD5Y0eIp2ozrFRlJYWsX1J/XjtXlbADh9SGKg1nDHeYfz4ZLsOgVzjeiIMB76fG2daRtzm+7/Bnjky3WsyCpi7FE9OO/IHjwyfR0fBxWsI/p04pikTjzw2ZrAtJevS2buxjymzN0SmH78gC6Bu4Gq/coL3zvdMzVJYEj39ny6fGugFnjRMb0YntSRhekFfLgkm8hwoapaA7Xgymo/g7rFMc9ttYjAyuwiFrjjz81s2P0DcNLArgxIiOP7VOd4vb84i/bREYGuqXfGn8gzMzbw+FepdY/D9HVMTcmkpnL1xvwtqGqDpN23SyzxMRGs3rqL35zcnylz07nzw5XkFleQW1zB4H9M54NbTmLB5gKiI8Ko8PmpcLul6l/ov+vjVYHhRVt2smBTAXm7a2vWebsruXjibAYmxAWuzYDTCvj7Ryu55JjegZbAjxtymb5yG7e8uYRfHNubrJ1l9O0Sy/xNBbwxfwvpeSW8Mtt5Lwnto+p0DV3x4jxuOWMQPTrGMCixPcsyC1kedJfU4i07WbxlJwD/m5/B/+ZncP1J/bjnoiMDXWMZBaXc+FoK8yacVed9Zu0sZbrbigt2RI94lmQU1kl2AO8szOS7dc45ExEmTE3JJLOgjMyCMr5dm0NcdEQgCfTtEktGQSmnPTaTuRPO4u2FtdeyVmXXtnSWZRZy7SsL2JJfSqXPT3FFFXPS8vlk2VZev+F4/vze8joxZBSUMmVuOsN6dqBnxxjScnazvag8cI4uyyzkhil1KwUrs4vILiyjd6d2VFX7ueyFuaxwj+GW/NI6XYhb8ktZkrGTm16r3Ualz8/fP1oZSAJQtwX6yuxNgcrKx+51mU+Xb+XT5c7w63PTLRG0lgd/fhQdYiIY2rNDYNqHt5xCx9hI+nSJZXhvpyUwICGO7+84g75dYgkLExZszg98YMn9OpPifqkARg1J5Ae3kO8QE8HIvp1ZvGUnE8YO5cvV29mxq4L/XDWCOWlOM75bfAyJ8dGBL0ONc4Z1Jz46ok7tOEzArw2TwW1nD+am0wYw8bs0Jv24CXCSV/+usXRsF0lRWe0F12E9O3DCwK5ceHRPHvhsDQr06RLLVV36UunzBxLS+NMGsnBzAUN7dmDttl2s37GbsUf1oH9CHL06xpC3u5KnZzhdLh/cchLH9OkUaO2ceXgit509mEufn0tURBhnD+3OsJ4dOKp3x0Dr5szDu/HZiro1S4BXrk9maUZhoOtHRDi2b6c6X7w/nD2YZZmFfL5yG0N7duB/N57Ayuwi4qIj+GBJViBpbcotoUtcFAUllYHjEmzMkT34+/lDSYyPZmF6AQMT4pgyN51py7cy5sgeDOkRzzMzNgRuDjgmqWOgQP2/0wfy0o+buP2cITz5zXqG9+5I1/ZR9OrUjs6xkXUS2+ih3Rk9tBsTPlzJiqyiQEtrYGIcfTrHosCP63MDtd+LjunFZyu2csubSwAC58B9Fw/jhikp3B2UcMBJME9fPYLPV2zjrCO6MWnWJv6fu25C+yiiI2pbB8f378LyrEIqfH4eu+xohvXqwL3TVvO/BRn4/BqoJYPTffmX91fUueh66qMzAejTpV2gjzwiTLgyuQ8PfLaG+z+trWB0jYti8pzNREWE8asT+vLmggzmpOVz2cgk7jz/CJIf+pYvVtaeA+cO686HS7MpKKnkvmmrmZOWzwXDewa6+6C29VpzDL9c7SSlQYlx5Oyq4LrJC4mPjuDei4YFYkmMjya3uIKR/TrRs2M7ZrjXLu6+cBgPBlWIGpwf//mRL/94Ol+t2h5IAuC01koqfYSHCacPTmBZZiGPfLGuTpfUvdNW11mnvpoKVVPc+y8C+8soKGHMUT3Zkl9CSvpOLjsudL/k67lE8OsT+zWY1jHWKczqZ+P+CXGB4V+d0I9v1zon0wvXHse7izJ44uv1ADxz9bEsydgJAgO6xuHzKznF5bSLCmfGn8+gYHclXeKiuOiYXlzk7iPSbZ28ffOJLMnYybUn9qNju0jmbsxj3qZ8/vmL4WzM2c2oIYmc85TT7L7upH4c0aMDo4d2o1NsFFERYdw59oigRNAREWFI9/YsSt/JL47tzW/PGMSQ7vEAdOsQw8RfjqzzHn9+bG+WZBRyZXIfThzYhfsuGsYFR/fiZw9/G3jfpw5OAJyaYU0iGN67U+AYfXHbaQzp3p6yqmraR0fwx9GDuem0gYF9/OHswbSLCmd3uY/v1uUwICGO/l1jmZmay7Un9uXsod05e2h3wsKEpM7tABjaowM1v2N094XDuOGU/lT7lT+dMySQfI7p48TwtzFH8PbCDApLq/j29lH06xrLki072ZCzm8T4aP7vjcUAfHv7KAYlxgXueBo1xPm1u/suGsbr87fw1zGHMzCxPc/MqL2+cNrgRG4/93AKSiq46OheXJGcRL+ucRSUVDLulP706+qcI2WV1XUSwZDu7Unu3wWARy8bzpXJfViRVcTw3h0JCxNemb050EIcNSSRZ64ewSmDujIh6JpC++gIzhjSrc7ndcHRPfl8xTbOH96DS0b05pIRzq+/XjqyN1e9NJ9lmYXk7a6kXWQ4N5wygMlzNtOzUwx/v+AkKqqqOX5AF0SE/16XzNlP/sCbCzI4YUAXRvbrzAvfb6RLXFSdJBDsX5cezWNfrWP9jmIGJrRn3Cn9WbxlZ6DQ/r9RA/n9WYOZuiiTM4/oRmmljzcXOJWAYb06kNA+mr5dYvku6IJyYnw0c/52Fr97awlfrd5Bx3aRTBh7BIvSCwLXdhLaR/PLEzoTGSYc27czL/6wkeP6deZXJ/Qjv6SCT5dv5erj+zKyb2dmb8gjuX8XbjljEGWV1URFhKGqxMdEEBsVwWUjewcSwelDErnj3CFcPHEOJw/qyu3nDOH6yQu595NV5BZXcExSR5655lgemb6ORekFpGwp4MzDu3H20G7MTM1lYb1rN28vzOD4AV341Ql9+cM7y+gUG0nn2ChOHtQ1cBw++n8n88TXqWzMKeGiY3rWaa0uSt/JZS/MpV+X2EBF4P6Lj+TeaU5FbdThiSS0j270szlQ0tYXKfZVcnKypqQ07OfdH9+t24EgnHlEt70vjHNPcl5xBVckOz+89uWq7VT7lQuO7rnP+16eWcjHy7K558JhgYKpKf0nfA7AyvvOJT4mssH8tJxi3lqQyT8uGEp4mATunf7T6CF0jova59gA/v11KjGR4dx65mF1pt/18Uoqqvw8fsUxja5X4auuUxsNlrOrnC9WbuP84T35+0cr+XZtDvdffCTXn9y/wbKzNuTy61cWEh8Twcr7zttrvEsydrI0o5AbTx3QYN7nK7ZRWukLfG5788a8dP79zXqm3XoqPTrGEBXRvHsq0vNKWJq5kz+9u5wPbjmJ4/p1YVd5FR0a+cx81X4Wbi7gZwO6EC5CWJhQXlXNpc/PZdwp/TnlsAQqfX4GJMRx5UvzWLi5gJtPG8D1J/cnoX00EWFSp6uzZptZO8v483vLuXPsERzVuyMPfb6GW888jJ4d2zWIYVlmId+t3cH4UYOIjghjZ0klr8zZzEs/OBWLC47uya1nHMbGXKfP/8/nHg44/xMTFx3BBUf35I156dz9yWo6xUay7J5z62y/2q8M+rvzFPq3bz6RkwZ15dY3l9Sp7b/06+M478gerN5axCuzNgcqLlsLy1izdRc3vZ7CA5ccyXUn9W/WZ9AcaTm7UVUGuxWktJxiEtpH0yk2imdnbODf3zgVvNvPGcJtZw9makomf31/BQDvjj+RDu0iAxfRbzvrMC4/rg9PfevcuvrmTSdwymEJlFdVEx0RhiqEhQnvLsqgqlq59sR+ZBaUUuHz06dLOzbs2N3gOiXANcf3ZcHm/DrXLbrFR/PAJUcx5qge+/W+RWSxqiY3Os/LieCnYsbaHbSLDOfkwxLaOpQWc8WLc1mUvpPXbzie04c0/B3q3OIKfvbwtwxMiOO7O85o/QAPwJ6S4f4oq6ym0ucPtFxDaUt+CVe+NI+Xfp3MCLfFtScLNuVz1aT5RIQJaf88v8H8tJxiXvphEw+6F9XfXpgRuIb02e9P5cheHfZYEdpd4SMuKnyvlaWWUlxexTlP/sj2XeVM/8NpDO3ZAVXlro9X0T4mgjvHDqXar5zwz28JDxO+/MPpdI6LotLnZ+22XYFW6r4oq6ymuLyK9xZn8cHiLPp0iWXKuJ/h8ytLtuyka/soRj/p9ArcfeGwRis7zWGJwBx0XvphI/+avo75d55d5w6nYFPmbGbU4d0YENRFZw4uhaWVjHjgm0ZbBI0prfQx7B7nf3PSH7kg1OHtl0qfn4yCUg7r1r7JZYrKqoiLCm/QKjtQ5VXVhIdJoOu4Rk2vwOr7zyMuev969C0RmIOO368UlVXtd9eVOXi89MNGTh2cwJG9Gt5y3ZjZG/KIiQwLXEMxe7dgUz6V1X5OG9yw9dxclgiMMcbj9pQIPPOfxcYYYxpnicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiP+8n9Q5mI5AJb9nP1BCBvr0u1jYM1Notr31hc+8bi2nf7G1s/VW30X5N/congQIhISlP/WdfWDtbYLK59Y3HtG4tr34UiNusaMsYYj7NEYIwxHue1RDCprQPYg4M1Notr31hc+8bi2nctHpunrhEYY4xpyGstAmOMMfVYIjDGGI/zTCIQkTEikioiaSIyoY1jSReRlSKyTERS3GldROQbEdng/u3cCnFMFpEcEVkVNK3ROMTxjHv8VojIyFaO6z4RyXaP2TIROT9o3p1uXKkisvdfut//uPqIyEwRWSMiq0XkD+70Nj1me4jrYDhmMSKyUESWu7Hd704fICIL3BjeFZEod3q0O57mzu/fynFNEZHNQcdshDu91c5/d3/hIrJURD5zx0N7vFT1kH8B4cBGYCAQBSwHhrVhPOlAQr1pjwET3OEJwKOtEMfpwEhg1d7iAM4HpgMCnAgsaOW47gPuaGTZYe7nGQ0McD/n8BDF1RMY6Q7HA+vd/bfpMdtDXAfDMROgvTscCSxwj8VU4Gp3+ovALe7w/wNedIevBt5t5bimAJc3snyrnf/u/m4H3gI+c8dDery80iI4HkhT1U2qWgm8A1zSxjHVdwnwmjv8GvDzUO9QVX8ECpoZxyXA6+qYD3QSkZ6tGFdTLgHeUdUKVd0MpOF83qGIa5uqLnGHi4G1QG/a+JjtIa6mtOYxU1Xd7Y5Gui8FzgLed6fXP2Y1x/J94GwRkVaMqymtdv6LSBJwAfBfd1wI8fHySiLoDWQGjWex5y9KqCnwtYgsFpHx7rTuqrrNHd4OdG+b0JqM42A4hr9zm+WTg7rO2iQutwl+LE5N8qA5ZvXigoPgmLndHMuAHOAbnBZIoar6Gtl/IDZ3fhHQtTXiUtWaY/awe8yeEpHo+nE1EnNL+w/wV8DvjnclxMfLK4ngYHOqqo4ExgK3isjpwTPVaee1+X29B0scrheAQcAIYBvw77YKRETaAx8Af1TVXcHz2vKYNRLXQXHMVLVaVUcASTgtjyPaIo766sclIkcBd+LE9zOgC/C31oxJRC4EclR1cWvu1yuJIBvoEzSe5E5rE6qa7f7NAT7C+XLsqGlqun9z2ii8puJo02OoqjvcL64feJnaroxWjUtEInEK2zdV9UN3cpsfs8biOliOWQ1VLQRmAifhdK1ENLL/QGzu/I5AfivFNcbtZlNVrQBepfWP2SnAxSKSjtOFfRbwNCE+Xl5JBIuAwe6V9yiciyrT2iIQEYkTkfiaYeBcYJUbz/XuYtcDn7RFfHuIYxpwnXv3xIlAUVB3SMjV64+9FOeY1cR1tXv3xABgMLAwRDEI8AqwVlWfDJrVpsesqbgOkmOWKCKd3OF2wDk41zBmApe7i9U/ZjXH8nLgO7eV1RpxrQtK6ILTDx98zEL+WarqnaqapKr9ccqp71T1V4T6eLXkle6D+YVz1X89Tv/kP9owjoE4d2wsB1bXxILTrzcD2AB8C3RphVjexukyqMLpd7yxqThw7pZ4zj1+K4HkVo7rDXe/K9yTv2fQ8v9w40oFxoYwrlNxun1WAMvc1/ltfcz2ENfBcMyOBpa6MawC7gn6HizEuVD9HhDtTo9xx9Pc+QNbOa7v3GO2CvgftXcWtdr5HxTjGdTeNRTS42WPmDDGGI/zSteQMcaYJlgiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmPqEZHqoKdPLpMWfFqtiPSXoKeqGnMwiNj7IsZ4Tpk6jx4wxhOsRWBMM4nzOxKPifNbEgtF5DB3en8R+c59UNkMEenrTu8uIh+J88z75SJysrupcBF5WZzn4H/t/merMW3GEoExDbWr1zV0VdC8IlUdDkzEeUokwLPAa6p6NPAm8Iw7/RngB1U9Buf3FVa70wcDz6nqkUAhcFmI348xe2T/WWxMPSKyW1XbNzI9HThLVTe5D3nbrqpdRSQP5/ENVe70baqaICK5QJI6DzCr2UZ/nEceD3bH/wZEqupDoX9nxjTOWgTG7BttYnhfVAQNV2PX6kwbs0RgzL65KujvPHd4Ls6TIgF+Bcxyh2cAt0DgR1A6tlaQxuwLq4kY01A795eranypqjW3kHYWkRU4tfpr3Gm/B14Vkb8AucA4d/ofgEkiciNOzf8WnKeqGnNQsWsExjSTe40gWVXz2joWY1qSdQ0ZY4zHWYvAGGM8zloExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHvf/AbYr8PPfBJnPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# the first 600 epochs\n",
    "plot_accuracy(history1)\n",
    "plot_loss(history1)\n",
    "# the next 500 epochs\n",
    "plot_accuracy(history2)\n",
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = DD_Net.predict([X_test_0, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  1  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  4  0  1  0  0  0  0  0  2  0  0]\n",
      " [ 0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  5  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2  0  2  0  1  0  0  0  0  1  0  0  0  1  0  1  0  0]\n",
      " [ 0  0  0  1  0  1  6  0  0  0  0  0  0  0  0  0  0  0  1  1  0]\n",
      " [ 0  0  0  1  0  0  1  9  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  7  0  0  0  0  1  1  0  0  1  0]\n",
      " [ 0  0  0  3  0  0  1  0  0  0  0  3  0  0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  7  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  0  9  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  7  0  0  0  2]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  1  0  1  0  0  0  0  0  0  2  0  0  0  0  0  0  0  4  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  7  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  1  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fad2469a1d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_pred_cls = np.argmax(Y_test_pred, axis=1)\n",
    "Y_test_cls = np.argmax(Y_test_input, axis=1)\n",
    "Y_test_cls[:10], Y_test_pred_cls[:10]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "normalize= None # 'true'\n",
    "cm = confusion_matrix(Y_test_cls, Y_test_pred_cls, normalize=normalize)\n",
    "print(cm)\n",
    "# print(np.sum(np.diagonal(cm)) / np.sum(cm)) # accuracy\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=le.classes_) #sorted(set(le.inverse_transform(Y_test_cls))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(xticks_rotation=90, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-vs-all AP      class_name  precision  recall  test_size  train_size\n",
      "0         0.673      brush_hair       0.75    0.50        6.0        19.0\n",
      "1         0.237           catch       0.30    0.30       10.0        34.0\n",
      "2         0.984            clap       0.85    1.00       11.0        24.0\n",
      "3         0.584    climb_stairs       0.36    0.71        7.0        27.0\n",
      "4         1.000            golf       1.00    0.92       12.0        30.0\n",
      "5         0.402            jump       0.50    0.22        9.0        19.0\n",
      "6         0.808       kick_ball       0.75    0.60       10.0        22.0\n",
      "7         0.941            pick       0.90    0.82       11.0        20.0\n",
      "8         0.866            pour       0.69    0.82       11.0        36.0\n",
      "9         0.990          pullup       0.88    1.00       14.0        38.0\n",
      "10        0.473            push       0.44    0.64       11.0        19.0\n",
      "11        0.487             run       0.43    0.33        9.0        27.0\n",
      "12        0.834      shoot_ball       0.70    0.78        9.0        18.0\n",
      "13        1.000       shoot_bow       1.00    1.00       15.0        35.0\n",
      "14        0.781       shoot_gun       1.00    0.69       13.0        24.0\n",
      "15        0.948             sit       0.75    0.86        7.0        19.0\n",
      "16        0.777           stand       0.70    0.64       11.0        16.0\n",
      "17        0.992  swing_baseball       1.00    0.73       15.0        39.0\n",
      "18        0.487           throw       0.50    0.44        9.0        31.0\n",
      "19        0.769            walk       0.58    0.78        9.0        26.0\n",
      "20        0.257            wave       0.43    0.43        7.0        23.0\n"
     ]
    }
   ],
   "source": [
    "# other statistics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, cls_name in enumerate(le.classes_):\n",
    "    precision = np.round(cm[i, i] / np.sum(cm[:, i]), 2)\n",
    "    recall = np.round(cm[i, i] / np.sum(cm[i, :]), 2)\n",
    "    train_size =  list(le.inverse_transform(np.argmax(Y_input, axis=1))).count(cls_name)\n",
    "    test_size =  list(le.inverse_transform(np.argmax(Y_test_input, axis=1))).count(cls_name)\n",
    "\n",
    "    ap = average_precision_score(Y_test_input[:, i], Y_test_pred[:, i])\n",
    "        \n",
    "    df = df.append({\n",
    "        'class_name': cls_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'train_size': train_size,\n",
    "        'test_size': test_size,\n",
    "        '1-vs-all AP': ap \n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'jhmdb_openpose_model_15.h5'\n",
    "ddnet.save_DDNet(DD_Net, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_labels(Y_true, Y_pred, le, filenames, labels=['wave']):\n",
    "    assert Y_true.shape[0] == Y_pred.shape[0] == len(filenames)\n",
    "    for yt, yp, fn in zip(Y_true, Y_pred, filenames):\n",
    "        cls_true = np.argmax(yt)\n",
    "        cls_pred = np.argmax(yp)\n",
    "        if le.inverse_transform([cls_true])[0] in labels:\n",
    "            correct = (cls_true == cls_pred)\n",
    "            print(\"{} \\t{}={:.2f} \\t{}={:.2f} \\t{}\".format(\n",
    "                correct,\n",
    "                le.inverse_transform([cls_pred])[0],\n",
    "                np.max(yp),\n",
    "                labels[0],\n",
    "                yp[cls_true],\n",
    "                fn\n",
    "            ))\n",
    "            \n",
    "check_labels(Y_test_input, Y_test_pred, le, Test_undoctored['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit using Training + Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 21) (216, 21)\n",
      "Refit using 762 samples\n",
      "[25 44 35 34 42 28 32 31 47 52 30 36 27 50 37 26 27 54 40 35 30]\n",
      "[2.16       1.22727273 1.54285714 1.58823529 1.28571429 1.92857143\n",
      " 1.6875     1.74193548 1.14893617 1.03846154 1.8        1.5\n",
      " 2.         1.08       1.45945946 2.07692308 2.         1.\n",
      " 1.35       1.54285714 1.8       ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_input.shape, Y_test_input.shape)\n",
    "X_rf_0 = np.concatenate([X_0, X_test_0])\n",
    "X_rf_1 = np.concatenate([X_1, X_test_1])\n",
    "Y_rf = np.concatenate([Y_input, Y_test_input])\n",
    "assert X_rf_0.shape[0] == X_rf_1.shape[0] == Y_rf.shape[0]\n",
    "print(\"Refit using {} samples\".format(Y_rf.shape[0]))\n",
    "rf_sample_weight = get_sample_weight(Y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "762/762 [==============================] - 8s 10ms/step - loss: 5.3000 - accuracy: 0.0630\n",
      "Epoch 2/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 5.0360 - accuracy: 0.0709\n",
      "Epoch 3/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 4.9918 - accuracy: 0.0748\n",
      "Epoch 4/800\n",
      "762/762 [==============================] - 0s 145us/step - loss: 4.7330 - accuracy: 0.1168\n",
      "Epoch 5/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 4.5633 - accuracy: 0.1549\n",
      "Epoch 6/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 4.4386 - accuracy: 0.1260\n",
      "Epoch 7/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 4.2322 - accuracy: 0.1811\n",
      "Epoch 8/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 4.0430 - accuracy: 0.2165\n",
      "Epoch 9/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 3.9586 - accuracy: 0.2375\n",
      "Epoch 10/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 3.8072 - accuracy: 0.2651\n",
      "Epoch 11/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 3.7576 - accuracy: 0.2703\n",
      "Epoch 12/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 3.5820 - accuracy: 0.2703\n",
      "Epoch 13/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 3.5505 - accuracy: 0.2703\n",
      "Epoch 14/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 3.3632 - accuracy: 0.3465\n",
      "Epoch 15/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 3.3083 - accuracy: 0.3530\n",
      "Epoch 16/800\n",
      "762/762 [==============================] - 0s 170us/step - loss: 3.1381 - accuracy: 0.3570\n",
      "Epoch 17/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 3.1205 - accuracy: 0.3780\n",
      "Epoch 18/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 3.0123 - accuracy: 0.4003\n",
      "Epoch 19/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 2.9384 - accuracy: 0.4252\n",
      "Epoch 20/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 2.8114 - accuracy: 0.4488\n",
      "Epoch 21/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 2.7724 - accuracy: 0.4462\n",
      "Epoch 22/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 2.6458 - accuracy: 0.4751\n",
      "Epoch 23/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 2.5285 - accuracy: 0.5157\n",
      "Epoch 24/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 2.5407 - accuracy: 0.5223\n",
      "Epoch 25/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 2.4319 - accuracy: 0.5144\n",
      "Epoch 26/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 2.3149 - accuracy: 0.5551\n",
      "Epoch 27/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 2.2177 - accuracy: 0.5814\n",
      "Epoch 28/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 2.2771 - accuracy: 0.5617\n",
      "Epoch 29/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 2.0435 - accuracy: 0.5997\n",
      "Epoch 30/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 2.1137 - accuracy: 0.6247\n",
      "Epoch 31/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 2.0128 - accuracy: 0.6378\n",
      "Epoch 32/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 2.0157 - accuracy: 0.6234\n",
      "Epoch 33/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 1.9386 - accuracy: 0.6417\n",
      "Epoch 34/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 1.8409 - accuracy: 0.6640\n",
      "Epoch 35/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 1.7731 - accuracy: 0.6693\n",
      "Epoch 36/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 1.7195 - accuracy: 0.6811\n",
      "Epoch 37/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 1.6009 - accuracy: 0.7060\n",
      "Epoch 38/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 1.6213 - accuracy: 0.7139\n",
      "Epoch 39/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 1.5124 - accuracy: 0.7231\n",
      "Epoch 40/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 1.4714 - accuracy: 0.7336\n",
      "Epoch 41/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 1.4904 - accuracy: 0.7205\n",
      "Epoch 42/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 1.3821 - accuracy: 0.7507\n",
      "Epoch 43/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 1.4168 - accuracy: 0.7349\n",
      "Epoch 44/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 1.2897 - accuracy: 0.7782\n",
      "Epoch 45/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 1.3152 - accuracy: 0.7900\n",
      "Epoch 46/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 1.2832 - accuracy: 0.7822\n",
      "Epoch 47/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 1.2576 - accuracy: 0.7953\n",
      "Epoch 48/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 1.1233 - accuracy: 0.8084\n",
      "Epoch 49/800\n",
      "762/762 [==============================] - 0s 172us/step - loss: 1.1115 - accuracy: 0.8215\n",
      "Epoch 50/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 1.0749 - accuracy: 0.8202\n",
      "Epoch 51/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.9919 - accuracy: 0.8412\n",
      "Epoch 52/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 1.0806 - accuracy: 0.8150\n",
      "Epoch 53/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.9795 - accuracy: 0.8333\n",
      "Epoch 54/800\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.9421 - accuracy: 0.8596\n",
      "Epoch 55/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.9496 - accuracy: 0.8556\n",
      "Epoch 56/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.9181 - accuracy: 0.8478\n",
      "Epoch 57/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.9354 - accuracy: 0.8386\n",
      "Epoch 58/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.8853 - accuracy: 0.8635\n",
      "Epoch 59/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.8203 - accuracy: 0.8661\n",
      "Epoch 60/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.8064 - accuracy: 0.8753\n",
      "Epoch 61/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.8322 - accuracy: 0.8609\n",
      "Epoch 62/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.7559 - accuracy: 0.8832\n",
      "Epoch 63/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.7680 - accuracy: 0.8819\n",
      "Epoch 64/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.6982 - accuracy: 0.9029\n",
      "Epoch 65/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.6815 - accuracy: 0.9042\n",
      "Epoch 66/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.6788 - accuracy: 0.9003\n",
      "Epoch 67/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.6205 - accuracy: 0.9160\n",
      "Epoch 68/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.6473 - accuracy: 0.9278\n",
      "Epoch 69/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.5973 - accuracy: 0.9147\n",
      "Epoch 70/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.5951 - accuracy: 0.9016\n",
      "Epoch 71/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.5803 - accuracy: 0.9239\n",
      "Epoch 72/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.5578 - accuracy: 0.9199\n",
      "Epoch 73/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.5700 - accuracy: 0.9199\n",
      "Epoch 74/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.5366 - accuracy: 0.9304\n",
      "Epoch 75/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.5486 - accuracy: 0.9239\n",
      "Epoch 76/800\n",
      "762/762 [==============================] - 0s 176us/step - loss: 0.4742 - accuracy: 0.9383\n",
      "Epoch 77/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.4567 - accuracy: 0.9449\n",
      "Epoch 78/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.4805 - accuracy: 0.9396\n",
      "Epoch 79/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.4729 - accuracy: 0.9291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.4546 - accuracy: 0.9396\n",
      "Epoch 81/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.3948 - accuracy: 0.9528\n",
      "Epoch 82/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.4165 - accuracy: 0.9528\n",
      "Epoch 83/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.4106 - accuracy: 0.9475\n",
      "Epoch 84/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.4383 - accuracy: 0.9409\n",
      "Epoch 85/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.3627 - accuracy: 0.9541\n",
      "Epoch 86/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.3330 - accuracy: 0.9698\n",
      "Epoch 87/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.3641 - accuracy: 0.9567\n",
      "Epoch 88/800\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.3458 - accuracy: 0.9593\n",
      "Epoch 89/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.3293 - accuracy: 0.9685\n",
      "Epoch 90/800\n",
      "762/762 [==============================] - 0s 119us/step - loss: 0.3466 - accuracy: 0.9541\n",
      "Epoch 91/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.3119 - accuracy: 0.9619\n",
      "Epoch 92/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.3025 - accuracy: 0.9685\n",
      "Epoch 93/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.3058 - accuracy: 0.9724\n",
      "Epoch 94/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.2675 - accuracy: 0.9724\n",
      "Epoch 95/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.2976 - accuracy: 0.9685\n",
      "Epoch 96/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.2856 - accuracy: 0.9751\n",
      "Epoch 97/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.2596 - accuracy: 0.9803\n",
      "Epoch 98/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.2772 - accuracy: 0.9816\n",
      "Epoch 99/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.2861 - accuracy: 0.9711\n",
      "Epoch 100/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.2967 - accuracy: 0.9646\n",
      "Epoch 101/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.2520 - accuracy: 0.9698\n",
      "Epoch 102/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.2467 - accuracy: 0.9764\n",
      "Epoch 103/800\n",
      "762/762 [==============================] - 0s 90us/step - loss: 0.2699 - accuracy: 0.9738\n",
      "Epoch 104/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.2510 - accuracy: 0.9816\n",
      "Epoch 105/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.2219 - accuracy: 0.9895\n",
      "Epoch 106/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.2469 - accuracy: 0.9856\n",
      "Epoch 107/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.2393 - accuracy: 0.9724\n",
      "Epoch 108/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.2436 - accuracy: 0.9738\n",
      "Epoch 109/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.2240 - accuracy: 0.9816\n",
      "Epoch 110/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.2049 - accuracy: 0.9829\n",
      "Epoch 111/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.2290 - accuracy: 0.9829\n",
      "Epoch 112/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1809 - accuracy: 0.9895\n",
      "Epoch 113/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.2138 - accuracy: 0.9803\n",
      "Epoch 114/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1815 - accuracy: 0.9856\n",
      "Epoch 115/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1936 - accuracy: 0.9882\n",
      "Epoch 116/800\n",
      "762/762 [==============================] - 0s 116us/step - loss: 0.2077 - accuracy: 0.9803\n",
      "Epoch 117/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1847 - accuracy: 0.9869\n",
      "Epoch 118/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1653 - accuracy: 0.9856\n",
      "Epoch 119/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1659 - accuracy: 0.9908\n",
      "Epoch 120/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1690 - accuracy: 0.9895\n",
      "Epoch 121/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1778 - accuracy: 0.9843\n",
      "Epoch 122/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1497 - accuracy: 0.9908\n",
      "Epoch 123/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1487 - accuracy: 0.9934\n",
      "Epoch 124/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1579 - accuracy: 0.9843\n",
      "Epoch 125/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1528 - accuracy: 0.9908\n",
      "Epoch 126/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1611 - accuracy: 0.9895\n",
      "Epoch 127/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1550 - accuracy: 0.9895\n",
      "Epoch 128/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1709 - accuracy: 0.9882\n",
      "Epoch 129/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1704 - accuracy: 0.9882\n",
      "Epoch 130/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1700 - accuracy: 0.9829\n",
      "Epoch 131/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1444 - accuracy: 0.9934\n",
      "Epoch 132/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1543 - accuracy: 0.9869\n",
      "Epoch 133/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1642 - accuracy: 0.9829\n",
      "Epoch 134/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1576 - accuracy: 0.9882\n",
      "Epoch 135/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1630 - accuracy: 0.9869\n",
      "Epoch 136/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1435 - accuracy: 0.9895\n",
      "Epoch 137/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1510 - accuracy: 0.9908\n",
      "Epoch 138/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1488 - accuracy: 0.9895\n",
      "Epoch 139/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1249 - accuracy: 0.9948\n",
      "Epoch 140/800\n",
      "762/762 [==============================] - 0s 178us/step - loss: 0.1430 - accuracy: 0.9882\n",
      "Epoch 141/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1465 - accuracy: 0.9856\n",
      "Epoch 142/800\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.1420 - accuracy: 0.9895\n",
      "Epoch 143/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1408 - accuracy: 0.9908\n",
      "Epoch 144/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1650 - accuracy: 0.9816\n",
      "Epoch 145/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1333 - accuracy: 0.9882\n",
      "Epoch 146/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1468 - accuracy: 0.9908\n",
      "Epoch 147/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1399 - accuracy: 0.9921\n",
      "Epoch 148/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1309 - accuracy: 0.9921\n",
      "Epoch 149/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1414 - accuracy: 0.9974\n",
      "Epoch 150/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1512 - accuracy: 0.9895\n",
      "Epoch 151/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1420 - accuracy: 0.9895\n",
      "Epoch 152/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1218 - accuracy: 0.9948\n",
      "Epoch 153/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1393 - accuracy: 0.9934\n",
      "Epoch 154/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1125 - accuracy: 0.9961\n",
      "Epoch 155/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1527 - accuracy: 0.9921\n",
      "Epoch 156/800\n",
      "762/762 [==============================] - 0s 175us/step - loss: 0.1362 - accuracy: 0.9908\n",
      "Epoch 157/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1258 - accuracy: 0.9948\n",
      "Epoch 158/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1221 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1366 - accuracy: 0.9921\n",
      "Epoch 160/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1340 - accuracy: 0.9869\n",
      "Epoch 161/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1231 - accuracy: 0.9908\n",
      "Epoch 162/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1187 - accuracy: 0.9961\n",
      "Epoch 163/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1142 - accuracy: 0.9934\n",
      "Epoch 164/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1457 - accuracy: 0.9882\n",
      "Epoch 165/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1486 - accuracy: 0.9908\n",
      "Epoch 166/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1511 - accuracy: 0.9869\n",
      "Epoch 167/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1264 - accuracy: 0.9948\n",
      "Epoch 168/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1130 - accuracy: 0.9934\n",
      "Epoch 169/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1203 - accuracy: 0.9948\n",
      "Epoch 170/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1106 - accuracy: 0.9987\n",
      "Epoch 171/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1277 - accuracy: 0.9921\n",
      "Epoch 172/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1474 - accuracy: 0.9882\n",
      "Epoch 173/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1446 - accuracy: 0.9908\n",
      "Epoch 174/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1356 - accuracy: 0.9934\n",
      "Epoch 175/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1425 - accuracy: 0.9856\n",
      "Epoch 176/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1348 - accuracy: 0.9895\n",
      "Epoch 177/800\n",
      "762/762 [==============================] - 0s 144us/step - loss: 0.1334 - accuracy: 0.9895\n",
      "Epoch 178/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1442 - accuracy: 0.9895\n",
      "Epoch 179/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1070 - accuracy: 0.9948\n",
      "Epoch 180/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1149 - accuracy: 1.0000\n",
      "Epoch 181/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1119 - accuracy: 0.9974\n",
      "Epoch 182/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1171 - accuracy: 0.9948\n",
      "Epoch 183/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1157 - accuracy: 0.9934\n",
      "Epoch 184/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1187 - accuracy: 0.9921\n",
      "Epoch 185/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1370 - accuracy: 0.9948\n",
      "Epoch 186/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1328 - accuracy: 0.9895\n",
      "Epoch 187/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1321 - accuracy: 0.9934\n",
      "Epoch 188/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1363 - accuracy: 0.9934\n",
      "Epoch 189/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1367 - accuracy: 0.9934\n",
      "Epoch 190/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1412 - accuracy: 0.9856\n",
      "Epoch 191/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1275 - accuracy: 0.9921\n",
      "Epoch 192/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1269 - accuracy: 0.9948\n",
      "Epoch 193/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1378 - accuracy: 0.9934\n",
      "Epoch 194/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1183 - accuracy: 0.9974\n",
      "Epoch 195/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1261 - accuracy: 0.9921\n",
      "Epoch 196/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1222 - accuracy: 0.9961\n",
      "Epoch 197/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1343 - accuracy: 0.9908\n",
      "Epoch 198/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1196 - accuracy: 0.9921\n",
      "Epoch 199/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1371 - accuracy: 0.9908\n",
      "Epoch 200/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1275 - accuracy: 0.9948\n",
      "Epoch 201/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1301 - accuracy: 0.9934\n",
      "Epoch 202/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1265 - accuracy: 0.9934\n",
      "Epoch 203/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1281 - accuracy: 0.9908\n",
      "Epoch 204/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1279 - accuracy: 0.9948\n",
      "Epoch 205/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1276 - accuracy: 0.9908\n",
      "Epoch 206/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1367 - accuracy: 0.9934\n",
      "Epoch 207/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1378 - accuracy: 0.9908\n",
      "Epoch 208/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1063 - accuracy: 0.9974\n",
      "Epoch 209/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1161 - accuracy: 0.9921\n",
      "Epoch 210/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1232 - accuracy: 0.9934\n",
      "Epoch 211/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1403 - accuracy: 0.9921\n",
      "Epoch 212/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1264 - accuracy: 0.9895\n",
      "Epoch 213/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1366 - accuracy: 0.9908\n",
      "Epoch 214/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1293 - accuracy: 0.9921\n",
      "Epoch 215/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1388 - accuracy: 0.9895\n",
      "Epoch 216/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1425 - accuracy: 0.9895\n",
      "Epoch 217/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1301 - accuracy: 0.9895\n",
      "Epoch 218/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1241 - accuracy: 0.9974\n",
      "Epoch 219/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1430 - accuracy: 0.9869\n",
      "Epoch 220/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1151 - accuracy: 0.9908\n",
      "Epoch 221/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1220 - accuracy: 0.9987\n",
      "Epoch 222/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1258 - accuracy: 0.9921\n",
      "Epoch 223/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1113 - accuracy: 0.9948\n",
      "Epoch 224/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1389 - accuracy: 0.9934\n",
      "Epoch 225/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1337 - accuracy: 0.9934\n",
      "Epoch 226/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1221 - accuracy: 0.9934\n",
      "Epoch 227/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1279 - accuracy: 0.9934\n",
      "Epoch 228/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1231 - accuracy: 0.9895\n",
      "Epoch 229/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1329 - accuracy: 0.9908\n",
      "Epoch 230/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1131 - accuracy: 0.9974\n",
      "Epoch 231/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1376 - accuracy: 0.9882\n",
      "Epoch 232/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1291 - accuracy: 0.9921\n",
      "Epoch 233/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1308 - accuracy: 0.9948\n",
      "Epoch 234/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1175 - accuracy: 0.9934\n",
      "Epoch 235/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1228 - accuracy: 0.9961\n",
      "Epoch 236/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1261 - accuracy: 0.9948\n",
      "Epoch 237/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 166us/step - loss: 0.1326 - accuracy: 0.9895\n",
      "Epoch 238/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1152 - accuracy: 0.9974\n",
      "Epoch 239/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1247 - accuracy: 0.9934\n",
      "Epoch 240/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1220 - accuracy: 0.9934\n",
      "Epoch 241/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1319 - accuracy: 0.9948\n",
      "Epoch 242/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1294 - accuracy: 0.9921\n",
      "Epoch 243/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1342 - accuracy: 0.9921\n",
      "Epoch 244/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1311 - accuracy: 0.9934\n",
      "Epoch 245/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1139 - accuracy: 0.9987\n",
      "Epoch 246/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1230 - accuracy: 0.9934\n",
      "Epoch 247/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1179 - accuracy: 0.9948\n",
      "Epoch 248/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1397 - accuracy: 0.9908\n",
      "Epoch 249/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1428 - accuracy: 0.9908\n",
      "Epoch 250/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1360 - accuracy: 0.9934\n",
      "Epoch 251/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1483 - accuracy: 0.9921\n",
      "Epoch 252/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1151 - accuracy: 0.9961\n",
      "Epoch 253/800\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.1223 - accuracy: 0.9921\n",
      "Epoch 254/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1249 - accuracy: 0.9961\n",
      "Epoch 255/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1170 - accuracy: 0.9961\n",
      "Epoch 256/800\n",
      "762/762 [==============================] - 0s 173us/step - loss: 0.1158 - accuracy: 0.9961\n",
      "Epoch 257/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1201 - accuracy: 0.9921\n",
      "Epoch 258/800\n",
      "762/762 [==============================] - 0s 175us/step - loss: 0.1295 - accuracy: 0.9908\n",
      "Epoch 259/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1425 - accuracy: 0.9934\n",
      "Epoch 260/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1238 - accuracy: 0.9974\n",
      "Epoch 261/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1190 - accuracy: 0.9987\n",
      "Epoch 262/800\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.1183 - accuracy: 0.9934\n",
      "Epoch 263/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1317 - accuracy: 0.9974\n",
      "Epoch 264/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1156 - accuracy: 0.9987\n",
      "Epoch 265/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1258 - accuracy: 0.9921\n",
      "Epoch 266/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1071 - accuracy: 0.9987\n",
      "Epoch 267/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1351 - accuracy: 0.9908\n",
      "Epoch 268/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1155 - accuracy: 0.9974\n",
      "Epoch 269/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1154 - accuracy: 0.9974\n",
      "Epoch 270/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1099 - accuracy: 1.0000\n",
      "Epoch 271/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1289 - accuracy: 0.9934\n",
      "Epoch 272/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1412 - accuracy: 0.9921\n",
      "Epoch 273/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1449 - accuracy: 0.9895\n",
      "Epoch 274/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1190 - accuracy: 0.9961\n",
      "Epoch 275/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1230 - accuracy: 0.9961\n",
      "Epoch 276/800\n",
      "762/762 [==============================] - 0s 128us/step - loss: 0.1303 - accuracy: 0.9882\n",
      "Epoch 277/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1190 - accuracy: 0.9895\n",
      "Epoch 278/800\n",
      "762/762 [==============================] - 0s 117us/step - loss: 0.1236 - accuracy: 0.9974\n",
      "Epoch 279/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1582 - accuracy: 0.9869\n",
      "Epoch 280/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1325 - accuracy: 0.9961\n",
      "Epoch 281/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1332 - accuracy: 0.9895\n",
      "Epoch 282/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1309 - accuracy: 0.9934\n",
      "Epoch 283/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1351 - accuracy: 0.9908\n",
      "Epoch 284/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1184 - accuracy: 0.9921\n",
      "Epoch 285/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1246 - accuracy: 0.9948\n",
      "Epoch 286/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1395 - accuracy: 0.9895\n",
      "Epoch 287/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1180 - accuracy: 0.9961\n",
      "Epoch 288/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1259 - accuracy: 0.9921\n",
      "Epoch 289/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1374 - accuracy: 0.9908\n",
      "Epoch 290/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1214 - accuracy: 0.9948\n",
      "Epoch 291/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1183 - accuracy: 0.9895\n",
      "Epoch 292/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1252 - accuracy: 0.9908\n",
      "Epoch 293/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1326 - accuracy: 0.9895\n",
      "Epoch 294/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1151 - accuracy: 0.9961\n",
      "Epoch 295/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1254 - accuracy: 0.9921\n",
      "Epoch 296/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1189 - accuracy: 0.9908\n",
      "Epoch 297/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1198 - accuracy: 0.9934\n",
      "Epoch 298/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1270 - accuracy: 0.9974\n",
      "Epoch 299/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1259 - accuracy: 0.9908\n",
      "Epoch 300/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1162 - accuracy: 0.9974\n",
      "Epoch 301/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1196 - accuracy: 0.9961\n",
      "Epoch 302/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1342 - accuracy: 0.9921\n",
      "Epoch 303/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1104 - accuracy: 0.9961\n",
      "Epoch 304/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1202 - accuracy: 0.9934\n",
      "Epoch 305/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1292 - accuracy: 0.9974\n",
      "Epoch 306/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1163 - accuracy: 0.9961\n",
      "Epoch 307/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1306 - accuracy: 0.9974\n",
      "Epoch 308/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1067 - accuracy: 0.9961\n",
      "Epoch 309/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1276 - accuracy: 0.9882\n",
      "Epoch 310/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1446 - accuracy: 0.9869\n",
      "Epoch 311/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1249 - accuracy: 0.9961\n",
      "Epoch 312/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1171 - accuracy: 0.9961\n",
      "Epoch 313/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1343 - accuracy: 0.9908\n",
      "Epoch 314/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1148 - accuracy: 0.9948\n",
      "Epoch 315/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1298 - accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1268 - accuracy: 0.9908\n",
      "Epoch 317/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1282 - accuracy: 0.9934\n",
      "Epoch 318/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1276 - accuracy: 0.9974\n",
      "Epoch 319/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1236 - accuracy: 0.9948\n",
      "Epoch 320/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1260 - accuracy: 0.9908\n",
      "Epoch 321/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1273 - accuracy: 0.9948\n",
      "Epoch 322/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1343 - accuracy: 0.9908\n",
      "Epoch 323/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1249 - accuracy: 0.9908\n",
      "Epoch 324/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1257 - accuracy: 0.9921\n",
      "Epoch 325/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1334 - accuracy: 0.9908\n",
      "Epoch 326/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1317 - accuracy: 0.9908\n",
      "Epoch 327/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1224 - accuracy: 0.9934\n",
      "Epoch 328/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1262 - accuracy: 0.9908\n",
      "Epoch 329/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1098 - accuracy: 0.9921\n",
      "Epoch 330/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1163 - accuracy: 0.9895\n",
      "Epoch 331/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1321 - accuracy: 0.9895\n",
      "Epoch 332/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1450 - accuracy: 0.9908\n",
      "Epoch 333/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1541 - accuracy: 0.9843\n",
      "Epoch 334/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1236 - accuracy: 0.9895\n",
      "Epoch 335/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1103 - accuracy: 0.9934\n",
      "Epoch 336/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1314 - accuracy: 0.9961\n",
      "Epoch 337/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1318 - accuracy: 0.9908\n",
      "Epoch 338/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1270 - accuracy: 0.9948\n",
      "Epoch 339/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1176 - accuracy: 0.9948\n",
      "Epoch 340/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1213 - accuracy: 0.9921\n",
      "Epoch 341/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1319 - accuracy: 0.9921\n",
      "Epoch 342/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1162 - accuracy: 0.9948\n",
      "Epoch 343/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1362 - accuracy: 0.9882\n",
      "Epoch 344/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1296 - accuracy: 0.9921\n",
      "Epoch 345/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1125 - accuracy: 0.9948\n",
      "Epoch 346/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1167 - accuracy: 0.9934\n",
      "Epoch 347/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1252 - accuracy: 0.9921\n",
      "Epoch 348/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1238 - accuracy: 0.9948\n",
      "Epoch 349/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1178 - accuracy: 0.9948\n",
      "Epoch 350/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1394 - accuracy: 0.9908\n",
      "Epoch 351/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1302 - accuracy: 0.9895\n",
      "Epoch 352/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1340 - accuracy: 0.9882\n",
      "Epoch 353/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1186 - accuracy: 0.9948\n",
      "Epoch 354/800\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.1357 - accuracy: 0.9856\n",
      "Epoch 355/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1219 - accuracy: 0.9948\n",
      "Epoch 356/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1180 - accuracy: 0.9921\n",
      "Epoch 357/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1345 - accuracy: 0.9934\n",
      "Epoch 358/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1071 - accuracy: 0.9987\n",
      "Epoch 359/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1234 - accuracy: 0.9921\n",
      "Epoch 360/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1218 - accuracy: 0.9921\n",
      "Epoch 361/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1307 - accuracy: 0.9908\n",
      "Epoch 362/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1100 - accuracy: 0.9974\n",
      "Epoch 363/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1148 - accuracy: 0.9934\n",
      "Epoch 364/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1062 - accuracy: 0.9934\n",
      "Epoch 365/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 366/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1332 - accuracy: 0.9882\n",
      "Epoch 367/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1359 - accuracy: 0.9843\n",
      "Epoch 368/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1076 - accuracy: 0.9961\n",
      "Epoch 369/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1121 - accuracy: 0.9934\n",
      "Epoch 370/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1215 - accuracy: 0.9948\n",
      "Epoch 371/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0967 - accuracy: 0.9987\n",
      "Epoch 372/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1362 - accuracy: 0.9895\n",
      "Epoch 373/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1119 - accuracy: 0.9934\n",
      "Epoch 374/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1155 - accuracy: 0.9961\n",
      "Epoch 375/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1201 - accuracy: 0.9934\n",
      "Epoch 376/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1206 - accuracy: 0.9948\n",
      "Epoch 377/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1276 - accuracy: 0.9961\n",
      "Epoch 378/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1227 - accuracy: 0.9921\n",
      "Epoch 379/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1226 - accuracy: 0.9934\n",
      "Epoch 380/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1160 - accuracy: 0.9974\n",
      "Epoch 381/800\n",
      "762/762 [==============================] - 0s 144us/step - loss: 0.1347 - accuracy: 0.9869\n",
      "Epoch 382/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1263 - accuracy: 0.9934\n",
      "Epoch 383/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1276 - accuracy: 0.9921\n",
      "Epoch 384/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1341 - accuracy: 0.9948\n",
      "Epoch 385/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1148 - accuracy: 0.9974\n",
      "Epoch 386/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1419 - accuracy: 0.9921\n",
      "Epoch 387/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1088 - accuracy: 0.9948\n",
      "Epoch 388/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1105 - accuracy: 0.9948\n",
      "Epoch 389/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1342 - accuracy: 0.9908\n",
      "Epoch 390/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1264 - accuracy: 0.9882\n",
      "Epoch 391/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1278 - accuracy: 0.9921\n",
      "Epoch 392/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1511 - accuracy: 0.9882\n",
      "Epoch 393/800\n",
      "762/762 [==============================] - 0s 144us/step - loss: 0.1387 - accuracy: 0.9934\n",
      "Epoch 394/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 153us/step - loss: 0.1156 - accuracy: 0.9934\n",
      "Epoch 395/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1302 - accuracy: 0.9934\n",
      "Epoch 396/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1166 - accuracy: 0.9948\n",
      "Epoch 397/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1140 - accuracy: 0.9974\n",
      "Epoch 398/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1189 - accuracy: 0.9961\n",
      "Epoch 399/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1245 - accuracy: 0.9882\n",
      "Epoch 400/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1308 - accuracy: 0.9908\n",
      "Epoch 401/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1187 - accuracy: 0.9948\n",
      "Epoch 402/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1230 - accuracy: 0.9921\n",
      "Epoch 403/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1130 - accuracy: 0.9961\n",
      "Epoch 404/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1089 - accuracy: 0.9934\n",
      "Epoch 405/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1246 - accuracy: 0.9974\n",
      "Epoch 406/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1426 - accuracy: 0.9882\n",
      "Epoch 407/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1414 - accuracy: 0.9934\n",
      "Epoch 408/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1112 - accuracy: 0.9948\n",
      "Epoch 409/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1279 - accuracy: 0.9895\n",
      "Epoch 410/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1116 - accuracy: 0.9961\n",
      "Epoch 411/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1073 - accuracy: 0.9961\n",
      "Epoch 412/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1067 - accuracy: 0.9987\n",
      "Epoch 413/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1212 - accuracy: 0.9921\n",
      "Epoch 414/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1380 - accuracy: 0.9895\n",
      "Epoch 415/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1098 - accuracy: 0.9948\n",
      "Epoch 416/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1036 - accuracy: 0.9987\n",
      "Epoch 417/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1225 - accuracy: 0.9974\n",
      "Epoch 418/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1231 - accuracy: 0.9869\n",
      "Epoch 419/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1253 - accuracy: 0.9921\n",
      "Epoch 420/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1274 - accuracy: 0.9908\n",
      "Epoch 421/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1162 - accuracy: 0.9934\n",
      "Epoch 422/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1165 - accuracy: 0.9961\n",
      "Epoch 423/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1030 - accuracy: 0.9987\n",
      "Epoch 424/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1311 - accuracy: 0.9921\n",
      "Epoch 425/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1224 - accuracy: 0.9934\n",
      "Epoch 426/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1090 - accuracy: 0.9948\n",
      "Epoch 427/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1086 - accuracy: 0.9934\n",
      "Epoch 428/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1103 - accuracy: 0.9961\n",
      "Epoch 429/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1038 - accuracy: 0.9961\n",
      "Epoch 430/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1294 - accuracy: 0.9934\n",
      "Epoch 431/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1195 - accuracy: 0.9895\n",
      "Epoch 432/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1034 - accuracy: 0.9974\n",
      "Epoch 433/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1219 - accuracy: 0.9921\n",
      "Epoch 434/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1209 - accuracy: 0.9895\n",
      "Epoch 435/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1385 - accuracy: 0.9921\n",
      "Epoch 436/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0999 - accuracy: 0.9948\n",
      "Epoch 437/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1307 - accuracy: 0.9934\n",
      "Epoch 438/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1261 - accuracy: 0.9948\n",
      "Epoch 439/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1132 - accuracy: 0.9934\n",
      "Epoch 440/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1102 - accuracy: 0.9974\n",
      "Epoch 441/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1150 - accuracy: 0.9948\n",
      "Epoch 442/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1295 - accuracy: 0.9908\n",
      "Epoch 443/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1022 - accuracy: 0.9987\n",
      "Epoch 444/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1251 - accuracy: 0.9921\n",
      "Epoch 445/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1423 - accuracy: 0.9921\n",
      "Epoch 446/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1244 - accuracy: 0.9895\n",
      "Epoch 447/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1246 - accuracy: 0.9882\n",
      "Epoch 448/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1227 - accuracy: 0.9948\n",
      "Epoch 449/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1271 - accuracy: 0.9882\n",
      "Epoch 450/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1218 - accuracy: 0.9921\n",
      "Epoch 451/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1152 - accuracy: 0.9948\n",
      "Epoch 452/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1199 - accuracy: 0.9934\n",
      "Epoch 453/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1316 - accuracy: 0.9961\n",
      "Epoch 454/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1098 - accuracy: 0.9948\n",
      "Epoch 455/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1204 - accuracy: 0.9948\n",
      "Epoch 456/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1220 - accuracy: 0.9921\n",
      "Epoch 457/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1144 - accuracy: 0.9961\n",
      "Epoch 458/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1154 - accuracy: 0.9934\n",
      "Epoch 459/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1274 - accuracy: 0.9921\n",
      "Epoch 460/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1162 - accuracy: 0.9934\n",
      "Epoch 461/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1299 - accuracy: 0.9948\n",
      "Epoch 462/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1199 - accuracy: 0.9961\n",
      "Epoch 463/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1077 - accuracy: 0.9948\n",
      "Epoch 464/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1251 - accuracy: 0.9948\n",
      "Epoch 465/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1151 - accuracy: 0.9934\n",
      "Epoch 466/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1081 - accuracy: 0.9961\n",
      "Epoch 467/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1274 - accuracy: 0.9934\n",
      "Epoch 468/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1359 - accuracy: 0.9882\n",
      "Epoch 469/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1358 - accuracy: 0.9934\n",
      "Epoch 470/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1144 - accuracy: 0.9934\n",
      "Epoch 471/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1145 - accuracy: 0.9934\n",
      "Epoch 472/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1150 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1266 - accuracy: 0.9961\n",
      "Epoch 474/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1155 - accuracy: 0.9974\n",
      "Epoch 475/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1053 - accuracy: 0.9948\n",
      "Epoch 476/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1185 - accuracy: 0.9961\n",
      "Epoch 477/800\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.1301 - accuracy: 0.9882\n",
      "Epoch 478/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1280 - accuracy: 0.9908\n",
      "Epoch 479/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1072 - accuracy: 0.9961\n",
      "Epoch 480/800\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.1198 - accuracy: 0.9934\n",
      "Epoch 481/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1192 - accuracy: 0.9974\n",
      "Epoch 482/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1073 - accuracy: 0.9961\n",
      "Epoch 483/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1358 - accuracy: 0.9895\n",
      "Epoch 484/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1194 - accuracy: 0.9987\n",
      "Epoch 485/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1241 - accuracy: 0.9934\n",
      "Epoch 486/800\n",
      "762/762 [==============================] - 0s 117us/step - loss: 0.1202 - accuracy: 0.9908\n",
      "Epoch 487/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1227 - accuracy: 0.9934\n",
      "Epoch 488/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1218 - accuracy: 0.9869\n",
      "Epoch 489/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1203 - accuracy: 0.9934\n",
      "Epoch 490/800\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.1015 - accuracy: 0.9974\n",
      "Epoch 491/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1332 - accuracy: 0.9934\n",
      "Epoch 492/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1238 - accuracy: 0.9934\n",
      "Epoch 493/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1174 - accuracy: 0.9961\n",
      "Epoch 494/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1252 - accuracy: 0.9948\n",
      "Epoch 495/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1121 - accuracy: 0.9961\n",
      "Epoch 496/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1036 - accuracy: 0.9948\n",
      "Epoch 497/800\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1179 - accuracy: 0.9921\n",
      "Epoch 498/800\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1198 - accuracy: 0.9961\n",
      "Epoch 499/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1234 - accuracy: 0.9908\n",
      "Epoch 500/800\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.1348 - accuracy: 0.9908\n",
      "Epoch 501/800\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1065 - accuracy: 0.9974\n",
      "Epoch 502/800\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1217 - accuracy: 0.9921\n",
      "Epoch 503/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0870 - accuracy: 0.9987\n",
      "Epoch 504/800\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.1136 - accuracy: 0.9934\n",
      "Epoch 505/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1525 - accuracy: 0.9882\n",
      "Epoch 506/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1277 - accuracy: 0.9948\n",
      "Epoch 507/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1214 - accuracy: 0.9961\n",
      "Epoch 508/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1242 - accuracy: 0.9934\n",
      "Epoch 509/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1230 - accuracy: 0.9895\n",
      "Epoch 510/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1163 - accuracy: 0.9921\n",
      "Epoch 511/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1233 - accuracy: 0.9948\n",
      "Epoch 512/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1139 - accuracy: 0.9934\n",
      "Epoch 513/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1087 - accuracy: 0.9961\n",
      "Epoch 514/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1183 - accuracy: 0.9934\n",
      "Epoch 515/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1165 - accuracy: 0.9948\n",
      "Epoch 516/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1168 - accuracy: 0.9961\n",
      "Epoch 517/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0897 - accuracy: 0.9987\n",
      "Epoch 518/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1303 - accuracy: 0.9908\n",
      "Epoch 519/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1072 - accuracy: 0.9974\n",
      "Epoch 520/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1124 - accuracy: 0.9974\n",
      "Epoch 521/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1320 - accuracy: 0.9961\n",
      "Epoch 522/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1113 - accuracy: 0.9948\n",
      "Epoch 523/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1416 - accuracy: 0.9934\n",
      "Epoch 524/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1322 - accuracy: 0.9895\n",
      "Epoch 525/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1257 - accuracy: 0.9908\n",
      "Epoch 526/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1059 - accuracy: 0.9974\n",
      "Epoch 527/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1266 - accuracy: 0.9882\n",
      "Epoch 528/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1078 - accuracy: 0.9921\n",
      "Epoch 529/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1211 - accuracy: 0.9921\n",
      "Epoch 530/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1204 - accuracy: 0.9948\n",
      "Epoch 531/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1095 - accuracy: 0.9974\n",
      "Epoch 532/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1263 - accuracy: 0.9961\n",
      "Epoch 533/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1190 - accuracy: 0.9921\n",
      "Epoch 534/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0988 - accuracy: 0.9974\n",
      "Epoch 535/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1019 - accuracy: 0.9974\n",
      "Epoch 536/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1131 - accuracy: 0.9961\n",
      "Epoch 537/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1204 - accuracy: 0.9948\n",
      "Epoch 538/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1148 - accuracy: 0.9987\n",
      "Epoch 539/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1358 - accuracy: 0.9895\n",
      "Epoch 540/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1095 - accuracy: 0.9987\n",
      "Epoch 541/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1101 - accuracy: 0.9934\n",
      "Epoch 542/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1094 - accuracy: 0.9961\n",
      "Epoch 543/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1045 - accuracy: 0.9961\n",
      "Epoch 544/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1274 - accuracy: 0.9895\n",
      "Epoch 545/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1212 - accuracy: 0.9948\n",
      "Epoch 546/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1200 - accuracy: 0.9908\n",
      "Epoch 547/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1218 - accuracy: 0.9948\n",
      "Epoch 548/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1218 - accuracy: 0.9921\n",
      "Epoch 549/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1014 - accuracy: 0.9974\n",
      "Epoch 550/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1164 - accuracy: 0.9961\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 143us/step - loss: 0.1096 - accuracy: 0.9934\n",
      "Epoch 552/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1023 - accuracy: 0.9974\n",
      "Epoch 553/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1387 - accuracy: 0.9895\n",
      "Epoch 554/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1101 - accuracy: 0.9961\n",
      "Epoch 555/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1094 - accuracy: 0.9921\n",
      "Epoch 556/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0997 - accuracy: 0.9948\n",
      "Epoch 557/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1079 - accuracy: 0.9934\n",
      "Epoch 558/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1243 - accuracy: 0.9961\n",
      "Epoch 559/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1088 - accuracy: 0.9948\n",
      "Epoch 560/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1116 - accuracy: 0.9948\n",
      "Epoch 561/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1096 - accuracy: 0.9948\n",
      "Epoch 562/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1227 - accuracy: 0.9921\n",
      "Epoch 563/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0995 - accuracy: 0.9974\n",
      "Epoch 564/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1157 - accuracy: 0.9934\n",
      "Epoch 565/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1146 - accuracy: 0.9961\n",
      "Epoch 566/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1237 - accuracy: 0.9908\n",
      "Epoch 567/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1250 - accuracy: 0.9921\n",
      "Epoch 568/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0984 - accuracy: 0.9987\n",
      "Epoch 569/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1108 - accuracy: 0.9961\n",
      "Epoch 570/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1192 - accuracy: 0.9934\n",
      "Epoch 571/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1003 - accuracy: 0.9948\n",
      "Epoch 572/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1084 - accuracy: 0.9987\n",
      "Epoch 573/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1067 - accuracy: 0.9961\n",
      "Epoch 574/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1052 - accuracy: 0.9974\n",
      "Epoch 575/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1296 - accuracy: 0.9908\n",
      "Epoch 576/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1181 - accuracy: 0.9948\n",
      "Epoch 577/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1172 - accuracy: 0.9934\n",
      "Epoch 578/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1153 - accuracy: 0.9961\n",
      "Epoch 579/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1071 - accuracy: 0.9961\n",
      "Epoch 580/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1173 - accuracy: 0.9934\n",
      "Epoch 581/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1252 - accuracy: 0.9921\n",
      "Epoch 582/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1113 - accuracy: 0.9961\n",
      "Epoch 583/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1294 - accuracy: 0.9921\n",
      "Epoch 584/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0963 - accuracy: 0.9948\n",
      "Epoch 585/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1091 - accuracy: 0.9961\n",
      "Epoch 586/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1076 - accuracy: 0.9987\n",
      "Epoch 587/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1071 - accuracy: 0.9987\n",
      "Epoch 588/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1071 - accuracy: 0.9908\n",
      "Epoch 589/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1187 - accuracy: 0.9948\n",
      "Epoch 590/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1029 - accuracy: 0.9987\n",
      "Epoch 591/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1216 - accuracy: 0.9934\n",
      "Epoch 592/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1177 - accuracy: 0.9908\n",
      "Epoch 593/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1027 - accuracy: 0.9934\n",
      "Epoch 594/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1101 - accuracy: 0.9961\n",
      "Epoch 595/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1082 - accuracy: 0.9921\n",
      "Epoch 596/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1237 - accuracy: 0.9934\n",
      "Epoch 597/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1180 - accuracy: 0.9921\n",
      "Epoch 598/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1241 - accuracy: 0.9921\n",
      "Epoch 599/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0941 - accuracy: 0.9974\n",
      "Epoch 600/800\n",
      "762/762 [==============================] - 0s 143us/step - loss: 0.1046 - accuracy: 0.9974\n",
      "Epoch 601/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1128 - accuracy: 0.9934\n",
      "Epoch 602/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1022 - accuracy: 0.9961\n",
      "Epoch 603/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1091 - accuracy: 0.9974\n",
      "Epoch 604/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1192 - accuracy: 0.9934\n",
      "Epoch 605/800\n",
      "762/762 [==============================] - 0s 145us/step - loss: 0.1132 - accuracy: 0.9934\n",
      "Epoch 606/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1297 - accuracy: 0.9882\n",
      "Epoch 607/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1174 - accuracy: 0.9921\n",
      "Epoch 608/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1134 - accuracy: 0.9934\n",
      "Epoch 609/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0994 - accuracy: 0.9948\n",
      "Epoch 610/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1147 - accuracy: 0.9921\n",
      "Epoch 611/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1198 - accuracy: 0.9934\n",
      "Epoch 612/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1142 - accuracy: 0.9948\n",
      "Epoch 613/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1162 - accuracy: 0.9921\n",
      "Epoch 614/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1111 - accuracy: 0.9948\n",
      "Epoch 615/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1283 - accuracy: 0.9895\n",
      "Epoch 616/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1035 - accuracy: 0.9934\n",
      "Epoch 617/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1022 - accuracy: 0.9987\n",
      "Epoch 618/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1234 - accuracy: 0.9895\n",
      "Epoch 619/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1194 - accuracy: 0.9934\n",
      "Epoch 620/800\n",
      "762/762 [==============================] - 0s 147us/step - loss: 0.1115 - accuracy: 0.9961\n",
      "Epoch 621/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1185 - accuracy: 0.9961\n",
      "Epoch 622/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1142 - accuracy: 0.9882\n",
      "Epoch 623/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1211 - accuracy: 0.9961\n",
      "Epoch 624/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1074 - accuracy: 0.9974\n",
      "Epoch 625/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1169 - accuracy: 0.9908\n",
      "Epoch 626/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1135 - accuracy: 0.9948\n",
      "Epoch 627/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1171 - accuracy: 0.9987\n",
      "Epoch 628/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1205 - accuracy: 0.9895\n",
      "Epoch 629/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1122 - accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 630/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1222 - accuracy: 0.9908\n",
      "Epoch 631/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1304 - accuracy: 0.9934\n",
      "Epoch 632/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1010 - accuracy: 0.9961\n",
      "Epoch 633/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0993 - accuracy: 0.9974\n",
      "Epoch 634/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1007 - accuracy: 0.9934\n",
      "Epoch 635/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1300 - accuracy: 0.9882\n",
      "Epoch 636/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1031 - accuracy: 0.9961\n",
      "Epoch 637/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1135 - accuracy: 0.9961\n",
      "Epoch 638/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1173 - accuracy: 0.9948\n",
      "Epoch 639/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1298 - accuracy: 0.9948\n",
      "Epoch 640/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1099 - accuracy: 0.9908\n",
      "Epoch 641/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0979 - accuracy: 1.0000\n",
      "Epoch 642/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1193 - accuracy: 0.9934\n",
      "Epoch 643/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1228 - accuracy: 0.9948\n",
      "Epoch 644/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1261 - accuracy: 0.9961\n",
      "Epoch 645/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0990 - accuracy: 0.9961\n",
      "Epoch 646/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 647/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1005 - accuracy: 0.9974\n",
      "Epoch 648/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1143 - accuracy: 0.9921\n",
      "Epoch 649/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1205 - accuracy: 0.9908\n",
      "Epoch 650/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1261 - accuracy: 0.9948\n",
      "Epoch 651/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1137 - accuracy: 0.9961\n",
      "Epoch 652/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1035 - accuracy: 0.9921\n",
      "Epoch 653/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1161 - accuracy: 0.9961\n",
      "Epoch 654/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1029 - accuracy: 0.9921\n",
      "Epoch 655/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1211 - accuracy: 0.9882\n",
      "Epoch 656/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1072 - accuracy: 0.9882\n",
      "Epoch 657/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1173 - accuracy: 0.9921\n",
      "Epoch 658/800\n",
      "762/762 [==============================] - 0s 147us/step - loss: 0.1090 - accuracy: 0.9948\n",
      "Epoch 659/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1194 - accuracy: 0.9961\n",
      "Epoch 660/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1256 - accuracy: 0.9908\n",
      "Epoch 661/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1061 - accuracy: 0.9921\n",
      "Epoch 662/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1214 - accuracy: 0.9921\n",
      "Epoch 663/800\n",
      "762/762 [==============================] - 0s 142us/step - loss: 0.1077 - accuracy: 0.9961\n",
      "Epoch 664/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 665/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1104 - accuracy: 0.9921\n",
      "Epoch 666/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1007 - accuracy: 0.9987\n",
      "Epoch 667/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1334 - accuracy: 0.9882\n",
      "Epoch 668/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1130 - accuracy: 0.9961\n",
      "Epoch 669/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1281 - accuracy: 0.9895\n",
      "Epoch 670/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1225 - accuracy: 0.9908\n",
      "Epoch 671/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1144 - accuracy: 0.9961\n",
      "Epoch 672/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1142 - accuracy: 0.9934\n",
      "Epoch 673/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1035 - accuracy: 0.9987\n",
      "Epoch 674/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1166 - accuracy: 0.9948\n",
      "Epoch 675/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1206 - accuracy: 0.9948\n",
      "Epoch 676/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1248 - accuracy: 0.9934\n",
      "Epoch 677/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0975 - accuracy: 0.9961\n",
      "Epoch 678/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1062 - accuracy: 0.9934\n",
      "Epoch 679/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1204 - accuracy: 0.9948\n",
      "Epoch 680/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1145 - accuracy: 0.9908\n",
      "Epoch 681/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1214 - accuracy: 0.9921\n",
      "Epoch 682/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1318 - accuracy: 0.9882\n",
      "Epoch 683/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1138 - accuracy: 0.9934\n",
      "Epoch 684/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1035 - accuracy: 0.9961\n",
      "Epoch 685/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1121 - accuracy: 0.9961\n",
      "Epoch 686/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1044 - accuracy: 0.9934\n",
      "Epoch 687/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1145 - accuracy: 0.9921\n",
      "Epoch 688/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1230 - accuracy: 0.9948\n",
      "Epoch 689/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1244 - accuracy: 0.9908\n",
      "Epoch 690/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1092 - accuracy: 0.9987\n",
      "Epoch 691/800\n",
      "762/762 [==============================] - 0s 147us/step - loss: 0.1049 - accuracy: 0.9974\n",
      "Epoch 692/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1179 - accuracy: 0.9934\n",
      "Epoch 693/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.0908 - accuracy: 0.9987\n",
      "Epoch 694/800\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1074 - accuracy: 0.9987\n",
      "Epoch 695/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1087 - accuracy: 0.9948\n",
      "Epoch 696/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1161 - accuracy: 0.9882\n",
      "Epoch 697/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1026 - accuracy: 0.9948\n",
      "Epoch 698/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1137 - accuracy: 0.9948\n",
      "Epoch 699/800\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1338 - accuracy: 0.9908\n",
      "Epoch 700/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1094 - accuracy: 0.9934\n",
      "Epoch 701/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1123 - accuracy: 0.9974\n",
      "Epoch 702/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1137 - accuracy: 0.9974\n",
      "Epoch 703/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1191 - accuracy: 0.9934\n",
      "Epoch 704/800\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1122 - accuracy: 0.9934\n",
      "Epoch 705/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1303 - accuracy: 0.9908\n",
      "Epoch 706/800\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1007 - accuracy: 0.9974\n",
      "Epoch 707/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1121 - accuracy: 0.9934\n",
      "Epoch 708/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 117us/step - loss: 0.1088 - accuracy: 0.9987\n",
      "Epoch 709/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1047 - accuracy: 0.9921\n",
      "Epoch 710/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1102 - accuracy: 0.9961\n",
      "Epoch 711/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0958 - accuracy: 0.9987\n",
      "Epoch 712/800\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1098 - accuracy: 0.9961\n",
      "Epoch 713/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1273 - accuracy: 0.9908\n",
      "Epoch 714/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1173 - accuracy: 0.9934\n",
      "Epoch 715/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1111 - accuracy: 0.9921\n",
      "Epoch 716/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1132 - accuracy: 0.9908\n",
      "Epoch 717/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1102 - accuracy: 0.9948\n",
      "Epoch 718/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1149 - accuracy: 0.9934\n",
      "Epoch 719/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1247 - accuracy: 0.9895\n",
      "Epoch 720/800\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1218 - accuracy: 0.9908\n",
      "Epoch 721/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0971 - accuracy: 0.9987\n",
      "Epoch 722/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1050 - accuracy: 1.0000\n",
      "Epoch 723/800\n",
      "762/762 [==============================] - 0s 95us/step - loss: 0.1073 - accuracy: 0.9961\n",
      "Epoch 724/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1112 - accuracy: 0.9948\n",
      "Epoch 725/800\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.1013 - accuracy: 0.9961\n",
      "Epoch 726/800\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1060 - accuracy: 0.9934\n",
      "Epoch 727/800\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1064 - accuracy: 0.9934\n",
      "Epoch 728/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.1152 - accuracy: 0.9934\n",
      "Epoch 729/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1172 - accuracy: 0.9934\n",
      "Epoch 730/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1029 - accuracy: 0.9961\n",
      "Epoch 731/800\n",
      "762/762 [==============================] - 0s 94us/step - loss: 0.1054 - accuracy: 0.9948\n",
      "Epoch 732/800\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0923 - accuracy: 0.9987\n",
      "Epoch 733/800\n",
      "762/762 [==============================] - 0s 93us/step - loss: 0.1136 - accuracy: 0.9948\n",
      "Epoch 734/800\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.1290 - accuracy: 0.9882\n",
      "Epoch 735/800\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0992 - accuracy: 0.9948\n",
      "Epoch 736/800\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1132 - accuracy: 0.9974\n",
      "Epoch 737/800\n",
      "762/762 [==============================] - 0s 146us/step - loss: 0.1215 - accuracy: 0.9921\n",
      "Epoch 738/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1090 - accuracy: 0.9921\n",
      "Epoch 739/800\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.1063 - accuracy: 0.9934\n",
      "Epoch 740/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1230 - accuracy: 0.9934\n",
      "Epoch 741/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1126 - accuracy: 0.9934\n",
      "Epoch 742/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1060 - accuracy: 0.9974\n",
      "Epoch 743/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1169 - accuracy: 0.9934\n",
      "Epoch 744/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1004 - accuracy: 0.9948\n",
      "Epoch 745/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0999 - accuracy: 0.9934\n",
      "Epoch 746/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1302 - accuracy: 0.9895\n",
      "Epoch 747/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1144 - accuracy: 0.9921\n",
      "Epoch 748/800\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.1253 - accuracy: 0.9948\n",
      "Epoch 749/800\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0988 - accuracy: 0.9948\n",
      "Epoch 750/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1047 - accuracy: 0.9921\n",
      "Epoch 751/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1006 - accuracy: 0.9961\n",
      "Epoch 752/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.0931 - accuracy: 0.9987\n",
      "Epoch 753/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.0975 - accuracy: 0.9974\n",
      "Epoch 754/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1010 - accuracy: 0.9961\n",
      "Epoch 755/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1044 - accuracy: 0.9948\n",
      "Epoch 756/800\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.1131 - accuracy: 0.9974\n",
      "Epoch 757/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1157 - accuracy: 0.9921\n",
      "Epoch 758/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1124 - accuracy: 0.9961\n",
      "Epoch 759/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1174 - accuracy: 0.9948\n",
      "Epoch 760/800\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1118 - accuracy: 0.9921\n",
      "Epoch 761/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1080 - accuracy: 0.9961\n",
      "Epoch 762/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1288 - accuracy: 0.9948\n",
      "Epoch 763/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0949 - accuracy: 0.9948\n",
      "Epoch 764/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0965 - accuracy: 0.9987\n",
      "Epoch 765/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1183 - accuracy: 0.9948\n",
      "Epoch 766/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1160 - accuracy: 0.9934\n",
      "Epoch 767/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0892 - accuracy: 0.9948\n",
      "Epoch 768/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0984 - accuracy: 0.9974\n",
      "Epoch 769/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1086 - accuracy: 0.9895\n",
      "Epoch 770/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0989 - accuracy: 0.9974\n",
      "Epoch 771/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1079 - accuracy: 1.0000\n",
      "Epoch 772/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1032 - accuracy: 0.9974\n",
      "Epoch 773/800\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1044 - accuracy: 0.9961\n",
      "Epoch 774/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1138 - accuracy: 0.9948\n",
      "Epoch 775/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1237 - accuracy: 0.9934\n",
      "Epoch 776/800\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1052 - accuracy: 0.9961\n",
      "Epoch 777/800\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1106 - accuracy: 0.9934\n",
      "Epoch 778/800\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1276 - accuracy: 0.9921\n",
      "Epoch 779/800\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1009 - accuracy: 0.9934\n",
      "Epoch 780/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1107 - accuracy: 0.9921\n",
      "Epoch 781/800\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1211 - accuracy: 0.9921\n",
      "Epoch 782/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1088 - accuracy: 0.9948\n",
      "Epoch 783/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1016 - accuracy: 0.9961\n",
      "Epoch 784/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1112 - accuracy: 0.9934\n",
      "Epoch 785/800\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1181 - accuracy: 0.9882\n",
      "Epoch 786/800\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1104 - accuracy: 0.9934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1012 - accuracy: 0.9974\n",
      "Epoch 788/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1233 - accuracy: 0.9934\n",
      "Epoch 789/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1269 - accuracy: 0.9934\n",
      "Epoch 790/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1044 - accuracy: 0.9987\n",
      "Epoch 791/800\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1018 - accuracy: 0.9908\n",
      "Epoch 792/800\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1012 - accuracy: 0.9948\n",
      "Epoch 793/800\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0972 - accuracy: 0.9948\n",
      "Epoch 794/800\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1109 - accuracy: 0.9921\n",
      "Epoch 795/800\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1173 - accuracy: 0.9961\n",
      "Epoch 796/800\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1097 - accuracy: 0.9948\n",
      "Epoch 797/800\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1085 - accuracy: 0.9934\n",
      "Epoch 798/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1193 - accuracy: 0.9921\n",
      "Epoch 799/800\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1016 - accuracy: 0.9974\n",
      "Epoch 800/800\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1069 - accuracy: 0.9961\n",
      "Epoch 1/500\n",
      "762/762 [==============================] - 6s 7ms/step - loss: 0.0986 - accuracy: 0.9934\n",
      "Epoch 2/500\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.1014 - accuracy: 0.9934\n",
      "Epoch 3/500\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1097 - accuracy: 0.9948\n",
      "Epoch 4/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1197 - accuracy: 0.9908\n",
      "Epoch 5/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1106 - accuracy: 0.9921\n",
      "Epoch 6/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1084 - accuracy: 0.9934\n",
      "Epoch 7/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0996 - accuracy: 0.9987\n",
      "Epoch 8/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1073 - accuracy: 0.9934\n",
      "Epoch 9/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0878 - accuracy: 0.9974\n",
      "Epoch 10/500\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.1028 - accuracy: 0.9948\n",
      "Epoch 11/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0957 - accuracy: 0.9974\n",
      "Epoch 12/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0993 - accuracy: 0.9961\n",
      "Epoch 13/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1287 - accuracy: 0.9908\n",
      "Epoch 14/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1081 - accuracy: 0.9934\n",
      "Epoch 15/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1103 - accuracy: 0.9974\n",
      "Epoch 16/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.0979 - accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1126 - accuracy: 0.9948\n",
      "Epoch 18/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1166 - accuracy: 0.9948\n",
      "Epoch 19/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0984 - accuracy: 0.9948\n",
      "Epoch 20/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1126 - accuracy: 0.9908\n",
      "Epoch 21/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1126 - accuracy: 0.9961\n",
      "Epoch 22/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1149 - accuracy: 0.9921\n",
      "Epoch 23/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1045 - accuracy: 0.9961\n",
      "Epoch 24/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1124 - accuracy: 0.9934\n",
      "Epoch 25/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1098 - accuracy: 0.9934\n",
      "Epoch 26/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1043 - accuracy: 0.9948\n",
      "Epoch 27/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1025 - accuracy: 0.9908\n",
      "Epoch 28/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1215 - accuracy: 0.9948\n",
      "Epoch 29/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1044 - accuracy: 0.9921\n",
      "Epoch 30/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1036 - accuracy: 0.9987\n",
      "Epoch 31/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1140 - accuracy: 0.9961\n",
      "Epoch 32/500\n",
      "762/762 [==============================] - 0s 171us/step - loss: 0.0931 - accuracy: 0.9974\n",
      "Epoch 33/500\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.0965 - accuracy: 0.9921\n",
      "Epoch 34/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1039 - accuracy: 0.9961\n",
      "Epoch 35/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1035 - accuracy: 0.9895\n",
      "Epoch 36/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0928 - accuracy: 0.9921\n",
      "Epoch 37/500\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1104 - accuracy: 0.9948\n",
      "Epoch 38/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0955 - accuracy: 0.9974\n",
      "Epoch 39/500\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1116 - accuracy: 0.9934\n",
      "Epoch 40/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1016 - accuracy: 0.9974\n",
      "Epoch 41/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1041 - accuracy: 0.9948\n",
      "Epoch 42/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1225 - accuracy: 0.9921\n",
      "Epoch 43/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0992 - accuracy: 0.9908\n",
      "Epoch 44/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1046 - accuracy: 0.9948\n",
      "Epoch 45/500\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.0829 - accuracy: 0.9961\n",
      "Epoch 46/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1212 - accuracy: 0.9948\n",
      "Epoch 47/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0847 - accuracy: 0.9961\n",
      "Epoch 48/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1109 - accuracy: 0.9948\n",
      "Epoch 49/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1064 - accuracy: 0.9974\n",
      "Epoch 50/500\n",
      "762/762 [==============================] - 0s 121us/step - loss: 0.1123 - accuracy: 0.9948\n",
      "Epoch 51/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0921 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0900 - accuracy: 0.9987\n",
      "Epoch 53/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0977 - accuracy: 0.9974\n",
      "Epoch 54/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0994 - accuracy: 0.9974\n",
      "Epoch 55/500\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.0949 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1130 - accuracy: 0.9948\n",
      "Epoch 57/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0851 - accuracy: 0.9987\n",
      "Epoch 58/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0995 - accuracy: 0.9948\n",
      "Epoch 59/500\n",
      "762/762 [==============================] - 0s 115us/step - loss: 0.1015 - accuracy: 0.9921\n",
      "Epoch 60/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1094 - accuracy: 0.9948\n",
      "Epoch 61/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1229 - accuracy: 0.9908\n",
      "Epoch 62/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1156 - accuracy: 0.9948\n",
      "Epoch 63/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0901 - accuracy: 0.9961\n",
      "Epoch 64/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1075 - accuracy: 0.9895\n",
      "Epoch 65/500\n",
      "762/762 [==============================] - 0s 113us/step - loss: 0.1180 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.1010 - accuracy: 0.9974\n",
      "Epoch 67/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0914 - accuracy: 0.9948\n",
      "Epoch 68/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0884 - accuracy: 0.9987\n",
      "Epoch 69/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0809 - accuracy: 0.9987\n",
      "Epoch 70/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1014 - accuracy: 0.9948\n",
      "Epoch 71/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0910 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.1057 - accuracy: 0.9921\n",
      "Epoch 73/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0905 - accuracy: 0.9974\n",
      "Epoch 74/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0969 - accuracy: 0.9934\n",
      "Epoch 75/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0930 - accuracy: 0.9961\n",
      "Epoch 76/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1018 - accuracy: 0.9934\n",
      "Epoch 77/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1109 - accuracy: 0.9961\n",
      "Epoch 78/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1090 - accuracy: 0.9921\n",
      "Epoch 79/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1088 - accuracy: 0.9961\n",
      "Epoch 80/500\n",
      "762/762 [==============================] - 0s 167us/step - loss: 0.1116 - accuracy: 0.9961\n",
      "Epoch 81/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0956 - accuracy: 0.9934\n",
      "Epoch 82/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1079 - accuracy: 0.9908\n",
      "Epoch 83/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1124 - accuracy: 0.9961\n",
      "Epoch 84/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0990 - accuracy: 0.9921\n",
      "Epoch 85/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1033 - accuracy: 0.9948\n",
      "Epoch 86/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0946 - accuracy: 0.9948\n",
      "Epoch 87/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1052 - accuracy: 0.9934\n",
      "Epoch 88/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1089 - accuracy: 0.9908\n",
      "Epoch 89/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0955 - accuracy: 0.9961\n",
      "Epoch 90/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0926 - accuracy: 0.9987\n",
      "Epoch 91/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1201 - accuracy: 0.9921\n",
      "Epoch 92/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1005 - accuracy: 0.9974\n",
      "Epoch 93/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1100 - accuracy: 0.9948\n",
      "Epoch 94/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1042 - accuracy: 0.9934\n",
      "Epoch 95/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1064 - accuracy: 0.9948\n",
      "Epoch 96/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1099 - accuracy: 0.9921\n",
      "Epoch 97/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0922 - accuracy: 0.9987\n",
      "Epoch 98/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0972 - accuracy: 0.9948\n",
      "Epoch 99/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0905 - accuracy: 0.9987\n",
      "Epoch 100/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0983 - accuracy: 0.9961\n",
      "Epoch 101/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1059 - accuracy: 0.9934\n",
      "Epoch 102/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1040 - accuracy: 0.9961\n",
      "Epoch 104/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1058 - accuracy: 0.9961\n",
      "Epoch 105/500\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.1001 - accuracy: 0.9948\n",
      "Epoch 106/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0927 - accuracy: 0.9934\n",
      "Epoch 107/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0880 - accuracy: 0.9974\n",
      "Epoch 108/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0986 - accuracy: 0.9948\n",
      "Epoch 109/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0954 - accuracy: 0.9974\n",
      "Epoch 110/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1027 - accuracy: 0.9921\n",
      "Epoch 111/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1131 - accuracy: 0.9974\n",
      "Epoch 112/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1087 - accuracy: 0.9948\n",
      "Epoch 113/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1064 - accuracy: 0.9948\n",
      "Epoch 114/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1035 - accuracy: 0.9961\n",
      "Epoch 115/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1034 - accuracy: 0.9974\n",
      "Epoch 116/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1073 - accuracy: 0.9948\n",
      "Epoch 117/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1020 - accuracy: 0.9948\n",
      "Epoch 118/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1057 - accuracy: 0.9921\n",
      "Epoch 119/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0983 - accuracy: 0.9974\n",
      "Epoch 120/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1035 - accuracy: 0.9921\n",
      "Epoch 121/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1158 - accuracy: 0.9908\n",
      "Epoch 122/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1186 - accuracy: 0.9948\n",
      "Epoch 123/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0982 - accuracy: 0.9948\n",
      "Epoch 124/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0969 - accuracy: 0.9921\n",
      "Epoch 125/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1003 - accuracy: 0.9961\n",
      "Epoch 126/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0854 - accuracy: 0.9987\n",
      "Epoch 127/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0988 - accuracy: 0.9948\n",
      "Epoch 128/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.0941 - accuracy: 0.9934\n",
      "Epoch 129/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1027 - accuracy: 0.9948\n",
      "Epoch 130/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1081 - accuracy: 0.9961\n",
      "Epoch 131/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1099 - accuracy: 0.9921\n",
      "Epoch 132/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0952 - accuracy: 0.9948\n",
      "Epoch 133/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0955 - accuracy: 0.9934\n",
      "Epoch 134/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1158 - accuracy: 0.9934\n",
      "Epoch 135/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0960 - accuracy: 0.9974\n",
      "Epoch 136/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 137/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0889 - accuracy: 0.9974\n",
      "Epoch 138/500\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1041 - accuracy: 0.9974\n",
      "Epoch 139/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0853 - accuracy: 0.9987\n",
      "Epoch 140/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0908 - accuracy: 0.9948\n",
      "Epoch 141/500\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.1103 - accuracy: 0.9987\n",
      "Epoch 142/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0998 - accuracy: 0.9961\n",
      "Epoch 143/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 144/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0941 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0983 - accuracy: 0.9974\n",
      "Epoch 146/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1010 - accuracy: 0.9934\n",
      "Epoch 147/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1028 - accuracy: 0.9961\n",
      "Epoch 148/500\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.0985 - accuracy: 0.9934\n",
      "Epoch 149/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1039 - accuracy: 0.9961\n",
      "Epoch 150/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0891 - accuracy: 0.9948\n",
      "Epoch 151/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1236 - accuracy: 0.9856\n",
      "Epoch 152/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0983 - accuracy: 0.9961\n",
      "Epoch 153/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.0995 - accuracy: 0.9921\n",
      "Epoch 154/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0905 - accuracy: 0.9961\n",
      "Epoch 155/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1036 - accuracy: 0.9948\n",
      "Epoch 156/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0914 - accuracy: 0.9987\n",
      "Epoch 157/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0856 - accuracy: 0.9961\n",
      "Epoch 158/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0961 - accuracy: 0.9934\n",
      "Epoch 159/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1034 - accuracy: 0.9908\n",
      "Epoch 160/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0905 - accuracy: 0.9961\n",
      "Epoch 161/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0820 - accuracy: 0.9974\n",
      "Epoch 162/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0947 - accuracy: 0.9948\n",
      "Epoch 163/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1104 - accuracy: 0.9961\n",
      "Epoch 164/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0815 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1029 - accuracy: 0.9948\n",
      "Epoch 166/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1151 - accuracy: 0.9921\n",
      "Epoch 167/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0825 - accuracy: 0.9987\n",
      "Epoch 168/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0894 - accuracy: 0.9974\n",
      "Epoch 169/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0817 - accuracy: 0.9961\n",
      "Epoch 170/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0991 - accuracy: 0.9934\n",
      "Epoch 171/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1094 - accuracy: 0.9921\n",
      "Epoch 172/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0885 - accuracy: 0.9948\n",
      "Epoch 173/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1052 - accuracy: 0.9921\n",
      "Epoch 174/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1057 - accuracy: 0.9948\n",
      "Epoch 175/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1124 - accuracy: 0.9961\n",
      "Epoch 176/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1130 - accuracy: 0.9869\n",
      "Epoch 177/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0890 - accuracy: 0.9961\n",
      "Epoch 178/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1030 - accuracy: 0.9961\n",
      "Epoch 179/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1058 - accuracy: 0.9948\n",
      "Epoch 180/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0926 - accuracy: 0.9987\n",
      "Epoch 181/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0962 - accuracy: 0.9961\n",
      "Epoch 182/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0810 - accuracy: 0.9987\n",
      "Epoch 183/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0867 - accuracy: 0.9961\n",
      "Epoch 184/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1256 - accuracy: 0.9869\n",
      "Epoch 185/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0938 - accuracy: 0.9961\n",
      "Epoch 186/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0870 - accuracy: 0.9974\n",
      "Epoch 187/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1050 - accuracy: 0.9961\n",
      "Epoch 188/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.0994 - accuracy: 0.9987\n",
      "Epoch 189/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0940 - accuracy: 0.9961\n",
      "Epoch 190/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0873 - accuracy: 0.9974\n",
      "Epoch 191/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1176 - accuracy: 0.9948\n",
      "Epoch 192/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 193/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0880 - accuracy: 0.9948\n",
      "Epoch 194/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1027 - accuracy: 0.9974\n",
      "Epoch 195/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0985 - accuracy: 0.9974\n",
      "Epoch 196/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1052 - accuracy: 0.9921\n",
      "Epoch 197/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1090 - accuracy: 0.9921\n",
      "Epoch 198/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0936 - accuracy: 0.9974\n",
      "Epoch 199/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0991 - accuracy: 0.9974\n",
      "Epoch 200/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1073 - accuracy: 0.9895\n",
      "Epoch 201/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1042 - accuracy: 0.9948\n",
      "Epoch 202/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1070 - accuracy: 0.9921\n",
      "Epoch 203/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1073 - accuracy: 0.9948\n",
      "Epoch 204/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1013 - accuracy: 0.9921\n",
      "Epoch 205/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1025 - accuracy: 0.9948\n",
      "Epoch 206/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1136 - accuracy: 0.9934\n",
      "Epoch 207/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1014 - accuracy: 0.9921\n",
      "Epoch 208/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.0982 - accuracy: 0.9934\n",
      "Epoch 209/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1250 - accuracy: 0.9908\n",
      "Epoch 210/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0890 - accuracy: 0.9948\n",
      "Epoch 211/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1081 - accuracy: 0.9948\n",
      "Epoch 212/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0899 - accuracy: 0.9987\n",
      "Epoch 213/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0988 - accuracy: 0.9934\n",
      "Epoch 214/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1054 - accuracy: 0.9934\n",
      "Epoch 215/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0890 - accuracy: 0.9974\n",
      "Epoch 216/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0979 - accuracy: 0.9921\n",
      "Epoch 217/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0881 - accuracy: 0.9987\n",
      "Epoch 218/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0862 - accuracy: 0.9974\n",
      "Epoch 219/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1099 - accuracy: 0.9961\n",
      "Epoch 220/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1010 - accuracy: 0.9948\n",
      "Epoch 221/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1042 - accuracy: 0.9961\n",
      "Epoch 222/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0830 - accuracy: 0.9987\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 159us/step - loss: 0.1005 - accuracy: 0.9961\n",
      "Epoch 224/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0948 - accuracy: 0.9921\n",
      "Epoch 225/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0869 - accuracy: 0.9961\n",
      "Epoch 226/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0988 - accuracy: 0.9948\n",
      "Epoch 227/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0964 - accuracy: 0.9948\n",
      "Epoch 228/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1001 - accuracy: 0.9948\n",
      "Epoch 229/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0940 - accuracy: 0.9921\n",
      "Epoch 230/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0968 - accuracy: 0.9921\n",
      "Epoch 231/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0942 - accuracy: 0.9948\n",
      "Epoch 232/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0879 - accuracy: 0.9961\n",
      "Epoch 233/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0961 - accuracy: 0.9934\n",
      "Epoch 234/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.1231 - accuracy: 0.9961\n",
      "Epoch 235/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1088 - accuracy: 0.9921\n",
      "Epoch 236/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1001 - accuracy: 0.9974\n",
      "Epoch 237/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0851 - accuracy: 0.9987\n",
      "Epoch 238/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1018 - accuracy: 0.9961\n",
      "Epoch 239/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0930 - accuracy: 0.9921\n",
      "Epoch 240/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.1009 - accuracy: 0.9974\n",
      "Epoch 241/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0933 - accuracy: 0.9961\n",
      "Epoch 242/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1098 - accuracy: 0.9961\n",
      "Epoch 243/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.1012 - accuracy: 0.9961\n",
      "Epoch 244/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.1012 - accuracy: 0.9921\n",
      "Epoch 245/500\n",
      "762/762 [==============================] - 0s 114us/step - loss: 0.0987 - accuracy: 0.9961\n",
      "Epoch 246/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0987 - accuracy: 0.9974\n",
      "Epoch 247/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0918 - accuracy: 0.9974\n",
      "Epoch 248/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0964 - accuracy: 0.9948\n",
      "Epoch 249/500\n",
      "762/762 [==============================] - 0s 121us/step - loss: 0.1014 - accuracy: 0.9961\n",
      "Epoch 250/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0917 - accuracy: 0.9961\n",
      "Epoch 251/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.1052 - accuracy: 0.9948\n",
      "Epoch 252/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0908 - accuracy: 0.9987\n",
      "Epoch 253/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0896 - accuracy: 0.9987\n",
      "Epoch 254/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.1026 - accuracy: 0.9948\n",
      "Epoch 255/500\n",
      "762/762 [==============================] - 0s 100us/step - loss: 0.0924 - accuracy: 0.9974\n",
      "Epoch 256/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0862 - accuracy: 0.9987\n",
      "Epoch 257/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0912 - accuracy: 0.9948\n",
      "Epoch 258/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0868 - accuracy: 0.9961\n",
      "Epoch 259/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0989 - accuracy: 0.9987\n",
      "Epoch 260/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1026 - accuracy: 0.9961\n",
      "Epoch 261/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0989 - accuracy: 0.9908\n",
      "Epoch 262/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0948 - accuracy: 0.9974\n",
      "Epoch 263/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0997 - accuracy: 0.9961\n",
      "Epoch 264/500\n",
      "762/762 [==============================] - 0s 97us/step - loss: 0.0980 - accuracy: 0.9948\n",
      "Epoch 265/500\n",
      "762/762 [==============================] - 0s 109us/step - loss: 0.0905 - accuracy: 0.9961\n",
      "Epoch 266/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0947 - accuracy: 0.9961\n",
      "Epoch 267/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0943 - accuracy: 0.9987\n",
      "Epoch 268/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.1033 - accuracy: 0.9921\n",
      "Epoch 269/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0914 - accuracy: 0.9974\n",
      "Epoch 270/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1194 - accuracy: 0.9921\n",
      "Epoch 271/500\n",
      "762/762 [==============================] - 0s 117us/step - loss: 0.0889 - accuracy: 0.9974\n",
      "Epoch 272/500\n",
      "762/762 [==============================] - 0s 112us/step - loss: 0.0912 - accuracy: 0.9974\n",
      "Epoch 273/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0912 - accuracy: 0.9948\n",
      "Epoch 274/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0864 - accuracy: 0.9948\n",
      "Epoch 275/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0959 - accuracy: 0.9961\n",
      "Epoch 276/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0941 - accuracy: 0.9921\n",
      "Epoch 277/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1006 - accuracy: 0.9948\n",
      "Epoch 278/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1030 - accuracy: 0.9961\n",
      "Epoch 279/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.0894 - accuracy: 0.9961\n",
      "Epoch 280/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1006 - accuracy: 0.9987\n",
      "Epoch 281/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0927 - accuracy: 0.9961\n",
      "Epoch 282/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0849 - accuracy: 0.9948\n",
      "Epoch 283/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0974 - accuracy: 0.9921\n",
      "Epoch 284/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1046 - accuracy: 0.9961\n",
      "Epoch 285/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0923 - accuracy: 0.9974\n",
      "Epoch 286/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0948 - accuracy: 0.9948\n",
      "Epoch 287/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0819 - accuracy: 0.9948\n",
      "Epoch 288/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1128 - accuracy: 0.9895\n",
      "Epoch 289/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.1030 - accuracy: 0.9961\n",
      "Epoch 290/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0923 - accuracy: 0.9974\n",
      "Epoch 291/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.1002 - accuracy: 0.9961\n",
      "Epoch 293/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1025 - accuracy: 0.9921\n",
      "Epoch 294/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0911 - accuracy: 0.9987\n",
      "Epoch 295/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1016 - accuracy: 0.9948\n",
      "Epoch 296/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1086 - accuracy: 0.9934\n",
      "Epoch 297/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.1139 - accuracy: 0.9882\n",
      "Epoch 298/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0930 - accuracy: 0.9987\n",
      "Epoch 299/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1060 - accuracy: 0.9934\n",
      "Epoch 300/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0990 - accuracy: 0.9974\n",
      "Epoch 301/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1018 - accuracy: 0.9882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/500\n",
      "762/762 [==============================] - 0s 172us/step - loss: 0.0935 - accuracy: 0.9987\n",
      "Epoch 303/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.1044 - accuracy: 0.9921\n",
      "Epoch 304/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0985 - accuracy: 0.9934\n",
      "Epoch 305/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0981 - accuracy: 0.9961\n",
      "Epoch 306/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1057 - accuracy: 0.9948\n",
      "Epoch 307/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0869 - accuracy: 0.9974\n",
      "Epoch 308/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0905 - accuracy: 0.9987\n",
      "Epoch 309/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1038 - accuracy: 0.9948\n",
      "Epoch 310/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0833 - accuracy: 0.9948\n",
      "Epoch 311/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0921 - accuracy: 0.9948\n",
      "Epoch 312/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0986 - accuracy: 0.9934\n",
      "Epoch 314/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0953 - accuracy: 0.9987\n",
      "Epoch 315/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0945 - accuracy: 0.9948\n",
      "Epoch 316/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0968 - accuracy: 0.9948\n",
      "Epoch 317/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0800 - accuracy: 0.9948\n",
      "Epoch 318/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0943 - accuracy: 0.9934\n",
      "Epoch 319/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0903 - accuracy: 0.9974\n",
      "Epoch 321/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0983 - accuracy: 0.9948\n",
      "Epoch 322/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1027 - accuracy: 0.9921\n",
      "Epoch 323/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1236 - accuracy: 0.9908\n",
      "Epoch 324/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0996 - accuracy: 0.9921\n",
      "Epoch 325/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1002 - accuracy: 0.9908\n",
      "Epoch 326/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0893 - accuracy: 0.9961\n",
      "Epoch 327/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1020 - accuracy: 0.9934\n",
      "Epoch 328/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0912 - accuracy: 0.9987\n",
      "Epoch 329/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1097 - accuracy: 0.9921\n",
      "Epoch 330/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.0901 - accuracy: 0.9987\n",
      "Epoch 331/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0941 - accuracy: 0.9961\n",
      "Epoch 332/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0996 - accuracy: 0.9948\n",
      "Epoch 333/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0940 - accuracy: 0.9974\n",
      "Epoch 334/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1011 - accuracy: 0.9974\n",
      "Epoch 335/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0846 - accuracy: 0.9987\n",
      "Epoch 336/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0999 - accuracy: 0.9961\n",
      "Epoch 337/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1051 - accuracy: 0.9961\n",
      "Epoch 338/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0909 - accuracy: 0.9974\n",
      "Epoch 339/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1008 - accuracy: 0.9895\n",
      "Epoch 340/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0884 - accuracy: 0.9987\n",
      "Epoch 341/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0927 - accuracy: 0.9961\n",
      "Epoch 342/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0885 - accuracy: 0.9948\n",
      "Epoch 343/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0875 - accuracy: 0.9961\n",
      "Epoch 344/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1027 - accuracy: 0.9948\n",
      "Epoch 345/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 346/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0923 - accuracy: 0.9921\n",
      "Epoch 347/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0943 - accuracy: 0.9934\n",
      "Epoch 348/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0993 - accuracy: 0.9934\n",
      "Epoch 349/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1080 - accuracy: 0.9921\n",
      "Epoch 350/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1037 - accuracy: 0.9948\n",
      "Epoch 351/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0901 - accuracy: 0.9961\n",
      "Epoch 352/500\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.0861 - accuracy: 0.9987\n",
      "Epoch 353/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.1007 - accuracy: 0.9908\n",
      "Epoch 354/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1072 - accuracy: 0.9961\n",
      "Epoch 355/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0861 - accuracy: 0.9974\n",
      "Epoch 356/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0786 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0872 - accuracy: 0.9948\n",
      "Epoch 358/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.0975 - accuracy: 0.9921\n",
      "Epoch 359/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0913 - accuracy: 0.9961\n",
      "Epoch 360/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0949 - accuracy: 0.9948\n",
      "Epoch 361/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.1069 - accuracy: 0.9948\n",
      "Epoch 362/500\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.1029 - accuracy: 0.9934\n",
      "Epoch 363/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0942 - accuracy: 0.9961\n",
      "Epoch 364/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0792 - accuracy: 0.9987\n",
      "Epoch 365/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.1072 - accuracy: 0.9934\n",
      "Epoch 366/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0904 - accuracy: 0.9974\n",
      "Epoch 367/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0908 - accuracy: 0.9987\n",
      "Epoch 368/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0901 - accuracy: 0.9961\n",
      "Epoch 369/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0925 - accuracy: 0.9961\n",
      "Epoch 370/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0905 - accuracy: 0.9948\n",
      "Epoch 371/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0955 - accuracy: 0.9987\n",
      "Epoch 372/500\n",
      "762/762 [==============================] - 0s 151us/step - loss: 0.0860 - accuracy: 0.9948\n",
      "Epoch 373/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0899 - accuracy: 0.9974\n",
      "Epoch 374/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0972 - accuracy: 0.9934\n",
      "Epoch 375/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0826 - accuracy: 0.9961\n",
      "Epoch 376/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0900 - accuracy: 0.9974\n",
      "Epoch 377/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0896 - accuracy: 0.9974\n",
      "Epoch 378/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0997 - accuracy: 0.9948\n",
      "Epoch 379/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0927 - accuracy: 0.9987\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/762 [==============================] - 0s 153us/step - loss: 0.0874 - accuracy: 0.9948\n",
      "Epoch 381/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0891 - accuracy: 0.9974\n",
      "Epoch 382/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0977 - accuracy: 0.9934\n",
      "Epoch 383/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1047 - accuracy: 0.9974\n",
      "Epoch 384/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0893 - accuracy: 0.9974\n",
      "Epoch 385/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0895 - accuracy: 0.9948\n",
      "Epoch 386/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1094 - accuracy: 0.9934\n",
      "Epoch 387/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1055 - accuracy: 0.9908\n",
      "Epoch 388/500\n",
      "762/762 [==============================] - 0s 111us/step - loss: 0.1085 - accuracy: 0.9934\n",
      "Epoch 389/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0897 - accuracy: 0.9934\n",
      "Epoch 390/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0924 - accuracy: 0.9948\n",
      "Epoch 391/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0905 - accuracy: 0.9974\n",
      "Epoch 392/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0870 - accuracy: 0.9948\n",
      "Epoch 393/500\n",
      "762/762 [==============================] - 0s 104us/step - loss: 0.0920 - accuracy: 0.9974\n",
      "Epoch 394/500\n",
      "762/762 [==============================] - 0s 98us/step - loss: 0.0868 - accuracy: 0.9961\n",
      "Epoch 395/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0900 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.1060 - accuracy: 0.9921\n",
      "Epoch 397/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0873 - accuracy: 0.9974\n",
      "Epoch 398/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0865 - accuracy: 0.9934\n",
      "Epoch 399/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0938 - accuracy: 0.9987\n",
      "Epoch 400/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0860 - accuracy: 0.9961\n",
      "Epoch 401/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.1050 - accuracy: 0.9921\n",
      "Epoch 402/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0951 - accuracy: 0.9934\n",
      "Epoch 403/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0944 - accuracy: 0.9948\n",
      "Epoch 404/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0918 - accuracy: 0.9948\n",
      "Epoch 405/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0899 - accuracy: 0.9961\n",
      "Epoch 406/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0992 - accuracy: 0.9974\n",
      "Epoch 407/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0789 - accuracy: 0.9974\n",
      "Epoch 408/500\n",
      "762/762 [==============================] - 0s 96us/step - loss: 0.0987 - accuracy: 0.9961\n",
      "Epoch 409/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0967 - accuracy: 0.9948\n",
      "Epoch 410/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0787 - accuracy: 0.9987\n",
      "Epoch 411/500\n",
      "762/762 [==============================] - 0s 101us/step - loss: 0.0906 - accuracy: 0.9974\n",
      "Epoch 412/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.0892 - accuracy: 0.9948\n",
      "Epoch 413/500\n",
      "762/762 [==============================] - 0s 102us/step - loss: 0.1011 - accuracy: 0.9948\n",
      "Epoch 414/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0945 - accuracy: 0.9961\n",
      "Epoch 415/500\n",
      "762/762 [==============================] - 0s 107us/step - loss: 0.0800 - accuracy: 0.9974\n",
      "Epoch 416/500\n",
      "762/762 [==============================] - 0s 105us/step - loss: 0.0867 - accuracy: 0.9961\n",
      "Epoch 417/500\n",
      "762/762 [==============================] - 0s 106us/step - loss: 0.0901 - accuracy: 0.9974\n",
      "Epoch 418/500\n",
      "762/762 [==============================] - 0s 108us/step - loss: 0.0888 - accuracy: 0.9948\n",
      "Epoch 419/500\n",
      "762/762 [==============================] - 0s 103us/step - loss: 0.0948 - accuracy: 0.9961\n",
      "Epoch 420/500\n",
      "762/762 [==============================] - 0s 114us/step - loss: 0.1016 - accuracy: 0.9948\n",
      "Epoch 421/500\n",
      "762/762 [==============================] - 0s 110us/step - loss: 0.0765 - accuracy: 0.9974\n",
      "Epoch 422/500\n",
      "762/762 [==============================] - 0s 99us/step - loss: 0.0902 - accuracy: 0.9921\n",
      "Epoch 423/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0900 - accuracy: 0.9934\n",
      "Epoch 424/500\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.0856 - accuracy: 0.9961\n",
      "Epoch 425/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0902 - accuracy: 0.9974\n",
      "Epoch 426/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.1097 - accuracy: 0.9921\n",
      "Epoch 427/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0924 - accuracy: 0.9961\n",
      "Epoch 428/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0968 - accuracy: 0.9961\n",
      "Epoch 429/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.1007 - accuracy: 0.9948\n",
      "Epoch 430/500\n",
      "762/762 [==============================] - 0s 148us/step - loss: 0.0854 - accuracy: 0.9934\n",
      "Epoch 431/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0984 - accuracy: 0.9948\n",
      "Epoch 432/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0836 - accuracy: 0.9987\n",
      "Epoch 433/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.1006 - accuracy: 0.9948\n",
      "Epoch 434/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.1024 - accuracy: 0.9948\n",
      "Epoch 435/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0865 - accuracy: 0.9974\n",
      "Epoch 436/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0898 - accuracy: 0.9974\n",
      "Epoch 437/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0970 - accuracy: 0.9921\n",
      "Epoch 438/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0883 - accuracy: 0.9961\n",
      "Epoch 439/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0979 - accuracy: 0.9974\n",
      "Epoch 440/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0907 - accuracy: 0.9948\n",
      "Epoch 441/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.1008 - accuracy: 0.9921\n",
      "Epoch 442/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0851 - accuracy: 0.9934\n",
      "Epoch 443/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0872 - accuracy: 0.9974\n",
      "Epoch 444/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0812 - accuracy: 0.9961\n",
      "Epoch 445/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0922 - accuracy: 0.9961\n",
      "Epoch 446/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0965 - accuracy: 0.9974\n",
      "Epoch 447/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0984 - accuracy: 0.9961\n",
      "Epoch 448/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.1025 - accuracy: 0.9934\n",
      "Epoch 449/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0849 - accuracy: 0.9961\n",
      "Epoch 450/500\n",
      "762/762 [==============================] - 0s 157us/step - loss: 0.0827 - accuracy: 0.9961\n",
      "Epoch 451/500\n",
      "762/762 [==============================] - 0s 152us/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0932 - accuracy: 0.9961\n",
      "Epoch 453/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0875 - accuracy: 0.9974\n",
      "Epoch 454/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0885 - accuracy: 0.9974\n",
      "Epoch 455/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0756 - accuracy: 0.9961\n",
      "Epoch 456/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0945 - accuracy: 0.9961\n",
      "Epoch 457/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0956 - accuracy: 0.9948\n",
      "Epoch 458/500\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.0818 - accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0927 - accuracy: 0.9961\n",
      "Epoch 460/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0824 - accuracy: 0.9974\n",
      "Epoch 461/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0961 - accuracy: 0.9948\n",
      "Epoch 462/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.1021 - accuracy: 0.9948\n",
      "Epoch 463/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.0949 - accuracy: 0.9987\n",
      "Epoch 464/500\n",
      "762/762 [==============================] - 0s 164us/step - loss: 0.0919 - accuracy: 0.9948\n",
      "Epoch 465/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0871 - accuracy: 0.9974\n",
      "Epoch 466/500\n",
      "762/762 [==============================] - 0s 170us/step - loss: 0.0856 - accuracy: 0.9974\n",
      "Epoch 467/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0917 - accuracy: 0.9961\n",
      "Epoch 468/500\n",
      "762/762 [==============================] - 0s 150us/step - loss: 0.0900 - accuracy: 0.9987\n",
      "Epoch 469/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0957 - accuracy: 0.9974\n",
      "Epoch 470/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0927 - accuracy: 0.9948\n",
      "Epoch 471/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0816 - accuracy: 0.9974\n",
      "Epoch 472/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0954 - accuracy: 0.9948\n",
      "Epoch 473/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0899 - accuracy: 0.9948\n",
      "Epoch 474/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0792 - accuracy: 0.9974\n",
      "Epoch 475/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0950 - accuracy: 0.9961\n",
      "Epoch 476/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0949 - accuracy: 0.9974\n",
      "Epoch 477/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0960 - accuracy: 0.9961\n",
      "Epoch 478/500\n",
      "762/762 [==============================] - 0s 168us/step - loss: 0.0799 - accuracy: 0.9987\n",
      "Epoch 479/500\n",
      "762/762 [==============================] - 0s 149us/step - loss: 0.0807 - accuracy: 0.9974\n",
      "Epoch 480/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0749 - accuracy: 0.9974\n",
      "Epoch 481/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0999 - accuracy: 0.9934\n",
      "Epoch 482/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0926 - accuracy: 0.9961\n",
      "Epoch 483/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0906 - accuracy: 0.9974\n",
      "Epoch 484/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.1095 - accuracy: 0.9948\n",
      "Epoch 485/500\n",
      "762/762 [==============================] - 0s 158us/step - loss: 0.0803 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "762/762 [==============================] - 0s 165us/step - loss: 0.1032 - accuracy: 0.9908\n",
      "Epoch 487/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0879 - accuracy: 0.9934\n",
      "Epoch 488/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0914 - accuracy: 0.9987\n",
      "Epoch 489/500\n",
      "762/762 [==============================] - 0s 155us/step - loss: 0.0919 - accuracy: 0.9948\n",
      "Epoch 490/500\n",
      "762/762 [==============================] - 0s 162us/step - loss: 0.0899 - accuracy: 0.9948\n",
      "Epoch 491/500\n",
      "762/762 [==============================] - 0s 163us/step - loss: 0.0863 - accuracy: 0.9961\n",
      "Epoch 492/500\n",
      "762/762 [==============================] - 0s 161us/step - loss: 0.0876 - accuracy: 0.9961\n",
      "Epoch 493/500\n",
      "762/762 [==============================] - 0s 153us/step - loss: 0.0851 - accuracy: 0.9987\n",
      "Epoch 494/500\n",
      "762/762 [==============================] - 0s 159us/step - loss: 0.0925 - accuracy: 0.9948\n",
      "Epoch 495/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "762/762 [==============================] - 0s 156us/step - loss: 0.0792 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "762/762 [==============================] - 0s 160us/step - loss: 0.0925 - accuracy: 0.9974\n",
      "Epoch 498/500\n",
      "762/762 [==============================] - 0s 154us/step - loss: 0.0992 - accuracy: 0.9948\n",
      "Epoch 499/500\n",
      "762/762 [==============================] - 0s 169us/step - loss: 0.0872 - accuracy: 0.9921\n",
      "Epoch 500/500\n",
      "762/762 [==============================] - 0s 166us/step - loss: 0.0945 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# create a new net\n",
    "rf_net = ddnet.create_DDNet(C)\n",
    "\n",
    "lr = 1e-3\n",
    "rf_net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "\n",
    "history1 = rf_net.fit([X_rf_0,X_rf_1],Y_rf,\n",
    "                    batch_size=len(Y_rf),\n",
    "                    epochs=800,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    sample_weight=rf_sample_weight\n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "rf_net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "\n",
    "history2 = rf_net.fit([X_rf_0,X_rf_1],Y_rf,\n",
    "                    batch_size=len(Y_rf),\n",
    "                    epochs=500,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    sample_weight=rf_sample_weight\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # the first 600 epochs\n",
    "    plot_accuracy(history1)\n",
    "    plot_loss(history1)\n",
    "    # the next 500 epochs\n",
    "    plot_accuracy(history2)\n",
    "    plot_loss(history2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jhmdb_le.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'jhmdb_openpose_model_15_refit.h5'\n",
    "ddnet.save_DDNet(rf_net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back from disk\n",
    "new_net = ddnet.load_DDNet(model_path)\n",
    "# Evaluate against test set, you should get the same accuracy\n",
    "new_net.evaluate([X_test_0,X_test_1],Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
