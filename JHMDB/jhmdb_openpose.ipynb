{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# <project_root>/ddnet/ddnet.py\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(''), '..', 'ddnet'))\n",
    "import ddnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "# directory that contains pickle files\n",
    "data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'openpose_zeros_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(T, C, le):\n",
    "    \"\"\"\n",
    "    Generate X (list of arrays) and Y (array) from a dict \n",
    "    \"\"\"\n",
    "    X = T['pose'] # list of arrays\n",
    "    Y = np.zeros(shape=(len(T['label']), C.clc_num)) # 2D array one-hot encoding of labels\n",
    "    Y[range(Y.shape[0]), le.transform(T['label'])] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for plotting\n",
    "# history is a history object from keras\n",
    "def plot_accuracy(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = pickle.load(open(os.path.join(data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test = pickle.load(open(os.path.join(data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 (40, 25, 2) (497, 21)\n",
      "195 (40, 25, 2) (195, 21)\n"
     ]
    }
   ],
   "source": [
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=25, joint_dim=2, num_classes=21, num_filters=32)\n",
    "\n",
    "X, Y = data_generator(Train,C,le)\n",
    "X_test,Y_test = data_generator(Test,C,le)\n",
    "\n",
    "print(len(X), X[0].shape, Y.shape)\n",
    "print(len(X_test), X_test[0].shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Invisible Joints with `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video without any nan: 4 out of 497\n",
      "nan entries in X_nan: 270780 out of 923200\n"
     ]
    }
   ],
   "source": [
    "def make_nan(p, copy=True):\n",
    "    \"\"\"\n",
    "    Convert 0 values to np.nan\n",
    "    \"\"\"\n",
    "    assert isinstance(p, np.ndarray)\n",
    "    q = p.copy() if copy else p\n",
    "    q[q == 0] = np.nan\n",
    "    return q\n",
    "\n",
    "def has_nan(p):\n",
    "    assert isinstance(p, np.ndarray)\n",
    "    return np.isnan(p).any()\n",
    "\n",
    "def count_nan(p):\n",
    "    assert isinstance(p, np.ndarray)\n",
    "    return np.isnan(p).sum()\n",
    "\n",
    "X_nan = list(map(make_nan, X))\n",
    "X_test_nan = list(map(make_nan, X_test))\n",
    "\n",
    "print(\"Video without any nan: {} out of {}\".format(len([p for p in X_nan if not has_nan(p)]), len(X_nan)))\n",
    "print(\"nan entries in X_nan: {} out of {}\".format(sum(map(count_nan, X_nan)), sum([p.size for p in X_nan])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* Select a subset of frequently-detected joints\n",
    "* Temporal interpolate\n",
    "* Fill the others with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10394   442   618  3416  7010   554  3772  8436  3498  4018 12290 17528\n",
      "  4020 12806 17696 12510 14292  7452 10258 20162 21580 18834 19672 20894\n",
      " 18628]\n",
      "Good joint indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 17, 18]\n",
      "[3420  480  552 1564 2446  596 1726 3214 1190 1322 3750 5560 1366 3772\n",
      " 6122 4244 5216 3394 5422 7196 7746 6594 6538 7154 6030]\n",
      "Good joint indices of test set:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 17]\n",
      "Video with nan before/after selecting top joints: 493 / 473\n",
      "nan entries in before/after selecting top joints: 270780 / 98076. Total 553920\n"
     ]
    }
   ],
   "source": [
    "def find_top_joints(X_nan, top=15):\n",
    "    \"\"\"\n",
    "    Find the indices of the `top` most frequently-detected joints \"\"\"\n",
    "    count_nan_per_joint = np.array([sum([count_nan(p[:, j, :]) for p in X_nan]) for j in range(X_nan[0].shape[1])])\n",
    "    print(count_nan_per_joint)\n",
    "#     print(np.sort(count_nan_per_joint))\n",
    "    good_joint_idx = np.argsort(count_nan_per_joint)[:top]\n",
    "    return good_joint_idx\n",
    "\n",
    "good_joint_idx = find_top_joints(X_nan)\n",
    "print(\"Good joint indices:\", sorted(good_joint_idx.tolist()))\n",
    "\n",
    "# note: the most frequently visible joints are not the same for train and test\n",
    "test_good_joint_idx = find_top_joints(X_test_nan)\n",
    "print(\"Good joint indices of test set: \", sorted(test_good_joint_idx.tolist()))\n",
    "\n",
    "\n",
    "HAND_PICKED_GOOD_JOINTS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16]\n",
    "\n",
    "good_joint_idx = HAND_PICKED_GOOD_JOINTS\n",
    "\n",
    "def filter_joints(p, good_joint_idx):\n",
    "    \"\"\"\n",
    "    Filter a point by only keeping joints in good_joint_idx\n",
    "    \"\"\"\n",
    "    return p[:, good_joint_idx, :]\n",
    "\n",
    "X_topj = [filter_joints(p, good_joint_idx) for p in X_nan]\n",
    "X_test_topj = [filter_joints(p, good_joint_idx) for p in X_test_nan]\n",
    "\n",
    "print(\"Video with nan before/after selecting top joints: {} / {}\".format(\n",
    "    sum(map(has_nan, X_nan)),\n",
    "    sum(map(has_nan, X_topj))\n",
    "))\n",
    "\n",
    "print(\"nan entries in before/after selecting top joints: {} / {}. Total {}\".format(\n",
    "    sum(map(count_nan, X_nan)),\n",
    "    sum(map(count_nan, X_topj)),\n",
    "    sum([p.size for p in X_topj])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with nan before/after temporal interp: 473 / 223\n",
      "nan entries in before/after temporal interp: 98076 / 41972\n"
     ]
    }
   ],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper function to handle real indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def temporal_interp(p):\n",
    "    \"\"\"\n",
    "    If a joint is detected in at least one frame in a video, \n",
    "    we interpolate the nan coordinates from other frames.\n",
    "    This is done independently for each joint.\n",
    "    Note: it can still leave some all-nan columns if a joint is never detected in any frame.\n",
    "    \"\"\"\n",
    "    p = p.copy()\n",
    "    for j in range(p.shape[1]): # joint\n",
    "        for coord in range(p.shape[2]): # x, y (,z)\n",
    "            view = p[:, j, coord]\n",
    "            if np.isnan(view).all() or  not np.isnan(view).any():\n",
    "                continue\n",
    "            nans, idx = nan_helper(view)\n",
    "            view[nans]= np.interp(idx(nans), idx(~nans), view[~nans])\n",
    "    return p\n",
    "\n",
    "X_interp = list(map(temporal_interp, X_topj))\n",
    "X_test_interp = list(map(temporal_interp, X_test_topj))\n",
    "\n",
    "\n",
    "print(\"Video with nan before/after temporal interp: {} / {}\".format(\n",
    "    sum(map(has_nan, X_topj)),\n",
    "    sum(map(has_nan, X_interp))\n",
    "))\n",
    "\n",
    "print(\"nan entries in before/after temporal interp: {} / {}\".format(\n",
    "    sum(map(count_nan, X_topj)),\n",
    "    sum(map(count_nan, X_interp))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_video_normalize(p, copy=True):\n",
    "    \"\"\"\n",
    "    For x,y[, z] independently:\n",
    "        Normalize into between -0.5~0.5\n",
    "    \"\"\"\n",
    "    q = p.copy() if copy else p\n",
    "    for coord in range(p.shape[2]):\n",
    "        view = q[:, :, coord]\n",
    "        a, b = np.nanmin(view), np.nanmax(view)\n",
    "#         q[:,:, coord] = (view - np.mean(view)) / np.std(view)\n",
    "        view[:] = ((view - a) / (b-a)) - 0.5\n",
    "\n",
    "    return q\n",
    "\n",
    "X_norm = [per_video_normalize(p) for p in X_interp]\n",
    "X_test_norm = [per_video_normalize(p) for p in X_test_interp]\n",
    "\n",
    "# print(X_norm[0][:,:,1])\n",
    "# print(X_test_norm[0][:,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2485 (2485, 21)\n",
      "[[        nan         nan]\n",
      " [ 0.35648388 -0.31977062]\n",
      " [ 0.40983151 -0.28174566]\n",
      " [ 0.3976841  -0.12309938]\n",
      " [ 0.39350666  0.0025622 ]\n",
      " [ 0.29927431 -0.34172396]\n",
      " [        nan         nan]\n",
      " [        nan         nan]\n",
      " [ 0.1599167  -0.19988977]\n",
      " [ 0.19673124 -0.19405013]\n",
      " [ 0.26252287  0.0187348 ]\n",
      " [ 0.12693885 -0.22700958]\n",
      " [ 0.09422604  0.01910504]\n",
      " [        nan         nan]\n",
      " [        nan         nan]] \n",
      "\n",
      " [[-0.278425   -0.00348136]\n",
      " [ 0.35648388 -0.31977062]\n",
      " [ 0.40983151 -0.28174566]\n",
      " [ 0.3976841  -0.12309938]\n",
      " [ 0.39350666  0.0025622 ]\n",
      " [ 0.29927431 -0.34172396]\n",
      " [-0.09498228  0.10119946]\n",
      " [-0.02302251 -0.16290479]\n",
      " [ 0.1599167  -0.19988977]\n",
      " [ 0.19673124 -0.19405013]\n",
      " [ 0.26252287  0.0187348 ]\n",
      " [ 0.12693885 -0.22700958]\n",
      " [ 0.09422604  0.01910504]\n",
      " [ 0.00697112  0.18625269]\n",
      " [ 0.49414327 -0.00382072]] \n",
      "\n",
      " [[-0.32108098  0.17762828]\n",
      " [ 0.35649019 -0.3198716 ]\n",
      " [ 0.4098252  -0.28691214]\n",
      " [ 0.39764624 -0.12313304]\n",
      " [ 0.39762731  0.00794746]\n",
      " [ 0.299268   -0.34179969]\n",
      " [ 0.14022634  0.39012078]\n",
      " [-0.29589614  0.01916862]\n",
      " [ 0.15996088 -0.20503942]\n",
      " [ 0.19677541 -0.19407538]\n",
      " [ 0.26249763  0.01876846]\n",
      " [ 0.1269704  -0.23226021]\n",
      " [ 0.09423866  0.01901248]\n",
      " [-0.24072831  0.21928841]\n",
      " [-0.49536641 -0.02997678]]\n"
     ]
    }
   ],
   "source": [
    "# fill in the remaining nans\n",
    "\n",
    "# def per_frame_fill_mean(p, copy=True):\n",
    "#     \"\"\"\n",
    "#     For each frame independently:\n",
    "#         for x, y[, z] independently:\n",
    "#             Fill nan entries with the mean of all other joints' coordinates\n",
    "#     This is defnitely not perfect, but may help.\n",
    "#     \"\"\"\n",
    "#     q = p.copy() if copy else p\n",
    "#     for f in range(q.shape[0]):\n",
    "#         for coord in range(q.shape[2]): # x,y\n",
    "#             view = q[f, :, coord]\n",
    "#             view[np.isnan(view)] = np.nanmean(view)\n",
    "    \n",
    "#     return q\n",
    "    \n",
    "def fill_nan_random(p, copy=True, sigma=.5):\n",
    "    \"\"\"\n",
    "    Fill nan values with normal distribution\n",
    "    \"\"\"\n",
    "    q = p.copy() if copy else p\n",
    "    q[np.isnan(q)] = np.random.randn(np.count_nonzero(np.isnan(q))) * sigma\n",
    "    return q\n",
    "\n",
    "def fill_nan_uniform(p, copy=True, a=-0.5, b=0.5):\n",
    "    \"\"\"\n",
    "    Fill nan values with normal distribution\n",
    "    \"\"\"\n",
    "    q = p.copy() if copy else p\n",
    "    q[np.isnan(q)] = np.random.random((np.count_nonzero(np.isnan(q)),)) * (b-a) + a\n",
    "    return q\n",
    "\n",
    "def fill_nan_bottom(p, copy=True):\n",
    "    q = p.copy() if copy else p\n",
    "    xview = q[:,:,0]\n",
    "    xview[np.isnan(xview)] = 0.\n",
    "    yview = q[:,:,1]\n",
    "    yview[np.isnan(yview)] = 0.5\n",
    "    return q\n",
    "    \n",
    "\n",
    "# def fill_nan_col_random(p, copy=True, sigma=.1)\n",
    "#     \"\"\"\n",
    "#     Fill each nan column with the same value drawn from normal distribution\n",
    "#     \"\"\"\n",
    "#     q = p.copy() if copy else p\n",
    "#     for j in range(q.shape[1]):\n",
    "#         for coord in range(q.shape[2]):\n",
    "#             view = q[:, j, coord]\n",
    "#             if np.all(np.isnan(view)):\n",
    "#                 view[:] = np.random.randn(1) * sigma\n",
    "#     return q\n",
    "\n",
    "def augment_nan(X, Y, num=5):\n",
    "    \"\"\"\n",
    "    Data augmentation.\n",
    "    X is a list of arrays.\n",
    "    \"\"\"\n",
    "    Xa = []\n",
    "    Ya = []\n",
    "    for p1, y1 in zip(X, Y):\n",
    "        Xa.extend([fill_nan_uniform(p1) for _ in range(num)])\n",
    "        Ya.extend([y1] * num)\n",
    "\n",
    "    Ya = np.stack(Ya)\n",
    "    assert len(Xa) == Ya.shape[0]\n",
    "    return Xa, Ya\n",
    "\n",
    "\n",
    "X_aug, Y_aug = augment_nan(X_norm, Y)\n",
    "print(len(X_aug), Y_aug.shape)\n",
    "\n",
    "\n",
    "# X_fillnan = [fill_nan_random(p, sigma=0.5) for p in X_norm]\n",
    "X_test_fillnan = [fill_nan_random(p, sigma=0.0) for p in X_test_norm]\n",
    "\n",
    "print(X_norm[0][0], \"\\n\\n\", X_aug[0][0], \"\\n\\n\", X_aug[1][1])\n",
    "    \n",
    "# assert not any (map(has_nan, X_fillnan))\n",
    "# X_fillnan[0][:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "X_input, Y_input = X_aug, Y_aug\n",
    "X_test_input, Y_test_input = X_test_fillnan, Y_test\n",
    "print(X_input[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDNet's preprocess and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine config with new # of joints\n",
    "C = ddnet.DDNetConfig(frame_length=32, num_joints=len(good_joint_idx), joint_dim=2, num_classes=21, num_filters=32)\n",
    "\n",
    "X_0, X_1 = ddnet.preprocess_batch(X_input, C)\n",
    "X_test_0, X_test_1 = ddnet.preprocess_batch(X_test_input, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 105)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 15, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                (None, 4, 256)       436544      M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 256)          0           model_11[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          32768       global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 128)          512         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_101 (LeakyReLU)     (None, 128)          0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           leaky_re_lu_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          16384       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 128)          512         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)     (None, 128)          0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128)          0           leaky_re_lu_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 21)           2709        dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 489,429\n",
      "Trainable params: 486,357\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net = ddnet.create_DDNet(C)\n",
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test and Save/Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2485 samples, validate on 195 samples\n",
      "Epoch 1/800\n",
      "2485/2485 [==============================] - 8s 3ms/step - loss: 3.8438 - accuracy: 0.0499 - val_loss: 3.0428 - val_accuracy: 0.1026\n",
      "Epoch 2/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 3.5350 - accuracy: 0.0620 - val_loss: 3.0413 - val_accuracy: 0.0821\n",
      "Epoch 3/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 3.4099 - accuracy: 0.0785 - val_loss: 3.0399 - val_accuracy: 0.0462\n",
      "Epoch 4/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 3.2856 - accuracy: 0.1010 - val_loss: 3.0377 - val_accuracy: 0.0923\n",
      "Epoch 5/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 3.1464 - accuracy: 0.1264 - val_loss: 3.0342 - val_accuracy: 0.1231\n",
      "Epoch 6/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 3.0409 - accuracy: 0.1384 - val_loss: 3.0289 - val_accuracy: 0.1385\n",
      "Epoch 7/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 2.9308 - accuracy: 0.1581 - val_loss: 3.0206 - val_accuracy: 0.1333\n",
      "Epoch 8/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 2.8794 - accuracy: 0.1803 - val_loss: 3.0101 - val_accuracy: 0.1333\n",
      "Epoch 9/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.8009 - accuracy: 0.1980 - val_loss: 2.9972 - val_accuracy: 0.1333\n",
      "Epoch 10/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 2.7002 - accuracy: 0.2201 - val_loss: 2.9831 - val_accuracy: 0.1282\n",
      "Epoch 11/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.6171 - accuracy: 0.2334 - val_loss: 2.9689 - val_accuracy: 0.1385\n",
      "Epoch 12/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 2.5793 - accuracy: 0.2596 - val_loss: 2.9540 - val_accuracy: 0.1385\n",
      "Epoch 13/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.5096 - accuracy: 0.2765 - val_loss: 2.9393 - val_accuracy: 0.1436\n",
      "Epoch 14/800\n",
      "2485/2485 [==============================] - 0s 81us/step - loss: 2.4241 - accuracy: 0.2974 - val_loss: 2.9236 - val_accuracy: 0.1487\n",
      "Epoch 15/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.3768 - accuracy: 0.3038 - val_loss: 2.9082 - val_accuracy: 0.1436\n",
      "Epoch 16/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 2.3272 - accuracy: 0.3131 - val_loss: 2.8940 - val_accuracy: 0.1487\n",
      "Epoch 17/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.2593 - accuracy: 0.3256 - val_loss: 2.8812 - val_accuracy: 0.1231\n",
      "Epoch 18/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 2.2274 - accuracy: 0.3513 - val_loss: 2.8696 - val_accuracy: 0.1282\n",
      "Epoch 19/800\n",
      "2485/2485 [==============================] - 0s 84us/step - loss: 2.1493 - accuracy: 0.3577 - val_loss: 2.8591 - val_accuracy: 0.1333\n",
      "Epoch 20/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 2.1024 - accuracy: 0.3722 - val_loss: 2.8494 - val_accuracy: 0.1436\n",
      "Epoch 21/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 2.0666 - accuracy: 0.3855 - val_loss: 2.8392 - val_accuracy: 0.1436\n",
      "Epoch 22/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 2.0438 - accuracy: 0.3811 - val_loss: 2.8295 - val_accuracy: 0.1385\n",
      "Epoch 23/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 1.9299 - accuracy: 0.4241 - val_loss: 2.8179 - val_accuracy: 0.1487\n",
      "Epoch 24/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 1.9113 - accuracy: 0.4205 - val_loss: 2.8063 - val_accuracy: 0.1487\n",
      "Epoch 25/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 1.8769 - accuracy: 0.4338 - val_loss: 2.7950 - val_accuracy: 0.1538\n",
      "Epoch 26/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 1.8178 - accuracy: 0.4414 - val_loss: 2.7831 - val_accuracy: 0.1487\n",
      "Epoch 27/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.8114 - accuracy: 0.4503 - val_loss: 2.7722 - val_accuracy: 0.1641\n",
      "Epoch 28/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 1.7834 - accuracy: 0.4604 - val_loss: 2.7615 - val_accuracy: 0.1744\n",
      "Epoch 29/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 1.7126 - accuracy: 0.4877 - val_loss: 2.7501 - val_accuracy: 0.1795\n",
      "Epoch 30/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.6993 - accuracy: 0.4740 - val_loss: 2.7383 - val_accuracy: 0.1744\n",
      "Epoch 31/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.6554 - accuracy: 0.4990 - val_loss: 2.7280 - val_accuracy: 0.1744\n",
      "Epoch 32/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 1.6004 - accuracy: 0.5082 - val_loss: 2.7198 - val_accuracy: 0.1744\n",
      "Epoch 33/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 1.5968 - accuracy: 0.5111 - val_loss: 2.7122 - val_accuracy: 0.1744\n",
      "Epoch 34/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 1.5821 - accuracy: 0.5195 - val_loss: 2.7031 - val_accuracy: 0.1744\n",
      "Epoch 35/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 1.5449 - accuracy: 0.5211 - val_loss: 2.6944 - val_accuracy: 0.1744\n",
      "Epoch 36/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 1.5363 - accuracy: 0.5388 - val_loss: 2.6869 - val_accuracy: 0.1692\n",
      "Epoch 37/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 1.4998 - accuracy: 0.5396 - val_loss: 2.6786 - val_accuracy: 0.1692\n",
      "Epoch 38/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 1.4424 - accuracy: 0.5569 - val_loss: 2.6676 - val_accuracy: 0.1692\n",
      "Epoch 39/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 1.4148 - accuracy: 0.5618 - val_loss: 2.6592 - val_accuracy: 0.1692\n",
      "Epoch 40/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.3981 - accuracy: 0.5742 - val_loss: 2.6526 - val_accuracy: 0.1744\n",
      "Epoch 41/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 1.3897 - accuracy: 0.5686 - val_loss: 2.6440 - val_accuracy: 0.1744\n",
      "Epoch 42/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 1.3694 - accuracy: 0.5710 - val_loss: 2.6339 - val_accuracy: 0.1795\n",
      "Epoch 43/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 1.3061 - accuracy: 0.5879 - val_loss: 2.6253 - val_accuracy: 0.1795\n",
      "Epoch 44/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 1.3122 - accuracy: 0.6004 - val_loss: 2.6168 - val_accuracy: 0.1795\n",
      "Epoch 45/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 1.2783 - accuracy: 0.6080 - val_loss: 2.6075 - val_accuracy: 0.1846\n",
      "Epoch 46/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 1.2561 - accuracy: 0.6105 - val_loss: 2.5950 - val_accuracy: 0.1897\n",
      "Epoch 47/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 1.2135 - accuracy: 0.6201 - val_loss: 2.5792 - val_accuracy: 0.1949\n",
      "Epoch 48/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 1.1793 - accuracy: 0.6439 - val_loss: 2.5600 - val_accuracy: 0.2000\n",
      "Epoch 49/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 1.1817 - accuracy: 0.6274 - val_loss: 2.5401 - val_accuracy: 0.2051\n",
      "Epoch 50/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 1.1533 - accuracy: 0.6414 - val_loss: 2.5235 - val_accuracy: 0.2103\n",
      "Epoch 51/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.1457 - accuracy: 0.6386 - val_loss: 2.5100 - val_accuracy: 0.2256\n",
      "Epoch 52/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.1208 - accuracy: 0.6535 - val_loss: 2.4964 - val_accuracy: 0.2308\n",
      "Epoch 53/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 1.1134 - accuracy: 0.6608 - val_loss: 2.4851 - val_accuracy: 0.2359\n",
      "Epoch 54/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 1.0801 - accuracy: 0.6624 - val_loss: 2.4773 - val_accuracy: 0.2308\n",
      "Epoch 55/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.0704 - accuracy: 0.6648 - val_loss: 2.4716 - val_accuracy: 0.2308\n",
      "Epoch 56/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 1.0622 - accuracy: 0.6704 - val_loss: 2.4652 - val_accuracy: 0.2308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 1.0111 - accuracy: 0.6849 - val_loss: 2.4567 - val_accuracy: 0.2256\n",
      "Epoch 58/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 1.0199 - accuracy: 0.6845 - val_loss: 2.4498 - val_accuracy: 0.2154\n",
      "Epoch 59/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.9899 - accuracy: 0.6966 - val_loss: 2.4459 - val_accuracy: 0.2154\n",
      "Epoch 60/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.9749 - accuracy: 0.7054 - val_loss: 2.4435 - val_accuracy: 0.2205\n",
      "Epoch 61/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.9512 - accuracy: 0.6998 - val_loss: 2.4423 - val_accuracy: 0.2359\n",
      "Epoch 62/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.9228 - accuracy: 0.7139 - val_loss: 2.4455 - val_accuracy: 0.2359\n",
      "Epoch 63/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.9292 - accuracy: 0.7155 - val_loss: 2.4447 - val_accuracy: 0.2308\n",
      "Epoch 64/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.9204 - accuracy: 0.7191 - val_loss: 2.4402 - val_accuracy: 0.2308\n",
      "Epoch 65/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.8953 - accuracy: 0.7191 - val_loss: 2.4344 - val_accuracy: 0.2410\n",
      "Epoch 66/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.8519 - accuracy: 0.7320 - val_loss: 2.4246 - val_accuracy: 0.2410\n",
      "Epoch 67/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.8390 - accuracy: 0.7453 - val_loss: 2.4176 - val_accuracy: 0.2410\n",
      "Epoch 68/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.8625 - accuracy: 0.7292 - val_loss: 2.4096 - val_accuracy: 0.2359\n",
      "Epoch 69/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.8209 - accuracy: 0.7441 - val_loss: 2.4046 - val_accuracy: 0.2308\n",
      "Epoch 70/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.8057 - accuracy: 0.7537 - val_loss: 2.4038 - val_accuracy: 0.2308\n",
      "Epoch 71/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.7858 - accuracy: 0.7626 - val_loss: 2.4054 - val_accuracy: 0.2308\n",
      "Epoch 72/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.7898 - accuracy: 0.7545 - val_loss: 2.4077 - val_accuracy: 0.2308\n",
      "Epoch 73/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.7601 - accuracy: 0.7682 - val_loss: 2.4144 - val_accuracy: 0.2308\n",
      "Epoch 74/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.7349 - accuracy: 0.7779 - val_loss: 2.4201 - val_accuracy: 0.2205\n",
      "Epoch 75/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.7227 - accuracy: 0.7763 - val_loss: 2.4232 - val_accuracy: 0.2103\n",
      "Epoch 76/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.7469 - accuracy: 0.7819 - val_loss: 2.4181 - val_accuracy: 0.2154\n",
      "Epoch 77/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.7212 - accuracy: 0.7811 - val_loss: 2.4075 - val_accuracy: 0.2256\n",
      "Epoch 78/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.7037 - accuracy: 0.7807 - val_loss: 2.3929 - val_accuracy: 0.2410\n",
      "Epoch 79/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.7059 - accuracy: 0.7819 - val_loss: 2.3803 - val_accuracy: 0.2564\n",
      "Epoch 80/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.6766 - accuracy: 0.8020 - val_loss: 2.3674 - val_accuracy: 0.2667\n",
      "Epoch 81/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.6565 - accuracy: 0.8020 - val_loss: 2.3581 - val_accuracy: 0.2667\n",
      "Epoch 82/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.6516 - accuracy: 0.8089 - val_loss: 2.3551 - val_accuracy: 0.2564\n",
      "Epoch 83/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.6521 - accuracy: 0.8044 - val_loss: 2.3596 - val_accuracy: 0.2462\n",
      "Epoch 84/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.6389 - accuracy: 0.8089 - val_loss: 2.3706 - val_accuracy: 0.2359\n",
      "Epoch 85/800\n",
      "2485/2485 [==============================] - 0s 82us/step - loss: 0.6194 - accuracy: 0.8153 - val_loss: 2.3829 - val_accuracy: 0.2359\n",
      "Epoch 86/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.6126 - accuracy: 0.8181 - val_loss: 2.3870 - val_accuracy: 0.2564\n",
      "Epoch 87/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.5936 - accuracy: 0.8306 - val_loss: 2.3910 - val_accuracy: 0.2667\n",
      "Epoch 88/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.5867 - accuracy: 0.8294 - val_loss: 2.3864 - val_accuracy: 0.2821\n",
      "Epoch 89/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.5602 - accuracy: 0.8342 - val_loss: 2.3652 - val_accuracy: 0.2974\n",
      "Epoch 90/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.5592 - accuracy: 0.8439 - val_loss: 2.3373 - val_accuracy: 0.3282\n",
      "Epoch 91/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.5485 - accuracy: 0.8414 - val_loss: 2.3183 - val_accuracy: 0.3333\n",
      "Epoch 92/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.5285 - accuracy: 0.8467 - val_loss: 2.3059 - val_accuracy: 0.3436\n",
      "Epoch 93/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.5378 - accuracy: 0.8459 - val_loss: 2.3137 - val_accuracy: 0.3385\n",
      "Epoch 94/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.5382 - accuracy: 0.8423 - val_loss: 2.3245 - val_accuracy: 0.3538\n",
      "Epoch 95/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.4993 - accuracy: 0.8608 - val_loss: 2.3347 - val_accuracy: 0.3282\n",
      "Epoch 96/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.4939 - accuracy: 0.8608 - val_loss: 2.3384 - val_accuracy: 0.3333\n",
      "Epoch 97/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.5032 - accuracy: 0.8596 - val_loss: 2.3452 - val_accuracy: 0.3436\n",
      "Epoch 98/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.4734 - accuracy: 0.8608 - val_loss: 2.3512 - val_accuracy: 0.3333\n",
      "Epoch 99/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.4677 - accuracy: 0.8680 - val_loss: 2.3604 - val_accuracy: 0.3282\n",
      "Epoch 100/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.4634 - accuracy: 0.8664 - val_loss: 2.3601 - val_accuracy: 0.3282\n",
      "Epoch 101/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.4591 - accuracy: 0.8724 - val_loss: 2.3560 - val_accuracy: 0.3231\n",
      "Epoch 102/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.4513 - accuracy: 0.8744 - val_loss: 2.3423 - val_accuracy: 0.3231\n",
      "Epoch 103/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.4303 - accuracy: 0.8793 - val_loss: 2.3296 - val_accuracy: 0.3282\n",
      "Epoch 104/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.4040 - accuracy: 0.8901 - val_loss: 2.3276 - val_accuracy: 0.3333\n",
      "Epoch 105/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.3953 - accuracy: 0.8861 - val_loss: 2.3268 - val_accuracy: 0.3282\n",
      "Epoch 106/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.4002 - accuracy: 0.8877 - val_loss: 2.3231 - val_accuracy: 0.3436\n",
      "Epoch 107/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.4051 - accuracy: 0.8873 - val_loss: 2.3202 - val_accuracy: 0.3487\n",
      "Epoch 108/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3911 - accuracy: 0.9010 - val_loss: 2.3213 - val_accuracy: 0.3436\n",
      "Epoch 109/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3956 - accuracy: 0.8950 - val_loss: 2.3199 - val_accuracy: 0.3436\n",
      "Epoch 110/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.3747 - accuracy: 0.9002 - val_loss: 2.3270 - val_accuracy: 0.3436\n",
      "Epoch 111/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.3535 - accuracy: 0.9119 - val_loss: 2.3473 - val_accuracy: 0.3333\n",
      "Epoch 112/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.3475 - accuracy: 0.9082 - val_loss: 2.3687 - val_accuracy: 0.3179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3519 - accuracy: 0.9038 - val_loss: 2.3869 - val_accuracy: 0.3026\n",
      "Epoch 114/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.3592 - accuracy: 0.9054 - val_loss: 2.3724 - val_accuracy: 0.3128\n",
      "Epoch 115/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3379 - accuracy: 0.9131 - val_loss: 2.3418 - val_accuracy: 0.3077\n",
      "Epoch 116/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.3378 - accuracy: 0.9123 - val_loss: 2.3105 - val_accuracy: 0.3282\n",
      "Epoch 117/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.3478 - accuracy: 0.9082 - val_loss: 2.2903 - val_accuracy: 0.3282\n",
      "Epoch 118/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.3108 - accuracy: 0.9195 - val_loss: 2.2833 - val_accuracy: 0.3333\n",
      "Epoch 119/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.3114 - accuracy: 0.9159 - val_loss: 2.2893 - val_accuracy: 0.3282\n",
      "Epoch 120/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3074 - accuracy: 0.9163 - val_loss: 2.3059 - val_accuracy: 0.3333\n",
      "Epoch 121/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.3110 - accuracy: 0.9171 - val_loss: 2.3234 - val_accuracy: 0.3231\n",
      "Epoch 122/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.3018 - accuracy: 0.9235 - val_loss: 2.3368 - val_accuracy: 0.3282\n",
      "Epoch 123/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.2856 - accuracy: 0.9312 - val_loss: 2.3471 - val_accuracy: 0.3333\n",
      "Epoch 124/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.2943 - accuracy: 0.9260 - val_loss: 2.3456 - val_accuracy: 0.3385\n",
      "Epoch 125/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.2802 - accuracy: 0.9308 - val_loss: 2.3442 - val_accuracy: 0.3436\n",
      "Epoch 126/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.2756 - accuracy: 0.9288 - val_loss: 2.3371 - val_accuracy: 0.3590\n",
      "Epoch 127/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.2530 - accuracy: 0.9408 - val_loss: 2.3316 - val_accuracy: 0.3641\n",
      "Epoch 128/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.2526 - accuracy: 0.9425 - val_loss: 2.3103 - val_accuracy: 0.3538\n",
      "Epoch 129/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.2541 - accuracy: 0.9376 - val_loss: 2.2975 - val_accuracy: 0.3590\n",
      "Epoch 130/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.2480 - accuracy: 0.9421 - val_loss: 2.2906 - val_accuracy: 0.3692\n",
      "Epoch 131/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.2391 - accuracy: 0.9445 - val_loss: 2.2910 - val_accuracy: 0.3487\n",
      "Epoch 132/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.2300 - accuracy: 0.9445 - val_loss: 2.3087 - val_accuracy: 0.3436\n",
      "Epoch 133/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.2300 - accuracy: 0.9525 - val_loss: 2.3421 - val_accuracy: 0.3385\n",
      "Epoch 134/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.2180 - accuracy: 0.9493 - val_loss: 2.3681 - val_accuracy: 0.3385\n",
      "Epoch 135/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.2191 - accuracy: 0.9509 - val_loss: 2.3850 - val_accuracy: 0.3436\n",
      "Epoch 136/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.2123 - accuracy: 0.9521 - val_loss: 2.3833 - val_accuracy: 0.3436\n",
      "Epoch 137/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.2084 - accuracy: 0.9525 - val_loss: 2.3879 - val_accuracy: 0.3487\n",
      "Epoch 138/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1974 - accuracy: 0.9610 - val_loss: 2.3898 - val_accuracy: 0.3538\n",
      "Epoch 139/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.2015 - accuracy: 0.9553 - val_loss: 2.3912 - val_accuracy: 0.3641\n",
      "Epoch 140/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.2031 - accuracy: 0.9509 - val_loss: 2.3768 - val_accuracy: 0.3641\n",
      "Epoch 141/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1861 - accuracy: 0.9610 - val_loss: 2.3556 - val_accuracy: 0.3641\n",
      "Epoch 142/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1987 - accuracy: 0.9521 - val_loss: 2.3306 - val_accuracy: 0.3692\n",
      "Epoch 143/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1885 - accuracy: 0.9545 - val_loss: 2.3117 - val_accuracy: 0.3744\n",
      "Epoch 144/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1912 - accuracy: 0.9557 - val_loss: 2.3211 - val_accuracy: 0.3692\n",
      "Epoch 145/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.1880 - accuracy: 0.9586 - val_loss: 2.3426 - val_accuracy: 0.3744\n",
      "Epoch 146/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.1779 - accuracy: 0.9614 - val_loss: 2.3740 - val_accuracy: 0.3641\n",
      "Epoch 147/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1726 - accuracy: 0.9662 - val_loss: 2.3942 - val_accuracy: 0.3641\n",
      "Epoch 148/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1704 - accuracy: 0.9618 - val_loss: 2.4111 - val_accuracy: 0.3744\n",
      "Epoch 149/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1587 - accuracy: 0.9694 - val_loss: 2.4265 - val_accuracy: 0.3641\n",
      "Epoch 150/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.1699 - accuracy: 0.9598 - val_loss: 2.4105 - val_accuracy: 0.3590\n",
      "Epoch 151/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.1651 - accuracy: 0.9650 - val_loss: 2.3797 - val_accuracy: 0.3846\n",
      "Epoch 152/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.1545 - accuracy: 0.9686 - val_loss: 2.3457 - val_accuracy: 0.3795\n",
      "Epoch 153/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1493 - accuracy: 0.9726 - val_loss: 2.3184 - val_accuracy: 0.3949\n",
      "Epoch 154/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.1600 - accuracy: 0.9686 - val_loss: 2.3097 - val_accuracy: 0.3897\n",
      "Epoch 155/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.1522 - accuracy: 0.9702 - val_loss: 2.3221 - val_accuracy: 0.3897\n",
      "Epoch 156/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.1467 - accuracy: 0.9678 - val_loss: 2.3205 - val_accuracy: 0.3949\n",
      "Epoch 157/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.1486 - accuracy: 0.9694 - val_loss: 2.3101 - val_accuracy: 0.3949\n",
      "Epoch 158/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1414 - accuracy: 0.9742 - val_loss: 2.3051 - val_accuracy: 0.4000\n",
      "Epoch 159/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1387 - accuracy: 0.9694 - val_loss: 2.3180 - val_accuracy: 0.4051\n",
      "Epoch 160/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.1256 - accuracy: 0.9775 - val_loss: 2.3223 - val_accuracy: 0.4256\n",
      "Epoch 161/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1215 - accuracy: 0.9767 - val_loss: 2.3372 - val_accuracy: 0.4359\n",
      "Epoch 162/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.1216 - accuracy: 0.9795 - val_loss: 2.3574 - val_accuracy: 0.4256\n",
      "Epoch 163/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.1293 - accuracy: 0.9726 - val_loss: 2.3911 - val_accuracy: 0.4256\n",
      "Epoch 164/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.1290 - accuracy: 0.9746 - val_loss: 2.4046 - val_accuracy: 0.4000\n",
      "Epoch 165/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1346 - accuracy: 0.9710 - val_loss: 2.4121 - val_accuracy: 0.3949\n",
      "Epoch 166/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1368 - accuracy: 0.9706 - val_loss: 2.4059 - val_accuracy: 0.4000\n",
      "Epoch 167/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.1108 - accuracy: 0.9791 - val_loss: 2.4075 - val_accuracy: 0.4000\n",
      "Epoch 168/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1141 - accuracy: 0.9771 - val_loss: 2.4162 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1199 - accuracy: 0.9755 - val_loss: 2.4224 - val_accuracy: 0.4000\n",
      "Epoch 170/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1138 - accuracy: 0.9791 - val_loss: 2.4194 - val_accuracy: 0.4051\n",
      "Epoch 171/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1113 - accuracy: 0.9819 - val_loss: 2.4230 - val_accuracy: 0.4103\n",
      "Epoch 172/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 2.4237 - val_accuracy: 0.4103\n",
      "Epoch 173/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1079 - accuracy: 0.9791 - val_loss: 2.4274 - val_accuracy: 0.4051\n",
      "Epoch 174/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.1052 - accuracy: 0.9835 - val_loss: 2.4365 - val_accuracy: 0.4205\n",
      "Epoch 175/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.1021 - accuracy: 0.9827 - val_loss: 2.4462 - val_accuracy: 0.4308\n",
      "Epoch 176/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1060 - accuracy: 0.9831 - val_loss: 2.4453 - val_accuracy: 0.4359\n",
      "Epoch 177/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.1070 - accuracy: 0.9791 - val_loss: 2.4451 - val_accuracy: 0.4462\n",
      "Epoch 178/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1059 - accuracy: 0.9827 - val_loss: 2.4451 - val_accuracy: 0.4410\n",
      "Epoch 179/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.1082 - accuracy: 0.9795 - val_loss: 2.4461 - val_accuracy: 0.4410\n",
      "Epoch 180/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1027 - accuracy: 0.9815 - val_loss: 2.4455 - val_accuracy: 0.4359\n",
      "Epoch 181/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0964 - accuracy: 0.9839 - val_loss: 2.4464 - val_accuracy: 0.4410\n",
      "Epoch 182/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.1029 - accuracy: 0.9835 - val_loss: 2.4463 - val_accuracy: 0.4410\n",
      "Epoch 183/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1024 - accuracy: 0.9815 - val_loss: 2.4487 - val_accuracy: 0.4410\n",
      "Epoch 184/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0965 - accuracy: 0.9843 - val_loss: 2.4512 - val_accuracy: 0.4410\n",
      "Epoch 185/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0990 - accuracy: 0.9803 - val_loss: 2.4528 - val_accuracy: 0.4359\n",
      "Epoch 186/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0970 - accuracy: 0.9847 - val_loss: 2.4493 - val_accuracy: 0.4359\n",
      "Epoch 187/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1002 - accuracy: 0.9815 - val_loss: 2.4462 - val_accuracy: 0.4410\n",
      "Epoch 188/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0984 - accuracy: 0.9823 - val_loss: 2.4456 - val_accuracy: 0.4462\n",
      "Epoch 189/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.1075 - accuracy: 0.9771 - val_loss: 2.4455 - val_accuracy: 0.4462\n",
      "Epoch 190/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.1024 - accuracy: 0.9803 - val_loss: 2.4474 - val_accuracy: 0.4410\n",
      "Epoch 191/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1037 - accuracy: 0.9811 - val_loss: 2.4503 - val_accuracy: 0.4410\n",
      "Epoch 192/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1024 - accuracy: 0.9799 - val_loss: 2.4536 - val_accuracy: 0.4410\n",
      "Epoch 193/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0971 - accuracy: 0.9835 - val_loss: 2.4567 - val_accuracy: 0.4410\n",
      "Epoch 194/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1062 - accuracy: 0.9795 - val_loss: 2.4601 - val_accuracy: 0.4410\n",
      "Epoch 195/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1038 - accuracy: 0.9795 - val_loss: 2.4637 - val_accuracy: 0.4462\n",
      "Epoch 196/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0902 - accuracy: 0.9823 - val_loss: 2.4661 - val_accuracy: 0.4462\n",
      "Epoch 197/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0944 - accuracy: 0.9831 - val_loss: 2.4670 - val_accuracy: 0.4462\n",
      "Epoch 198/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0992 - accuracy: 0.9823 - val_loss: 2.4665 - val_accuracy: 0.4462\n",
      "Epoch 199/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0909 - accuracy: 0.9843 - val_loss: 2.4647 - val_accuracy: 0.4462\n",
      "Epoch 200/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0911 - accuracy: 0.9863 - val_loss: 2.4625 - val_accuracy: 0.4462\n",
      "Epoch 201/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0928 - accuracy: 0.9819 - val_loss: 2.4588 - val_accuracy: 0.4462\n",
      "Epoch 202/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0977 - accuracy: 0.9827 - val_loss: 2.4580 - val_accuracy: 0.4513\n",
      "Epoch 203/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0918 - accuracy: 0.9831 - val_loss: 2.4573 - val_accuracy: 0.4513\n",
      "Epoch 204/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0903 - accuracy: 0.9879 - val_loss: 2.4565 - val_accuracy: 0.4513\n",
      "Epoch 205/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0943 - accuracy: 0.9851 - val_loss: 2.4556 - val_accuracy: 0.4564\n",
      "Epoch 206/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0933 - accuracy: 0.9847 - val_loss: 2.4552 - val_accuracy: 0.4564\n",
      "Epoch 207/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0920 - accuracy: 0.9835 - val_loss: 2.4550 - val_accuracy: 0.4564\n",
      "Epoch 208/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1037 - accuracy: 0.9811 - val_loss: 2.4552 - val_accuracy: 0.4564\n",
      "Epoch 209/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0943 - accuracy: 0.9823 - val_loss: 2.4552 - val_accuracy: 0.4564\n",
      "Epoch 210/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0904 - accuracy: 0.9863 - val_loss: 2.4559 - val_accuracy: 0.4564\n",
      "Epoch 211/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0923 - accuracy: 0.9835 - val_loss: 2.4566 - val_accuracy: 0.4564\n",
      "Epoch 212/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0965 - accuracy: 0.9867 - val_loss: 2.4578 - val_accuracy: 0.4615\n",
      "Epoch 213/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0913 - accuracy: 0.9851 - val_loss: 2.4588 - val_accuracy: 0.4615\n",
      "Epoch 214/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0994 - accuracy: 0.9803 - val_loss: 2.4599 - val_accuracy: 0.4615\n",
      "Epoch 215/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0899 - accuracy: 0.9839 - val_loss: 2.4611 - val_accuracy: 0.4615\n",
      "Epoch 216/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0934 - accuracy: 0.9839 - val_loss: 2.4621 - val_accuracy: 0.4564\n",
      "Epoch 217/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.1006 - accuracy: 0.9827 - val_loss: 2.4631 - val_accuracy: 0.4513\n",
      "Epoch 218/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0886 - accuracy: 0.9847 - val_loss: 2.4642 - val_accuracy: 0.4513\n",
      "Epoch 219/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0928 - accuracy: 0.9863 - val_loss: 2.4650 - val_accuracy: 0.4513\n",
      "Epoch 220/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1021 - accuracy: 0.9827 - val_loss: 2.4657 - val_accuracy: 0.4564\n",
      "Epoch 221/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0987 - accuracy: 0.9795 - val_loss: 2.4660 - val_accuracy: 0.4615\n",
      "Epoch 222/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0927 - accuracy: 0.9835 - val_loss: 2.4663 - val_accuracy: 0.4615\n",
      "Epoch 223/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0953 - accuracy: 0.9835 - val_loss: 2.4665 - val_accuracy: 0.4615\n",
      "Epoch 224/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1043 - accuracy: 0.9811 - val_loss: 2.4666 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0919 - accuracy: 0.9859 - val_loss: 2.4665 - val_accuracy: 0.4615\n",
      "Epoch 226/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1015 - accuracy: 0.9791 - val_loss: 2.4666 - val_accuracy: 0.4615\n",
      "Epoch 227/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0919 - accuracy: 0.9847 - val_loss: 2.4663 - val_accuracy: 0.4615\n",
      "Epoch 228/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.1033 - accuracy: 0.9819 - val_loss: 2.4664 - val_accuracy: 0.4615\n",
      "Epoch 229/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0896 - accuracy: 0.9871 - val_loss: 2.4661 - val_accuracy: 0.4615\n",
      "Epoch 230/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0948 - accuracy: 0.9827 - val_loss: 2.4658 - val_accuracy: 0.4615\n",
      "Epoch 231/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0924 - accuracy: 0.9863 - val_loss: 2.4656 - val_accuracy: 0.4615\n",
      "Epoch 232/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0995 - accuracy: 0.9839 - val_loss: 2.4652 - val_accuracy: 0.4564\n",
      "Epoch 233/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 2.4649 - val_accuracy: 0.4564\n",
      "Epoch 234/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0983 - accuracy: 0.9823 - val_loss: 2.4649 - val_accuracy: 0.4615\n",
      "Epoch 235/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0855 - accuracy: 0.9883 - val_loss: 2.4646 - val_accuracy: 0.4615\n",
      "Epoch 236/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.1023 - accuracy: 0.9835 - val_loss: 2.4644 - val_accuracy: 0.4615\n",
      "Epoch 237/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0975 - accuracy: 0.9827 - val_loss: 2.4641 - val_accuracy: 0.4615\n",
      "Epoch 238/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0886 - accuracy: 0.9859 - val_loss: 2.4638 - val_accuracy: 0.4615\n",
      "Epoch 239/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0883 - accuracy: 0.9843 - val_loss: 2.4635 - val_accuracy: 0.4615\n",
      "Epoch 240/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0909 - accuracy: 0.9855 - val_loss: 2.4633 - val_accuracy: 0.4615\n",
      "Epoch 241/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0955 - accuracy: 0.9835 - val_loss: 2.4628 - val_accuracy: 0.4615\n",
      "Epoch 242/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0966 - accuracy: 0.9811 - val_loss: 2.4624 - val_accuracy: 0.4615\n",
      "Epoch 243/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0996 - accuracy: 0.9779 - val_loss: 2.4620 - val_accuracy: 0.4615\n",
      "Epoch 244/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0897 - accuracy: 0.9875 - val_loss: 2.4616 - val_accuracy: 0.4667\n",
      "Epoch 245/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0836 - accuracy: 0.9879 - val_loss: 2.4614 - val_accuracy: 0.4667\n",
      "Epoch 246/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0902 - accuracy: 0.9839 - val_loss: 2.4613 - val_accuracy: 0.4667\n",
      "Epoch 247/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0857 - accuracy: 0.9887 - val_loss: 2.4611 - val_accuracy: 0.4667\n",
      "Epoch 248/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0941 - accuracy: 0.9855 - val_loss: 2.4612 - val_accuracy: 0.4667\n",
      "Epoch 249/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0931 - accuracy: 0.9827 - val_loss: 2.4613 - val_accuracy: 0.4667\n",
      "Epoch 250/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0951 - accuracy: 0.9819 - val_loss: 2.4614 - val_accuracy: 0.4615\n",
      "Epoch 251/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.1021 - accuracy: 0.9771 - val_loss: 2.4617 - val_accuracy: 0.4615\n",
      "Epoch 252/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.1029 - accuracy: 0.9799 - val_loss: 2.4620 - val_accuracy: 0.4615\n",
      "Epoch 253/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.1006 - accuracy: 0.9811 - val_loss: 2.4622 - val_accuracy: 0.4564\n",
      "Epoch 254/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0962 - accuracy: 0.9831 - val_loss: 2.4625 - val_accuracy: 0.4615\n",
      "Epoch 255/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0934 - accuracy: 0.9847 - val_loss: 2.4623 - val_accuracy: 0.4615\n",
      "Epoch 256/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0976 - accuracy: 0.9811 - val_loss: 2.4623 - val_accuracy: 0.4615\n",
      "Epoch 257/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0886 - accuracy: 0.9875 - val_loss: 2.4625 - val_accuracy: 0.4615\n",
      "Epoch 258/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0873 - accuracy: 0.9879 - val_loss: 2.4627 - val_accuracy: 0.4615\n",
      "Epoch 259/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0984 - accuracy: 0.9815 - val_loss: 2.4627 - val_accuracy: 0.4667\n",
      "Epoch 260/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.1010 - accuracy: 0.9827 - val_loss: 2.4629 - val_accuracy: 0.4667\n",
      "Epoch 261/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0921 - accuracy: 0.9851 - val_loss: 2.4629 - val_accuracy: 0.4667\n",
      "Epoch 262/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0894 - accuracy: 0.9863 - val_loss: 2.4628 - val_accuracy: 0.4667\n",
      "Epoch 263/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0977 - accuracy: 0.9819 - val_loss: 2.4630 - val_accuracy: 0.4667\n",
      "Epoch 264/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0965 - accuracy: 0.9807 - val_loss: 2.4630 - val_accuracy: 0.4667\n",
      "Epoch 265/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0943 - accuracy: 0.9835 - val_loss: 2.4631 - val_accuracy: 0.4667\n",
      "Epoch 266/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0946 - accuracy: 0.9835 - val_loss: 2.4633 - val_accuracy: 0.4667\n",
      "Epoch 267/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0965 - accuracy: 0.9811 - val_loss: 2.4634 - val_accuracy: 0.4667\n",
      "Epoch 268/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0887 - accuracy: 0.9859 - val_loss: 2.4635 - val_accuracy: 0.4667\n",
      "Epoch 269/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0873 - accuracy: 0.9867 - val_loss: 2.4634 - val_accuracy: 0.4667\n",
      "Epoch 270/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1050 - accuracy: 0.9815 - val_loss: 2.4635 - val_accuracy: 0.4667\n",
      "Epoch 271/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0940 - accuracy: 0.9839 - val_loss: 2.4636 - val_accuracy: 0.4667\n",
      "Epoch 272/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0882 - accuracy: 0.9855 - val_loss: 2.4637 - val_accuracy: 0.4667\n",
      "Epoch 273/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.1026 - accuracy: 0.9775 - val_loss: 2.4637 - val_accuracy: 0.4615\n",
      "Epoch 274/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0950 - accuracy: 0.9839 - val_loss: 2.4637 - val_accuracy: 0.4615\n",
      "Epoch 275/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0940 - accuracy: 0.9839 - val_loss: 2.4636 - val_accuracy: 0.4615\n",
      "Epoch 276/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0926 - accuracy: 0.9827 - val_loss: 2.4631 - val_accuracy: 0.4615\n",
      "Epoch 277/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0942 - accuracy: 0.9827 - val_loss: 2.4627 - val_accuracy: 0.4615\n",
      "Epoch 278/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0961 - accuracy: 0.9831 - val_loss: 2.4623 - val_accuracy: 0.4615\n",
      "Epoch 279/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0991 - accuracy: 0.9847 - val_loss: 2.4620 - val_accuracy: 0.4615\n",
      "Epoch 280/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0862 - accuracy: 0.9875 - val_loss: 2.4617 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0966 - accuracy: 0.9851 - val_loss: 2.4611 - val_accuracy: 0.4667\n",
      "Epoch 282/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0843 - accuracy: 0.9875 - val_loss: 2.4607 - val_accuracy: 0.4718\n",
      "Epoch 283/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0943 - accuracy: 0.9823 - val_loss: 2.4602 - val_accuracy: 0.4718\n",
      "Epoch 284/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1005 - accuracy: 0.9807 - val_loss: 2.4598 - val_accuracy: 0.4718\n",
      "Epoch 285/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0922 - accuracy: 0.9819 - val_loss: 2.4594 - val_accuracy: 0.4718\n",
      "Epoch 286/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0953 - accuracy: 0.9827 - val_loss: 2.4590 - val_accuracy: 0.4718\n",
      "Epoch 287/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0885 - accuracy: 0.9851 - val_loss: 2.4585 - val_accuracy: 0.4667\n",
      "Epoch 288/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0838 - accuracy: 0.9887 - val_loss: 2.4580 - val_accuracy: 0.4667\n",
      "Epoch 289/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0925 - accuracy: 0.9835 - val_loss: 2.4576 - val_accuracy: 0.4667\n",
      "Epoch 290/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0857 - accuracy: 0.9847 - val_loss: 2.4573 - val_accuracy: 0.4667\n",
      "Epoch 291/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0905 - accuracy: 0.9839 - val_loss: 2.4568 - val_accuracy: 0.4667\n",
      "Epoch 292/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0899 - accuracy: 0.9823 - val_loss: 2.4566 - val_accuracy: 0.4667\n",
      "Epoch 293/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0857 - accuracy: 0.9863 - val_loss: 2.4562 - val_accuracy: 0.4718\n",
      "Epoch 294/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0858 - accuracy: 0.9879 - val_loss: 2.4558 - val_accuracy: 0.4718\n",
      "Epoch 295/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0902 - accuracy: 0.9835 - val_loss: 2.4555 - val_accuracy: 0.4769\n",
      "Epoch 296/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0969 - accuracy: 0.9811 - val_loss: 2.4552 - val_accuracy: 0.4769\n",
      "Epoch 297/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0870 - accuracy: 0.9859 - val_loss: 2.4549 - val_accuracy: 0.4769\n",
      "Epoch 298/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0902 - accuracy: 0.9867 - val_loss: 2.4550 - val_accuracy: 0.4769\n",
      "Epoch 299/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0911 - accuracy: 0.9831 - val_loss: 2.4548 - val_accuracy: 0.4769\n",
      "Epoch 300/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0919 - accuracy: 0.9847 - val_loss: 2.4546 - val_accuracy: 0.4769\n",
      "Epoch 301/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0951 - accuracy: 0.9823 - val_loss: 2.4545 - val_accuracy: 0.4769\n",
      "Epoch 302/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0953 - accuracy: 0.9851 - val_loss: 2.4543 - val_accuracy: 0.4769\n",
      "Epoch 303/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0922 - accuracy: 0.9855 - val_loss: 2.4541 - val_accuracy: 0.4769\n",
      "Epoch 304/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0895 - accuracy: 0.9855 - val_loss: 2.4540 - val_accuracy: 0.4769\n",
      "Epoch 305/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 2.4539 - val_accuracy: 0.4769\n",
      "Epoch 306/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0923 - accuracy: 0.9843 - val_loss: 2.4539 - val_accuracy: 0.4769\n",
      "Epoch 307/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.1020 - accuracy: 0.9819 - val_loss: 2.4537 - val_accuracy: 0.4769\n",
      "Epoch 308/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9811 - val_loss: 2.4536 - val_accuracy: 0.4769\n",
      "Epoch 309/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0900 - accuracy: 0.9859 - val_loss: 2.4533 - val_accuracy: 0.4769\n",
      "Epoch 310/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0879 - accuracy: 0.9879 - val_loss: 2.4531 - val_accuracy: 0.4769\n",
      "Epoch 311/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0905 - accuracy: 0.9855 - val_loss: 2.4528 - val_accuracy: 0.4769\n",
      "Epoch 312/800\n",
      "2485/2485 [==============================] - 0s 57us/step - loss: 0.0908 - accuracy: 0.9855 - val_loss: 2.4524 - val_accuracy: 0.4769\n",
      "Epoch 313/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0949 - accuracy: 0.9835 - val_loss: 2.4519 - val_accuracy: 0.4769\n",
      "Epoch 314/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0953 - accuracy: 0.9855 - val_loss: 2.4515 - val_accuracy: 0.4769\n",
      "Epoch 315/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0921 - accuracy: 0.9827 - val_loss: 2.4511 - val_accuracy: 0.4769\n",
      "Epoch 316/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0950 - accuracy: 0.9827 - val_loss: 2.4505 - val_accuracy: 0.4769\n",
      "Epoch 317/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0974 - accuracy: 0.9827 - val_loss: 2.4498 - val_accuracy: 0.4769\n",
      "Epoch 318/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0835 - accuracy: 0.9879 - val_loss: 2.4492 - val_accuracy: 0.4769\n",
      "Epoch 319/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0843 - accuracy: 0.9855 - val_loss: 2.4481 - val_accuracy: 0.4821\n",
      "Epoch 320/800\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0913 - accuracy: 0.9831 - val_loss: 2.4470 - val_accuracy: 0.4821\n",
      "Epoch 321/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0897 - accuracy: 0.9855 - val_loss: 2.4461 - val_accuracy: 0.4821\n",
      "Epoch 322/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0884 - accuracy: 0.9839 - val_loss: 2.4450 - val_accuracy: 0.4821\n",
      "Epoch 323/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0957 - accuracy: 0.9819 - val_loss: 2.4441 - val_accuracy: 0.4821\n",
      "Epoch 324/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0897 - accuracy: 0.9855 - val_loss: 2.4432 - val_accuracy: 0.4821\n",
      "Epoch 325/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0891 - accuracy: 0.9867 - val_loss: 2.4423 - val_accuracy: 0.4821\n",
      "Epoch 326/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0917 - accuracy: 0.9851 - val_loss: 2.4417 - val_accuracy: 0.4821\n",
      "Epoch 327/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0870 - accuracy: 0.9871 - val_loss: 2.4409 - val_accuracy: 0.4821\n",
      "Epoch 328/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0959 - accuracy: 0.9819 - val_loss: 2.4403 - val_accuracy: 0.4821\n",
      "Epoch 329/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0993 - accuracy: 0.9811 - val_loss: 2.4395 - val_accuracy: 0.4769\n",
      "Epoch 330/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0915 - accuracy: 0.9867 - val_loss: 2.4386 - val_accuracy: 0.4769\n",
      "Epoch 331/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0954 - accuracy: 0.9855 - val_loss: 2.4378 - val_accuracy: 0.4769\n",
      "Epoch 332/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0881 - accuracy: 0.9863 - val_loss: 2.4372 - val_accuracy: 0.4769\n",
      "Epoch 333/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.1046 - accuracy: 0.9783 - val_loss: 2.4367 - val_accuracy: 0.4769\n",
      "Epoch 334/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0898 - accuracy: 0.9867 - val_loss: 2.4361 - val_accuracy: 0.4769\n",
      "Epoch 335/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0908 - accuracy: 0.9883 - val_loss: 2.4356 - val_accuracy: 0.4769\n",
      "Epoch 336/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0914 - accuracy: 0.9831 - val_loss: 2.4349 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0862 - accuracy: 0.9871 - val_loss: 2.4341 - val_accuracy: 0.4821\n",
      "Epoch 338/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0879 - accuracy: 0.9851 - val_loss: 2.4334 - val_accuracy: 0.4821\n",
      "Epoch 339/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0840 - accuracy: 0.9867 - val_loss: 2.4327 - val_accuracy: 0.4821\n",
      "Epoch 340/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0900 - accuracy: 0.9855 - val_loss: 2.4319 - val_accuracy: 0.4821\n",
      "Epoch 341/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0830 - accuracy: 0.9883 - val_loss: 2.4310 - val_accuracy: 0.4821\n",
      "Epoch 342/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0884 - accuracy: 0.9839 - val_loss: 2.4302 - val_accuracy: 0.4821\n",
      "Epoch 343/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0969 - accuracy: 0.9819 - val_loss: 2.4294 - val_accuracy: 0.4821\n",
      "Epoch 344/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0874 - accuracy: 0.9855 - val_loss: 2.4286 - val_accuracy: 0.4821\n",
      "Epoch 345/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0859 - accuracy: 0.9867 - val_loss: 2.4278 - val_accuracy: 0.4821\n",
      "Epoch 346/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0930 - accuracy: 0.9831 - val_loss: 2.4270 - val_accuracy: 0.4872\n",
      "Epoch 347/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0971 - accuracy: 0.9811 - val_loss: 2.4260 - val_accuracy: 0.4872\n",
      "Epoch 348/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1030 - accuracy: 0.9799 - val_loss: 2.4252 - val_accuracy: 0.4872\n",
      "Epoch 349/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0906 - accuracy: 0.9835 - val_loss: 2.4246 - val_accuracy: 0.4872\n",
      "Epoch 350/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0877 - accuracy: 0.9847 - val_loss: 2.4235 - val_accuracy: 0.4872\n",
      "Epoch 351/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0907 - accuracy: 0.9859 - val_loss: 2.4224 - val_accuracy: 0.4872\n",
      "Epoch 352/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0924 - accuracy: 0.9851 - val_loss: 2.4212 - val_accuracy: 0.4872\n",
      "Epoch 353/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0936 - accuracy: 0.9855 - val_loss: 2.4201 - val_accuracy: 0.4872\n",
      "Epoch 354/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0876 - accuracy: 0.9867 - val_loss: 2.4190 - val_accuracy: 0.4872\n",
      "Epoch 355/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0885 - accuracy: 0.9863 - val_loss: 2.4178 - val_accuracy: 0.4872\n",
      "Epoch 356/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0929 - accuracy: 0.9855 - val_loss: 2.4167 - val_accuracy: 0.4872\n",
      "Epoch 357/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0855 - accuracy: 0.9827 - val_loss: 2.4159 - val_accuracy: 0.4923\n",
      "Epoch 358/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0969 - accuracy: 0.9783 - val_loss: 2.4152 - val_accuracy: 0.4923\n",
      "Epoch 359/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0866 - accuracy: 0.9863 - val_loss: 2.4145 - val_accuracy: 0.4923\n",
      "Epoch 360/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0911 - accuracy: 0.9847 - val_loss: 2.4139 - val_accuracy: 0.4923\n",
      "Epoch 361/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0878 - accuracy: 0.9851 - val_loss: 2.4131 - val_accuracy: 0.4923\n",
      "Epoch 362/800\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0947 - accuracy: 0.9851 - val_loss: 2.4121 - val_accuracy: 0.4923\n",
      "Epoch 363/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0929 - accuracy: 0.9843 - val_loss: 2.4113 - val_accuracy: 0.4923\n",
      "Epoch 364/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0912 - accuracy: 0.9835 - val_loss: 2.4105 - val_accuracy: 0.4923\n",
      "Epoch 365/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0955 - accuracy: 0.9831 - val_loss: 2.4097 - val_accuracy: 0.4923\n",
      "Epoch 366/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.1030 - accuracy: 0.9791 - val_loss: 2.4091 - val_accuracy: 0.4923\n",
      "Epoch 367/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0876 - accuracy: 0.9863 - val_loss: 2.4086 - val_accuracy: 0.4923\n",
      "Epoch 368/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0882 - accuracy: 0.9839 - val_loss: 2.4080 - val_accuracy: 0.4923\n",
      "Epoch 369/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0884 - accuracy: 0.9851 - val_loss: 2.4074 - val_accuracy: 0.4923\n",
      "Epoch 370/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0937 - accuracy: 0.9843 - val_loss: 2.4069 - val_accuracy: 0.4974\n",
      "Epoch 371/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0967 - accuracy: 0.9835 - val_loss: 2.4061 - val_accuracy: 0.4974\n",
      "Epoch 372/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0947 - accuracy: 0.9827 - val_loss: 2.4055 - val_accuracy: 0.4974\n",
      "Epoch 373/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0859 - accuracy: 0.9855 - val_loss: 2.4048 - val_accuracy: 0.4974\n",
      "Epoch 374/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0893 - accuracy: 0.9839 - val_loss: 2.4040 - val_accuracy: 0.4974\n",
      "Epoch 375/800\n",
      "2485/2485 [==============================] - 0s 82us/step - loss: 0.0850 - accuracy: 0.9879 - val_loss: 2.4031 - val_accuracy: 0.4974\n",
      "Epoch 376/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1014 - accuracy: 0.9787 - val_loss: 2.4024 - val_accuracy: 0.4974\n",
      "Epoch 377/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0950 - accuracy: 0.9835 - val_loss: 2.4021 - val_accuracy: 0.4974\n",
      "Epoch 378/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0950 - accuracy: 0.9839 - val_loss: 2.4016 - val_accuracy: 0.4974\n",
      "Epoch 379/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0886 - accuracy: 0.9839 - val_loss: 2.4010 - val_accuracy: 0.4974\n",
      "Epoch 380/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0925 - accuracy: 0.9843 - val_loss: 2.4006 - val_accuracy: 0.4974\n",
      "Epoch 381/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0940 - accuracy: 0.9803 - val_loss: 2.4004 - val_accuracy: 0.4974\n",
      "Epoch 382/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0961 - accuracy: 0.9839 - val_loss: 2.4002 - val_accuracy: 0.4974\n",
      "Epoch 383/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0907 - accuracy: 0.9843 - val_loss: 2.4001 - val_accuracy: 0.4974\n",
      "Epoch 384/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.1008 - accuracy: 0.9799 - val_loss: 2.4001 - val_accuracy: 0.4974\n",
      "Epoch 385/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0903 - accuracy: 0.9871 - val_loss: 2.4000 - val_accuracy: 0.4974\n",
      "Epoch 386/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0865 - accuracy: 0.9847 - val_loss: 2.3999 - val_accuracy: 0.4974\n",
      "Epoch 387/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0943 - accuracy: 0.9859 - val_loss: 2.3998 - val_accuracy: 0.4974\n",
      "Epoch 388/800\n",
      "2485/2485 [==============================] - 0s 83us/step - loss: 0.0955 - accuracy: 0.9799 - val_loss: 2.3997 - val_accuracy: 0.4974\n",
      "Epoch 389/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0834 - accuracy: 0.9883 - val_loss: 2.3995 - val_accuracy: 0.4974\n",
      "Epoch 390/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0798 - accuracy: 0.9871 - val_loss: 2.3991 - val_accuracy: 0.4974\n",
      "Epoch 391/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0886 - accuracy: 0.9831 - val_loss: 2.3986 - val_accuracy: 0.4974\n",
      "Epoch 392/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0867 - accuracy: 0.9859 - val_loss: 2.3980 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0962 - accuracy: 0.9803 - val_loss: 2.3973 - val_accuracy: 0.4974\n",
      "Epoch 394/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0877 - accuracy: 0.9855 - val_loss: 2.3964 - val_accuracy: 0.4974\n",
      "Epoch 395/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0889 - accuracy: 0.9831 - val_loss: 2.3956 - val_accuracy: 0.4974\n",
      "Epoch 396/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0876 - accuracy: 0.9855 - val_loss: 2.3946 - val_accuracy: 0.4974\n",
      "Epoch 397/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0909 - accuracy: 0.9827 - val_loss: 2.3937 - val_accuracy: 0.5026\n",
      "Epoch 398/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0854 - accuracy: 0.9839 - val_loss: 2.3928 - val_accuracy: 0.5026\n",
      "Epoch 399/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0906 - accuracy: 0.9831 - val_loss: 2.3920 - val_accuracy: 0.5026\n",
      "Epoch 400/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0936 - accuracy: 0.9851 - val_loss: 2.3911 - val_accuracy: 0.5026\n",
      "Epoch 401/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0907 - accuracy: 0.9847 - val_loss: 2.3898 - val_accuracy: 0.5026\n",
      "Epoch 402/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0881 - accuracy: 0.9839 - val_loss: 2.3887 - val_accuracy: 0.5026\n",
      "Epoch 403/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0925 - accuracy: 0.9843 - val_loss: 2.3875 - val_accuracy: 0.5026\n",
      "Epoch 404/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0943 - accuracy: 0.9871 - val_loss: 2.3862 - val_accuracy: 0.5026\n",
      "Epoch 405/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0917 - accuracy: 0.9823 - val_loss: 2.3854 - val_accuracy: 0.5026\n",
      "Epoch 406/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0932 - accuracy: 0.9811 - val_loss: 2.3846 - val_accuracy: 0.5026\n",
      "Epoch 407/800\n",
      "2485/2485 [==============================] - 0s 81us/step - loss: 0.0875 - accuracy: 0.9863 - val_loss: 2.3836 - val_accuracy: 0.5026\n",
      "Epoch 408/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0880 - accuracy: 0.9851 - val_loss: 2.3826 - val_accuracy: 0.5026\n",
      "Epoch 409/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0891 - accuracy: 0.9835 - val_loss: 2.3815 - val_accuracy: 0.5026\n",
      "Epoch 410/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0847 - accuracy: 0.9883 - val_loss: 2.3803 - val_accuracy: 0.4974\n",
      "Epoch 411/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0937 - accuracy: 0.9851 - val_loss: 2.3794 - val_accuracy: 0.4974\n",
      "Epoch 412/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0946 - accuracy: 0.9827 - val_loss: 2.3785 - val_accuracy: 0.4974\n",
      "Epoch 413/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0948 - accuracy: 0.9867 - val_loss: 2.3775 - val_accuracy: 0.4974\n",
      "Epoch 414/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0892 - accuracy: 0.9847 - val_loss: 2.3764 - val_accuracy: 0.4974\n",
      "Epoch 415/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0959 - accuracy: 0.9815 - val_loss: 2.3754 - val_accuracy: 0.4974\n",
      "Epoch 416/800\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0935 - accuracy: 0.9835 - val_loss: 2.3744 - val_accuracy: 0.4974\n",
      "Epoch 417/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0980 - accuracy: 0.9819 - val_loss: 2.3735 - val_accuracy: 0.4974\n",
      "Epoch 418/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0841 - accuracy: 0.9843 - val_loss: 2.3728 - val_accuracy: 0.4974\n",
      "Epoch 419/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.1014 - accuracy: 0.9791 - val_loss: 2.3721 - val_accuracy: 0.4974\n",
      "Epoch 420/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0901 - accuracy: 0.9855 - val_loss: 2.3714 - val_accuracy: 0.4974\n",
      "Epoch 421/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0786 - accuracy: 0.9879 - val_loss: 2.3706 - val_accuracy: 0.5026\n",
      "Epoch 422/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0878 - accuracy: 0.9883 - val_loss: 2.3702 - val_accuracy: 0.5026\n",
      "Epoch 423/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0969 - accuracy: 0.9819 - val_loss: 2.3697 - val_accuracy: 0.5026\n",
      "Epoch 424/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0892 - accuracy: 0.9843 - val_loss: 2.3691 - val_accuracy: 0.5026\n",
      "Epoch 425/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0871 - accuracy: 0.9851 - val_loss: 2.3683 - val_accuracy: 0.5026\n",
      "Epoch 426/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0902 - accuracy: 0.9863 - val_loss: 2.3676 - val_accuracy: 0.5026\n",
      "Epoch 427/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0950 - accuracy: 0.9839 - val_loss: 2.3668 - val_accuracy: 0.5026\n",
      "Epoch 428/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0869 - accuracy: 0.9875 - val_loss: 2.3660 - val_accuracy: 0.5026\n",
      "Epoch 429/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0866 - accuracy: 0.9847 - val_loss: 2.3654 - val_accuracy: 0.5026\n",
      "Epoch 430/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0779 - accuracy: 0.9899 - val_loss: 2.3647 - val_accuracy: 0.5026\n",
      "Epoch 431/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0822 - accuracy: 0.9875 - val_loss: 2.3641 - val_accuracy: 0.5026\n",
      "Epoch 432/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0874 - accuracy: 0.9851 - val_loss: 2.3630 - val_accuracy: 0.5026\n",
      "Epoch 433/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0913 - accuracy: 0.9835 - val_loss: 2.3623 - val_accuracy: 0.5026\n",
      "Epoch 434/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0904 - accuracy: 0.9843 - val_loss: 2.3617 - val_accuracy: 0.5026\n",
      "Epoch 435/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0939 - accuracy: 0.9819 - val_loss: 2.3609 - val_accuracy: 0.5026\n",
      "Epoch 436/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0965 - accuracy: 0.9811 - val_loss: 2.3599 - val_accuracy: 0.5026\n",
      "Epoch 437/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0855 - accuracy: 0.9863 - val_loss: 2.3591 - val_accuracy: 0.5026\n",
      "Epoch 438/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0904 - accuracy: 0.9851 - val_loss: 2.3581 - val_accuracy: 0.5077\n",
      "Epoch 439/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0896 - accuracy: 0.9839 - val_loss: 2.3575 - val_accuracy: 0.5077\n",
      "Epoch 440/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0936 - accuracy: 0.9827 - val_loss: 2.3569 - val_accuracy: 0.5077\n",
      "Epoch 441/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0893 - accuracy: 0.9867 - val_loss: 2.3561 - val_accuracy: 0.5077\n",
      "Epoch 442/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0921 - accuracy: 0.9839 - val_loss: 2.3555 - val_accuracy: 0.5077\n",
      "Epoch 443/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0954 - accuracy: 0.9807 - val_loss: 2.3550 - val_accuracy: 0.5077\n",
      "Epoch 444/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0850 - accuracy: 0.9871 - val_loss: 2.3544 - val_accuracy: 0.5077\n",
      "Epoch 445/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0892 - accuracy: 0.9839 - val_loss: 2.3538 - val_accuracy: 0.5077\n",
      "Epoch 446/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0885 - accuracy: 0.9831 - val_loss: 2.3532 - val_accuracy: 0.5077\n",
      "Epoch 447/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0789 - accuracy: 0.9891 - val_loss: 2.3527 - val_accuracy: 0.5077\n",
      "Epoch 448/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0873 - accuracy: 0.9847 - val_loss: 2.3520 - val_accuracy: 0.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0863 - accuracy: 0.9859 - val_loss: 2.3516 - val_accuracy: 0.5077\n",
      "Epoch 450/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0877 - accuracy: 0.9859 - val_loss: 2.3512 - val_accuracy: 0.5077\n",
      "Epoch 451/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0918 - accuracy: 0.9839 - val_loss: 2.3506 - val_accuracy: 0.5077\n",
      "Epoch 452/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0878 - accuracy: 0.9863 - val_loss: 2.3499 - val_accuracy: 0.5077\n",
      "Epoch 453/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0762 - accuracy: 0.9871 - val_loss: 2.3491 - val_accuracy: 0.5077\n",
      "Epoch 454/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0855 - accuracy: 0.9867 - val_loss: 2.3486 - val_accuracy: 0.5077\n",
      "Epoch 455/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0892 - accuracy: 0.9883 - val_loss: 2.3481 - val_accuracy: 0.5077\n",
      "Epoch 456/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0849 - accuracy: 0.9855 - val_loss: 2.3475 - val_accuracy: 0.5077\n",
      "Epoch 457/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0833 - accuracy: 0.9863 - val_loss: 2.3468 - val_accuracy: 0.5077\n",
      "Epoch 458/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0866 - accuracy: 0.9863 - val_loss: 2.3461 - val_accuracy: 0.5077\n",
      "Epoch 459/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0839 - accuracy: 0.9855 - val_loss: 2.3453 - val_accuracy: 0.5077\n",
      "Epoch 460/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0859 - accuracy: 0.9871 - val_loss: 2.3447 - val_accuracy: 0.5077\n",
      "Epoch 461/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0898 - accuracy: 0.9831 - val_loss: 2.3442 - val_accuracy: 0.5077\n",
      "Epoch 462/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0916 - accuracy: 0.9823 - val_loss: 2.3433 - val_accuracy: 0.5077\n",
      "Epoch 463/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0859 - accuracy: 0.9851 - val_loss: 2.3428 - val_accuracy: 0.5077\n",
      "Epoch 464/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0860 - accuracy: 0.9863 - val_loss: 2.3422 - val_accuracy: 0.5077\n",
      "Epoch 465/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0915 - accuracy: 0.9871 - val_loss: 2.3417 - val_accuracy: 0.5077\n",
      "Epoch 466/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0975 - accuracy: 0.9839 - val_loss: 2.3413 - val_accuracy: 0.5077\n",
      "Epoch 467/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0933 - accuracy: 0.9839 - val_loss: 2.3408 - val_accuracy: 0.5077\n",
      "Epoch 468/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0932 - accuracy: 0.9835 - val_loss: 2.3405 - val_accuracy: 0.5077\n",
      "Epoch 469/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0810 - accuracy: 0.9883 - val_loss: 2.3402 - val_accuracy: 0.5077\n",
      "Epoch 470/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0836 - accuracy: 0.9871 - val_loss: 2.3396 - val_accuracy: 0.5077\n",
      "Epoch 471/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0849 - accuracy: 0.9879 - val_loss: 2.3392 - val_accuracy: 0.5077\n",
      "Epoch 472/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0898 - accuracy: 0.9863 - val_loss: 2.3388 - val_accuracy: 0.5128\n",
      "Epoch 473/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0861 - accuracy: 0.9891 - val_loss: 2.3382 - val_accuracy: 0.5128\n",
      "Epoch 474/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0938 - accuracy: 0.9811 - val_loss: 2.3378 - val_accuracy: 0.5128\n",
      "Epoch 475/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.1000 - accuracy: 0.9811 - val_loss: 2.3372 - val_accuracy: 0.5128\n",
      "Epoch 476/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0940 - accuracy: 0.9855 - val_loss: 2.3364 - val_accuracy: 0.5128\n",
      "Epoch 477/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0866 - accuracy: 0.9859 - val_loss: 2.3359 - val_accuracy: 0.5128\n",
      "Epoch 478/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0900 - accuracy: 0.9859 - val_loss: 2.3355 - val_accuracy: 0.5128\n",
      "Epoch 479/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0820 - accuracy: 0.9891 - val_loss: 2.3349 - val_accuracy: 0.5128\n",
      "Epoch 480/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0845 - accuracy: 0.9855 - val_loss: 2.3343 - val_accuracy: 0.5128\n",
      "Epoch 481/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0941 - accuracy: 0.9823 - val_loss: 2.3336 - val_accuracy: 0.5128\n",
      "Epoch 482/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0929 - accuracy: 0.9863 - val_loss: 2.3329 - val_accuracy: 0.5128\n",
      "Epoch 483/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0830 - accuracy: 0.9887 - val_loss: 2.3321 - val_accuracy: 0.5128\n",
      "Epoch 484/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0971 - accuracy: 0.9819 - val_loss: 2.3314 - val_accuracy: 0.5128\n",
      "Epoch 485/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0839 - accuracy: 0.9883 - val_loss: 2.3307 - val_accuracy: 0.5128\n",
      "Epoch 486/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0808 - accuracy: 0.9879 - val_loss: 2.3302 - val_accuracy: 0.5128\n",
      "Epoch 487/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0793 - accuracy: 0.9907 - val_loss: 2.3295 - val_accuracy: 0.5128\n",
      "Epoch 488/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0940 - accuracy: 0.9839 - val_loss: 2.3287 - val_accuracy: 0.5128\n",
      "Epoch 489/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0816 - accuracy: 0.9891 - val_loss: 2.3279 - val_accuracy: 0.5128\n",
      "Epoch 490/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0837 - accuracy: 0.9863 - val_loss: 2.3269 - val_accuracy: 0.5128\n",
      "Epoch 491/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0909 - accuracy: 0.9871 - val_loss: 2.3260 - val_accuracy: 0.5128\n",
      "Epoch 492/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0801 - accuracy: 0.9875 - val_loss: 2.3251 - val_accuracy: 0.5128\n",
      "Epoch 493/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0908 - accuracy: 0.9835 - val_loss: 2.3242 - val_accuracy: 0.5128\n",
      "Epoch 494/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0936 - accuracy: 0.9811 - val_loss: 2.3235 - val_accuracy: 0.5128\n",
      "Epoch 495/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0870 - accuracy: 0.9851 - val_loss: 2.3224 - val_accuracy: 0.5128\n",
      "Epoch 496/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0778 - accuracy: 0.9879 - val_loss: 2.3216 - val_accuracy: 0.5128\n",
      "Epoch 497/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0889 - accuracy: 0.9843 - val_loss: 2.3207 - val_accuracy: 0.5128\n",
      "Epoch 498/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0941 - accuracy: 0.9843 - val_loss: 2.3201 - val_accuracy: 0.5128\n",
      "Epoch 499/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0904 - accuracy: 0.9799 - val_loss: 2.3192 - val_accuracy: 0.5128\n",
      "Epoch 500/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0812 - accuracy: 0.9879 - val_loss: 2.3184 - val_accuracy: 0.5128\n",
      "Epoch 501/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0910 - accuracy: 0.9831 - val_loss: 2.3175 - val_accuracy: 0.5128\n",
      "Epoch 502/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0822 - accuracy: 0.9863 - val_loss: 2.3166 - val_accuracy: 0.5128\n",
      "Epoch 503/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0816 - accuracy: 0.9859 - val_loss: 2.3156 - val_accuracy: 0.5128\n",
      "Epoch 504/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0909 - accuracy: 0.9815 - val_loss: 2.3148 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0868 - accuracy: 0.9851 - val_loss: 2.3140 - val_accuracy: 0.5128\n",
      "Epoch 506/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0880 - accuracy: 0.9831 - val_loss: 2.3132 - val_accuracy: 0.5128\n",
      "Epoch 507/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0956 - accuracy: 0.9831 - val_loss: 2.3125 - val_accuracy: 0.5128\n",
      "Epoch 508/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0886 - accuracy: 0.9827 - val_loss: 2.3117 - val_accuracy: 0.5128\n",
      "Epoch 509/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0936 - accuracy: 0.9835 - val_loss: 2.3111 - val_accuracy: 0.5128\n",
      "Epoch 510/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0916 - accuracy: 0.9859 - val_loss: 2.3105 - val_accuracy: 0.5128\n",
      "Epoch 511/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0896 - accuracy: 0.9831 - val_loss: 2.3100 - val_accuracy: 0.5128\n",
      "Epoch 512/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0861 - accuracy: 0.9835 - val_loss: 2.3094 - val_accuracy: 0.5128\n",
      "Epoch 513/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0875 - accuracy: 0.9859 - val_loss: 2.3087 - val_accuracy: 0.5128\n",
      "Epoch 514/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0967 - accuracy: 0.9819 - val_loss: 2.3081 - val_accuracy: 0.5128\n",
      "Epoch 515/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0927 - accuracy: 0.9851 - val_loss: 2.3074 - val_accuracy: 0.5128\n",
      "Epoch 516/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0880 - accuracy: 0.9847 - val_loss: 2.3065 - val_accuracy: 0.5128\n",
      "Epoch 517/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0886 - accuracy: 0.9855 - val_loss: 2.3057 - val_accuracy: 0.5128\n",
      "Epoch 518/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0830 - accuracy: 0.9875 - val_loss: 2.3050 - val_accuracy: 0.5128\n",
      "Epoch 519/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0894 - accuracy: 0.9843 - val_loss: 2.3044 - val_accuracy: 0.5128\n",
      "Epoch 520/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0946 - accuracy: 0.9835 - val_loss: 2.3037 - val_accuracy: 0.5128\n",
      "Epoch 521/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0827 - accuracy: 0.9891 - val_loss: 2.3032 - val_accuracy: 0.5128\n",
      "Epoch 522/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0873 - accuracy: 0.9847 - val_loss: 2.3028 - val_accuracy: 0.5128\n",
      "Epoch 523/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0876 - accuracy: 0.9863 - val_loss: 2.3023 - val_accuracy: 0.5128\n",
      "Epoch 524/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0862 - accuracy: 0.9847 - val_loss: 2.3018 - val_accuracy: 0.5128\n",
      "Epoch 525/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0840 - accuracy: 0.9843 - val_loss: 2.3011 - val_accuracy: 0.5128\n",
      "Epoch 526/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0893 - accuracy: 0.9831 - val_loss: 2.3003 - val_accuracy: 0.5128\n",
      "Epoch 527/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0996 - accuracy: 0.9795 - val_loss: 2.2997 - val_accuracy: 0.5128\n",
      "Epoch 528/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0867 - accuracy: 0.9819 - val_loss: 2.2991 - val_accuracy: 0.5128\n",
      "Epoch 529/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0921 - accuracy: 0.9879 - val_loss: 2.2986 - val_accuracy: 0.5128\n",
      "Epoch 530/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0864 - accuracy: 0.9883 - val_loss: 2.2980 - val_accuracy: 0.5128\n",
      "Epoch 531/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0812 - accuracy: 0.9871 - val_loss: 2.2973 - val_accuracy: 0.5128\n",
      "Epoch 532/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0937 - accuracy: 0.9835 - val_loss: 2.2964 - val_accuracy: 0.5128\n",
      "Epoch 533/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0970 - accuracy: 0.9787 - val_loss: 2.2957 - val_accuracy: 0.5128\n",
      "Epoch 534/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0825 - accuracy: 0.9847 - val_loss: 2.2948 - val_accuracy: 0.5128\n",
      "Epoch 535/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0862 - accuracy: 0.9867 - val_loss: 2.2939 - val_accuracy: 0.5128\n",
      "Epoch 536/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0828 - accuracy: 0.9871 - val_loss: 2.2929 - val_accuracy: 0.5128\n",
      "Epoch 537/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0926 - accuracy: 0.9843 - val_loss: 2.2923 - val_accuracy: 0.5077\n",
      "Epoch 538/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0942 - accuracy: 0.9839 - val_loss: 2.2914 - val_accuracy: 0.5077\n",
      "Epoch 539/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0843 - accuracy: 0.9847 - val_loss: 2.2907 - val_accuracy: 0.5128\n",
      "Epoch 540/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9895 - val_loss: 2.2899 - val_accuracy: 0.5128\n",
      "Epoch 541/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0878 - accuracy: 0.9867 - val_loss: 2.2894 - val_accuracy: 0.5128\n",
      "Epoch 542/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0852 - accuracy: 0.9847 - val_loss: 2.2885 - val_accuracy: 0.5128\n",
      "Epoch 543/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0915 - accuracy: 0.9827 - val_loss: 2.2878 - val_accuracy: 0.5128\n",
      "Epoch 544/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0832 - accuracy: 0.9847 - val_loss: 2.2869 - val_accuracy: 0.5128\n",
      "Epoch 545/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0927 - accuracy: 0.9823 - val_loss: 2.2862 - val_accuracy: 0.5128\n",
      "Epoch 546/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0826 - accuracy: 0.9879 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 547/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0852 - accuracy: 0.9863 - val_loss: 2.2846 - val_accuracy: 0.5128\n",
      "Epoch 548/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0756 - accuracy: 0.9887 - val_loss: 2.2838 - val_accuracy: 0.5128\n",
      "Epoch 549/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0904 - accuracy: 0.9859 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 550/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0926 - accuracy: 0.9835 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 551/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0867 - accuracy: 0.9859 - val_loss: 2.2815 - val_accuracy: 0.5128\n",
      "Epoch 552/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0855 - accuracy: 0.9867 - val_loss: 2.2810 - val_accuracy: 0.5128\n",
      "Epoch 553/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0849 - accuracy: 0.9851 - val_loss: 2.2807 - val_accuracy: 0.5128\n",
      "Epoch 554/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0984 - accuracy: 0.9795 - val_loss: 2.2803 - val_accuracy: 0.5128\n",
      "Epoch 555/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0830 - accuracy: 0.9875 - val_loss: 2.2798 - val_accuracy: 0.5128\n",
      "Epoch 556/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0865 - accuracy: 0.9819 - val_loss: 2.2794 - val_accuracy: 0.5128\n",
      "Epoch 557/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0868 - accuracy: 0.9855 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 558/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0907 - accuracy: 0.9827 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 559/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0913 - accuracy: 0.9803 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 560/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0900 - accuracy: 0.9871 - val_loss: 2.2789 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0902 - accuracy: 0.9843 - val_loss: 2.2788 - val_accuracy: 0.5128\n",
      "Epoch 562/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0833 - accuracy: 0.9875 - val_loss: 2.2784 - val_accuracy: 0.5128\n",
      "Epoch 563/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0956 - accuracy: 0.9787 - val_loss: 2.2783 - val_accuracy: 0.5128\n",
      "Epoch 564/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0895 - accuracy: 0.9827 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 565/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0948 - accuracy: 0.9803 - val_loss: 2.2782 - val_accuracy: 0.5128\n",
      "Epoch 566/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0803 - accuracy: 0.9903 - val_loss: 2.2780 - val_accuracy: 0.5077\n",
      "Epoch 567/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0882 - accuracy: 0.9859 - val_loss: 2.2781 - val_accuracy: 0.5077\n",
      "Epoch 568/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0876 - accuracy: 0.9855 - val_loss: 2.2781 - val_accuracy: 0.5077\n",
      "Epoch 569/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0909 - accuracy: 0.9803 - val_loss: 2.2781 - val_accuracy: 0.5077\n",
      "Epoch 570/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0822 - accuracy: 0.9815 - val_loss: 2.2779 - val_accuracy: 0.5077\n",
      "Epoch 571/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0886 - accuracy: 0.9847 - val_loss: 2.2777 - val_accuracy: 0.5077\n",
      "Epoch 572/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0869 - accuracy: 0.9855 - val_loss: 2.2773 - val_accuracy: 0.5077\n",
      "Epoch 573/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0799 - accuracy: 0.9851 - val_loss: 2.2769 - val_accuracy: 0.5077\n",
      "Epoch 574/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0692 - accuracy: 0.9915 - val_loss: 2.2765 - val_accuracy: 0.5077\n",
      "Epoch 575/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0818 - accuracy: 0.9891 - val_loss: 2.2760 - val_accuracy: 0.5077\n",
      "Epoch 576/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0938 - accuracy: 0.9839 - val_loss: 2.2753 - val_accuracy: 0.5077\n",
      "Epoch 577/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0828 - accuracy: 0.9859 - val_loss: 2.2748 - val_accuracy: 0.5077\n",
      "Epoch 578/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0892 - accuracy: 0.9835 - val_loss: 2.2745 - val_accuracy: 0.5077\n",
      "Epoch 579/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0837 - accuracy: 0.9883 - val_loss: 2.2741 - val_accuracy: 0.5077\n",
      "Epoch 580/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0868 - accuracy: 0.9827 - val_loss: 2.2737 - val_accuracy: 0.5077\n",
      "Epoch 581/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0922 - accuracy: 0.9859 - val_loss: 2.2735 - val_accuracy: 0.5128\n",
      "Epoch 582/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0898 - accuracy: 0.9879 - val_loss: 2.2733 - val_accuracy: 0.5128\n",
      "Epoch 583/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0854 - accuracy: 0.9871 - val_loss: 2.2729 - val_accuracy: 0.5128\n",
      "Epoch 584/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0850 - accuracy: 0.9843 - val_loss: 2.2726 - val_accuracy: 0.5128\n",
      "Epoch 585/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0863 - accuracy: 0.9847 - val_loss: 2.2724 - val_accuracy: 0.5128\n",
      "Epoch 586/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0803 - accuracy: 0.9899 - val_loss: 2.2722 - val_accuracy: 0.5128\n",
      "Epoch 587/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0896 - accuracy: 0.9847 - val_loss: 2.2719 - val_accuracy: 0.5128\n",
      "Epoch 588/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0953 - accuracy: 0.9819 - val_loss: 2.2718 - val_accuracy: 0.5128\n",
      "Epoch 589/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0803 - accuracy: 0.9891 - val_loss: 2.2715 - val_accuracy: 0.5128\n",
      "Epoch 590/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0747 - accuracy: 0.9895 - val_loss: 2.2710 - val_accuracy: 0.5128\n",
      "Epoch 591/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0878 - accuracy: 0.9843 - val_loss: 2.2706 - val_accuracy: 0.5128\n",
      "Epoch 592/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0889 - accuracy: 0.9831 - val_loss: 2.2703 - val_accuracy: 0.5128\n",
      "Epoch 593/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0863 - accuracy: 0.9883 - val_loss: 2.2699 - val_accuracy: 0.5128\n",
      "Epoch 594/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0819 - accuracy: 0.9855 - val_loss: 2.2693 - val_accuracy: 0.5128\n",
      "Epoch 595/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0765 - accuracy: 0.9871 - val_loss: 2.2689 - val_accuracy: 0.5128\n",
      "Epoch 596/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0875 - accuracy: 0.9843 - val_loss: 2.2686 - val_accuracy: 0.5128\n",
      "Epoch 597/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0869 - accuracy: 0.9867 - val_loss: 2.2683 - val_accuracy: 0.5128\n",
      "Epoch 598/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0800 - accuracy: 0.9867 - val_loss: 2.2679 - val_accuracy: 0.5128\n",
      "Epoch 599/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0905 - accuracy: 0.9803 - val_loss: 2.2674 - val_accuracy: 0.5128\n",
      "Epoch 600/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0844 - accuracy: 0.9839 - val_loss: 2.2667 - val_accuracy: 0.5128\n",
      "Epoch 601/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0809 - accuracy: 0.9863 - val_loss: 2.2659 - val_accuracy: 0.5128\n",
      "Epoch 602/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0865 - accuracy: 0.9847 - val_loss: 2.2653 - val_accuracy: 0.5128\n",
      "Epoch 603/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0888 - accuracy: 0.9847 - val_loss: 2.2648 - val_accuracy: 0.5128\n",
      "Epoch 604/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0771 - accuracy: 0.9875 - val_loss: 2.2643 - val_accuracy: 0.5179\n",
      "Epoch 605/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0850 - accuracy: 0.9851 - val_loss: 2.2639 - val_accuracy: 0.5179\n",
      "Epoch 606/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0854 - accuracy: 0.9835 - val_loss: 2.2634 - val_accuracy: 0.5179\n",
      "Epoch 607/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0849 - accuracy: 0.9863 - val_loss: 2.2631 - val_accuracy: 0.5179\n",
      "Epoch 608/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0866 - accuracy: 0.9863 - val_loss: 2.2628 - val_accuracy: 0.5179\n",
      "Epoch 609/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0752 - accuracy: 0.9891 - val_loss: 2.2624 - val_accuracy: 0.5179\n",
      "Epoch 610/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0762 - accuracy: 0.9907 - val_loss: 2.2620 - val_accuracy: 0.5179\n",
      "Epoch 611/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0851 - accuracy: 0.9859 - val_loss: 2.2615 - val_accuracy: 0.5179\n",
      "Epoch 612/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0879 - accuracy: 0.9851 - val_loss: 2.2610 - val_accuracy: 0.5179\n",
      "Epoch 613/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0786 - accuracy: 0.9891 - val_loss: 2.2606 - val_accuracy: 0.5179\n",
      "Epoch 614/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0770 - accuracy: 0.9875 - val_loss: 2.2601 - val_accuracy: 0.5179\n",
      "Epoch 615/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0845 - accuracy: 0.9875 - val_loss: 2.2597 - val_accuracy: 0.5179\n",
      "Epoch 616/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0901 - accuracy: 0.9827 - val_loss: 2.2596 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0868 - accuracy: 0.9863 - val_loss: 2.2596 - val_accuracy: 0.5179\n",
      "Epoch 618/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0936 - accuracy: 0.9815 - val_loss: 2.2595 - val_accuracy: 0.5179\n",
      "Epoch 619/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0877 - accuracy: 0.9843 - val_loss: 2.2595 - val_accuracy: 0.5179\n",
      "Epoch 620/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0847 - accuracy: 0.9863 - val_loss: 2.2595 - val_accuracy: 0.5179\n",
      "Epoch 621/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0915 - accuracy: 0.9835 - val_loss: 2.2596 - val_accuracy: 0.5179\n",
      "Epoch 622/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0840 - accuracy: 0.9875 - val_loss: 2.2596 - val_accuracy: 0.5179\n",
      "Epoch 623/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0870 - accuracy: 0.9823 - val_loss: 2.2596 - val_accuracy: 0.5179\n",
      "Epoch 624/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0860 - accuracy: 0.9851 - val_loss: 2.2598 - val_accuracy: 0.5179\n",
      "Epoch 625/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0816 - accuracy: 0.9855 - val_loss: 2.2598 - val_accuracy: 0.5179\n",
      "Epoch 626/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0851 - accuracy: 0.9843 - val_loss: 2.2599 - val_accuracy: 0.5179\n",
      "Epoch 627/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0843 - accuracy: 0.9855 - val_loss: 2.2598 - val_accuracy: 0.5231\n",
      "Epoch 628/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0809 - accuracy: 0.9879 - val_loss: 2.2601 - val_accuracy: 0.5231\n",
      "Epoch 629/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0834 - accuracy: 0.9847 - val_loss: 2.2604 - val_accuracy: 0.5231\n",
      "Epoch 630/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0770 - accuracy: 0.9891 - val_loss: 2.2605 - val_accuracy: 0.5179\n",
      "Epoch 631/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0879 - accuracy: 0.9827 - val_loss: 2.2605 - val_accuracy: 0.5179\n",
      "Epoch 632/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0829 - accuracy: 0.9867 - val_loss: 2.2607 - val_accuracy: 0.5179\n",
      "Epoch 633/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0781 - accuracy: 0.9871 - val_loss: 2.2609 - val_accuracy: 0.5179\n",
      "Epoch 634/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0781 - accuracy: 0.9883 - val_loss: 2.2611 - val_accuracy: 0.5179\n",
      "Epoch 635/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0893 - accuracy: 0.9851 - val_loss: 2.2612 - val_accuracy: 0.5179\n",
      "Epoch 636/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0813 - accuracy: 0.9839 - val_loss: 2.2615 - val_accuracy: 0.5179\n",
      "Epoch 637/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0913 - accuracy: 0.9831 - val_loss: 2.2617 - val_accuracy: 0.5179\n",
      "Epoch 638/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0847 - accuracy: 0.9859 - val_loss: 2.2618 - val_accuracy: 0.5128\n",
      "Epoch 639/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0838 - accuracy: 0.9883 - val_loss: 2.2619 - val_accuracy: 0.5128\n",
      "Epoch 640/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0818 - accuracy: 0.9851 - val_loss: 2.2617 - val_accuracy: 0.5128\n",
      "Epoch 641/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0751 - accuracy: 0.9915 - val_loss: 2.2612 - val_accuracy: 0.5128\n",
      "Epoch 642/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0820 - accuracy: 0.9843 - val_loss: 2.2608 - val_accuracy: 0.5128\n",
      "Epoch 643/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0852 - accuracy: 0.9855 - val_loss: 2.2605 - val_accuracy: 0.5128\n",
      "Epoch 644/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0900 - accuracy: 0.9859 - val_loss: 2.2604 - val_accuracy: 0.5128\n",
      "Epoch 645/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0806 - accuracy: 0.9879 - val_loss: 2.2603 - val_accuracy: 0.5128\n",
      "Epoch 646/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0851 - accuracy: 0.9859 - val_loss: 2.2601 - val_accuracy: 0.5128\n",
      "Epoch 647/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0816 - accuracy: 0.9855 - val_loss: 2.2596 - val_accuracy: 0.5128\n",
      "Epoch 648/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0806 - accuracy: 0.9903 - val_loss: 2.2589 - val_accuracy: 0.5128\n",
      "Epoch 649/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0911 - accuracy: 0.9827 - val_loss: 2.2584 - val_accuracy: 0.5128\n",
      "Epoch 650/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0824 - accuracy: 0.9879 - val_loss: 2.2580 - val_accuracy: 0.5128\n",
      "Epoch 651/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0850 - accuracy: 0.9887 - val_loss: 2.2575 - val_accuracy: 0.5128\n",
      "Epoch 652/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0909 - accuracy: 0.9839 - val_loss: 2.2572 - val_accuracy: 0.5128\n",
      "Epoch 653/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0831 - accuracy: 0.9903 - val_loss: 2.2570 - val_accuracy: 0.5128\n",
      "Epoch 654/800\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0763 - accuracy: 0.9875 - val_loss: 2.2565 - val_accuracy: 0.5128\n",
      "Epoch 655/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0850 - accuracy: 0.9887 - val_loss: 2.2561 - val_accuracy: 0.5128\n",
      "Epoch 656/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0876 - accuracy: 0.9847 - val_loss: 2.2559 - val_accuracy: 0.5128\n",
      "Epoch 657/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0881 - accuracy: 0.9855 - val_loss: 2.2557 - val_accuracy: 0.5128\n",
      "Epoch 658/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0933 - accuracy: 0.9859 - val_loss: 2.2557 - val_accuracy: 0.5128\n",
      "Epoch 659/800\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0911 - accuracy: 0.9847 - val_loss: 2.2556 - val_accuracy: 0.5128\n",
      "Epoch 660/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9875 - val_loss: 2.2556 - val_accuracy: 0.5128\n",
      "Epoch 661/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0820 - accuracy: 0.9863 - val_loss: 2.2554 - val_accuracy: 0.5128\n",
      "Epoch 662/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0775 - accuracy: 0.9875 - val_loss: 2.2552 - val_accuracy: 0.5128\n",
      "Epoch 663/800\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0788 - accuracy: 0.9891 - val_loss: 2.2550 - val_accuracy: 0.5128\n",
      "Epoch 664/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0829 - accuracy: 0.9867 - val_loss: 2.2546 - val_accuracy: 0.5128\n",
      "Epoch 665/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0912 - accuracy: 0.9835 - val_loss: 2.2542 - val_accuracy: 0.5128\n",
      "Epoch 666/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0880 - accuracy: 0.9863 - val_loss: 2.2540 - val_accuracy: 0.5179\n",
      "Epoch 667/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0788 - accuracy: 0.9843 - val_loss: 2.2537 - val_accuracy: 0.5179\n",
      "Epoch 668/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0862 - accuracy: 0.9835 - val_loss: 2.2535 - val_accuracy: 0.5179\n",
      "Epoch 669/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0843 - accuracy: 0.9835 - val_loss: 2.2533 - val_accuracy: 0.5179\n",
      "Epoch 670/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0796 - accuracy: 0.9851 - val_loss: 2.2533 - val_accuracy: 0.5179\n",
      "Epoch 671/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0804 - accuracy: 0.9903 - val_loss: 2.2532 - val_accuracy: 0.5179\n",
      "Epoch 672/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0798 - accuracy: 0.9895 - val_loss: 2.2530 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0840 - accuracy: 0.9875 - val_loss: 2.2530 - val_accuracy: 0.5179\n",
      "Epoch 674/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0865 - accuracy: 0.9815 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 675/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0772 - accuracy: 0.9883 - val_loss: 2.2528 - val_accuracy: 0.5179\n",
      "Epoch 676/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0797 - accuracy: 0.9883 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 677/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0812 - accuracy: 0.9847 - val_loss: 2.2527 - val_accuracy: 0.5179\n",
      "Epoch 678/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0804 - accuracy: 0.9867 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 679/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0772 - accuracy: 0.9887 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 680/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0784 - accuracy: 0.9883 - val_loss: 2.2526 - val_accuracy: 0.5128\n",
      "Epoch 681/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0824 - accuracy: 0.9871 - val_loss: 2.2528 - val_accuracy: 0.5128\n",
      "Epoch 682/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0914 - accuracy: 0.9851 - val_loss: 2.2530 - val_accuracy: 0.5128\n",
      "Epoch 683/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0821 - accuracy: 0.9879 - val_loss: 2.2530 - val_accuracy: 0.5128\n",
      "Epoch 684/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0776 - accuracy: 0.9891 - val_loss: 2.2531 - val_accuracy: 0.5128\n",
      "Epoch 685/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0861 - accuracy: 0.9835 - val_loss: 2.2531 - val_accuracy: 0.5128\n",
      "Epoch 686/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0797 - accuracy: 0.9867 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 687/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0882 - accuracy: 0.9831 - val_loss: 2.2528 - val_accuracy: 0.5179\n",
      "Epoch 688/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0902 - accuracy: 0.9819 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 689/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0859 - accuracy: 0.9851 - val_loss: 2.2523 - val_accuracy: 0.5179\n",
      "Epoch 690/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0832 - accuracy: 0.9871 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 691/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0852 - accuracy: 0.9851 - val_loss: 2.2518 - val_accuracy: 0.5179\n",
      "Epoch 692/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0790 - accuracy: 0.9871 - val_loss: 2.2518 - val_accuracy: 0.5179\n",
      "Epoch 693/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0944 - accuracy: 0.9839 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 694/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0872 - accuracy: 0.9863 - val_loss: 2.2518 - val_accuracy: 0.5179\n",
      "Epoch 695/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0787 - accuracy: 0.9871 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 696/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0868 - accuracy: 0.9859 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 697/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0744 - accuracy: 0.9895 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 698/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0819 - accuracy: 0.9855 - val_loss: 2.2522 - val_accuracy: 0.5179\n",
      "Epoch 699/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0847 - accuracy: 0.9863 - val_loss: 2.2523 - val_accuracy: 0.5179\n",
      "Epoch 700/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0816 - accuracy: 0.9883 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 701/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0837 - accuracy: 0.9859 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 702/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0805 - accuracy: 0.9867 - val_loss: 2.2521 - val_accuracy: 0.5179\n",
      "Epoch 703/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0838 - accuracy: 0.9851 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 704/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0854 - accuracy: 0.9847 - val_loss: 2.2516 - val_accuracy: 0.5179\n",
      "Epoch 705/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0921 - accuracy: 0.9819 - val_loss: 2.2514 - val_accuracy: 0.5179\n",
      "Epoch 706/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0810 - accuracy: 0.9847 - val_loss: 2.2513 - val_accuracy: 0.5179\n",
      "Epoch 707/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0828 - accuracy: 0.9887 - val_loss: 2.2511 - val_accuracy: 0.5179\n",
      "Epoch 708/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0746 - accuracy: 0.9899 - val_loss: 2.2509 - val_accuracy: 0.5179\n",
      "Epoch 709/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0804 - accuracy: 0.9871 - val_loss: 2.2506 - val_accuracy: 0.5179\n",
      "Epoch 710/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0878 - accuracy: 0.9839 - val_loss: 2.2506 - val_accuracy: 0.5179\n",
      "Epoch 711/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0834 - accuracy: 0.9867 - val_loss: 2.2502 - val_accuracy: 0.5179\n",
      "Epoch 712/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0820 - accuracy: 0.9883 - val_loss: 2.2503 - val_accuracy: 0.5179\n",
      "Epoch 713/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0886 - accuracy: 0.9823 - val_loss: 2.2505 - val_accuracy: 0.5179\n",
      "Epoch 714/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0819 - accuracy: 0.9855 - val_loss: 2.2507 - val_accuracy: 0.5179\n",
      "Epoch 715/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0777 - accuracy: 0.9879 - val_loss: 2.2512 - val_accuracy: 0.5179\n",
      "Epoch 716/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0904 - accuracy: 0.9831 - val_loss: 2.2512 - val_accuracy: 0.5179\n",
      "Epoch 717/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0816 - accuracy: 0.9855 - val_loss: 2.2515 - val_accuracy: 0.5179\n",
      "Epoch 718/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0856 - accuracy: 0.9843 - val_loss: 2.2517 - val_accuracy: 0.5179\n",
      "Epoch 719/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0844 - accuracy: 0.9879 - val_loss: 2.2520 - val_accuracy: 0.5179\n",
      "Epoch 720/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0792 - accuracy: 0.9879 - val_loss: 2.2521 - val_accuracy: 0.5179\n",
      "Epoch 721/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9827 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 722/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0860 - accuracy: 0.9847 - val_loss: 2.2520 - val_accuracy: 0.5179\n",
      "Epoch 723/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0753 - accuracy: 0.9855 - val_loss: 2.2521 - val_accuracy: 0.5179\n",
      "Epoch 724/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0894 - accuracy: 0.9847 - val_loss: 2.2520 - val_accuracy: 0.5179\n",
      "Epoch 725/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0793 - accuracy: 0.9867 - val_loss: 2.2522 - val_accuracy: 0.5179\n",
      "Epoch 726/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0839 - accuracy: 0.9847 - val_loss: 2.2519 - val_accuracy: 0.5179\n",
      "Epoch 727/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0712 - accuracy: 0.9907 - val_loss: 2.2518 - val_accuracy: 0.5179\n",
      "Epoch 728/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0885 - accuracy: 0.9859 - val_loss: 2.2519 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0845 - accuracy: 0.9883 - val_loss: 2.2522 - val_accuracy: 0.5179\n",
      "Epoch 730/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0838 - accuracy: 0.9859 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 731/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0864 - accuracy: 0.9859 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 732/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0734 - accuracy: 0.9920 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 733/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0883 - accuracy: 0.9835 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 734/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0842 - accuracy: 0.9875 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 735/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0820 - accuracy: 0.9871 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 736/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0913 - accuracy: 0.9819 - val_loss: 2.2523 - val_accuracy: 0.5179\n",
      "Epoch 737/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0878 - accuracy: 0.9823 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 738/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0845 - accuracy: 0.9843 - val_loss: 2.2527 - val_accuracy: 0.5179\n",
      "Epoch 739/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0849 - accuracy: 0.9839 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 740/800\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0923 - accuracy: 0.9855 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 741/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0752 - accuracy: 0.9920 - val_loss: 2.2528 - val_accuracy: 0.5179\n",
      "Epoch 742/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.1010 - accuracy: 0.9779 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 743/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0815 - accuracy: 0.9839 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 744/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0878 - accuracy: 0.9855 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 745/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0763 - accuracy: 0.9895 - val_loss: 2.2527 - val_accuracy: 0.5179\n",
      "Epoch 746/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0757 - accuracy: 0.9875 - val_loss: 2.2527 - val_accuracy: 0.5179\n",
      "Epoch 747/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0834 - accuracy: 0.9851 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 748/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0780 - accuracy: 0.9895 - val_loss: 2.2529 - val_accuracy: 0.5179\n",
      "Epoch 749/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0752 - accuracy: 0.9895 - val_loss: 2.2528 - val_accuracy: 0.5179\n",
      "Epoch 750/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0796 - accuracy: 0.9887 - val_loss: 2.2528 - val_accuracy: 0.5179\n",
      "Epoch 751/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0790 - accuracy: 0.9875 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 752/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0834 - accuracy: 0.9851 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 753/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0757 - accuracy: 0.9859 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 754/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0802 - accuracy: 0.9867 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 755/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0849 - accuracy: 0.9859 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 756/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0865 - accuracy: 0.9819 - val_loss: 2.2526 - val_accuracy: 0.5179\n",
      "Epoch 757/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0729 - accuracy: 0.9891 - val_loss: 2.2525 - val_accuracy: 0.5179\n",
      "Epoch 758/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0860 - accuracy: 0.9851 - val_loss: 2.2524 - val_accuracy: 0.5179\n",
      "Epoch 759/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0814 - accuracy: 0.9859 - val_loss: 2.2522 - val_accuracy: 0.5179\n",
      "Epoch 760/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0790 - accuracy: 0.9879 - val_loss: 2.2520 - val_accuracy: 0.5179\n",
      "Epoch 761/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0835 - accuracy: 0.9863 - val_loss: 2.2517 - val_accuracy: 0.5179\n",
      "Epoch 762/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0816 - accuracy: 0.9891 - val_loss: 2.2513 - val_accuracy: 0.5179\n",
      "Epoch 763/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0886 - accuracy: 0.9839 - val_loss: 2.2509 - val_accuracy: 0.5179\n",
      "Epoch 764/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0779 - accuracy: 0.9887 - val_loss: 2.2503 - val_accuracy: 0.5179\n",
      "Epoch 765/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0845 - accuracy: 0.9855 - val_loss: 2.2497 - val_accuracy: 0.5179\n",
      "Epoch 766/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0830 - accuracy: 0.9839 - val_loss: 2.2495 - val_accuracy: 0.5179\n",
      "Epoch 767/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0801 - accuracy: 0.9859 - val_loss: 2.2489 - val_accuracy: 0.5179\n",
      "Epoch 768/800\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0839 - accuracy: 0.9855 - val_loss: 2.2484 - val_accuracy: 0.5179\n",
      "Epoch 769/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0773 - accuracy: 0.9851 - val_loss: 2.2481 - val_accuracy: 0.5179\n",
      "Epoch 770/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0785 - accuracy: 0.9835 - val_loss: 2.2478 - val_accuracy: 0.5179\n",
      "Epoch 771/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0838 - accuracy: 0.9851 - val_loss: 2.2477 - val_accuracy: 0.5179\n",
      "Epoch 772/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0866 - accuracy: 0.9859 - val_loss: 2.2475 - val_accuracy: 0.5179\n",
      "Epoch 773/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0855 - accuracy: 0.9867 - val_loss: 2.2474 - val_accuracy: 0.5179\n",
      "Epoch 774/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0922 - accuracy: 0.9855 - val_loss: 2.2472 - val_accuracy: 0.5179\n",
      "Epoch 775/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0812 - accuracy: 0.9843 - val_loss: 2.2470 - val_accuracy: 0.5179\n",
      "Epoch 776/800\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0953 - accuracy: 0.9799 - val_loss: 2.2468 - val_accuracy: 0.5179\n",
      "Epoch 777/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0811 - accuracy: 0.9879 - val_loss: 2.2465 - val_accuracy: 0.5179\n",
      "Epoch 778/800\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0867 - accuracy: 0.9863 - val_loss: 2.2462 - val_accuracy: 0.5179\n",
      "Epoch 779/800\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0836 - accuracy: 0.9859 - val_loss: 2.2459 - val_accuracy: 0.5179\n",
      "Epoch 780/800\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0929 - accuracy: 0.9875 - val_loss: 2.2460 - val_accuracy: 0.5179\n",
      "Epoch 781/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9835 - val_loss: 2.2460 - val_accuracy: 0.5179\n",
      "Epoch 782/800\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0770 - accuracy: 0.9911 - val_loss: 2.2460 - val_accuracy: 0.5179\n",
      "Epoch 783/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0840 - accuracy: 0.9879 - val_loss: 2.2461 - val_accuracy: 0.5179\n",
      "Epoch 784/800\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0922 - accuracy: 0.9843 - val_loss: 2.2463 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/800\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0776 - accuracy: 0.9855 - val_loss: 2.2461 - val_accuracy: 0.5128\n",
      "Epoch 786/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0804 - accuracy: 0.9871 - val_loss: 2.2459 - val_accuracy: 0.5128\n",
      "Epoch 787/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0802 - accuracy: 0.9879 - val_loss: 2.2460 - val_accuracy: 0.5128\n",
      "Epoch 788/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0921 - accuracy: 0.9843 - val_loss: 2.2462 - val_accuracy: 0.5128\n",
      "Epoch 789/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0855 - accuracy: 0.9851 - val_loss: 2.2463 - val_accuracy: 0.5128\n",
      "Epoch 790/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9839 - val_loss: 2.2462 - val_accuracy: 0.5128\n",
      "Epoch 791/800\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0821 - accuracy: 0.9847 - val_loss: 2.2464 - val_accuracy: 0.5128\n",
      "Epoch 792/800\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0806 - accuracy: 0.9879 - val_loss: 2.2466 - val_accuracy: 0.5128\n",
      "Epoch 793/800\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9883 - val_loss: 2.2467 - val_accuracy: 0.5128\n",
      "Epoch 794/800\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0839 - accuracy: 0.9875 - val_loss: 2.2468 - val_accuracy: 0.5128\n",
      "Epoch 795/800\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0747 - accuracy: 0.9891 - val_loss: 2.2471 - val_accuracy: 0.5128\n",
      "Epoch 796/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0925 - accuracy: 0.9795 - val_loss: 2.2471 - val_accuracy: 0.5128\n",
      "Epoch 797/800\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0867 - accuracy: 0.9807 - val_loss: 2.2473 - val_accuracy: 0.5128\n",
      "Epoch 798/800\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0750 - accuracy: 0.9899 - val_loss: 2.2474 - val_accuracy: 0.5128\n",
      "Epoch 799/800\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0846 - accuracy: 0.9835 - val_loss: 2.2473 - val_accuracy: 0.5128\n",
      "Epoch 800/800\n",
      "2485/2485 [==============================] - 0s 83us/step - loss: 0.0838 - accuracy: 0.9867 - val_loss: 2.2473 - val_accuracy: 0.5128\n",
      "Train on 2485 samples, validate on 195 samples\n",
      "Epoch 1/600\n",
      "2485/2485 [==============================] - 7s 3ms/step - loss: 0.0856 - accuracy: 0.9827 - val_loss: 2.2475 - val_accuracy: 0.5231\n",
      "Epoch 2/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0816 - accuracy: 0.9867 - val_loss: 2.2575 - val_accuracy: 0.5179\n",
      "Epoch 3/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0765 - accuracy: 0.9887 - val_loss: 2.2644 - val_accuracy: 0.5128\n",
      "Epoch 4/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0777 - accuracy: 0.9891 - val_loss: 2.2646 - val_accuracy: 0.5128\n",
      "Epoch 5/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0764 - accuracy: 0.9895 - val_loss: 2.2670 - val_accuracy: 0.5128\n",
      "Epoch 6/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0924 - accuracy: 0.9835 - val_loss: 2.2688 - val_accuracy: 0.5179\n",
      "Epoch 7/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0907 - accuracy: 0.9831 - val_loss: 2.2770 - val_accuracy: 0.5179\n",
      "Epoch 8/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0778 - accuracy: 0.9871 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 9/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0766 - accuracy: 0.9871 - val_loss: 2.2913 - val_accuracy: 0.5128\n",
      "Epoch 10/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0854 - accuracy: 0.9859 - val_loss: 2.2992 - val_accuracy: 0.5128\n",
      "Epoch 11/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0815 - accuracy: 0.9831 - val_loss: 2.3024 - val_accuracy: 0.5128\n",
      "Epoch 12/600\n",
      "2485/2485 [==============================] - 0s 59us/step - loss: 0.0876 - accuracy: 0.9839 - val_loss: 2.3073 - val_accuracy: 0.5077\n",
      "Epoch 13/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0838 - accuracy: 0.9855 - val_loss: 2.3116 - val_accuracy: 0.5077\n",
      "Epoch 14/600\n",
      "2485/2485 [==============================] - 0s 57us/step - loss: 0.0793 - accuracy: 0.9887 - val_loss: 2.3150 - val_accuracy: 0.5128\n",
      "Epoch 15/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0718 - accuracy: 0.9895 - val_loss: 2.3169 - val_accuracy: 0.5128\n",
      "Epoch 16/600\n",
      "2485/2485 [==============================] - 0s 54us/step - loss: 0.0879 - accuracy: 0.9835 - val_loss: 2.3173 - val_accuracy: 0.5128\n",
      "Epoch 17/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0866 - accuracy: 0.9827 - val_loss: 2.3167 - val_accuracy: 0.5128\n",
      "Epoch 18/600\n",
      "2485/2485 [==============================] - 0s 53us/step - loss: 0.0858 - accuracy: 0.9839 - val_loss: 2.3167 - val_accuracy: 0.5128\n",
      "Epoch 19/600\n",
      "2485/2485 [==============================] - 0s 59us/step - loss: 0.0749 - accuracy: 0.9883 - val_loss: 2.3163 - val_accuracy: 0.5128\n",
      "Epoch 20/600\n",
      "2485/2485 [==============================] - 0s 50us/step - loss: 0.0851 - accuracy: 0.9843 - val_loss: 2.3149 - val_accuracy: 0.5231\n",
      "Epoch 21/600\n",
      "2485/2485 [==============================] - 0s 59us/step - loss: 0.0791 - accuracy: 0.9851 - val_loss: 2.3145 - val_accuracy: 0.5231\n",
      "Epoch 22/600\n",
      "2485/2485 [==============================] - 0s 55us/step - loss: 0.0802 - accuracy: 0.9823 - val_loss: 2.3135 - val_accuracy: 0.5231\n",
      "Epoch 23/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0766 - accuracy: 0.9879 - val_loss: 2.3129 - val_accuracy: 0.5231\n",
      "Epoch 24/600\n",
      "2485/2485 [==============================] - 0s 55us/step - loss: 0.0756 - accuracy: 0.9895 - val_loss: 2.3120 - val_accuracy: 0.5231\n",
      "Epoch 25/600\n",
      "2485/2485 [==============================] - 0s 58us/step - loss: 0.0835 - accuracy: 0.9851 - val_loss: 2.3117 - val_accuracy: 0.5231\n",
      "Epoch 26/600\n",
      "2485/2485 [==============================] - 0s 54us/step - loss: 0.0757 - accuracy: 0.9903 - val_loss: 2.3112 - val_accuracy: 0.5231\n",
      "Epoch 27/600\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0846 - accuracy: 0.9859 - val_loss: 2.3106 - val_accuracy: 0.5231\n",
      "Epoch 28/600\n",
      "2485/2485 [==============================] - 0s 57us/step - loss: 0.0730 - accuracy: 0.9903 - val_loss: 2.3096 - val_accuracy: 0.5179\n",
      "Epoch 29/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0724 - accuracy: 0.9895 - val_loss: 2.3087 - val_accuracy: 0.5179\n",
      "Epoch 30/600\n",
      "2485/2485 [==============================] - 0s 56us/step - loss: 0.0772 - accuracy: 0.9924 - val_loss: 2.3083 - val_accuracy: 0.5179\n",
      "Epoch 31/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0734 - accuracy: 0.9891 - val_loss: 2.3082 - val_accuracy: 0.5179\n",
      "Epoch 32/600\n",
      "2485/2485 [==============================] - 0s 55us/step - loss: 0.0794 - accuracy: 0.9851 - val_loss: 2.3080 - val_accuracy: 0.5179\n",
      "Epoch 33/600\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0725 - accuracy: 0.9895 - val_loss: 2.3080 - val_accuracy: 0.5179\n",
      "Epoch 34/600\n",
      "2485/2485 [==============================] - 0s 55us/step - loss: 0.0831 - accuracy: 0.9843 - val_loss: 2.3083 - val_accuracy: 0.5179\n",
      "Epoch 35/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0911 - accuracy: 0.9827 - val_loss: 2.3083 - val_accuracy: 0.5179\n",
      "Epoch 36/600\n",
      "2485/2485 [==============================] - 0s 53us/step - loss: 0.0757 - accuracy: 0.9867 - val_loss: 2.3082 - val_accuracy: 0.5179\n",
      "Epoch 37/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0799 - accuracy: 0.9863 - val_loss: 2.3082 - val_accuracy: 0.5179\n",
      "Epoch 38/600\n",
      "2485/2485 [==============================] - 0s 53us/step - loss: 0.0807 - accuracy: 0.9855 - val_loss: 2.3083 - val_accuracy: 0.5179\n",
      "Epoch 39/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0740 - accuracy: 0.9867 - val_loss: 2.3083 - val_accuracy: 0.5179\n",
      "Epoch 40/600\n",
      "2485/2485 [==============================] - 0s 59us/step - loss: 0.0746 - accuracy: 0.9859 - val_loss: 2.3080 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0826 - accuracy: 0.9851 - val_loss: 2.3079 - val_accuracy: 0.5179\n",
      "Epoch 42/600\n",
      "2485/2485 [==============================] - 0s 58us/step - loss: 0.0908 - accuracy: 0.9807 - val_loss: 2.3077 - val_accuracy: 0.5179\n",
      "Epoch 43/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0795 - accuracy: 0.9855 - val_loss: 2.3074 - val_accuracy: 0.5179\n",
      "Epoch 44/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0840 - accuracy: 0.9835 - val_loss: 2.3070 - val_accuracy: 0.5179\n",
      "Epoch 45/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0837 - accuracy: 0.9843 - val_loss: 2.3065 - val_accuracy: 0.5179\n",
      "Epoch 46/600\n",
      "2485/2485 [==============================] - 0s 58us/step - loss: 0.0813 - accuracy: 0.9855 - val_loss: 2.3063 - val_accuracy: 0.5179\n",
      "Epoch 47/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0730 - accuracy: 0.9875 - val_loss: 2.3060 - val_accuracy: 0.5179\n",
      "Epoch 48/600\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0785 - accuracy: 0.9875 - val_loss: 2.3058 - val_accuracy: 0.5179\n",
      "Epoch 49/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0701 - accuracy: 0.9895 - val_loss: 2.3056 - val_accuracy: 0.5179\n",
      "Epoch 50/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0891 - accuracy: 0.9839 - val_loss: 2.3053 - val_accuracy: 0.5179\n",
      "Epoch 51/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0723 - accuracy: 0.9903 - val_loss: 2.3049 - val_accuracy: 0.5179\n",
      "Epoch 52/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0781 - accuracy: 0.9863 - val_loss: 2.3047 - val_accuracy: 0.5179\n",
      "Epoch 53/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0753 - accuracy: 0.9887 - val_loss: 2.3044 - val_accuracy: 0.5179\n",
      "Epoch 54/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0711 - accuracy: 0.9887 - val_loss: 2.3039 - val_accuracy: 0.5179\n",
      "Epoch 55/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0738 - accuracy: 0.9883 - val_loss: 2.3037 - val_accuracy: 0.5179\n",
      "Epoch 56/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0665 - accuracy: 0.9932 - val_loss: 2.3034 - val_accuracy: 0.5179\n",
      "Epoch 57/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0742 - accuracy: 0.9895 - val_loss: 2.3031 - val_accuracy: 0.5179\n",
      "Epoch 58/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0847 - accuracy: 0.9819 - val_loss: 2.3028 - val_accuracy: 0.5179\n",
      "Epoch 59/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0741 - accuracy: 0.9871 - val_loss: 2.3023 - val_accuracy: 0.5179\n",
      "Epoch 60/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9887 - val_loss: 2.3017 - val_accuracy: 0.5179\n",
      "Epoch 61/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0793 - accuracy: 0.9883 - val_loss: 2.3013 - val_accuracy: 0.5179\n",
      "Epoch 62/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0769 - accuracy: 0.9883 - val_loss: 2.3009 - val_accuracy: 0.5179\n",
      "Epoch 63/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0746 - accuracy: 0.9883 - val_loss: 2.3005 - val_accuracy: 0.5179\n",
      "Epoch 64/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0700 - accuracy: 0.9875 - val_loss: 2.3001 - val_accuracy: 0.5179\n",
      "Epoch 65/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0771 - accuracy: 0.9871 - val_loss: 2.2996 - val_accuracy: 0.5179\n",
      "Epoch 66/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0777 - accuracy: 0.9835 - val_loss: 2.2992 - val_accuracy: 0.5179\n",
      "Epoch 67/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0801 - accuracy: 0.9875 - val_loss: 2.2988 - val_accuracy: 0.5179\n",
      "Epoch 68/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0661 - accuracy: 0.9924 - val_loss: 2.2986 - val_accuracy: 0.5179\n",
      "Epoch 69/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0848 - accuracy: 0.9835 - val_loss: 2.2984 - val_accuracy: 0.5179\n",
      "Epoch 70/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0795 - accuracy: 0.9843 - val_loss: 2.2981 - val_accuracy: 0.5179\n",
      "Epoch 71/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0803 - accuracy: 0.9843 - val_loss: 2.2977 - val_accuracy: 0.5179\n",
      "Epoch 72/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0728 - accuracy: 0.9887 - val_loss: 2.2975 - val_accuracy: 0.5179\n",
      "Epoch 73/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0721 - accuracy: 0.9895 - val_loss: 2.2970 - val_accuracy: 0.5179\n",
      "Epoch 74/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0795 - accuracy: 0.9819 - val_loss: 2.2967 - val_accuracy: 0.5179\n",
      "Epoch 75/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0777 - accuracy: 0.9859 - val_loss: 2.2963 - val_accuracy: 0.5179\n",
      "Epoch 76/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0639 - accuracy: 0.9911 - val_loss: 2.2958 - val_accuracy: 0.5179\n",
      "Epoch 77/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0808 - accuracy: 0.9871 - val_loss: 2.2956 - val_accuracy: 0.5179\n",
      "Epoch 78/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0797 - accuracy: 0.9883 - val_loss: 2.2952 - val_accuracy: 0.5179\n",
      "Epoch 79/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0714 - accuracy: 0.9883 - val_loss: 2.2948 - val_accuracy: 0.5179\n",
      "Epoch 80/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0789 - accuracy: 0.9883 - val_loss: 2.2945 - val_accuracy: 0.5179\n",
      "Epoch 81/600\n",
      "2485/2485 [==============================] - 0s 83us/step - loss: 0.0820 - accuracy: 0.9855 - val_loss: 2.2942 - val_accuracy: 0.5179\n",
      "Epoch 82/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0808 - accuracy: 0.9867 - val_loss: 2.2939 - val_accuracy: 0.5179\n",
      "Epoch 83/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0702 - accuracy: 0.9903 - val_loss: 2.2933 - val_accuracy: 0.5179\n",
      "Epoch 84/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0739 - accuracy: 0.9863 - val_loss: 2.2927 - val_accuracy: 0.5128\n",
      "Epoch 85/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0774 - accuracy: 0.9891 - val_loss: 2.2924 - val_accuracy: 0.5128\n",
      "Epoch 86/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0881 - accuracy: 0.9859 - val_loss: 2.2921 - val_accuracy: 0.5128\n",
      "Epoch 87/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0708 - accuracy: 0.9895 - val_loss: 2.2920 - val_accuracy: 0.5128\n",
      "Epoch 88/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0753 - accuracy: 0.9863 - val_loss: 2.2916 - val_accuracy: 0.5128\n",
      "Epoch 89/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0857 - accuracy: 0.9843 - val_loss: 2.2911 - val_accuracy: 0.5128\n",
      "Epoch 90/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0744 - accuracy: 0.9859 - val_loss: 2.2906 - val_accuracy: 0.5128\n",
      "Epoch 91/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0811 - accuracy: 0.9871 - val_loss: 2.2903 - val_accuracy: 0.5128\n",
      "Epoch 92/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0734 - accuracy: 0.9863 - val_loss: 2.2901 - val_accuracy: 0.5128\n",
      "Epoch 93/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0750 - accuracy: 0.9855 - val_loss: 2.2897 - val_accuracy: 0.5128\n",
      "Epoch 94/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0718 - accuracy: 0.9907 - val_loss: 2.2896 - val_accuracy: 0.5128\n",
      "Epoch 95/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0767 - accuracy: 0.9851 - val_loss: 2.2892 - val_accuracy: 0.5128\n",
      "Epoch 96/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0798 - accuracy: 0.9879 - val_loss: 2.2887 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0812 - accuracy: 0.9859 - val_loss: 2.2883 - val_accuracy: 0.5128\n",
      "Epoch 98/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0730 - accuracy: 0.9887 - val_loss: 2.2880 - val_accuracy: 0.5128\n",
      "Epoch 99/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0776 - accuracy: 0.9867 - val_loss: 2.2877 - val_accuracy: 0.5128\n",
      "Epoch 100/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0770 - accuracy: 0.9859 - val_loss: 2.2874 - val_accuracy: 0.5128\n",
      "Epoch 101/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0716 - accuracy: 0.9907 - val_loss: 2.2871 - val_accuracy: 0.5128\n",
      "Epoch 102/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0746 - accuracy: 0.9871 - val_loss: 2.2869 - val_accuracy: 0.5128\n",
      "Epoch 103/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0757 - accuracy: 0.9871 - val_loss: 2.2868 - val_accuracy: 0.5128\n",
      "Epoch 104/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0744 - accuracy: 0.9867 - val_loss: 2.2868 - val_accuracy: 0.5128\n",
      "Epoch 105/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0834 - accuracy: 0.9847 - val_loss: 2.2868 - val_accuracy: 0.5128\n",
      "Epoch 106/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0746 - accuracy: 0.9891 - val_loss: 2.2867 - val_accuracy: 0.5128\n",
      "Epoch 107/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0722 - accuracy: 0.9875 - val_loss: 2.2867 - val_accuracy: 0.5128\n",
      "Epoch 108/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0733 - accuracy: 0.9875 - val_loss: 2.2866 - val_accuracy: 0.5128\n",
      "Epoch 109/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0769 - accuracy: 0.9855 - val_loss: 2.2865 - val_accuracy: 0.5128\n",
      "Epoch 110/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0834 - accuracy: 0.9879 - val_loss: 2.2863 - val_accuracy: 0.5128\n",
      "Epoch 111/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0738 - accuracy: 0.9875 - val_loss: 2.2862 - val_accuracy: 0.5128\n",
      "Epoch 112/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0725 - accuracy: 0.9879 - val_loss: 2.2860 - val_accuracy: 0.5128\n",
      "Epoch 113/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0813 - accuracy: 0.9883 - val_loss: 2.2859 - val_accuracy: 0.5128\n",
      "Epoch 114/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0813 - accuracy: 0.9859 - val_loss: 2.2859 - val_accuracy: 0.5128\n",
      "Epoch 115/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0745 - accuracy: 0.9879 - val_loss: 2.2857 - val_accuracy: 0.5128\n",
      "Epoch 116/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0784 - accuracy: 0.9867 - val_loss: 2.2853 - val_accuracy: 0.5128\n",
      "Epoch 117/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0817 - accuracy: 0.9867 - val_loss: 2.2851 - val_accuracy: 0.5128\n",
      "Epoch 118/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0770 - accuracy: 0.9863 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 119/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0767 - accuracy: 0.9879 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 120/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0783 - accuracy: 0.9863 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 121/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0823 - accuracy: 0.9827 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 122/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0784 - accuracy: 0.9863 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 123/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0752 - accuracy: 0.9879 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 124/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0818 - accuracy: 0.9891 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 125/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0802 - accuracy: 0.9867 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 126/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0773 - accuracy: 0.9855 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 127/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0797 - accuracy: 0.9859 - val_loss: 2.2807 - val_accuracy: 0.5128\n",
      "Epoch 128/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0748 - accuracy: 0.9920 - val_loss: 2.2803 - val_accuracy: 0.5128\n",
      "Epoch 129/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0819 - accuracy: 0.9871 - val_loss: 2.2799 - val_accuracy: 0.5128\n",
      "Epoch 130/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0725 - accuracy: 0.9883 - val_loss: 2.2793 - val_accuracy: 0.5128\n",
      "Epoch 131/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0715 - accuracy: 0.9879 - val_loss: 2.2788 - val_accuracy: 0.5128\n",
      "Epoch 132/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0851 - accuracy: 0.9859 - val_loss: 2.2785 - val_accuracy: 0.5128\n",
      "Epoch 133/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0746 - accuracy: 0.9879 - val_loss: 2.2780 - val_accuracy: 0.5128\n",
      "Epoch 134/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0757 - accuracy: 0.9879 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 135/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0670 - accuracy: 0.9911 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 136/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0774 - accuracy: 0.9867 - val_loss: 2.2770 - val_accuracy: 0.5128\n",
      "Epoch 137/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0792 - accuracy: 0.9875 - val_loss: 2.2767 - val_accuracy: 0.5128\n",
      "Epoch 138/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0678 - accuracy: 0.9907 - val_loss: 2.2763 - val_accuracy: 0.5128\n",
      "Epoch 139/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0701 - accuracy: 0.9863 - val_loss: 2.2759 - val_accuracy: 0.5128\n",
      "Epoch 140/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0783 - accuracy: 0.9871 - val_loss: 2.2756 - val_accuracy: 0.5128\n",
      "Epoch 141/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0710 - accuracy: 0.9887 - val_loss: 2.2754 - val_accuracy: 0.5128\n",
      "Epoch 142/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0768 - accuracy: 0.9875 - val_loss: 2.2750 - val_accuracy: 0.5128\n",
      "Epoch 143/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0859 - accuracy: 0.9863 - val_loss: 2.2750 - val_accuracy: 0.5128\n",
      "Epoch 144/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0710 - accuracy: 0.9895 - val_loss: 2.2748 - val_accuracy: 0.5128\n",
      "Epoch 145/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0722 - accuracy: 0.9891 - val_loss: 2.2746 - val_accuracy: 0.5128\n",
      "Epoch 146/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0697 - accuracy: 0.9915 - val_loss: 2.2747 - val_accuracy: 0.5128\n",
      "Epoch 147/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0729 - accuracy: 0.9907 - val_loss: 2.2746 - val_accuracy: 0.5128\n",
      "Epoch 148/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0730 - accuracy: 0.9895 - val_loss: 2.2746 - val_accuracy: 0.5128\n",
      "Epoch 149/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0791 - accuracy: 0.9847 - val_loss: 2.2746 - val_accuracy: 0.5128\n",
      "Epoch 150/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0785 - accuracy: 0.9871 - val_loss: 2.2743 - val_accuracy: 0.5128\n",
      "Epoch 151/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0734 - accuracy: 0.9879 - val_loss: 2.2741 - val_accuracy: 0.5128\n",
      "Epoch 152/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0865 - accuracy: 0.9811 - val_loss: 2.2739 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0782 - accuracy: 0.9891 - val_loss: 2.2736 - val_accuracy: 0.5128\n",
      "Epoch 154/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0749 - accuracy: 0.9867 - val_loss: 2.2734 - val_accuracy: 0.5128\n",
      "Epoch 155/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0691 - accuracy: 0.9899 - val_loss: 2.2732 - val_accuracy: 0.5128\n",
      "Epoch 156/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0741 - accuracy: 0.9859 - val_loss: 2.2734 - val_accuracy: 0.5128\n",
      "Epoch 157/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0791 - accuracy: 0.9855 - val_loss: 2.2733 - val_accuracy: 0.5128\n",
      "Epoch 158/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0721 - accuracy: 0.9891 - val_loss: 2.2733 - val_accuracy: 0.5128\n",
      "Epoch 159/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0815 - accuracy: 0.9875 - val_loss: 2.2734 - val_accuracy: 0.5128\n",
      "Epoch 160/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0781 - accuracy: 0.9887 - val_loss: 2.2736 - val_accuracy: 0.5128\n",
      "Epoch 161/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0785 - accuracy: 0.9879 - val_loss: 2.2738 - val_accuracy: 0.5128\n",
      "Epoch 162/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0801 - accuracy: 0.9855 - val_loss: 2.2739 - val_accuracy: 0.5128\n",
      "Epoch 163/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0788 - accuracy: 0.9851 - val_loss: 2.2743 - val_accuracy: 0.5128\n",
      "Epoch 164/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0756 - accuracy: 0.9867 - val_loss: 2.2746 - val_accuracy: 0.5128\n",
      "Epoch 165/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0824 - accuracy: 0.9839 - val_loss: 2.2747 - val_accuracy: 0.5128\n",
      "Epoch 166/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0737 - accuracy: 0.9859 - val_loss: 2.2751 - val_accuracy: 0.5128\n",
      "Epoch 167/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0714 - accuracy: 0.9875 - val_loss: 2.2752 - val_accuracy: 0.5128\n",
      "Epoch 168/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0682 - accuracy: 0.9911 - val_loss: 2.2754 - val_accuracy: 0.5128\n",
      "Epoch 169/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0725 - accuracy: 0.9879 - val_loss: 2.2754 - val_accuracy: 0.5128\n",
      "Epoch 170/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0803 - accuracy: 0.9839 - val_loss: 2.2756 - val_accuracy: 0.5128\n",
      "Epoch 171/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0806 - accuracy: 0.9851 - val_loss: 2.2757 - val_accuracy: 0.5128\n",
      "Epoch 172/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0669 - accuracy: 0.9907 - val_loss: 2.2758 - val_accuracy: 0.5128\n",
      "Epoch 173/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0750 - accuracy: 0.9899 - val_loss: 2.2760 - val_accuracy: 0.5128\n",
      "Epoch 174/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0738 - accuracy: 0.9879 - val_loss: 2.2762 - val_accuracy: 0.5128\n",
      "Epoch 175/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0724 - accuracy: 0.9891 - val_loss: 2.2765 - val_accuracy: 0.5128\n",
      "Epoch 176/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0735 - accuracy: 0.9875 - val_loss: 2.2768 - val_accuracy: 0.5128\n",
      "Epoch 177/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0819 - accuracy: 0.9859 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 178/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0750 - accuracy: 0.9875 - val_loss: 2.2775 - val_accuracy: 0.5128\n",
      "Epoch 179/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0777 - accuracy: 0.9859 - val_loss: 2.2779 - val_accuracy: 0.5128\n",
      "Epoch 180/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0728 - accuracy: 0.9899 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 181/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0758 - accuracy: 0.9871 - val_loss: 2.2785 - val_accuracy: 0.5128\n",
      "Epoch 182/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0715 - accuracy: 0.9867 - val_loss: 2.2785 - val_accuracy: 0.5128\n",
      "Epoch 183/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0740 - accuracy: 0.9891 - val_loss: 2.2786 - val_accuracy: 0.5128\n",
      "Epoch 184/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0802 - accuracy: 0.9875 - val_loss: 2.2787 - val_accuracy: 0.5128\n",
      "Epoch 185/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0787 - accuracy: 0.9875 - val_loss: 2.2785 - val_accuracy: 0.5128\n",
      "Epoch 186/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0769 - accuracy: 0.9871 - val_loss: 2.2784 - val_accuracy: 0.5128\n",
      "Epoch 187/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0748 - accuracy: 0.9891 - val_loss: 2.2783 - val_accuracy: 0.5128\n",
      "Epoch 188/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0673 - accuracy: 0.9899 - val_loss: 2.2782 - val_accuracy: 0.5128\n",
      "Epoch 189/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0703 - accuracy: 0.9891 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 190/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0710 - accuracy: 0.9907 - val_loss: 2.2778 - val_accuracy: 0.5128\n",
      "Epoch 191/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0814 - accuracy: 0.9835 - val_loss: 2.2777 - val_accuracy: 0.5128\n",
      "Epoch 192/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0764 - accuracy: 0.9863 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 193/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0750 - accuracy: 0.9851 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 194/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0762 - accuracy: 0.9855 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 195/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0708 - accuracy: 0.9879 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 196/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0684 - accuracy: 0.9911 - val_loss: 2.2767 - val_accuracy: 0.5128\n",
      "Epoch 197/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0709 - accuracy: 0.9851 - val_loss: 2.2766 - val_accuracy: 0.5128\n",
      "Epoch 198/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0739 - accuracy: 0.9855 - val_loss: 2.2766 - val_accuracy: 0.5128\n",
      "Epoch 199/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0658 - accuracy: 0.9899 - val_loss: 2.2768 - val_accuracy: 0.5128\n",
      "Epoch 200/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0823 - accuracy: 0.9835 - val_loss: 2.2770 - val_accuracy: 0.5128\n",
      "Epoch 201/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0780 - accuracy: 0.9875 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 202/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0691 - accuracy: 0.9907 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 203/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0723 - accuracy: 0.9855 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 204/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0810 - accuracy: 0.9867 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 205/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 206/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0727 - accuracy: 0.9887 - val_loss: 2.2770 - val_accuracy: 0.5128\n",
      "Epoch 207/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0846 - accuracy: 0.9839 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 208/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0713 - accuracy: 0.9879 - val_loss: 2.2769 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0754 - accuracy: 0.9887 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 210/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0802 - accuracy: 0.9835 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 211/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0678 - accuracy: 0.9928 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 212/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0736 - accuracy: 0.9875 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 213/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0702 - accuracy: 0.9907 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 214/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0816 - accuracy: 0.9863 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 215/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0661 - accuracy: 0.9907 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 216/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0728 - accuracy: 0.9875 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 217/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0834 - accuracy: 0.9855 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 218/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0719 - accuracy: 0.9895 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 219/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0690 - accuracy: 0.9891 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 220/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0737 - accuracy: 0.9887 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 221/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0755 - accuracy: 0.9875 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 222/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0747 - accuracy: 0.9887 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 223/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0708 - accuracy: 0.9887 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 224/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0787 - accuracy: 0.9887 - val_loss: 2.2777 - val_accuracy: 0.5128\n",
      "Epoch 225/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0730 - accuracy: 0.9883 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 226/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0709 - accuracy: 0.9895 - val_loss: 2.2775 - val_accuracy: 0.5128\n",
      "Epoch 227/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0796 - accuracy: 0.9843 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 228/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0753 - accuracy: 0.9883 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 229/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0767 - accuracy: 0.9863 - val_loss: 2.2772 - val_accuracy: 0.5128\n",
      "Epoch 230/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0765 - accuracy: 0.9891 - val_loss: 2.2770 - val_accuracy: 0.5128\n",
      "Epoch 231/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0792 - accuracy: 0.9855 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 232/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0687 - accuracy: 0.9911 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 233/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0744 - accuracy: 0.9879 - val_loss: 2.2768 - val_accuracy: 0.5128\n",
      "Epoch 234/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0772 - accuracy: 0.9863 - val_loss: 2.2766 - val_accuracy: 0.5128\n",
      "Epoch 235/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0817 - accuracy: 0.9843 - val_loss: 2.2767 - val_accuracy: 0.5128\n",
      "Epoch 236/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0741 - accuracy: 0.9851 - val_loss: 2.2767 - val_accuracy: 0.5128\n",
      "Epoch 237/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0729 - accuracy: 0.9907 - val_loss: 2.2767 - val_accuracy: 0.5128\n",
      "Epoch 238/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0781 - accuracy: 0.9875 - val_loss: 2.2769 - val_accuracy: 0.5128\n",
      "Epoch 239/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0738 - accuracy: 0.9863 - val_loss: 2.2771 - val_accuracy: 0.5128\n",
      "Epoch 240/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0776 - accuracy: 0.9887 - val_loss: 2.2773 - val_accuracy: 0.5128\n",
      "Epoch 241/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0801 - accuracy: 0.9879 - val_loss: 2.2774 - val_accuracy: 0.5128\n",
      "Epoch 242/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0786 - accuracy: 0.9867 - val_loss: 2.2776 - val_accuracy: 0.5128\n",
      "Epoch 243/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0730 - accuracy: 0.9867 - val_loss: 2.2782 - val_accuracy: 0.5128\n",
      "Epoch 244/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0809 - accuracy: 0.9875 - val_loss: 2.2787 - val_accuracy: 0.5128\n",
      "Epoch 245/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0810 - accuracy: 0.9839 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 246/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0674 - accuracy: 0.9903 - val_loss: 2.2799 - val_accuracy: 0.5128\n",
      "Epoch 247/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0751 - accuracy: 0.9879 - val_loss: 2.2804 - val_accuracy: 0.5128\n",
      "Epoch 248/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0822 - accuracy: 0.9851 - val_loss: 2.2807 - val_accuracy: 0.5128\n",
      "Epoch 249/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0777 - accuracy: 0.9863 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 250/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0725 - accuracy: 0.9887 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 251/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0752 - accuracy: 0.9883 - val_loss: 2.2818 - val_accuracy: 0.5128\n",
      "Epoch 252/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0733 - accuracy: 0.9879 - val_loss: 2.2819 - val_accuracy: 0.5128\n",
      "Epoch 253/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0746 - accuracy: 0.9879 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 254/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0753 - accuracy: 0.9867 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 255/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0813 - accuracy: 0.9851 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 256/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0750 - accuracy: 0.9891 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 257/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0745 - accuracy: 0.9887 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 258/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0743 - accuracy: 0.9887 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 259/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0723 - accuracy: 0.9891 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 260/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0777 - accuracy: 0.9871 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 261/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0787 - accuracy: 0.9871 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 262/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0661 - accuracy: 0.9915 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 263/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0719 - accuracy: 0.9891 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 264/600\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0799 - accuracy: 0.9863 - val_loss: 2.2821 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0764 - accuracy: 0.9883 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 266/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9863 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 267/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0739 - accuracy: 0.9867 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 268/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0759 - accuracy: 0.9883 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 269/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0709 - accuracy: 0.9883 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 270/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0684 - accuracy: 0.9879 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 271/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0677 - accuracy: 0.9907 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 272/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0684 - accuracy: 0.9903 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 273/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0736 - accuracy: 0.9899 - val_loss: 2.2818 - val_accuracy: 0.5128\n",
      "Epoch 274/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0678 - accuracy: 0.9903 - val_loss: 2.2818 - val_accuracy: 0.5128\n",
      "Epoch 275/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0692 - accuracy: 0.9895 - val_loss: 2.2815 - val_accuracy: 0.5128\n",
      "Epoch 276/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0679 - accuracy: 0.9907 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 277/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0712 - accuracy: 0.9891 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 278/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0808 - accuracy: 0.9855 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 279/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0738 - accuracy: 0.9899 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 280/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0729 - accuracy: 0.9895 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 281/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0771 - accuracy: 0.9863 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 282/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0731 - accuracy: 0.9887 - val_loss: 2.2808 - val_accuracy: 0.5128\n",
      "Epoch 283/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0793 - accuracy: 0.9867 - val_loss: 2.2808 - val_accuracy: 0.5128\n",
      "Epoch 284/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0769 - accuracy: 0.9907 - val_loss: 2.2810 - val_accuracy: 0.5128\n",
      "Epoch 285/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0721 - accuracy: 0.9883 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 286/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0747 - accuracy: 0.9879 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 287/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0680 - accuracy: 0.9903 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 288/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0730 - accuracy: 0.9867 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 289/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0753 - accuracy: 0.9883 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 290/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0718 - accuracy: 0.9887 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 291/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0745 - accuracy: 0.9879 - val_loss: 2.2813 - val_accuracy: 0.5128\n",
      "Epoch 292/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0742 - accuracy: 0.9907 - val_loss: 2.2813 - val_accuracy: 0.5128\n",
      "Epoch 293/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0720 - accuracy: 0.9883 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 294/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0703 - accuracy: 0.9887 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 295/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0723 - accuracy: 0.9911 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 296/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0711 - accuracy: 0.9895 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 297/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0740 - accuracy: 0.9883 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 298/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0687 - accuracy: 0.9883 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 299/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0736 - accuracy: 0.9855 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 300/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0652 - accuracy: 0.9915 - val_loss: 2.2808 - val_accuracy: 0.5128\n",
      "Epoch 301/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0703 - accuracy: 0.9899 - val_loss: 2.2806 - val_accuracy: 0.5128\n",
      "Epoch 302/600\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0768 - accuracy: 0.9871 - val_loss: 2.2805 - val_accuracy: 0.5128\n",
      "Epoch 303/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0697 - accuracy: 0.9907 - val_loss: 2.2804 - val_accuracy: 0.5128\n",
      "Epoch 304/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0759 - accuracy: 0.9859 - val_loss: 2.2804 - val_accuracy: 0.5128\n",
      "Epoch 305/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0734 - accuracy: 0.9883 - val_loss: 2.2805 - val_accuracy: 0.5128\n",
      "Epoch 306/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0719 - accuracy: 0.9911 - val_loss: 2.2805 - val_accuracy: 0.5128\n",
      "Epoch 307/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0757 - accuracy: 0.9867 - val_loss: 2.2806 - val_accuracy: 0.5128\n",
      "Epoch 308/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0820 - accuracy: 0.9867 - val_loss: 2.2808 - val_accuracy: 0.5128\n",
      "Epoch 309/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0701 - accuracy: 0.9887 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 310/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0724 - accuracy: 0.9903 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 311/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0747 - accuracy: 0.9891 - val_loss: 2.2818 - val_accuracy: 0.5128\n",
      "Epoch 312/600\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0811 - accuracy: 0.9851 - val_loss: 2.2819 - val_accuracy: 0.5128\n",
      "Epoch 313/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0737 - accuracy: 0.9855 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 314/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 315/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0711 - accuracy: 0.9883 - val_loss: 2.2825 - val_accuracy: 0.5128\n",
      "Epoch 316/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0711 - accuracy: 0.9879 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 317/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0666 - accuracy: 0.9903 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 318/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0708 - accuracy: 0.9903 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 319/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0724 - accuracy: 0.9899 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 320/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0659 - accuracy: 0.9895 - val_loss: 2.2834 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0698 - accuracy: 0.9899 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 322/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0724 - accuracy: 0.9867 - val_loss: 2.2838 - val_accuracy: 0.5128\n",
      "Epoch 323/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0774 - accuracy: 0.9859 - val_loss: 2.2841 - val_accuracy: 0.5128\n",
      "Epoch 324/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0691 - accuracy: 0.9899 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 325/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0668 - accuracy: 0.9895 - val_loss: 2.2846 - val_accuracy: 0.5128\n",
      "Epoch 326/600\n",
      "2485/2485 [==============================] - 0s 65us/step - loss: 0.0781 - accuracy: 0.9867 - val_loss: 2.2847 - val_accuracy: 0.5128\n",
      "Epoch 327/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0713 - accuracy: 0.9903 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 328/600\n",
      "2485/2485 [==============================] - 0s 81us/step - loss: 0.0730 - accuracy: 0.9891 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 329/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0663 - accuracy: 0.9903 - val_loss: 2.2846 - val_accuracy: 0.5128\n",
      "Epoch 330/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0723 - accuracy: 0.9891 - val_loss: 2.2846 - val_accuracy: 0.5128\n",
      "Epoch 331/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0744 - accuracy: 0.9907 - val_loss: 2.2847 - val_accuracy: 0.5128\n",
      "Epoch 332/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0706 - accuracy: 0.9879 - val_loss: 2.2845 - val_accuracy: 0.5128\n",
      "Epoch 333/600\n",
      "2485/2485 [==============================] - 0s 85us/step - loss: 0.0753 - accuracy: 0.9883 - val_loss: 2.2844 - val_accuracy: 0.5128\n",
      "Epoch 334/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0806 - accuracy: 0.9831 - val_loss: 2.2841 - val_accuracy: 0.5128\n",
      "Epoch 335/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0730 - accuracy: 0.9903 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 336/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0730 - accuracy: 0.9859 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 337/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0725 - accuracy: 0.9879 - val_loss: 2.2837 - val_accuracy: 0.5128\n",
      "Epoch 338/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0754 - accuracy: 0.9871 - val_loss: 2.2837 - val_accuracy: 0.5128\n",
      "Epoch 339/600\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0699 - accuracy: 0.9911 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 340/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0722 - accuracy: 0.9883 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 341/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0710 - accuracy: 0.9903 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 342/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0780 - accuracy: 0.9871 - val_loss: 2.2838 - val_accuracy: 0.5128\n",
      "Epoch 343/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0687 - accuracy: 0.9907 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 344/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0798 - accuracy: 0.9855 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 345/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0806 - accuracy: 0.9855 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 346/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0830 - accuracy: 0.9859 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 347/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0714 - accuracy: 0.9895 - val_loss: 2.2841 - val_accuracy: 0.5128\n",
      "Epoch 348/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0780 - accuracy: 0.9867 - val_loss: 2.2844 - val_accuracy: 0.5128\n",
      "Epoch 349/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0778 - accuracy: 0.9863 - val_loss: 2.2845 - val_accuracy: 0.5128\n",
      "Epoch 350/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0729 - accuracy: 0.9899 - val_loss: 2.2845 - val_accuracy: 0.5128\n",
      "Epoch 351/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0755 - accuracy: 0.9879 - val_loss: 2.2847 - val_accuracy: 0.5128\n",
      "Epoch 352/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0707 - accuracy: 0.9879 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 353/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0600 - accuracy: 0.9932 - val_loss: 2.2850 - val_accuracy: 0.5128\n",
      "Epoch 354/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0704 - accuracy: 0.9891 - val_loss: 2.2851 - val_accuracy: 0.5128\n",
      "Epoch 355/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0727 - accuracy: 0.9883 - val_loss: 2.2851 - val_accuracy: 0.5128\n",
      "Epoch 356/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0727 - accuracy: 0.9879 - val_loss: 2.2852 - val_accuracy: 0.5128\n",
      "Epoch 357/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0690 - accuracy: 0.9891 - val_loss: 2.2853 - val_accuracy: 0.5128\n",
      "Epoch 358/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0721 - accuracy: 0.9879 - val_loss: 2.2855 - val_accuracy: 0.5128\n",
      "Epoch 359/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0827 - accuracy: 0.9835 - val_loss: 2.2855 - val_accuracy: 0.5128\n",
      "Epoch 360/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0708 - accuracy: 0.9887 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 361/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0690 - accuracy: 0.9887 - val_loss: 2.2855 - val_accuracy: 0.5128\n",
      "Epoch 362/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0774 - accuracy: 0.9863 - val_loss: 2.2855 - val_accuracy: 0.5128\n",
      "Epoch 363/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0719 - accuracy: 0.9883 - val_loss: 2.2856 - val_accuracy: 0.5128\n",
      "Epoch 364/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0710 - accuracy: 0.9895 - val_loss: 2.2856 - val_accuracy: 0.5128\n",
      "Epoch 365/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0743 - accuracy: 0.9875 - val_loss: 2.2856 - val_accuracy: 0.5128\n",
      "Epoch 366/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0692 - accuracy: 0.9907 - val_loss: 2.2856 - val_accuracy: 0.5128\n",
      "Epoch 367/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0705 - accuracy: 0.9891 - val_loss: 2.2856 - val_accuracy: 0.5128\n",
      "Epoch 368/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0716 - accuracy: 0.9891 - val_loss: 2.2861 - val_accuracy: 0.5128\n",
      "Epoch 369/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0668 - accuracy: 0.9915 - val_loss: 2.2862 - val_accuracy: 0.5128\n",
      "Epoch 370/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0675 - accuracy: 0.9883 - val_loss: 2.2863 - val_accuracy: 0.5128\n",
      "Epoch 371/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0729 - accuracy: 0.9879 - val_loss: 2.2860 - val_accuracy: 0.5128\n",
      "Epoch 372/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0779 - accuracy: 0.9855 - val_loss: 2.2857 - val_accuracy: 0.5128\n",
      "Epoch 373/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0692 - accuracy: 0.9883 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 374/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0729 - accuracy: 0.9871 - val_loss: 2.2852 - val_accuracy: 0.5128\n",
      "Epoch 375/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0753 - accuracy: 0.9887 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 376/600\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0699 - accuracy: 0.9899 - val_loss: 2.2846 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0767 - accuracy: 0.9863 - val_loss: 2.2844 - val_accuracy: 0.5128\n",
      "Epoch 378/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0747 - accuracy: 0.9867 - val_loss: 2.2842 - val_accuracy: 0.5128\n",
      "Epoch 379/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0715 - accuracy: 0.9895 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 380/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0668 - accuracy: 0.9907 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 381/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0717 - accuracy: 0.9855 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 382/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0748 - accuracy: 0.9895 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 383/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0683 - accuracy: 0.9903 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 384/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0768 - accuracy: 0.9891 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 385/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0764 - accuracy: 0.9871 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 386/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0747 - accuracy: 0.9867 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 387/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0777 - accuracy: 0.9859 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 388/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0720 - accuracy: 0.9871 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 389/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0873 - accuracy: 0.9847 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 390/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0752 - accuracy: 0.9855 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 391/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0681 - accuracy: 0.9903 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 392/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0753 - accuracy: 0.9903 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 393/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0702 - accuracy: 0.9911 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 394/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0671 - accuracy: 0.9924 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 395/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0753 - accuracy: 0.9867 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 396/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0712 - accuracy: 0.9879 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 397/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0644 - accuracy: 0.9907 - val_loss: 2.2827 - val_accuracy: 0.5128\n",
      "Epoch 398/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0763 - accuracy: 0.9871 - val_loss: 2.2826 - val_accuracy: 0.5128\n",
      "Epoch 399/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0719 - accuracy: 0.9867 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 400/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0671 - accuracy: 0.9911 - val_loss: 2.2826 - val_accuracy: 0.5128\n",
      "Epoch 401/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0710 - accuracy: 0.9883 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 402/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0692 - accuracy: 0.9915 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 403/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0696 - accuracy: 0.9911 - val_loss: 2.2825 - val_accuracy: 0.5128\n",
      "Epoch 404/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0725 - accuracy: 0.9871 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 405/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0738 - accuracy: 0.9883 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 406/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0794 - accuracy: 0.9887 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 407/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0734 - accuracy: 0.9867 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 408/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0708 - accuracy: 0.9920 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 409/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0736 - accuracy: 0.9871 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 410/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0662 - accuracy: 0.9924 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 411/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0719 - accuracy: 0.9895 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 412/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0794 - accuracy: 0.9867 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 413/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0738 - accuracy: 0.9887 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 414/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0667 - accuracy: 0.9903 - val_loss: 2.2823 - val_accuracy: 0.5128\n",
      "Epoch 415/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0714 - accuracy: 0.9871 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 416/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0696 - accuracy: 0.9899 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 417/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0847 - accuracy: 0.9859 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 418/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0713 - accuracy: 0.9875 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 419/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0680 - accuracy: 0.9883 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 420/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0722 - accuracy: 0.9867 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 421/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0660 - accuracy: 0.9924 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 422/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0728 - accuracy: 0.9875 - val_loss: 2.2822 - val_accuracy: 0.5128\n",
      "Epoch 423/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0709 - accuracy: 0.9867 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 424/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0722 - accuracy: 0.9875 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 425/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0688 - accuracy: 0.9903 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 426/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0692 - accuracy: 0.9903 - val_loss: 2.2819 - val_accuracy: 0.5128\n",
      "Epoch 427/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0744 - accuracy: 0.9875 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 428/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0734 - accuracy: 0.9867 - val_loss: 2.2815 - val_accuracy: 0.5128\n",
      "Epoch 429/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0670 - accuracy: 0.9920 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 430/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0797 - accuracy: 0.9851 - val_loss: 2.2813 - val_accuracy: 0.5128\n",
      "Epoch 431/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0762 - accuracy: 0.9863 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 432/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0724 - accuracy: 0.9879 - val_loss: 2.2809 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0659 - accuracy: 0.9907 - val_loss: 2.2806 - val_accuracy: 0.5128\n",
      "Epoch 434/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0720 - accuracy: 0.9875 - val_loss: 2.2804 - val_accuracy: 0.5128\n",
      "Epoch 435/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0757 - accuracy: 0.9903 - val_loss: 2.2803 - val_accuracy: 0.5128\n",
      "Epoch 436/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0731 - accuracy: 0.9867 - val_loss: 2.2802 - val_accuracy: 0.5128\n",
      "Epoch 437/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0767 - accuracy: 0.9871 - val_loss: 2.2801 - val_accuracy: 0.5128\n",
      "Epoch 438/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0743 - accuracy: 0.9879 - val_loss: 2.2800 - val_accuracy: 0.5128\n",
      "Epoch 439/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0672 - accuracy: 0.9883 - val_loss: 2.2799 - val_accuracy: 0.5128\n",
      "Epoch 440/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0730 - accuracy: 0.9891 - val_loss: 2.2798 - val_accuracy: 0.5128\n",
      "Epoch 441/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0662 - accuracy: 0.9895 - val_loss: 2.2797 - val_accuracy: 0.5128\n",
      "Epoch 442/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0643 - accuracy: 0.9924 - val_loss: 2.2797 - val_accuracy: 0.5128\n",
      "Epoch 443/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0784 - accuracy: 0.9863 - val_loss: 2.2797 - val_accuracy: 0.5128\n",
      "Epoch 444/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0690 - accuracy: 0.9920 - val_loss: 2.2798 - val_accuracy: 0.5128\n",
      "Epoch 445/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0866 - accuracy: 0.9847 - val_loss: 2.2796 - val_accuracy: 0.5128\n",
      "Epoch 446/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0658 - accuracy: 0.9920 - val_loss: 2.2795 - val_accuracy: 0.5128\n",
      "Epoch 447/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0819 - accuracy: 0.9871 - val_loss: 2.2795 - val_accuracy: 0.5128\n",
      "Epoch 448/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0772 - accuracy: 0.9859 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 449/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0690 - accuracy: 0.9883 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 450/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0696 - accuracy: 0.9915 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 451/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0684 - accuracy: 0.9879 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 452/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0741 - accuracy: 0.9879 - val_loss: 2.2793 - val_accuracy: 0.5128\n",
      "Epoch 453/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0773 - accuracy: 0.9891 - val_loss: 2.2792 - val_accuracy: 0.5128\n",
      "Epoch 454/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0775 - accuracy: 0.9883 - val_loss: 2.2791 - val_accuracy: 0.5128\n",
      "Epoch 455/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0789 - accuracy: 0.9871 - val_loss: 2.2791 - val_accuracy: 0.5128\n",
      "Epoch 456/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0761 - accuracy: 0.9863 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 457/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0684 - accuracy: 0.9887 - val_loss: 2.2788 - val_accuracy: 0.5128\n",
      "Epoch 458/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0709 - accuracy: 0.9863 - val_loss: 2.2786 - val_accuracy: 0.5128\n",
      "Epoch 459/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0691 - accuracy: 0.9899 - val_loss: 2.2784 - val_accuracy: 0.5128\n",
      "Epoch 460/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0706 - accuracy: 0.9871 - val_loss: 2.2784 - val_accuracy: 0.5128\n",
      "Epoch 461/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0809 - accuracy: 0.9843 - val_loss: 2.2782 - val_accuracy: 0.5128\n",
      "Epoch 462/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0673 - accuracy: 0.9891 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 463/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0693 - accuracy: 0.9895 - val_loss: 2.2782 - val_accuracy: 0.5128\n",
      "Epoch 464/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0637 - accuracy: 0.9903 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 465/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0670 - accuracy: 0.9915 - val_loss: 2.2781 - val_accuracy: 0.5128\n",
      "Epoch 466/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0700 - accuracy: 0.9863 - val_loss: 2.2783 - val_accuracy: 0.5128\n",
      "Epoch 467/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0643 - accuracy: 0.9920 - val_loss: 2.2783 - val_accuracy: 0.5128\n",
      "Epoch 468/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0745 - accuracy: 0.9871 - val_loss: 2.2784 - val_accuracy: 0.5128\n",
      "Epoch 469/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0719 - accuracy: 0.9851 - val_loss: 2.2785 - val_accuracy: 0.5128\n",
      "Epoch 470/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0661 - accuracy: 0.9875 - val_loss: 2.2786 - val_accuracy: 0.5128\n",
      "Epoch 471/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0861 - accuracy: 0.9847 - val_loss: 2.2787 - val_accuracy: 0.5128\n",
      "Epoch 472/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0645 - accuracy: 0.9911 - val_loss: 2.2789 - val_accuracy: 0.5128\n",
      "Epoch 473/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0621 - accuracy: 0.9920 - val_loss: 2.2788 - val_accuracy: 0.5128\n",
      "Epoch 474/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0714 - accuracy: 0.9883 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 475/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0685 - accuracy: 0.9887 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 476/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0697 - accuracy: 0.9883 - val_loss: 2.2789 - val_accuracy: 0.5128\n",
      "Epoch 477/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0712 - accuracy: 0.9871 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 478/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0687 - accuracy: 0.9895 - val_loss: 2.2790 - val_accuracy: 0.5128\n",
      "Epoch 479/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0739 - accuracy: 0.9871 - val_loss: 2.2793 - val_accuracy: 0.5128\n",
      "Epoch 480/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0689 - accuracy: 0.9867 - val_loss: 2.2797 - val_accuracy: 0.5128\n",
      "Epoch 481/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0723 - accuracy: 0.9891 - val_loss: 2.2799 - val_accuracy: 0.5128\n",
      "Epoch 482/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0780 - accuracy: 0.9879 - val_loss: 2.2801 - val_accuracy: 0.5128\n",
      "Epoch 483/600\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0766 - accuracy: 0.9851 - val_loss: 2.2803 - val_accuracy: 0.5128\n",
      "Epoch 484/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0660 - accuracy: 0.9895 - val_loss: 2.2806 - val_accuracy: 0.5128\n",
      "Epoch 485/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0660 - accuracy: 0.9895 - val_loss: 2.2806 - val_accuracy: 0.5128\n",
      "Epoch 486/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0710 - accuracy: 0.9911 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 487/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0641 - accuracy: 0.9903 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 488/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0673 - accuracy: 0.9871 - val_loss: 2.2810 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0763 - accuracy: 0.9843 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 490/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0676 - accuracy: 0.9891 - val_loss: 2.2809 - val_accuracy: 0.5128\n",
      "Epoch 491/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0649 - accuracy: 0.9903 - val_loss: 2.2810 - val_accuracy: 0.5128\n",
      "Epoch 492/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0736 - accuracy: 0.9883 - val_loss: 2.2811 - val_accuracy: 0.5128\n",
      "Epoch 493/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0684 - accuracy: 0.9903 - val_loss: 2.2812 - val_accuracy: 0.5128\n",
      "Epoch 494/600\n",
      "2485/2485 [==============================] - 0s 80us/step - loss: 0.0733 - accuracy: 0.9847 - val_loss: 2.2814 - val_accuracy: 0.5128\n",
      "Epoch 495/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 496/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0705 - accuracy: 0.9907 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 497/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0672 - accuracy: 0.9887 - val_loss: 2.2816 - val_accuracy: 0.5128\n",
      "Epoch 498/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0741 - accuracy: 0.9875 - val_loss: 2.2817 - val_accuracy: 0.5128\n",
      "Epoch 499/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0716 - accuracy: 0.9879 - val_loss: 2.2818 - val_accuracy: 0.5128\n",
      "Epoch 500/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9871 - val_loss: 2.2820 - val_accuracy: 0.5128\n",
      "Epoch 501/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0699 - accuracy: 0.9895 - val_loss: 2.2821 - val_accuracy: 0.5128\n",
      "Epoch 502/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0679 - accuracy: 0.9887 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 503/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0652 - accuracy: 0.9899 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 504/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0704 - accuracy: 0.9903 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 505/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0672 - accuracy: 0.9883 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 506/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0734 - accuracy: 0.9867 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 507/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0687 - accuracy: 0.9891 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 508/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0751 - accuracy: 0.9887 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 509/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0745 - accuracy: 0.9875 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 510/600\n",
      "2485/2485 [==============================] - 0s 71us/step - loss: 0.0654 - accuracy: 0.9895 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 511/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0724 - accuracy: 0.9879 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 512/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0743 - accuracy: 0.9871 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 513/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0725 - accuracy: 0.9871 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 514/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0729 - accuracy: 0.9879 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 515/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0679 - accuracy: 0.9883 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 516/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0714 - accuracy: 0.9891 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 517/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0785 - accuracy: 0.9871 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 518/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0812 - accuracy: 0.9835 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 519/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0743 - accuracy: 0.9883 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 520/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0710 - accuracy: 0.9851 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 521/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0704 - accuracy: 0.9883 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 522/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0731 - accuracy: 0.9859 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 523/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0747 - accuracy: 0.9867 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 524/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0713 - accuracy: 0.9875 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 525/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0655 - accuracy: 0.9903 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 526/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0702 - accuracy: 0.9883 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 527/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0687 - accuracy: 0.9920 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 528/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0628 - accuracy: 0.9903 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 529/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0734 - accuracy: 0.9867 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 530/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0653 - accuracy: 0.9903 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 531/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0830 - accuracy: 0.9843 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 532/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0753 - accuracy: 0.9863 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 533/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0765 - accuracy: 0.9883 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 534/600\n",
      "2485/2485 [==============================] - 0s 59us/step - loss: 0.0576 - accuracy: 0.9920 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 535/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9871 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 536/600\n",
      "2485/2485 [==============================] - 0s 60us/step - loss: 0.0704 - accuracy: 0.9911 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 537/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0684 - accuracy: 0.9903 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 538/600\n",
      "2485/2485 [==============================] - 0s 61us/step - loss: 0.0746 - accuracy: 0.9867 - val_loss: 2.2842 - val_accuracy: 0.5128\n",
      "Epoch 539/600\n",
      "2485/2485 [==============================] - 0s 66us/step - loss: 0.0711 - accuracy: 0.9879 - val_loss: 2.2841 - val_accuracy: 0.5128\n",
      "Epoch 540/600\n",
      "2485/2485 [==============================] - 0s 62us/step - loss: 0.0758 - accuracy: 0.9855 - val_loss: 2.2841 - val_accuracy: 0.5128\n",
      "Epoch 541/600\n",
      "2485/2485 [==============================] - 0s 69us/step - loss: 0.0706 - accuracy: 0.9924 - val_loss: 2.2838 - val_accuracy: 0.5128\n",
      "Epoch 542/600\n",
      "2485/2485 [==============================] - 0s 63us/step - loss: 0.0654 - accuracy: 0.9895 - val_loss: 2.2837 - val_accuracy: 0.5128\n",
      "Epoch 543/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9883 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 544/600\n",
      "2485/2485 [==============================] - 0s 58us/step - loss: 0.0701 - accuracy: 0.9879 - val_loss: 2.2834 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/600\n",
      "2485/2485 [==============================] - 0s 68us/step - loss: 0.0732 - accuracy: 0.9879 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 546/600\n",
      "2485/2485 [==============================] - 0s 58us/step - loss: 0.0722 - accuracy: 0.9875 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 547/600\n",
      "2485/2485 [==============================] - 0s 67us/step - loss: 0.0682 - accuracy: 0.9895 - val_loss: 2.2826 - val_accuracy: 0.5128\n",
      "Epoch 548/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0639 - accuracy: 0.9932 - val_loss: 2.2825 - val_accuracy: 0.5128\n",
      "Epoch 549/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0745 - accuracy: 0.9859 - val_loss: 2.2824 - val_accuracy: 0.5128\n",
      "Epoch 550/600\n",
      "2485/2485 [==============================] - 0s 64us/step - loss: 0.0626 - accuracy: 0.9920 - val_loss: 2.2826 - val_accuracy: 0.5128\n",
      "Epoch 551/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0681 - accuracy: 0.9907 - val_loss: 2.2827 - val_accuracy: 0.5128\n",
      "Epoch 552/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0695 - accuracy: 0.9883 - val_loss: 2.2827 - val_accuracy: 0.5128\n",
      "Epoch 553/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0662 - accuracy: 0.9899 - val_loss: 2.2827 - val_accuracy: 0.5128\n",
      "Epoch 554/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0661 - accuracy: 0.9899 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 555/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0728 - accuracy: 0.9891 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 556/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0719 - accuracy: 0.9899 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 557/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0683 - accuracy: 0.9895 - val_loss: 2.2831 - val_accuracy: 0.5128\n",
      "Epoch 558/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0785 - accuracy: 0.9855 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 559/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0640 - accuracy: 0.9911 - val_loss: 2.2834 - val_accuracy: 0.5128\n",
      "Epoch 560/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0711 - accuracy: 0.9875 - val_loss: 2.2837 - val_accuracy: 0.5128\n",
      "Epoch 561/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0673 - accuracy: 0.9911 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 562/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0711 - accuracy: 0.9891 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 563/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0715 - accuracy: 0.9855 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 564/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0674 - accuracy: 0.9932 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 565/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0715 - accuracy: 0.9875 - val_loss: 2.2839 - val_accuracy: 0.5128\n",
      "Epoch 566/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0696 - accuracy: 0.9871 - val_loss: 2.2837 - val_accuracy: 0.5128\n",
      "Epoch 567/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0723 - accuracy: 0.9907 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 568/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0719 - accuracy: 0.9875 - val_loss: 2.2832 - val_accuracy: 0.5128\n",
      "Epoch 569/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0778 - accuracy: 0.9855 - val_loss: 2.2829 - val_accuracy: 0.5128\n",
      "Epoch 570/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0644 - accuracy: 0.9928 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 571/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0693 - accuracy: 0.9875 - val_loss: 2.2828 - val_accuracy: 0.5128\n",
      "Epoch 572/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0652 - accuracy: 0.9907 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 573/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0674 - accuracy: 0.9907 - val_loss: 2.2830 - val_accuracy: 0.5128\n",
      "Epoch 574/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0678 - accuracy: 0.9887 - val_loss: 2.2833 - val_accuracy: 0.5128\n",
      "Epoch 575/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0684 - accuracy: 0.9887 - val_loss: 2.2835 - val_accuracy: 0.5128\n",
      "Epoch 576/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0760 - accuracy: 0.9855 - val_loss: 2.2836 - val_accuracy: 0.5128\n",
      "Epoch 577/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0658 - accuracy: 0.9911 - val_loss: 2.2838 - val_accuracy: 0.5128\n",
      "Epoch 578/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0747 - accuracy: 0.9847 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 579/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0650 - accuracy: 0.9911 - val_loss: 2.2840 - val_accuracy: 0.5128\n",
      "Epoch 580/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0641 - accuracy: 0.9903 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 581/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0716 - accuracy: 0.9863 - val_loss: 2.2844 - val_accuracy: 0.5128\n",
      "Epoch 582/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0675 - accuracy: 0.9891 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 583/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0673 - accuracy: 0.9928 - val_loss: 2.2843 - val_accuracy: 0.5128\n",
      "Epoch 584/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0764 - accuracy: 0.9859 - val_loss: 2.2846 - val_accuracy: 0.5128\n",
      "Epoch 585/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0731 - accuracy: 0.9887 - val_loss: 2.2847 - val_accuracy: 0.5128\n",
      "Epoch 586/600\n",
      "2485/2485 [==============================] - 0s 73us/step - loss: 0.0693 - accuracy: 0.9887 - val_loss: 2.2848 - val_accuracy: 0.5128\n",
      "Epoch 587/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0679 - accuracy: 0.9887 - val_loss: 2.2850 - val_accuracy: 0.5128\n",
      "Epoch 588/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0681 - accuracy: 0.9907 - val_loss: 2.2850 - val_accuracy: 0.5128\n",
      "Epoch 589/600\n",
      "2485/2485 [==============================] - 0s 77us/step - loss: 0.0712 - accuracy: 0.9899 - val_loss: 2.2853 - val_accuracy: 0.5128\n",
      "Epoch 590/600\n",
      "2485/2485 [==============================] - 0s 88us/step - loss: 0.0615 - accuracy: 0.9915 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 591/600\n",
      "2485/2485 [==============================] - 0s 76us/step - loss: 0.0693 - accuracy: 0.9895 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 592/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0726 - accuracy: 0.9899 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 593/600\n",
      "2485/2485 [==============================] - 0s 75us/step - loss: 0.0662 - accuracy: 0.9891 - val_loss: 2.2854 - val_accuracy: 0.5128\n",
      "Epoch 594/600\n",
      "2485/2485 [==============================] - 0s 70us/step - loss: 0.0761 - accuracy: 0.9895 - val_loss: 2.2855 - val_accuracy: 0.5128\n",
      "Epoch 595/600\n",
      "2485/2485 [==============================] - 0s 78us/step - loss: 0.0731 - accuracy: 0.9859 - val_loss: 2.2857 - val_accuracy: 0.5128\n",
      "Epoch 596/600\n",
      "2485/2485 [==============================] - 0s 72us/step - loss: 0.0749 - accuracy: 0.9883 - val_loss: 2.2859 - val_accuracy: 0.5128\n",
      "Epoch 597/600\n",
      "2485/2485 [==============================] - 0s 74us/step - loss: 0.0723 - accuracy: 0.9859 - val_loss: 2.2859 - val_accuracy: 0.5128\n",
      "Epoch 598/600\n",
      "2485/2485 [==============================] - 0s 81us/step - loss: 0.0675 - accuracy: 0.9871 - val_loss: 2.2859 - val_accuracy: 0.5128\n",
      "Epoch 599/600\n",
      "2485/2485 [==============================] - 0s 83us/step - loss: 0.0696 - accuracy: 0.9887 - val_loss: 2.2857 - val_accuracy: 0.5128\n",
      "Epoch 600/600\n",
      "2485/2485 [==============================] - 0s 79us/step - loss: 0.0637 - accuracy: 0.9907 - val_loss: 2.2857 - val_accuracy: 0.5128\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "\n",
    "# K.set_session(tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=32, inter_op_parallelism_threads=16)))\n",
    "\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=1e-5)\n",
    "\n",
    "history1 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=800,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input)      \n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history2 = DD_Net.fit([X_0,X_1],Y_input,\n",
    "                    batch_size=len(Y_input),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test_input)      \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# the first 600 epochs\n",
    "plot_accuracy(history1)\n",
    "plot_loss(history1)\n",
    "# the next 500 epochs\n",
    "plot_accuracy(history2)\n",
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = DD_Net.predict([X_test_0, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f206d673160>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_pred_cls = np.argmax(Y_test_pred, axis=1)\n",
    "Y_test_cls = np.argmax(Y_test, axis=1)\n",
    "Y_test_cls[:10], Y_test_pred_cls[:10]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "normalize= None # 'true'\n",
    "cm = confusion_matrix(Y_test_cls, Y_test_pred_cls, normalize=normalize)\n",
    "# print(cm)\n",
    "# print(np.sum(np.diagonal(cm)) / np.sum(cm)) # accuracy\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=le.classes_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(xticks_rotation=90, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'jhmdb_lite_model.h5'\n",
    "ddnet.save_DDNet(DD_Net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back from disk\n",
    "new_net = ddnet.load_DDNet(model_path)\n",
    "# Evaluate against test set, you should get the same accuracy\n",
    "new_net.evaluate([X_test_0,X_test_1],Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Imputation\n",
    "##########################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def per_frame_normalized(p):\n",
    "    # mean and std is calculated within a frame, across all joints\n",
    "    # separately for x,y\n",
    "    mean = np.nanmean(p, axis=(1,))\n",
    "    std = np.nanstd(p, axis=(1,))\n",
    "    return (p - np.expand_dims(mean, 1)) / np.expand_dims(std, 1)\n",
    "\n",
    "def per_video_normalize(p):\n",
    "    # noramlize x and y separate\n",
    "    mean = np.nanmean(p, axis=(0,1))\n",
    "    std = np.nanstd(p, axis=(0,1))\n",
    "    return (p - mean) / std\n",
    "    \n",
    "# all_frames_normalized = np.concatenate(list(map(per_frame_normalized, X_interp)))\n",
    "# print(all_frames_normalized.shape)\n",
    "# print(all_frames_normalized[0])\n",
    "# print(count_nan(all_frames_normalized))\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0, initial_strategy='mean', verbose=1)\n",
    "# imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "all_frames_normalized_flat_imputed = imp.fit_transform(all_frames_normalized.reshape((all_frames_normalized.shape[0], -1)))\n",
    "print(all_frames_normalized_flat_imputed[0])\n",
    "\n",
    "def impute(p, imp):\n",
    "    # per-frame normalize\n",
    "    mean = np.nanmean(p, axis=(1,))\n",
    "    std = np.nanstd(p, axis=(1,))\n",
    "    p_normalized = (p - np.expand_dims(mean, 1)) / np.expand_dims(std, 1)\n",
    "    \n",
    "    # impute\n",
    "    q = p_normalized.reshape((p_normalized.shape[0], -1))\n",
    "    q = imp.transform(q)\n",
    "    q = q.reshape(p.shape)\n",
    "    print(q.shape)\n",
    "    # per-frame de-normalize\n",
    "    return (q *  np.expand_dims(std, 1) ) + np.expand_dims(mean, 1)\n",
    "\n",
    "\n",
    "# def per_frame_impute(p, imp):\n",
    "#     q = np.empty_like(p)\n",
    "#     for i, frame in enumerate(p):\n",
    "#         scaler = MinMaxScaler()\n",
    "#         frame_scaled = scaler.fit_transform(frame)\n",
    "#         f_flat = frame_scaled.reshape((1, -1))\n",
    "#         f_flat_imputed = imp.transform(f_flat)\n",
    "#         f_imputed = f_flat_imputed.reshape(frame.shape)\n",
    "#         frame_imputed = scaler.inverse_transform(f_imputed)\n",
    "#         q[i] =  frame_imputed\n",
    "#     return q\n",
    "print(impute(X_interp[0], imp)[0])\n",
    "\n",
    "X_imputed = [per_video_normalize(impute(p, imp)) for p in X_interp]\n",
    "X_test_imputed = [per_video_normalize(impute(p, imp)) for p in X_test_interp]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
