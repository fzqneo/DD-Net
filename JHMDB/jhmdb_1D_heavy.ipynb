{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 25 # the number of joints\n",
    "        self.joint_d = 2 # the dimension of joints\n",
    "        self.clc_num = 21 # the number of class\n",
    "        self.feat_d = 300\n",
    "        self.filters = 64\n",
    "        self.data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'openpose_all_jhmdb_hybrid')\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(T,C,le):\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(T['pose']))): \n",
    "        p = np.copy(T['pose'][i])\n",
    "        p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "\n",
    "        label = np.zeros(C.clc_num)\n",
    "        label[le.transform(T['label'])[i]-1] = 1   \n",
    "\n",
    "        M = get_CG(p,C)\n",
    "\n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "    return X_0,X_1,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H.value,W.value],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "    \n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "        \n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)\n",
    "\n",
    "\n",
    "def build_DD_Net(C):\n",
    "    M = Input(name='M', shape=(C.frame_l,C.feat_d))  \n",
    "    P = Input(name='P', shape=(C.frame_l,C.joint_n,C.joint_d)) \n",
    "    \n",
    "    FM = build_FM(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(C.clc_num, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 25, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 4, 512)       1744896     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 512)          0           model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65536       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 128)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16384       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 128)          0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 21)           2709        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,830,549\n",
      "Trainable params: 1,824,917\n",
      "Non-trainable params: 5,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C)\n",
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [00:02<00:00, 242.98it/s]\n",
      "100%|██████████| 195/195 [00:00<00:00, 252.85it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(os.path.join(C.data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test = pickle.load(open(os.path.join(C.data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/zf/DD-Net/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 497 samples, validate on 195 samples\n",
      "Epoch 1/600\n",
      "497/497 [==============================] - 3s 7ms/step - loss: 3.9961 - accuracy: 0.0201 - val_loss: 3.4324 - val_accuracy: 0.0308\n",
      "Epoch 2/600\n",
      "497/497 [==============================] - 0s 470us/step - loss: 3.6034 - accuracy: 0.0503 - val_loss: 3.5655 - val_accuracy: 0.0308\n",
      "Epoch 3/600\n",
      "497/497 [==============================] - 0s 439us/step - loss: 3.4175 - accuracy: 0.0966 - val_loss: 3.5209 - val_accuracy: 0.0308\n",
      "Epoch 4/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 3.2207 - accuracy: 0.1388 - val_loss: 3.4545 - val_accuracy: 0.0615\n",
      "Epoch 5/600\n",
      "497/497 [==============================] - 0s 437us/step - loss: 3.1410 - accuracy: 0.1429 - val_loss: 3.3888 - val_accuracy: 0.0615\n",
      "Epoch 6/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 3.0621 - accuracy: 0.1710 - val_loss: 3.3933 - val_accuracy: 0.1179\n",
      "Epoch 7/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 2.8908 - accuracy: 0.1831 - val_loss: 3.4814 - val_accuracy: 0.0923\n",
      "Epoch 8/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 2.9078 - accuracy: 0.1751 - val_loss: 3.5799 - val_accuracy: 0.0462\n",
      "Epoch 9/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 2.7710 - accuracy: 0.2032 - val_loss: 3.7012 - val_accuracy: 0.0359\n",
      "Epoch 10/600\n",
      "497/497 [==============================] - 0s 441us/step - loss: 2.7714 - accuracy: 0.1751 - val_loss: 3.7359 - val_accuracy: 0.0359\n",
      "Epoch 11/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 2.8015 - accuracy: 0.2213 - val_loss: 3.7894 - val_accuracy: 0.0308\n",
      "Epoch 12/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 2.6352 - accuracy: 0.2817 - val_loss: 3.8154 - val_accuracy: 0.0308\n",
      "Epoch 13/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 2.5418 - accuracy: 0.2596 - val_loss: 3.8127 - val_accuracy: 0.0308\n",
      "Epoch 14/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 2.4818 - accuracy: 0.2656 - val_loss: 3.7843 - val_accuracy: 0.0359\n",
      "Epoch 15/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 2.4364 - accuracy: 0.2555 - val_loss: 3.7290 - val_accuracy: 0.0359\n",
      "Epoch 16/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 2.4316 - accuracy: 0.3038 - val_loss: 3.6585 - val_accuracy: 0.0359\n",
      "Epoch 17/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 2.3158 - accuracy: 0.3159 - val_loss: 3.5728 - val_accuracy: 0.0359\n",
      "Epoch 18/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 2.2568 - accuracy: 0.3058 - val_loss: 3.4873 - val_accuracy: 0.0410\n",
      "Epoch 19/600\n",
      "497/497 [==============================] - 0s 452us/step - loss: 2.2405 - accuracy: 0.3320 - val_loss: 3.4116 - val_accuracy: 0.0667\n",
      "Epoch 20/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 2.1079 - accuracy: 0.3622 - val_loss: 3.3529 - val_accuracy: 0.0872\n",
      "Epoch 21/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 2.0548 - accuracy: 0.3843 - val_loss: 3.3092 - val_accuracy: 0.1026\n",
      "Epoch 22/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 2.0596 - accuracy: 0.3964 - val_loss: 3.2853 - val_accuracy: 0.1077\n",
      "Epoch 23/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 1.9635 - accuracy: 0.4145 - val_loss: 3.2569 - val_accuracy: 0.1026\n",
      "Epoch 24/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 1.9338 - accuracy: 0.3883 - val_loss: 3.2122 - val_accuracy: 0.1077\n",
      "Epoch 25/600\n",
      "497/497 [==============================] - 0s 429us/step - loss: 1.9514 - accuracy: 0.4286 - val_loss: 3.1542 - val_accuracy: 0.1179\n",
      "Epoch 26/600\n",
      "497/497 [==============================] - 0s 436us/step - loss: 1.9015 - accuracy: 0.4447 - val_loss: 3.1024 - val_accuracy: 0.1333\n",
      "Epoch 27/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 1.7997 - accuracy: 0.4909 - val_loss: 3.0478 - val_accuracy: 0.1436\n",
      "Epoch 28/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 1.7679 - accuracy: 0.4849 - val_loss: 2.9948 - val_accuracy: 0.1590\n",
      "Epoch 29/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 1.7490 - accuracy: 0.4849 - val_loss: 2.9376 - val_accuracy: 0.1692\n",
      "Epoch 30/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 1.6902 - accuracy: 0.5050 - val_loss: 2.9003 - val_accuracy: 0.1641\n",
      "Epoch 31/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 1.6763 - accuracy: 0.4990 - val_loss: 2.8854 - val_accuracy: 0.1641\n",
      "Epoch 32/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 1.6069 - accuracy: 0.5292 - val_loss: 2.8653 - val_accuracy: 0.1641\n",
      "Epoch 33/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 1.5538 - accuracy: 0.5332 - val_loss: 2.8525 - val_accuracy: 0.1641\n",
      "Epoch 34/600\n",
      "497/497 [==============================] - 0s 460us/step - loss: 1.5135 - accuracy: 0.5473 - val_loss: 2.8350 - val_accuracy: 0.1590\n",
      "Epoch 35/600\n",
      "497/497 [==============================] - 0s 497us/step - loss: 1.4799 - accuracy: 0.5755 - val_loss: 2.8175 - val_accuracy: 0.1795\n",
      "Epoch 36/600\n",
      "497/497 [==============================] - 0s 462us/step - loss: 1.4636 - accuracy: 0.5634 - val_loss: 2.7881 - val_accuracy: 0.1744\n",
      "Epoch 37/600\n",
      "497/497 [==============================] - 0s 480us/step - loss: 1.4116 - accuracy: 0.5714 - val_loss: 2.7493 - val_accuracy: 0.1744\n",
      "Epoch 38/600\n",
      "497/497 [==============================] - 0s 509us/step - loss: 1.4606 - accuracy: 0.5553 - val_loss: 2.7132 - val_accuracy: 0.1897\n",
      "Epoch 39/600\n",
      "497/497 [==============================] - 0s 545us/step - loss: 1.4234 - accuracy: 0.5795 - val_loss: 2.6786 - val_accuracy: 0.1795\n",
      "Epoch 40/600\n",
      "497/497 [==============================] - 0s 530us/step - loss: 1.3232 - accuracy: 0.6137 - val_loss: 2.6478 - val_accuracy: 0.1744\n",
      "Epoch 41/600\n",
      "497/497 [==============================] - 0s 677us/step - loss: 1.3143 - accuracy: 0.6177 - val_loss: 2.6243 - val_accuracy: 0.1795\n",
      "Epoch 42/600\n",
      "497/497 [==============================] - 0s 650us/step - loss: 1.2960 - accuracy: 0.6197 - val_loss: 2.6092 - val_accuracy: 0.1846\n",
      "Epoch 43/600\n",
      "497/497 [==============================] - 0s 640us/step - loss: 1.2726 - accuracy: 0.6318 - val_loss: 2.6047 - val_accuracy: 0.1795\n",
      "Epoch 44/600\n",
      "497/497 [==============================] - 0s 668us/step - loss: 1.1774 - accuracy: 0.6861 - val_loss: 2.5936 - val_accuracy: 0.1795\n",
      "Epoch 45/600\n",
      "497/497 [==============================] - 0s 570us/step - loss: 1.1643 - accuracy: 0.6600 - val_loss: 2.5796 - val_accuracy: 0.1846\n",
      "Epoch 46/600\n",
      "497/497 [==============================] - 0s 580us/step - loss: 1.1394 - accuracy: 0.6962 - val_loss: 2.5638 - val_accuracy: 0.2000\n",
      "Epoch 47/600\n",
      "497/497 [==============================] - 0s 569us/step - loss: 1.1057 - accuracy: 0.6901 - val_loss: 2.5522 - val_accuracy: 0.2051\n",
      "Epoch 48/600\n",
      "497/497 [==============================] - 0s 509us/step - loss: 1.1089 - accuracy: 0.6781 - val_loss: 2.5416 - val_accuracy: 0.2308\n",
      "Epoch 49/600\n",
      "497/497 [==============================] - 0s 578us/step - loss: 1.0638 - accuracy: 0.7123 - val_loss: 2.5281 - val_accuracy: 0.2615\n",
      "Epoch 50/600\n",
      "497/497 [==============================] - 0s 479us/step - loss: 1.0665 - accuracy: 0.7042 - val_loss: 2.5212 - val_accuracy: 0.2615\n",
      "Epoch 51/600\n",
      "497/497 [==============================] - 0s 461us/step - loss: 0.9976 - accuracy: 0.7404 - val_loss: 2.5126 - val_accuracy: 0.2769\n",
      "Epoch 52/600\n",
      "497/497 [==============================] - 0s 451us/step - loss: 0.9703 - accuracy: 0.7364 - val_loss: 2.5016 - val_accuracy: 0.2513\n",
      "Epoch 53/600\n",
      "497/497 [==============================] - 0s 443us/step - loss: 0.9358 - accuracy: 0.7545 - val_loss: 2.4989 - val_accuracy: 0.2410\n",
      "Epoch 54/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.8845 - accuracy: 0.7686 - val_loss: 2.5104 - val_accuracy: 0.2256\n",
      "Epoch 55/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.9019 - accuracy: 0.7465 - val_loss: 2.5170 - val_accuracy: 0.2103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.8714 - accuracy: 0.7726 - val_loss: 2.5089 - val_accuracy: 0.2051\n",
      "Epoch 57/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.8610 - accuracy: 0.7425 - val_loss: 2.4882 - val_accuracy: 0.2154\n",
      "Epoch 58/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.8335 - accuracy: 0.7726 - val_loss: 2.4631 - val_accuracy: 0.2410\n",
      "Epoch 59/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.8158 - accuracy: 0.7948 - val_loss: 2.4378 - val_accuracy: 0.2564\n",
      "Epoch 60/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.7725 - accuracy: 0.7887 - val_loss: 2.4249 - val_accuracy: 0.2769\n",
      "Epoch 61/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.7871 - accuracy: 0.7787 - val_loss: 2.4180 - val_accuracy: 0.2872\n",
      "Epoch 62/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.7980 - accuracy: 0.7827 - val_loss: 2.4156 - val_accuracy: 0.3026\n",
      "Epoch 63/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.7247 - accuracy: 0.8249 - val_loss: 2.4185 - val_accuracy: 0.2974\n",
      "Epoch 64/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.6972 - accuracy: 0.8431 - val_loss: 2.4213 - val_accuracy: 0.3026\n",
      "Epoch 65/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 0.6476 - accuracy: 0.8511 - val_loss: 2.4199 - val_accuracy: 0.3179\n",
      "Epoch 66/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.6491 - accuracy: 0.8451 - val_loss: 2.4274 - val_accuracy: 0.3026\n",
      "Epoch 67/600\n",
      "497/497 [==============================] - 0s 444us/step - loss: 0.6122 - accuracy: 0.8571 - val_loss: 2.4300 - val_accuracy: 0.3026\n",
      "Epoch 68/600\n",
      "497/497 [==============================] - 0s 470us/step - loss: 0.6066 - accuracy: 0.8551 - val_loss: 2.4390 - val_accuracy: 0.2923\n",
      "Epoch 69/600\n",
      "497/497 [==============================] - 0s 437us/step - loss: 0.6005 - accuracy: 0.8773 - val_loss: 2.4460 - val_accuracy: 0.2923\n",
      "Epoch 70/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 0.6205 - accuracy: 0.8390 - val_loss: 2.4426 - val_accuracy: 0.2974\n",
      "Epoch 71/600\n",
      "497/497 [==============================] - 0s 443us/step - loss: 0.5810 - accuracy: 0.8692 - val_loss: 2.4346 - val_accuracy: 0.2974\n",
      "Epoch 72/600\n",
      "497/497 [==============================] - 0s 466us/step - loss: 0.5852 - accuracy: 0.8592 - val_loss: 2.4177 - val_accuracy: 0.2872\n",
      "Epoch 73/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.5611 - accuracy: 0.8652 - val_loss: 2.3943 - val_accuracy: 0.2718\n",
      "Epoch 74/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.4859 - accuracy: 0.8994 - val_loss: 2.3710 - val_accuracy: 0.2769\n",
      "Epoch 75/600\n",
      "497/497 [==============================] - 0s 435us/step - loss: 0.5149 - accuracy: 0.8954 - val_loss: 2.3470 - val_accuracy: 0.2974\n",
      "Epoch 76/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.4545 - accuracy: 0.9195 - val_loss: 2.3364 - val_accuracy: 0.2872\n",
      "Epoch 77/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.4437 - accuracy: 0.9155 - val_loss: 2.3273 - val_accuracy: 0.3077\n",
      "Epoch 78/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.4710 - accuracy: 0.8994 - val_loss: 2.3278 - val_accuracy: 0.2923\n",
      "Epoch 79/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.4869 - accuracy: 0.8974 - val_loss: 2.3270 - val_accuracy: 0.3077\n",
      "Epoch 80/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.4218 - accuracy: 0.9215 - val_loss: 2.3308 - val_accuracy: 0.3179\n",
      "Epoch 81/600\n",
      "497/497 [==============================] - 0s 460us/step - loss: 0.4112 - accuracy: 0.9276 - val_loss: 2.3333 - val_accuracy: 0.3128\n",
      "Epoch 82/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.3780 - accuracy: 0.9477 - val_loss: 2.3266 - val_accuracy: 0.3179\n",
      "Epoch 83/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.3804 - accuracy: 0.9416 - val_loss: 2.3212 - val_accuracy: 0.3282\n",
      "Epoch 84/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.3946 - accuracy: 0.9155 - val_loss: 2.3114 - val_accuracy: 0.3436\n",
      "Epoch 85/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.4004 - accuracy: 0.8954 - val_loss: 2.3125 - val_accuracy: 0.3385\n",
      "Epoch 86/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.3194 - accuracy: 0.9416 - val_loss: 2.3208 - val_accuracy: 0.3333\n",
      "Epoch 87/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.3683 - accuracy: 0.9256 - val_loss: 2.3298 - val_accuracy: 0.3282\n",
      "Epoch 88/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.3679 - accuracy: 0.9376 - val_loss: 2.3386 - val_accuracy: 0.3333\n",
      "Epoch 89/600\n",
      "497/497 [==============================] - 0s 460us/step - loss: 0.3571 - accuracy: 0.9396 - val_loss: 2.3343 - val_accuracy: 0.3333\n",
      "Epoch 90/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.3390 - accuracy: 0.9416 - val_loss: 2.3196 - val_accuracy: 0.3333\n",
      "Epoch 91/600\n",
      "497/497 [==============================] - 0s 448us/step - loss: 0.3155 - accuracy: 0.9477 - val_loss: 2.3097 - val_accuracy: 0.3385\n",
      "Epoch 92/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.3400 - accuracy: 0.9356 - val_loss: 2.3043 - val_accuracy: 0.3282\n",
      "Epoch 93/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.2667 - accuracy: 0.9577 - val_loss: 2.3007 - val_accuracy: 0.3333\n",
      "Epoch 94/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.3158 - accuracy: 0.9497 - val_loss: 2.2966 - val_accuracy: 0.3487\n",
      "Epoch 95/600\n",
      "497/497 [==============================] - 0s 447us/step - loss: 0.2914 - accuracy: 0.9618 - val_loss: 2.2976 - val_accuracy: 0.3436\n",
      "Epoch 96/600\n",
      "497/497 [==============================] - 0s 448us/step - loss: 0.2791 - accuracy: 0.9497 - val_loss: 2.2988 - val_accuracy: 0.3487\n",
      "Epoch 97/600\n",
      "497/497 [==============================] - 0s 463us/step - loss: 0.2776 - accuracy: 0.9598 - val_loss: 2.3052 - val_accuracy: 0.3282\n",
      "Epoch 98/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.2740 - accuracy: 0.9557 - val_loss: 2.3162 - val_accuracy: 0.3231\n",
      "Epoch 99/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.2509 - accuracy: 0.9698 - val_loss: 2.3174 - val_accuracy: 0.3231\n",
      "Epoch 100/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.2809 - accuracy: 0.9577 - val_loss: 2.3149 - val_accuracy: 0.3282\n",
      "Epoch 101/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.2364 - accuracy: 0.9638 - val_loss: 2.3115 - val_accuracy: 0.3333\n",
      "Epoch 102/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.2559 - accuracy: 0.9718 - val_loss: 2.2992 - val_accuracy: 0.3436\n",
      "Epoch 103/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.2156 - accuracy: 0.9759 - val_loss: 2.2882 - val_accuracy: 0.3487\n",
      "Epoch 104/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.2355 - accuracy: 0.9678 - val_loss: 2.2820 - val_accuracy: 0.3487\n",
      "Epoch 105/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.2231 - accuracy: 0.9698 - val_loss: 2.2767 - val_accuracy: 0.3538\n",
      "Epoch 106/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.2061 - accuracy: 0.9759 - val_loss: 2.2728 - val_accuracy: 0.3641\n",
      "Epoch 107/600\n",
      "497/497 [==============================] - 0s 441us/step - loss: 0.1956 - accuracy: 0.9879 - val_loss: 2.2685 - val_accuracy: 0.3744\n",
      "Epoch 108/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.2186 - accuracy: 0.9718 - val_loss: 2.2604 - val_accuracy: 0.3795\n",
      "Epoch 109/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.2397 - accuracy: 0.9598 - val_loss: 2.2529 - val_accuracy: 0.3795\n",
      "Epoch 110/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1978 - accuracy: 0.9839 - val_loss: 2.2482 - val_accuracy: 0.3795\n",
      "Epoch 111/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.2286 - accuracy: 0.9557 - val_loss: 2.2420 - val_accuracy: 0.3795\n",
      "Epoch 112/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1813 - accuracy: 0.9839 - val_loss: 2.2405 - val_accuracy: 0.3846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.2149 - accuracy: 0.9738 - val_loss: 2.2407 - val_accuracy: 0.3795\n",
      "Epoch 114/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.2235 - accuracy: 0.9698 - val_loss: 2.2421 - val_accuracy: 0.3795\n",
      "Epoch 115/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.2348 - accuracy: 0.9658 - val_loss: 2.2396 - val_accuracy: 0.3744\n",
      "Epoch 116/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.2351 - accuracy: 0.9618 - val_loss: 2.2392 - val_accuracy: 0.3795\n",
      "Epoch 117/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1963 - accuracy: 0.9799 - val_loss: 2.2401 - val_accuracy: 0.3744\n",
      "Epoch 118/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.2036 - accuracy: 0.9819 - val_loss: 2.2360 - val_accuracy: 0.3744\n",
      "Epoch 119/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1789 - accuracy: 0.9879 - val_loss: 2.2310 - val_accuracy: 0.3744\n",
      "Epoch 120/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1784 - accuracy: 0.9879 - val_loss: 2.2257 - val_accuracy: 0.3846\n",
      "Epoch 121/600\n",
      "497/497 [==============================] - 0s 374us/step - loss: 0.1770 - accuracy: 0.9879 - val_loss: 2.2203 - val_accuracy: 0.3897\n",
      "Epoch 122/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1797 - accuracy: 0.9779 - val_loss: 2.2125 - val_accuracy: 0.4051\n",
      "Epoch 123/600\n",
      "497/497 [==============================] - 0s 374us/step - loss: 0.1892 - accuracy: 0.9718 - val_loss: 2.2043 - val_accuracy: 0.4103\n",
      "Epoch 124/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1705 - accuracy: 0.9899 - val_loss: 2.1968 - val_accuracy: 0.4256\n",
      "Epoch 125/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1763 - accuracy: 0.9839 - val_loss: 2.1911 - val_accuracy: 0.4359\n",
      "Epoch 126/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1772 - accuracy: 0.9879 - val_loss: 2.1851 - val_accuracy: 0.4359\n",
      "Epoch 127/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1823 - accuracy: 0.9779 - val_loss: 2.1775 - val_accuracy: 0.4308\n",
      "Epoch 128/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.2196 - accuracy: 0.9678 - val_loss: 2.1714 - val_accuracy: 0.4359\n",
      "Epoch 129/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1806 - accuracy: 0.9779 - val_loss: 2.1649 - val_accuracy: 0.4410\n",
      "Epoch 130/600\n",
      "497/497 [==============================] - 0s 425us/step - loss: 0.1726 - accuracy: 0.9920 - val_loss: 2.1607 - val_accuracy: 0.4410\n",
      "Epoch 131/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1923 - accuracy: 0.9839 - val_loss: 2.1568 - val_accuracy: 0.4359\n",
      "Epoch 132/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1725 - accuracy: 0.9839 - val_loss: 2.1523 - val_accuracy: 0.4359\n",
      "Epoch 133/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1833 - accuracy: 0.9738 - val_loss: 2.1488 - val_accuracy: 0.4308\n",
      "Epoch 134/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1730 - accuracy: 0.9799 - val_loss: 2.1452 - val_accuracy: 0.4308\n",
      "Epoch 135/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1985 - accuracy: 0.9658 - val_loss: 2.1421 - val_accuracy: 0.4359\n",
      "Epoch 136/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1685 - accuracy: 0.9738 - val_loss: 2.1411 - val_accuracy: 0.4308\n",
      "Epoch 137/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1600 - accuracy: 0.9859 - val_loss: 2.1411 - val_accuracy: 0.4308\n",
      "Epoch 138/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1848 - accuracy: 0.9839 - val_loss: 2.1421 - val_accuracy: 0.4308\n",
      "Epoch 139/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1883 - accuracy: 0.9759 - val_loss: 2.1417 - val_accuracy: 0.4256\n",
      "Epoch 140/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1716 - accuracy: 0.9899 - val_loss: 2.1413 - val_accuracy: 0.4308\n",
      "Epoch 141/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1806 - accuracy: 0.9759 - val_loss: 2.1409 - val_accuracy: 0.4359\n",
      "Epoch 142/600\n",
      "497/497 [==============================] - 0s 374us/step - loss: 0.1729 - accuracy: 0.9759 - val_loss: 2.1400 - val_accuracy: 0.4205\n",
      "Epoch 143/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1755 - accuracy: 0.9920 - val_loss: 2.1398 - val_accuracy: 0.4308\n",
      "Epoch 144/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1738 - accuracy: 0.9819 - val_loss: 2.1396 - val_accuracy: 0.4308\n",
      "Epoch 145/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1533 - accuracy: 0.9859 - val_loss: 2.1387 - val_accuracy: 0.4359\n",
      "Epoch 146/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1770 - accuracy: 0.9738 - val_loss: 2.1374 - val_accuracy: 0.4359\n",
      "Epoch 147/600\n",
      "497/497 [==============================] - 0s 437us/step - loss: 0.1734 - accuracy: 0.9819 - val_loss: 2.1368 - val_accuracy: 0.4359\n",
      "Epoch 148/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1798 - accuracy: 0.9738 - val_loss: 2.1353 - val_accuracy: 0.4359\n",
      "Epoch 149/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1827 - accuracy: 0.9759 - val_loss: 2.1338 - val_accuracy: 0.4410\n",
      "Epoch 150/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1851 - accuracy: 0.9738 - val_loss: 2.1324 - val_accuracy: 0.4462\n",
      "Epoch 151/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1731 - accuracy: 0.9920 - val_loss: 2.1307 - val_accuracy: 0.4462\n",
      "Epoch 152/600\n",
      "497/497 [==============================] - 0s 370us/step - loss: 0.1803 - accuracy: 0.9839 - val_loss: 2.1294 - val_accuracy: 0.4462\n",
      "Epoch 153/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1700 - accuracy: 0.9839 - val_loss: 2.1282 - val_accuracy: 0.4513\n",
      "Epoch 154/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1578 - accuracy: 0.9859 - val_loss: 2.1273 - val_accuracy: 0.4513\n",
      "Epoch 155/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1443 - accuracy: 0.9899 - val_loss: 2.1265 - val_accuracy: 0.4513\n",
      "Epoch 156/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1675 - accuracy: 0.9819 - val_loss: 2.1259 - val_accuracy: 0.4513\n",
      "Epoch 157/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1622 - accuracy: 0.9799 - val_loss: 2.1257 - val_accuracy: 0.4564\n",
      "Epoch 158/600\n",
      "497/497 [==============================] - 0s 452us/step - loss: 0.1600 - accuracy: 0.9799 - val_loss: 2.1252 - val_accuracy: 0.4564\n",
      "Epoch 159/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1841 - accuracy: 0.9759 - val_loss: 2.1250 - val_accuracy: 0.4564\n",
      "Epoch 160/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1578 - accuracy: 0.9899 - val_loss: 2.1252 - val_accuracy: 0.4564\n",
      "Epoch 161/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1795 - accuracy: 0.9738 - val_loss: 2.1246 - val_accuracy: 0.4564\n",
      "Epoch 162/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1792 - accuracy: 0.9738 - val_loss: 2.1241 - val_accuracy: 0.4564\n",
      "Epoch 163/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1547 - accuracy: 0.9899 - val_loss: 2.1237 - val_accuracy: 0.4564\n",
      "Epoch 164/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1745 - accuracy: 0.9759 - val_loss: 2.1230 - val_accuracy: 0.4564\n",
      "Epoch 165/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1500 - accuracy: 0.9879 - val_loss: 2.1227 - val_accuracy: 0.4564\n",
      "Epoch 166/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1529 - accuracy: 0.9779 - val_loss: 2.1222 - val_accuracy: 0.4615\n",
      "Epoch 167/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1573 - accuracy: 0.9759 - val_loss: 2.1217 - val_accuracy: 0.4615\n",
      "Epoch 168/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1638 - accuracy: 0.9899 - val_loss: 2.1209 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1448 - accuracy: 0.9899 - val_loss: 2.1204 - val_accuracy: 0.4615\n",
      "Epoch 170/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1718 - accuracy: 0.9799 - val_loss: 2.1196 - val_accuracy: 0.4615\n",
      "Epoch 171/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 0.1581 - accuracy: 0.9920 - val_loss: 2.1188 - val_accuracy: 0.4615\n",
      "Epoch 172/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1662 - accuracy: 0.9839 - val_loss: 2.1179 - val_accuracy: 0.4564\n",
      "Epoch 173/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1501 - accuracy: 0.9879 - val_loss: 2.1172 - val_accuracy: 0.4615\n",
      "Epoch 174/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1689 - accuracy: 0.9839 - val_loss: 2.1163 - val_accuracy: 0.4615\n",
      "Epoch 175/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1487 - accuracy: 0.9839 - val_loss: 2.1153 - val_accuracy: 0.4615\n",
      "Epoch 176/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1655 - accuracy: 0.9920 - val_loss: 2.1144 - val_accuracy: 0.4615\n",
      "Epoch 177/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1511 - accuracy: 0.9859 - val_loss: 2.1134 - val_accuracy: 0.4615\n",
      "Epoch 178/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.1568 - accuracy: 0.9839 - val_loss: 2.1126 - val_accuracy: 0.4615\n",
      "Epoch 179/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1717 - accuracy: 0.9859 - val_loss: 2.1117 - val_accuracy: 0.4615\n",
      "Epoch 180/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1642 - accuracy: 0.9799 - val_loss: 2.1110 - val_accuracy: 0.4615\n",
      "Epoch 181/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1737 - accuracy: 0.9879 - val_loss: 2.1102 - val_accuracy: 0.4667\n",
      "Epoch 182/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.1691 - accuracy: 0.9779 - val_loss: 2.1097 - val_accuracy: 0.4667\n",
      "Epoch 183/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1573 - accuracy: 0.9859 - val_loss: 2.1087 - val_accuracy: 0.4667\n",
      "Epoch 184/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1627 - accuracy: 0.9819 - val_loss: 2.1081 - val_accuracy: 0.4718\n",
      "Epoch 185/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1563 - accuracy: 0.9839 - val_loss: 2.1074 - val_accuracy: 0.4718\n",
      "Epoch 186/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1830 - accuracy: 0.9799 - val_loss: 2.1068 - val_accuracy: 0.4718\n",
      "Epoch 187/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1514 - accuracy: 0.9920 - val_loss: 2.1060 - val_accuracy: 0.4718\n",
      "Epoch 188/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1594 - accuracy: 0.9839 - val_loss: 2.1055 - val_accuracy: 0.4718\n",
      "Epoch 189/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1665 - accuracy: 0.9799 - val_loss: 2.1048 - val_accuracy: 0.4718\n",
      "Epoch 190/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1696 - accuracy: 0.9799 - val_loss: 2.1042 - val_accuracy: 0.4718\n",
      "Epoch 191/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1784 - accuracy: 0.9738 - val_loss: 2.1037 - val_accuracy: 0.4718\n",
      "Epoch 192/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1525 - accuracy: 0.9859 - val_loss: 2.1029 - val_accuracy: 0.4718\n",
      "Epoch 193/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1517 - accuracy: 0.9859 - val_loss: 2.1022 - val_accuracy: 0.4769\n",
      "Epoch 194/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1559 - accuracy: 0.9879 - val_loss: 2.1017 - val_accuracy: 0.4769\n",
      "Epoch 195/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1463 - accuracy: 0.9839 - val_loss: 2.1013 - val_accuracy: 0.4769\n",
      "Epoch 196/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1443 - accuracy: 0.9899 - val_loss: 2.1010 - val_accuracy: 0.4718\n",
      "Epoch 197/600\n",
      "497/497 [==============================] - 0s 372us/step - loss: 0.1839 - accuracy: 0.9738 - val_loss: 2.1010 - val_accuracy: 0.4718\n",
      "Epoch 198/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1680 - accuracy: 0.9799 - val_loss: 2.1008 - val_accuracy: 0.4667\n",
      "Epoch 199/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1698 - accuracy: 0.9799 - val_loss: 2.1008 - val_accuracy: 0.4718\n",
      "Epoch 200/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1544 - accuracy: 0.9879 - val_loss: 2.1006 - val_accuracy: 0.4667\n",
      "Epoch 201/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1610 - accuracy: 0.9718 - val_loss: 2.1003 - val_accuracy: 0.4667\n",
      "Epoch 202/600\n",
      "497/497 [==============================] - 0s 438us/step - loss: 0.1659 - accuracy: 0.9799 - val_loss: 2.1001 - val_accuracy: 0.4769\n",
      "Epoch 203/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1413 - accuracy: 0.9879 - val_loss: 2.1000 - val_accuracy: 0.4769\n",
      "Epoch 204/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1476 - accuracy: 0.9879 - val_loss: 2.0998 - val_accuracy: 0.4769\n",
      "Epoch 205/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1566 - accuracy: 0.9859 - val_loss: 2.0996 - val_accuracy: 0.4769\n",
      "Epoch 206/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1396 - accuracy: 0.9940 - val_loss: 2.0996 - val_accuracy: 0.4769\n",
      "Epoch 207/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1495 - accuracy: 0.9819 - val_loss: 2.0992 - val_accuracy: 0.4769\n",
      "Epoch 208/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1792 - accuracy: 0.9839 - val_loss: 2.0992 - val_accuracy: 0.4769\n",
      "Epoch 209/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1534 - accuracy: 0.9839 - val_loss: 2.0992 - val_accuracy: 0.4769\n",
      "Epoch 210/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1545 - accuracy: 0.9920 - val_loss: 2.0990 - val_accuracy: 0.4769\n",
      "Epoch 211/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1554 - accuracy: 0.9839 - val_loss: 2.0988 - val_accuracy: 0.4821\n",
      "Epoch 212/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1527 - accuracy: 0.9879 - val_loss: 2.0985 - val_accuracy: 0.4821\n",
      "Epoch 213/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1663 - accuracy: 0.9819 - val_loss: 2.0983 - val_accuracy: 0.4821\n",
      "Epoch 214/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1637 - accuracy: 0.9839 - val_loss: 2.0980 - val_accuracy: 0.4872\n",
      "Epoch 215/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1493 - accuracy: 0.9859 - val_loss: 2.0979 - val_accuracy: 0.4872\n",
      "Epoch 216/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1618 - accuracy: 0.9879 - val_loss: 2.0979 - val_accuracy: 0.4872\n",
      "Epoch 217/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1470 - accuracy: 0.9920 - val_loss: 2.0976 - val_accuracy: 0.4872\n",
      "Epoch 218/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1700 - accuracy: 0.9718 - val_loss: 2.0974 - val_accuracy: 0.4872\n",
      "Epoch 219/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1782 - accuracy: 0.9779 - val_loss: 2.0972 - val_accuracy: 0.4923\n",
      "Epoch 220/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1543 - accuracy: 0.9899 - val_loss: 2.0972 - val_accuracy: 0.4923\n",
      "Epoch 221/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1624 - accuracy: 0.9839 - val_loss: 2.0971 - val_accuracy: 0.4974\n",
      "Epoch 222/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1498 - accuracy: 0.9879 - val_loss: 2.0969 - val_accuracy: 0.4974\n",
      "Epoch 223/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1538 - accuracy: 0.9879 - val_loss: 2.0965 - val_accuracy: 0.4974\n",
      "Epoch 224/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1653 - accuracy: 0.9779 - val_loss: 2.0963 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1769 - accuracy: 0.9759 - val_loss: 2.0961 - val_accuracy: 0.4974\n",
      "Epoch 226/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1615 - accuracy: 0.9879 - val_loss: 2.0959 - val_accuracy: 0.4974\n",
      "Epoch 227/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1423 - accuracy: 0.9879 - val_loss: 2.0958 - val_accuracy: 0.4974\n",
      "Epoch 228/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1715 - accuracy: 0.9799 - val_loss: 2.0954 - val_accuracy: 0.4974\n",
      "Epoch 229/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1576 - accuracy: 0.9839 - val_loss: 2.0956 - val_accuracy: 0.4974\n",
      "Epoch 230/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1558 - accuracy: 0.9899 - val_loss: 2.0956 - val_accuracy: 0.4923\n",
      "Epoch 231/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1429 - accuracy: 0.9980 - val_loss: 2.0955 - val_accuracy: 0.4923\n",
      "Epoch 232/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1625 - accuracy: 0.9899 - val_loss: 2.0953 - val_accuracy: 0.4923\n",
      "Epoch 233/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1781 - accuracy: 0.9779 - val_loss: 2.0951 - val_accuracy: 0.4923\n",
      "Epoch 234/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1805 - accuracy: 0.9819 - val_loss: 2.0947 - val_accuracy: 0.4923\n",
      "Epoch 235/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1801 - accuracy: 0.9718 - val_loss: 2.0943 - val_accuracy: 0.4923\n",
      "Epoch 236/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1888 - accuracy: 0.9738 - val_loss: 2.0942 - val_accuracy: 0.4923\n",
      "Epoch 237/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1642 - accuracy: 0.9698 - val_loss: 2.0942 - val_accuracy: 0.4923\n",
      "Epoch 238/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1679 - accuracy: 0.9779 - val_loss: 2.0939 - val_accuracy: 0.4923\n",
      "Epoch 239/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1657 - accuracy: 0.9879 - val_loss: 2.0934 - val_accuracy: 0.4923\n",
      "Epoch 240/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1500 - accuracy: 0.9879 - val_loss: 2.0930 - val_accuracy: 0.4923\n",
      "Epoch 241/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1732 - accuracy: 0.9839 - val_loss: 2.0932 - val_accuracy: 0.4923\n",
      "Epoch 242/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1529 - accuracy: 0.9859 - val_loss: 2.0931 - val_accuracy: 0.4923\n",
      "Epoch 243/600\n",
      "497/497 [==============================] - 0s 370us/step - loss: 0.1579 - accuracy: 0.9920 - val_loss: 2.0930 - val_accuracy: 0.4923\n",
      "Epoch 244/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1669 - accuracy: 0.9839 - val_loss: 2.0933 - val_accuracy: 0.4923\n",
      "Epoch 245/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1551 - accuracy: 0.9879 - val_loss: 2.0932 - val_accuracy: 0.4923\n",
      "Epoch 246/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1588 - accuracy: 0.9859 - val_loss: 2.0929 - val_accuracy: 0.4923\n",
      "Epoch 247/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1490 - accuracy: 0.9879 - val_loss: 2.0927 - val_accuracy: 0.4923\n",
      "Epoch 248/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1598 - accuracy: 0.9940 - val_loss: 2.0928 - val_accuracy: 0.4923\n",
      "Epoch 249/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1659 - accuracy: 0.9839 - val_loss: 2.0926 - val_accuracy: 0.4923\n",
      "Epoch 250/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1579 - accuracy: 0.9839 - val_loss: 2.0926 - val_accuracy: 0.4923\n",
      "Epoch 251/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1489 - accuracy: 0.9879 - val_loss: 2.0926 - val_accuracy: 0.4923\n",
      "Epoch 252/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1580 - accuracy: 0.9839 - val_loss: 2.0927 - val_accuracy: 0.4923\n",
      "Epoch 253/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1655 - accuracy: 0.9799 - val_loss: 2.0928 - val_accuracy: 0.4872\n",
      "Epoch 254/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1507 - accuracy: 0.9819 - val_loss: 2.0927 - val_accuracy: 0.4872\n",
      "Epoch 255/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1724 - accuracy: 0.9819 - val_loss: 2.0927 - val_accuracy: 0.4923\n",
      "Epoch 256/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1612 - accuracy: 0.9839 - val_loss: 2.0930 - val_accuracy: 0.4923\n",
      "Epoch 257/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1758 - accuracy: 0.9738 - val_loss: 2.0931 - val_accuracy: 0.4923\n",
      "Epoch 258/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1663 - accuracy: 0.9879 - val_loss: 2.0934 - val_accuracy: 0.4923\n",
      "Epoch 259/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1524 - accuracy: 0.9839 - val_loss: 2.0936 - val_accuracy: 0.4923\n",
      "Epoch 260/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1645 - accuracy: 0.9859 - val_loss: 2.0937 - val_accuracy: 0.4923\n",
      "Epoch 261/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1551 - accuracy: 0.9779 - val_loss: 2.0938 - val_accuracy: 0.4872\n",
      "Epoch 262/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1473 - accuracy: 0.9879 - val_loss: 2.0941 - val_accuracy: 0.4872\n",
      "Epoch 263/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1730 - accuracy: 0.9819 - val_loss: 2.0942 - val_accuracy: 0.4872\n",
      "Epoch 264/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1768 - accuracy: 0.9738 - val_loss: 2.0950 - val_accuracy: 0.4872\n",
      "Epoch 265/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1415 - accuracy: 0.9920 - val_loss: 2.0954 - val_accuracy: 0.4872\n",
      "Epoch 266/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.1584 - accuracy: 0.9879 - val_loss: 2.0957 - val_accuracy: 0.4872\n",
      "Epoch 267/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1467 - accuracy: 0.9920 - val_loss: 2.0957 - val_accuracy: 0.4872\n",
      "Epoch 268/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1493 - accuracy: 0.9839 - val_loss: 2.0958 - val_accuracy: 0.4872\n",
      "Epoch 269/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1636 - accuracy: 0.9839 - val_loss: 2.0960 - val_accuracy: 0.4872\n",
      "Epoch 270/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1680 - accuracy: 0.9698 - val_loss: 2.0962 - val_accuracy: 0.4872\n",
      "Epoch 271/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1602 - accuracy: 0.9899 - val_loss: 2.0964 - val_accuracy: 0.4872\n",
      "Epoch 272/600\n",
      "497/497 [==============================] - 0s 435us/step - loss: 0.1595 - accuracy: 0.9879 - val_loss: 2.0966 - val_accuracy: 0.4872\n",
      "Epoch 273/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1651 - accuracy: 0.9879 - val_loss: 2.0968 - val_accuracy: 0.4872\n",
      "Epoch 274/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1568 - accuracy: 0.9899 - val_loss: 2.0973 - val_accuracy: 0.4872\n",
      "Epoch 275/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1544 - accuracy: 0.9819 - val_loss: 2.0972 - val_accuracy: 0.4872\n",
      "Epoch 276/600\n",
      "497/497 [==============================] - 0s 369us/step - loss: 0.1650 - accuracy: 0.9839 - val_loss: 2.0974 - val_accuracy: 0.4872\n",
      "Epoch 277/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.1437 - accuracy: 0.9899 - val_loss: 2.0975 - val_accuracy: 0.4872\n",
      "Epoch 278/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1564 - accuracy: 0.9819 - val_loss: 2.0973 - val_accuracy: 0.4872\n",
      "Epoch 279/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1663 - accuracy: 0.9859 - val_loss: 2.0977 - val_accuracy: 0.4872\n",
      "Epoch 280/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1472 - accuracy: 0.9879 - val_loss: 2.0979 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1442 - accuracy: 0.9940 - val_loss: 2.0975 - val_accuracy: 0.4872\n",
      "Epoch 282/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1669 - accuracy: 0.9859 - val_loss: 2.0975 - val_accuracy: 0.4872\n",
      "Epoch 283/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1470 - accuracy: 0.9879 - val_loss: 2.0972 - val_accuracy: 0.4872\n",
      "Epoch 284/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1753 - accuracy: 0.9839 - val_loss: 2.0970 - val_accuracy: 0.4872\n",
      "Epoch 285/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1644 - accuracy: 0.9779 - val_loss: 2.0974 - val_accuracy: 0.4872\n",
      "Epoch 286/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1494 - accuracy: 0.9899 - val_loss: 2.0973 - val_accuracy: 0.4872\n",
      "Epoch 287/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1568 - accuracy: 0.9899 - val_loss: 2.0972 - val_accuracy: 0.4872\n",
      "Epoch 288/600\n",
      "497/497 [==============================] - 0s 374us/step - loss: 0.1697 - accuracy: 0.9718 - val_loss: 2.0972 - val_accuracy: 0.4872\n",
      "Epoch 289/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1611 - accuracy: 0.9879 - val_loss: 2.0970 - val_accuracy: 0.4872\n",
      "Epoch 290/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1660 - accuracy: 0.9779 - val_loss: 2.0970 - val_accuracy: 0.4872\n",
      "Epoch 291/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1822 - accuracy: 0.9799 - val_loss: 2.0971 - val_accuracy: 0.4872\n",
      "Epoch 292/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1661 - accuracy: 0.9799 - val_loss: 2.0970 - val_accuracy: 0.4872\n",
      "Epoch 293/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.1625 - accuracy: 0.9899 - val_loss: 2.0970 - val_accuracy: 0.4872\n",
      "Epoch 294/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1917 - accuracy: 0.9759 - val_loss: 2.0969 - val_accuracy: 0.4872\n",
      "Epoch 295/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1808 - accuracy: 0.9759 - val_loss: 2.0967 - val_accuracy: 0.4872\n",
      "Epoch 296/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1754 - accuracy: 0.9799 - val_loss: 2.0966 - val_accuracy: 0.4872\n",
      "Epoch 297/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1647 - accuracy: 0.9819 - val_loss: 2.0963 - val_accuracy: 0.4872\n",
      "Epoch 298/600\n",
      "497/497 [==============================] - 0s 429us/step - loss: 0.1523 - accuracy: 0.9859 - val_loss: 2.0961 - val_accuracy: 0.4872\n",
      "Epoch 299/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1461 - accuracy: 0.9899 - val_loss: 2.0957 - val_accuracy: 0.4872\n",
      "Epoch 300/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1709 - accuracy: 0.9799 - val_loss: 2.0952 - val_accuracy: 0.4872\n",
      "Epoch 301/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1575 - accuracy: 0.9799 - val_loss: 2.0948 - val_accuracy: 0.4821\n",
      "Epoch 302/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1705 - accuracy: 0.9859 - val_loss: 2.0946 - val_accuracy: 0.4821\n",
      "Epoch 303/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1791 - accuracy: 0.9819 - val_loss: 2.0947 - val_accuracy: 0.4821\n",
      "Epoch 304/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1671 - accuracy: 0.9859 - val_loss: 2.0946 - val_accuracy: 0.4821\n",
      "Epoch 305/600\n",
      "497/497 [==============================] - 0s 438us/step - loss: 0.1734 - accuracy: 0.9718 - val_loss: 2.0946 - val_accuracy: 0.4821\n",
      "Epoch 306/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1865 - accuracy: 0.9658 - val_loss: 2.0945 - val_accuracy: 0.4821\n",
      "Epoch 307/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1577 - accuracy: 0.9879 - val_loss: 2.0944 - val_accuracy: 0.4821\n",
      "Epoch 308/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1821 - accuracy: 0.9799 - val_loss: 2.0942 - val_accuracy: 0.4821\n",
      "Epoch 309/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1637 - accuracy: 0.9819 - val_loss: 2.0943 - val_accuracy: 0.4821\n",
      "Epoch 310/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1818 - accuracy: 0.9779 - val_loss: 2.0944 - val_accuracy: 0.4821\n",
      "Epoch 311/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.1700 - accuracy: 0.9759 - val_loss: 2.0946 - val_accuracy: 0.4769\n",
      "Epoch 312/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1538 - accuracy: 0.9879 - val_loss: 2.0947 - val_accuracy: 0.4769\n",
      "Epoch 313/600\n",
      "497/497 [==============================] - 0s 436us/step - loss: 0.1554 - accuracy: 0.9759 - val_loss: 2.0948 - val_accuracy: 0.4769\n",
      "Epoch 314/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1451 - accuracy: 0.9819 - val_loss: 2.0947 - val_accuracy: 0.4769\n",
      "Epoch 315/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1881 - accuracy: 0.9799 - val_loss: 2.0949 - val_accuracy: 0.4769\n",
      "Epoch 316/600\n",
      "497/497 [==============================] - 0s 376us/step - loss: 0.1467 - accuracy: 0.9899 - val_loss: 2.0949 - val_accuracy: 0.4769\n",
      "Epoch 317/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1502 - accuracy: 0.9819 - val_loss: 2.0952 - val_accuracy: 0.4769\n",
      "Epoch 318/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1822 - accuracy: 0.9738 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 319/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.1768 - accuracy: 0.9799 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 320/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1499 - accuracy: 0.9859 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 321/600\n",
      "497/497 [==============================] - 0s 445us/step - loss: 0.1504 - accuracy: 0.9819 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 322/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1502 - accuracy: 0.9920 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 323/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1378 - accuracy: 0.9920 - val_loss: 2.0955 - val_accuracy: 0.4769\n",
      "Epoch 324/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1623 - accuracy: 0.9779 - val_loss: 2.0955 - val_accuracy: 0.4769\n",
      "Epoch 325/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1677 - accuracy: 0.9839 - val_loss: 2.0952 - val_accuracy: 0.4769\n",
      "Epoch 326/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.1850 - accuracy: 0.9799 - val_loss: 2.0951 - val_accuracy: 0.4769\n",
      "Epoch 327/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1599 - accuracy: 0.9879 - val_loss: 2.0948 - val_accuracy: 0.4769\n",
      "Epoch 328/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1566 - accuracy: 0.9879 - val_loss: 2.0948 - val_accuracy: 0.4769\n",
      "Epoch 329/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1776 - accuracy: 0.9799 - val_loss: 2.0950 - val_accuracy: 0.4769\n",
      "Epoch 330/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1485 - accuracy: 0.9879 - val_loss: 2.0950 - val_accuracy: 0.4769\n",
      "Epoch 331/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1471 - accuracy: 0.9899 - val_loss: 2.0954 - val_accuracy: 0.4769\n",
      "Epoch 332/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1569 - accuracy: 0.9819 - val_loss: 2.0954 - val_accuracy: 0.4769\n",
      "Epoch 333/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1696 - accuracy: 0.9738 - val_loss: 2.0954 - val_accuracy: 0.4769\n",
      "Epoch 334/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1465 - accuracy: 0.9960 - val_loss: 2.0957 - val_accuracy: 0.4769\n",
      "Epoch 335/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1622 - accuracy: 0.9920 - val_loss: 2.0960 - val_accuracy: 0.4769\n",
      "Epoch 336/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1616 - accuracy: 0.9779 - val_loss: 2.0960 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1452 - accuracy: 0.9899 - val_loss: 2.0961 - val_accuracy: 0.4769\n",
      "Epoch 338/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1563 - accuracy: 0.9879 - val_loss: 2.0960 - val_accuracy: 0.4769\n",
      "Epoch 339/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1365 - accuracy: 0.9859 - val_loss: 2.0958 - val_accuracy: 0.4769\n",
      "Epoch 340/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1732 - accuracy: 0.9859 - val_loss: 2.0962 - val_accuracy: 0.4769\n",
      "Epoch 341/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1454 - accuracy: 0.9940 - val_loss: 2.0963 - val_accuracy: 0.4769\n",
      "Epoch 342/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1679 - accuracy: 0.9738 - val_loss: 2.0966 - val_accuracy: 0.4769\n",
      "Epoch 343/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1580 - accuracy: 0.9920 - val_loss: 2.0967 - val_accuracy: 0.4769\n",
      "Epoch 344/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1311 - accuracy: 0.9920 - val_loss: 2.0969 - val_accuracy: 0.4769\n",
      "Epoch 345/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1834 - accuracy: 0.9698 - val_loss: 2.0969 - val_accuracy: 0.4769\n",
      "Epoch 346/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1532 - accuracy: 0.9859 - val_loss: 2.0970 - val_accuracy: 0.4769\n",
      "Epoch 347/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1519 - accuracy: 0.9759 - val_loss: 2.0969 - val_accuracy: 0.4769\n",
      "Epoch 348/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1741 - accuracy: 0.9799 - val_loss: 2.0969 - val_accuracy: 0.4769\n",
      "Epoch 349/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1602 - accuracy: 0.9819 - val_loss: 2.0969 - val_accuracy: 0.4769\n",
      "Epoch 350/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1521 - accuracy: 0.9819 - val_loss: 2.0970 - val_accuracy: 0.4769\n",
      "Epoch 351/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1417 - accuracy: 0.9920 - val_loss: 2.0973 - val_accuracy: 0.4769\n",
      "Epoch 352/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1763 - accuracy: 0.9779 - val_loss: 2.0974 - val_accuracy: 0.4769\n",
      "Epoch 353/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1746 - accuracy: 0.9839 - val_loss: 2.0976 - val_accuracy: 0.4769\n",
      "Epoch 354/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1588 - accuracy: 0.9859 - val_loss: 2.0976 - val_accuracy: 0.4769\n",
      "Epoch 355/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1404 - accuracy: 0.9879 - val_loss: 2.0974 - val_accuracy: 0.4769\n",
      "Epoch 356/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1486 - accuracy: 0.9940 - val_loss: 2.0976 - val_accuracy: 0.4769\n",
      "Epoch 357/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1703 - accuracy: 0.9779 - val_loss: 2.0979 - val_accuracy: 0.4769\n",
      "Epoch 358/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1467 - accuracy: 0.9819 - val_loss: 2.0979 - val_accuracy: 0.4769\n",
      "Epoch 359/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1590 - accuracy: 0.9859 - val_loss: 2.0981 - val_accuracy: 0.4769\n",
      "Epoch 360/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1715 - accuracy: 0.9718 - val_loss: 2.0984 - val_accuracy: 0.4769\n",
      "Epoch 361/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1622 - accuracy: 0.9859 - val_loss: 2.0985 - val_accuracy: 0.4769\n",
      "Epoch 362/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1445 - accuracy: 0.9960 - val_loss: 2.0985 - val_accuracy: 0.4769\n",
      "Epoch 363/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1493 - accuracy: 0.9859 - val_loss: 2.0987 - val_accuracy: 0.4769\n",
      "Epoch 364/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1447 - accuracy: 0.9920 - val_loss: 2.0988 - val_accuracy: 0.4769\n",
      "Epoch 365/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1788 - accuracy: 0.9839 - val_loss: 2.0994 - val_accuracy: 0.4769\n",
      "Epoch 366/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1386 - accuracy: 0.9960 - val_loss: 2.0997 - val_accuracy: 0.4769\n",
      "Epoch 367/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1453 - accuracy: 0.9920 - val_loss: 2.1000 - val_accuracy: 0.4769\n",
      "Epoch 368/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1577 - accuracy: 0.9879 - val_loss: 2.1002 - val_accuracy: 0.4769\n",
      "Epoch 369/600\n",
      "497/497 [==============================] - 0s 438us/step - loss: 0.1545 - accuracy: 0.9879 - val_loss: 2.1007 - val_accuracy: 0.4769\n",
      "Epoch 370/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1724 - accuracy: 0.9759 - val_loss: 2.1009 - val_accuracy: 0.4769\n",
      "Epoch 371/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1587 - accuracy: 0.9839 - val_loss: 2.1006 - val_accuracy: 0.4769\n",
      "Epoch 372/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1649 - accuracy: 0.9799 - val_loss: 2.1009 - val_accuracy: 0.4769\n",
      "Epoch 373/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1416 - accuracy: 0.9879 - val_loss: 2.1011 - val_accuracy: 0.4769\n",
      "Epoch 374/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1699 - accuracy: 0.9779 - val_loss: 2.1013 - val_accuracy: 0.4769\n",
      "Epoch 375/600\n",
      "497/497 [==============================] - 0s 425us/step - loss: 0.1595 - accuracy: 0.9839 - val_loss: 2.1017 - val_accuracy: 0.4769\n",
      "Epoch 376/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1782 - accuracy: 0.9799 - val_loss: 2.1018 - val_accuracy: 0.4769\n",
      "Epoch 377/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1694 - accuracy: 0.9718 - val_loss: 2.1023 - val_accuracy: 0.4769\n",
      "Epoch 378/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1395 - accuracy: 0.9859 - val_loss: 2.1024 - val_accuracy: 0.4769\n",
      "Epoch 379/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1540 - accuracy: 0.9859 - val_loss: 2.1025 - val_accuracy: 0.4769\n",
      "Epoch 380/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1534 - accuracy: 0.9859 - val_loss: 2.1027 - val_accuracy: 0.4769\n",
      "Epoch 381/600\n",
      "497/497 [==============================] - 0s 429us/step - loss: 0.1564 - accuracy: 0.9819 - val_loss: 2.1028 - val_accuracy: 0.4769\n",
      "Epoch 382/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1631 - accuracy: 0.9819 - val_loss: 2.1033 - val_accuracy: 0.4769\n",
      "Epoch 383/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1483 - accuracy: 0.9859 - val_loss: 2.1035 - val_accuracy: 0.4769\n",
      "Epoch 384/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1585 - accuracy: 0.9799 - val_loss: 2.1039 - val_accuracy: 0.4769\n",
      "Epoch 385/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1617 - accuracy: 0.9859 - val_loss: 2.1042 - val_accuracy: 0.4769\n",
      "Epoch 386/600\n",
      "497/497 [==============================] - 0s 435us/step - loss: 0.1577 - accuracy: 0.9839 - val_loss: 2.1044 - val_accuracy: 0.4769\n",
      "Epoch 387/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1649 - accuracy: 0.9799 - val_loss: 2.1047 - val_accuracy: 0.4769\n",
      "Epoch 388/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1516 - accuracy: 0.9879 - val_loss: 2.1049 - val_accuracy: 0.4769\n",
      "Epoch 389/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1613 - accuracy: 0.9859 - val_loss: 2.1057 - val_accuracy: 0.4769\n",
      "Epoch 390/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1720 - accuracy: 0.9819 - val_loss: 2.1064 - val_accuracy: 0.4769\n",
      "Epoch 391/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1611 - accuracy: 0.9879 - val_loss: 2.1072 - val_accuracy: 0.4769\n",
      "Epoch 392/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1777 - accuracy: 0.9738 - val_loss: 2.1077 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1603 - accuracy: 0.9799 - val_loss: 2.1079 - val_accuracy: 0.4769\n",
      "Epoch 394/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1700 - accuracy: 0.9819 - val_loss: 2.1083 - val_accuracy: 0.4769\n",
      "Epoch 395/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1458 - accuracy: 0.9899 - val_loss: 2.1085 - val_accuracy: 0.4769\n",
      "Epoch 396/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1519 - accuracy: 0.9899 - val_loss: 2.1090 - val_accuracy: 0.4769\n",
      "Epoch 397/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1299 - accuracy: 0.9879 - val_loss: 2.1092 - val_accuracy: 0.4769\n",
      "Epoch 398/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1408 - accuracy: 0.9839 - val_loss: 2.1098 - val_accuracy: 0.4769\n",
      "Epoch 399/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1658 - accuracy: 0.9839 - val_loss: 2.1104 - val_accuracy: 0.4769\n",
      "Epoch 400/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1608 - accuracy: 0.9819 - val_loss: 2.1108 - val_accuracy: 0.4769\n",
      "Epoch 401/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1391 - accuracy: 0.9920 - val_loss: 2.1111 - val_accuracy: 0.4769\n",
      "Epoch 402/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1469 - accuracy: 0.9859 - val_loss: 2.1116 - val_accuracy: 0.4769\n",
      "Epoch 403/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1567 - accuracy: 0.9779 - val_loss: 2.1117 - val_accuracy: 0.4769\n",
      "Epoch 404/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1556 - accuracy: 0.9879 - val_loss: 2.1119 - val_accuracy: 0.4769\n",
      "Epoch 405/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1842 - accuracy: 0.9759 - val_loss: 2.1121 - val_accuracy: 0.4769\n",
      "Epoch 406/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1491 - accuracy: 0.9859 - val_loss: 2.1121 - val_accuracy: 0.4769\n",
      "Epoch 407/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1661 - accuracy: 0.9759 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 408/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1458 - accuracy: 0.9899 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 409/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1451 - accuracy: 0.9879 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 410/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1756 - accuracy: 0.9879 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 411/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1504 - accuracy: 0.9899 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 412/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1507 - accuracy: 0.9779 - val_loss: 2.1126 - val_accuracy: 0.4718\n",
      "Epoch 413/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1656 - accuracy: 0.9799 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 414/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1549 - accuracy: 0.9799 - val_loss: 2.1124 - val_accuracy: 0.4769\n",
      "Epoch 415/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1565 - accuracy: 0.9839 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 416/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1678 - accuracy: 0.9839 - val_loss: 2.1122 - val_accuracy: 0.4769\n",
      "Epoch 417/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1618 - accuracy: 0.9799 - val_loss: 2.1121 - val_accuracy: 0.4769\n",
      "Epoch 418/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1458 - accuracy: 0.9879 - val_loss: 2.1117 - val_accuracy: 0.4769\n",
      "Epoch 419/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1739 - accuracy: 0.9718 - val_loss: 2.1116 - val_accuracy: 0.4769\n",
      "Epoch 420/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1430 - accuracy: 0.9879 - val_loss: 2.1111 - val_accuracy: 0.4769\n",
      "Epoch 421/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.1738 - accuracy: 0.9759 - val_loss: 2.1107 - val_accuracy: 0.4769\n",
      "Epoch 422/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1574 - accuracy: 0.9859 - val_loss: 2.1103 - val_accuracy: 0.4769\n",
      "Epoch 423/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1511 - accuracy: 0.9879 - val_loss: 2.1102 - val_accuracy: 0.4769\n",
      "Epoch 424/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1408 - accuracy: 0.9879 - val_loss: 2.1100 - val_accuracy: 0.4769\n",
      "Epoch 425/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1674 - accuracy: 0.9819 - val_loss: 2.1100 - val_accuracy: 0.4769\n",
      "Epoch 426/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1668 - accuracy: 0.9839 - val_loss: 2.1100 - val_accuracy: 0.4769\n",
      "Epoch 427/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1441 - accuracy: 0.9859 - val_loss: 2.1103 - val_accuracy: 0.4769\n",
      "Epoch 428/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1725 - accuracy: 0.9839 - val_loss: 2.1102 - val_accuracy: 0.4769\n",
      "Epoch 429/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1364 - accuracy: 0.9899 - val_loss: 2.1100 - val_accuracy: 0.4769\n",
      "Epoch 430/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1725 - accuracy: 0.9799 - val_loss: 2.1098 - val_accuracy: 0.4769\n",
      "Epoch 431/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1654 - accuracy: 0.9839 - val_loss: 2.1098 - val_accuracy: 0.4769\n",
      "Epoch 432/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1571 - accuracy: 0.9899 - val_loss: 2.1097 - val_accuracy: 0.4769\n",
      "Epoch 433/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1561 - accuracy: 0.9940 - val_loss: 2.1094 - val_accuracy: 0.4769\n",
      "Epoch 434/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1446 - accuracy: 0.9920 - val_loss: 2.1094 - val_accuracy: 0.4769\n",
      "Epoch 435/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1493 - accuracy: 0.9940 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 436/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1326 - accuracy: 0.9940 - val_loss: 2.1092 - val_accuracy: 0.4769\n",
      "Epoch 437/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1597 - accuracy: 0.9779 - val_loss: 2.1094 - val_accuracy: 0.4769\n",
      "Epoch 438/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1359 - accuracy: 0.9940 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 439/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1539 - accuracy: 0.9839 - val_loss: 2.1090 - val_accuracy: 0.4769\n",
      "Epoch 440/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.1594 - accuracy: 0.9819 - val_loss: 2.1092 - val_accuracy: 0.4769\n",
      "Epoch 441/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1827 - accuracy: 0.9819 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 442/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1704 - accuracy: 0.9718 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 443/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1730 - accuracy: 0.9859 - val_loss: 2.1090 - val_accuracy: 0.4769\n",
      "Epoch 444/600\n",
      "497/497 [==============================] - 0s 440us/step - loss: 0.1685 - accuracy: 0.9819 - val_loss: 2.1090 - val_accuracy: 0.4769\n",
      "Epoch 445/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1556 - accuracy: 0.9779 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 446/600\n",
      "497/497 [==============================] - 0s 441us/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 2.1094 - val_accuracy: 0.4769\n",
      "Epoch 447/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1564 - accuracy: 0.9839 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 448/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1473 - accuracy: 0.9839 - val_loss: 2.1092 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1588 - accuracy: 0.9899 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 450/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1435 - accuracy: 0.9859 - val_loss: 2.1093 - val_accuracy: 0.4769\n",
      "Epoch 451/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1384 - accuracy: 0.9859 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 452/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1523 - accuracy: 0.9859 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 453/600\n",
      "497/497 [==============================] - 0s 429us/step - loss: 0.1524 - accuracy: 0.9839 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 454/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1522 - accuracy: 0.9859 - val_loss: 2.1088 - val_accuracy: 0.4769\n",
      "Epoch 455/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1542 - accuracy: 0.9839 - val_loss: 2.1087 - val_accuracy: 0.4769\n",
      "Epoch 456/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1853 - accuracy: 0.9718 - val_loss: 2.1086 - val_accuracy: 0.4769\n",
      "Epoch 457/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1595 - accuracy: 0.9960 - val_loss: 2.1086 - val_accuracy: 0.4769\n",
      "Epoch 458/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1503 - accuracy: 0.9839 - val_loss: 2.1085 - val_accuracy: 0.4769\n",
      "Epoch 459/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1715 - accuracy: 0.9819 - val_loss: 2.1085 - val_accuracy: 0.4769\n",
      "Epoch 460/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1503 - accuracy: 0.9899 - val_loss: 2.1088 - val_accuracy: 0.4769\n",
      "Epoch 461/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1455 - accuracy: 0.9879 - val_loss: 2.1091 - val_accuracy: 0.4769\n",
      "Epoch 462/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1383 - accuracy: 0.9879 - val_loss: 2.1094 - val_accuracy: 0.4769\n",
      "Epoch 463/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1639 - accuracy: 0.9799 - val_loss: 2.1097 - val_accuracy: 0.4769\n",
      "Epoch 464/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1620 - accuracy: 0.9819 - val_loss: 2.1100 - val_accuracy: 0.4769\n",
      "Epoch 465/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1664 - accuracy: 0.9859 - val_loss: 2.1105 - val_accuracy: 0.4769\n",
      "Epoch 466/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1729 - accuracy: 0.9819 - val_loss: 2.1107 - val_accuracy: 0.4769\n",
      "Epoch 467/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1719 - accuracy: 0.9799 - val_loss: 2.1111 - val_accuracy: 0.4769\n",
      "Epoch 468/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1493 - accuracy: 0.9879 - val_loss: 2.1114 - val_accuracy: 0.4769\n",
      "Epoch 469/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1353 - accuracy: 0.9879 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 470/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1273 - accuracy: 0.9940 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 471/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1442 - accuracy: 0.9920 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 472/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1612 - accuracy: 0.9738 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 473/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1534 - accuracy: 0.9859 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 474/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 475/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1606 - accuracy: 0.9819 - val_loss: 2.1129 - val_accuracy: 0.4769\n",
      "Epoch 476/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1356 - accuracy: 0.9879 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 477/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1335 - accuracy: 0.9899 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 478/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1459 - accuracy: 0.9879 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 479/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1769 - accuracy: 0.9779 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 480/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1502 - accuracy: 0.9879 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 481/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1451 - accuracy: 0.9879 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 482/600\n",
      "497/497 [==============================] - 0s 425us/step - loss: 0.1555 - accuracy: 0.9799 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 483/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1524 - accuracy: 0.9819 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 484/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1631 - accuracy: 0.9899 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 485/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1629 - accuracy: 0.9859 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 486/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1526 - accuracy: 0.9940 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 487/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1666 - accuracy: 0.9859 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 488/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1573 - accuracy: 0.9859 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 489/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1666 - accuracy: 0.9839 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 490/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1524 - accuracy: 0.9859 - val_loss: 2.1124 - val_accuracy: 0.4769\n",
      "Epoch 491/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1421 - accuracy: 0.9859 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 492/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1603 - accuracy: 0.9859 - val_loss: 2.1122 - val_accuracy: 0.4769\n",
      "Epoch 493/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1511 - accuracy: 0.9899 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 494/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1575 - accuracy: 0.9799 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 495/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1733 - accuracy: 0.9738 - val_loss: 2.1117 - val_accuracy: 0.4769\n",
      "Epoch 496/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1538 - accuracy: 0.9859 - val_loss: 2.1119 - val_accuracy: 0.4769\n",
      "Epoch 497/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1749 - accuracy: 0.9759 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 498/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1589 - accuracy: 0.9779 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 499/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1521 - accuracy: 0.9859 - val_loss: 2.1119 - val_accuracy: 0.4769\n",
      "Epoch 500/600\n",
      "497/497 [==============================] - 0s 440us/step - loss: 0.1368 - accuracy: 0.9899 - val_loss: 2.1121 - val_accuracy: 0.4769\n",
      "Epoch 501/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1378 - accuracy: 0.9940 - val_loss: 2.1119 - val_accuracy: 0.4769\n",
      "Epoch 502/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1717 - accuracy: 0.9759 - val_loss: 2.1122 - val_accuracy: 0.4769\n",
      "Epoch 503/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1417 - accuracy: 0.9940 - val_loss: 2.1124 - val_accuracy: 0.4769\n",
      "Epoch 504/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1526 - accuracy: 0.9738 - val_loss: 2.1126 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1515 - accuracy: 0.9920 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 506/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1617 - accuracy: 0.9859 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 507/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1530 - accuracy: 0.9839 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 508/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1529 - accuracy: 0.9920 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 509/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1403 - accuracy: 0.9899 - val_loss: 2.1129 - val_accuracy: 0.4769\n",
      "Epoch 510/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1706 - accuracy: 0.9839 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 511/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1323 - accuracy: 0.9899 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 512/600\n",
      "497/497 [==============================] - 0s 372us/step - loss: 0.1344 - accuracy: 0.9980 - val_loss: 2.1132 - val_accuracy: 0.4769\n",
      "Epoch 513/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1462 - accuracy: 0.9920 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 514/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1625 - accuracy: 0.9819 - val_loss: 2.1132 - val_accuracy: 0.4769\n",
      "Epoch 515/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1358 - accuracy: 0.9879 - val_loss: 2.1132 - val_accuracy: 0.4769\n",
      "Epoch 516/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1310 - accuracy: 0.9920 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 517/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1650 - accuracy: 0.9859 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 518/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1661 - accuracy: 0.9738 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 519/600\n",
      "497/497 [==============================] - 0s 429us/step - loss: 0.1643 - accuracy: 0.9779 - val_loss: 2.1136 - val_accuracy: 0.4769\n",
      "Epoch 520/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1369 - accuracy: 0.9920 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 521/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1487 - accuracy: 0.9899 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 522/600\n",
      "497/497 [==============================] - 0s 438us/step - loss: 0.1424 - accuracy: 0.9839 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 523/600\n",
      "497/497 [==============================] - 0s 369us/step - loss: 0.1566 - accuracy: 0.9859 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 524/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1448 - accuracy: 0.9899 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 525/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1377 - accuracy: 0.9899 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 526/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1319 - accuracy: 0.9920 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 527/600\n",
      "497/497 [==============================] - 0s 438us/step - loss: 0.1518 - accuracy: 0.9899 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 528/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1425 - accuracy: 0.9899 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 529/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1625 - accuracy: 0.9779 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 530/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1396 - accuracy: 0.9899 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 531/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1510 - accuracy: 0.9920 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 532/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1507 - accuracy: 0.9960 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 533/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1546 - accuracy: 0.9859 - val_loss: 2.1134 - val_accuracy: 0.4769\n",
      "Epoch 534/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1538 - accuracy: 0.9779 - val_loss: 2.1135 - val_accuracy: 0.4769\n",
      "Epoch 535/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1564 - accuracy: 0.9759 - val_loss: 2.1140 - val_accuracy: 0.4769\n",
      "Epoch 536/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1459 - accuracy: 0.9940 - val_loss: 2.1142 - val_accuracy: 0.4769\n",
      "Epoch 537/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1338 - accuracy: 0.9940 - val_loss: 2.1144 - val_accuracy: 0.4769\n",
      "Epoch 538/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1652 - accuracy: 0.9839 - val_loss: 2.1147 - val_accuracy: 0.4769\n",
      "Epoch 539/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1396 - accuracy: 0.9859 - val_loss: 2.1149 - val_accuracy: 0.4769\n",
      "Epoch 540/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1475 - accuracy: 0.9879 - val_loss: 2.1150 - val_accuracy: 0.4769\n",
      "Epoch 541/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 0.1376 - accuracy: 0.9960 - val_loss: 2.1148 - val_accuracy: 0.4769\n",
      "Epoch 542/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1523 - accuracy: 0.9819 - val_loss: 2.1150 - val_accuracy: 0.4769\n",
      "Epoch 543/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1384 - accuracy: 0.9879 - val_loss: 2.1149 - val_accuracy: 0.4769\n",
      "Epoch 544/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1564 - accuracy: 0.9859 - val_loss: 2.1151 - val_accuracy: 0.4769\n",
      "Epoch 545/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1529 - accuracy: 0.9879 - val_loss: 2.1151 - val_accuracy: 0.4769\n",
      "Epoch 546/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1467 - accuracy: 0.9839 - val_loss: 2.1149 - val_accuracy: 0.4769\n",
      "Epoch 547/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1641 - accuracy: 0.9799 - val_loss: 2.1147 - val_accuracy: 0.4769\n",
      "Epoch 548/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1433 - accuracy: 0.9879 - val_loss: 2.1144 - val_accuracy: 0.4769\n",
      "Epoch 549/600\n",
      "497/497 [==============================] - 0s 425us/step - loss: 0.1600 - accuracy: 0.9859 - val_loss: 2.1143 - val_accuracy: 0.4769\n",
      "Epoch 550/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1615 - accuracy: 0.9859 - val_loss: 2.1141 - val_accuracy: 0.4769\n",
      "Epoch 551/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1736 - accuracy: 0.9879 - val_loss: 2.1140 - val_accuracy: 0.4769\n",
      "Epoch 552/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1554 - accuracy: 0.9879 - val_loss: 2.1143 - val_accuracy: 0.4769\n",
      "Epoch 553/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1595 - accuracy: 0.9899 - val_loss: 2.1144 - val_accuracy: 0.4769\n",
      "Epoch 554/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1562 - accuracy: 0.9879 - val_loss: 2.1143 - val_accuracy: 0.4769\n",
      "Epoch 555/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1581 - accuracy: 0.9819 - val_loss: 2.1137 - val_accuracy: 0.4769\n",
      "Epoch 556/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1470 - accuracy: 0.9859 - val_loss: 2.1137 - val_accuracy: 0.4769\n",
      "Epoch 557/600\n",
      "497/497 [==============================] - 0s 424us/step - loss: 0.1512 - accuracy: 0.9859 - val_loss: 2.1137 - val_accuracy: 0.4769\n",
      "Epoch 558/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1443 - accuracy: 0.9879 - val_loss: 2.1136 - val_accuracy: 0.4769\n",
      "Epoch 559/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.1327 - accuracy: 0.9940 - val_loss: 2.1132 - val_accuracy: 0.4769\n",
      "Epoch 560/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1849 - accuracy: 0.9779 - val_loss: 2.1131 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1538 - accuracy: 0.9879 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 562/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.1501 - accuracy: 0.9859 - val_loss: 2.1133 - val_accuracy: 0.4769\n",
      "Epoch 563/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1531 - accuracy: 0.9920 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 564/600\n",
      "497/497 [==============================] - 0s 443us/step - loss: 0.1347 - accuracy: 0.9879 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 565/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1568 - accuracy: 0.9799 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 566/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1488 - accuracy: 0.9899 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 567/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1576 - accuracy: 0.9819 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 568/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1414 - accuracy: 0.9839 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 569/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1459 - accuracy: 0.9920 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 570/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1533 - accuracy: 0.9819 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 571/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1544 - accuracy: 0.9839 - val_loss: 2.1126 - val_accuracy: 0.4769\n",
      "Epoch 572/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1487 - accuracy: 0.9920 - val_loss: 2.1125 - val_accuracy: 0.4769\n",
      "Epoch 573/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1656 - accuracy: 0.9779 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 574/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1474 - accuracy: 0.9879 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 575/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1717 - accuracy: 0.9779 - val_loss: 2.1124 - val_accuracy: 0.4769\n",
      "Epoch 576/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1458 - accuracy: 0.9879 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 577/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 2.1131 - val_accuracy: 0.4769\n",
      "Epoch 578/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1512 - accuracy: 0.9839 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 579/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1612 - accuracy: 0.9799 - val_loss: 2.1132 - val_accuracy: 0.4769\n",
      "Epoch 580/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1445 - accuracy: 0.9799 - val_loss: 2.1130 - val_accuracy: 0.4769\n",
      "Epoch 581/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1512 - accuracy: 0.9899 - val_loss: 2.1128 - val_accuracy: 0.4769\n",
      "Epoch 582/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1473 - accuracy: 0.9899 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 583/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1386 - accuracy: 0.9899 - val_loss: 2.1127 - val_accuracy: 0.4769\n",
      "Epoch 584/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1358 - accuracy: 0.9819 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 585/600\n",
      "497/497 [==============================] - 0s 442us/step - loss: 0.1498 - accuracy: 0.9920 - val_loss: 2.1123 - val_accuracy: 0.4769\n",
      "Epoch 586/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1490 - accuracy: 0.9879 - val_loss: 2.1122 - val_accuracy: 0.4769\n",
      "Epoch 587/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1366 - accuracy: 0.9940 - val_loss: 2.1119 - val_accuracy: 0.4769\n",
      "Epoch 588/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1608 - accuracy: 0.9839 - val_loss: 2.1118 - val_accuracy: 0.4769\n",
      "Epoch 589/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1544 - accuracy: 0.9879 - val_loss: 2.1116 - val_accuracy: 0.4769\n",
      "Epoch 590/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1389 - accuracy: 0.9859 - val_loss: 2.1115 - val_accuracy: 0.4769\n",
      "Epoch 591/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1369 - accuracy: 0.9920 - val_loss: 2.1113 - val_accuracy: 0.4769\n",
      "Epoch 592/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1508 - accuracy: 0.9879 - val_loss: 2.1111 - val_accuracy: 0.4769\n",
      "Epoch 593/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1527 - accuracy: 0.9839 - val_loss: 2.1109 - val_accuracy: 0.4769\n",
      "Epoch 594/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1683 - accuracy: 0.9839 - val_loss: 2.1109 - val_accuracy: 0.4769\n",
      "Epoch 595/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1641 - accuracy: 0.9819 - val_loss: 2.1108 - val_accuracy: 0.4769\n",
      "Epoch 596/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1626 - accuracy: 0.9859 - val_loss: 2.1107 - val_accuracy: 0.4769\n",
      "Epoch 597/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1513 - accuracy: 0.9859 - val_loss: 2.1105 - val_accuracy: 0.4769\n",
      "Epoch 598/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1627 - accuracy: 0.9859 - val_loss: 2.1104 - val_accuracy: 0.4769\n",
      "Epoch 599/600\n",
      "497/497 [==============================] - 0s 376us/step - loss: 0.1373 - accuracy: 0.9920 - val_loss: 2.1101 - val_accuracy: 0.4769\n",
      "Epoch 600/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1420 - accuracy: 0.9879 - val_loss: 2.1104 - val_accuracy: 0.4769\n",
      "Train on 497 samples, validate on 195 samples\n",
      "Epoch 1/600\n",
      "497/497 [==============================] - 3s 6ms/step - loss: 0.1505 - accuracy: 0.9879 - val_loss: 2.0962 - val_accuracy: 0.4769\n",
      "Epoch 2/600\n",
      "497/497 [==============================] - 0s 496us/step - loss: 0.1492 - accuracy: 0.9879 - val_loss: 2.0848 - val_accuracy: 0.4769\n",
      "Epoch 3/600\n",
      "497/497 [==============================] - 0s 453us/step - loss: 0.1460 - accuracy: 0.9899 - val_loss: 2.0766 - val_accuracy: 0.4872\n",
      "Epoch 4/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1618 - accuracy: 0.9799 - val_loss: 2.0836 - val_accuracy: 0.4872\n",
      "Epoch 5/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1498 - accuracy: 0.9839 - val_loss: 2.0945 - val_accuracy: 0.4821\n",
      "Epoch 6/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1636 - accuracy: 0.9799 - val_loss: 2.1066 - val_accuracy: 0.4718\n",
      "Epoch 7/600\n",
      "497/497 [==============================] - 0s 450us/step - loss: 0.1459 - accuracy: 0.9899 - val_loss: 2.1225 - val_accuracy: 0.4821\n",
      "Epoch 8/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1416 - accuracy: 0.9899 - val_loss: 2.1383 - val_accuracy: 0.4718\n",
      "Epoch 9/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1364 - accuracy: 0.9899 - val_loss: 2.1520 - val_accuracy: 0.4718\n",
      "Epoch 10/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1548 - accuracy: 0.9879 - val_loss: 2.1614 - val_accuracy: 0.4718\n",
      "Epoch 11/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1192 - accuracy: 0.9899 - val_loss: 2.1649 - val_accuracy: 0.4821\n",
      "Epoch 12/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1337 - accuracy: 0.9940 - val_loss: 2.1711 - val_accuracy: 0.4769\n",
      "Epoch 13/600\n",
      "497/497 [==============================] - 0s 448us/step - loss: 0.1396 - accuracy: 0.9899 - val_loss: 2.1708 - val_accuracy: 0.4769\n",
      "Epoch 14/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1660 - accuracy: 0.9839 - val_loss: 2.1719 - val_accuracy: 0.4769\n",
      "Epoch 15/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 2.1722 - val_accuracy: 0.4821\n",
      "Epoch 16/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1334 - accuracy: 0.9899 - val_loss: 2.1696 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1526 - accuracy: 0.9738 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 18/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1347 - accuracy: 0.9819 - val_loss: 2.1637 - val_accuracy: 0.4872\n",
      "Epoch 19/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1509 - accuracy: 0.9839 - val_loss: 2.1613 - val_accuracy: 0.4872\n",
      "Epoch 20/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1388 - accuracy: 0.9819 - val_loss: 2.1586 - val_accuracy: 0.4821\n",
      "Epoch 21/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1258 - accuracy: 0.9940 - val_loss: 2.1545 - val_accuracy: 0.4821\n",
      "Epoch 22/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1113 - accuracy: 0.9940 - val_loss: 2.1498 - val_accuracy: 0.4821\n",
      "Epoch 23/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1445 - accuracy: 0.9899 - val_loss: 2.1461 - val_accuracy: 0.4821\n",
      "Epoch 24/600\n",
      "497/497 [==============================] - 0s 431us/step - loss: 0.1383 - accuracy: 0.9799 - val_loss: 2.1430 - val_accuracy: 0.4821\n",
      "Epoch 25/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1422 - accuracy: 0.9839 - val_loss: 2.1434 - val_accuracy: 0.4821\n",
      "Epoch 26/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1364 - accuracy: 0.9879 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 27/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1362 - accuracy: 0.9879 - val_loss: 2.1448 - val_accuracy: 0.4872\n",
      "Epoch 28/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1383 - accuracy: 0.9920 - val_loss: 2.1450 - val_accuracy: 0.4872\n",
      "Epoch 29/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1196 - accuracy: 0.9879 - val_loss: 2.1456 - val_accuracy: 0.4821\n",
      "Epoch 30/600\n",
      "497/497 [==============================] - 0s 434us/step - loss: 0.1373 - accuracy: 0.9839 - val_loss: 2.1463 - val_accuracy: 0.4821\n",
      "Epoch 31/600\n",
      "497/497 [==============================] - 0s 445us/step - loss: 0.1291 - accuracy: 0.9879 - val_loss: 2.1482 - val_accuracy: 0.4821\n",
      "Epoch 32/600\n",
      "497/497 [==============================] - 0s 435us/step - loss: 0.1304 - accuracy: 0.9920 - val_loss: 2.1513 - val_accuracy: 0.4821\n",
      "Epoch 33/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1301 - accuracy: 0.9859 - val_loss: 2.1537 - val_accuracy: 0.4769\n",
      "Epoch 34/600\n",
      "497/497 [==============================] - 0s 444us/step - loss: 0.1291 - accuracy: 0.9940 - val_loss: 2.1555 - val_accuracy: 0.4769\n",
      "Epoch 35/600\n",
      "497/497 [==============================] - 0s 453us/step - loss: 0.1299 - accuracy: 0.9899 - val_loss: 2.1563 - val_accuracy: 0.4769\n",
      "Epoch 36/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1458 - accuracy: 0.9839 - val_loss: 2.1595 - val_accuracy: 0.4769\n",
      "Epoch 37/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1289 - accuracy: 0.9899 - val_loss: 2.1606 - val_accuracy: 0.4821\n",
      "Epoch 38/600\n",
      "497/497 [==============================] - 0s 444us/step - loss: 0.1325 - accuracy: 0.9899 - val_loss: 2.1616 - val_accuracy: 0.4821\n",
      "Epoch 39/600\n",
      "497/497 [==============================] - 0s 454us/step - loss: 0.1375 - accuracy: 0.9920 - val_loss: 2.1625 - val_accuracy: 0.4821\n",
      "Epoch 40/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1344 - accuracy: 0.9899 - val_loss: 2.1633 - val_accuracy: 0.4821\n",
      "Epoch 41/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1595 - accuracy: 0.9839 - val_loss: 2.1636 - val_accuracy: 0.4821\n",
      "Epoch 42/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1148 - accuracy: 0.9940 - val_loss: 2.1643 - val_accuracy: 0.4821\n",
      "Epoch 43/600\n",
      "497/497 [==============================] - 0s 426us/step - loss: 0.1437 - accuracy: 0.9819 - val_loss: 2.1647 - val_accuracy: 0.4821\n",
      "Epoch 44/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1410 - accuracy: 0.9859 - val_loss: 2.1646 - val_accuracy: 0.4821\n",
      "Epoch 45/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1216 - accuracy: 0.9899 - val_loss: 2.1643 - val_accuracy: 0.4718\n",
      "Epoch 46/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1457 - accuracy: 0.9859 - val_loss: 2.1640 - val_accuracy: 0.4718\n",
      "Epoch 47/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1290 - accuracy: 0.9839 - val_loss: 2.1638 - val_accuracy: 0.4718\n",
      "Epoch 48/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1237 - accuracy: 0.9899 - val_loss: 2.1635 - val_accuracy: 0.4718\n",
      "Epoch 49/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1337 - accuracy: 0.9920 - val_loss: 2.1633 - val_accuracy: 0.4718\n",
      "Epoch 50/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1287 - accuracy: 0.9899 - val_loss: 2.1634 - val_accuracy: 0.4718\n",
      "Epoch 51/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1341 - accuracy: 0.9799 - val_loss: 2.1632 - val_accuracy: 0.4718\n",
      "Epoch 52/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1254 - accuracy: 0.9859 - val_loss: 2.1630 - val_accuracy: 0.4718\n",
      "Epoch 53/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1265 - accuracy: 0.9920 - val_loss: 2.1633 - val_accuracy: 0.4718\n",
      "Epoch 54/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1434 - accuracy: 0.9859 - val_loss: 2.1636 - val_accuracy: 0.4718\n",
      "Epoch 55/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1550 - accuracy: 0.9819 - val_loss: 2.1637 - val_accuracy: 0.4718\n",
      "Epoch 56/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1410 - accuracy: 0.9879 - val_loss: 2.1641 - val_accuracy: 0.4769\n",
      "Epoch 57/600\n",
      "497/497 [==============================] - 0s 430us/step - loss: 0.1317 - accuracy: 0.9879 - val_loss: 2.1644 - val_accuracy: 0.4769\n",
      "Epoch 58/600\n",
      "497/497 [==============================] - 0s 457us/step - loss: 0.1248 - accuracy: 0.9859 - val_loss: 2.1644 - val_accuracy: 0.4769\n",
      "Epoch 59/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1173 - accuracy: 0.9899 - val_loss: 2.1643 - val_accuracy: 0.4769\n",
      "Epoch 60/600\n",
      "497/497 [==============================] - 0s 441us/step - loss: 0.1248 - accuracy: 0.9920 - val_loss: 2.1643 - val_accuracy: 0.4718\n",
      "Epoch 61/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1257 - accuracy: 0.9899 - val_loss: 2.1640 - val_accuracy: 0.4718\n",
      "Epoch 62/600\n",
      "497/497 [==============================] - 0s 441us/step - loss: 0.1328 - accuracy: 0.9819 - val_loss: 2.1641 - val_accuracy: 0.4718\n",
      "Epoch 63/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1374 - accuracy: 0.9879 - val_loss: 2.1643 - val_accuracy: 0.4718\n",
      "Epoch 64/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1523 - accuracy: 0.9899 - val_loss: 2.1644 - val_accuracy: 0.4769\n",
      "Epoch 65/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1432 - accuracy: 0.9819 - val_loss: 2.1648 - val_accuracy: 0.4718\n",
      "Epoch 66/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1304 - accuracy: 0.9920 - val_loss: 2.1646 - val_accuracy: 0.4769\n",
      "Epoch 67/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1368 - accuracy: 0.9879 - val_loss: 2.1647 - val_accuracy: 0.4769\n",
      "Epoch 68/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1370 - accuracy: 0.9920 - val_loss: 2.1647 - val_accuracy: 0.4769\n",
      "Epoch 69/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1267 - accuracy: 0.9879 - val_loss: 2.1646 - val_accuracy: 0.4769\n",
      "Epoch 70/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1405 - accuracy: 0.9859 - val_loss: 2.1642 - val_accuracy: 0.4769\n",
      "Epoch 71/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1413 - accuracy: 0.9839 - val_loss: 2.1639 - val_accuracy: 0.4769\n",
      "Epoch 72/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1308 - accuracy: 0.9899 - val_loss: 2.1639 - val_accuracy: 0.4769\n",
      "Epoch 73/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1268 - accuracy: 0.9899 - val_loss: 2.1634 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1215 - accuracy: 0.9920 - val_loss: 2.1632 - val_accuracy: 0.4769\n",
      "Epoch 75/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1441 - accuracy: 0.9839 - val_loss: 2.1626 - val_accuracy: 0.4769\n",
      "Epoch 76/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1259 - accuracy: 0.9920 - val_loss: 2.1625 - val_accuracy: 0.4769\n",
      "Epoch 77/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1303 - accuracy: 0.9920 - val_loss: 2.1627 - val_accuracy: 0.4769\n",
      "Epoch 78/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1508 - accuracy: 0.9799 - val_loss: 2.1625 - val_accuracy: 0.4769\n",
      "Epoch 79/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1486 - accuracy: 0.9819 - val_loss: 2.1624 - val_accuracy: 0.4769\n",
      "Epoch 80/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1310 - accuracy: 0.9899 - val_loss: 2.1619 - val_accuracy: 0.4769\n",
      "Epoch 81/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1408 - accuracy: 0.9899 - val_loss: 2.1615 - val_accuracy: 0.4769\n",
      "Epoch 82/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1430 - accuracy: 0.9839 - val_loss: 2.1607 - val_accuracy: 0.4769\n",
      "Epoch 83/600\n",
      "497/497 [==============================] - 0s 427us/step - loss: 0.1428 - accuracy: 0.9899 - val_loss: 2.1602 - val_accuracy: 0.4769\n",
      "Epoch 84/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1272 - accuracy: 0.9940 - val_loss: 2.1597 - val_accuracy: 0.4769\n",
      "Epoch 85/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1270 - accuracy: 0.9940 - val_loss: 2.1594 - val_accuracy: 0.4769\n",
      "Epoch 86/600\n",
      "497/497 [==============================] - 0s 428us/step - loss: 0.1233 - accuracy: 0.9899 - val_loss: 2.1592 - val_accuracy: 0.4769\n",
      "Epoch 87/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1134 - accuracy: 0.9960 - val_loss: 2.1584 - val_accuracy: 0.4769\n",
      "Epoch 88/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1374 - accuracy: 0.9819 - val_loss: 2.1581 - val_accuracy: 0.4769\n",
      "Epoch 89/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1348 - accuracy: 0.9879 - val_loss: 2.1577 - val_accuracy: 0.4769\n",
      "Epoch 90/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1477 - accuracy: 0.9799 - val_loss: 2.1576 - val_accuracy: 0.4769\n",
      "Epoch 91/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1272 - accuracy: 0.9960 - val_loss: 2.1575 - val_accuracy: 0.4769\n",
      "Epoch 92/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1234 - accuracy: 0.9899 - val_loss: 2.1572 - val_accuracy: 0.4769\n",
      "Epoch 93/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1386 - accuracy: 0.9899 - val_loss: 2.1569 - val_accuracy: 0.4769\n",
      "Epoch 94/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1143 - accuracy: 0.9960 - val_loss: 2.1563 - val_accuracy: 0.4821\n",
      "Epoch 95/600\n",
      "497/497 [==============================] - 0s 436us/step - loss: 0.1411 - accuracy: 0.9859 - val_loss: 2.1562 - val_accuracy: 0.4821\n",
      "Epoch 96/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1387 - accuracy: 0.9819 - val_loss: 2.1558 - val_accuracy: 0.4821\n",
      "Epoch 97/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1265 - accuracy: 0.9859 - val_loss: 2.1556 - val_accuracy: 0.4821\n",
      "Epoch 98/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1412 - accuracy: 0.9839 - val_loss: 2.1552 - val_accuracy: 0.4821\n",
      "Epoch 99/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1211 - accuracy: 0.9859 - val_loss: 2.1550 - val_accuracy: 0.4821\n",
      "Epoch 100/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1226 - accuracy: 0.9879 - val_loss: 2.1546 - val_accuracy: 0.4821\n",
      "Epoch 101/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1313 - accuracy: 0.9940 - val_loss: 2.1541 - val_accuracy: 0.4821\n",
      "Epoch 102/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1300 - accuracy: 0.9920 - val_loss: 2.1539 - val_accuracy: 0.4821\n",
      "Epoch 103/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1389 - accuracy: 0.9819 - val_loss: 2.1541 - val_accuracy: 0.4821\n",
      "Epoch 104/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1376 - accuracy: 0.9920 - val_loss: 2.1543 - val_accuracy: 0.4821\n",
      "Epoch 105/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1361 - accuracy: 0.9859 - val_loss: 2.1541 - val_accuracy: 0.4821\n",
      "Epoch 106/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1450 - accuracy: 0.9920 - val_loss: 2.1541 - val_accuracy: 0.4821\n",
      "Epoch 107/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1292 - accuracy: 0.9940 - val_loss: 2.1540 - val_accuracy: 0.4821\n",
      "Epoch 108/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1267 - accuracy: 0.9899 - val_loss: 2.1540 - val_accuracy: 0.4821\n",
      "Epoch 109/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1258 - accuracy: 0.9899 - val_loss: 2.1543 - val_accuracy: 0.4821\n",
      "Epoch 110/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1215 - accuracy: 0.9879 - val_loss: 2.1539 - val_accuracy: 0.4821\n",
      "Epoch 111/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1176 - accuracy: 0.9920 - val_loss: 2.1542 - val_accuracy: 0.4821\n",
      "Epoch 112/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1207 - accuracy: 0.9859 - val_loss: 2.1542 - val_accuracy: 0.4821\n",
      "Epoch 113/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1307 - accuracy: 0.9879 - val_loss: 2.1544 - val_accuracy: 0.4821\n",
      "Epoch 114/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1304 - accuracy: 0.9899 - val_loss: 2.1542 - val_accuracy: 0.4821\n",
      "Epoch 115/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1299 - accuracy: 0.9839 - val_loss: 2.1541 - val_accuracy: 0.4821\n",
      "Epoch 116/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1442 - accuracy: 0.9819 - val_loss: 2.1543 - val_accuracy: 0.4821\n",
      "Epoch 117/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1149 - accuracy: 0.9899 - val_loss: 2.1542 - val_accuracy: 0.4821\n",
      "Epoch 118/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1321 - accuracy: 0.9839 - val_loss: 2.1543 - val_accuracy: 0.4821\n",
      "Epoch 119/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1147 - accuracy: 0.9960 - val_loss: 2.1547 - val_accuracy: 0.4821\n",
      "Epoch 120/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1303 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4821\n",
      "Epoch 121/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1316 - accuracy: 0.9899 - val_loss: 2.1546 - val_accuracy: 0.4821\n",
      "Epoch 122/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1490 - accuracy: 0.9879 - val_loss: 2.1547 - val_accuracy: 0.4821\n",
      "Epoch 123/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1222 - accuracy: 0.9879 - val_loss: 2.1550 - val_accuracy: 0.4821\n",
      "Epoch 124/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1271 - accuracy: 0.9940 - val_loss: 2.1550 - val_accuracy: 0.4821\n",
      "Epoch 125/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1123 - accuracy: 0.9940 - val_loss: 2.1550 - val_accuracy: 0.4821\n",
      "Epoch 126/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1231 - accuracy: 0.9859 - val_loss: 2.1552 - val_accuracy: 0.4821\n",
      "Epoch 127/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1248 - accuracy: 0.9940 - val_loss: 2.1552 - val_accuracy: 0.4821\n",
      "Epoch 128/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1251 - accuracy: 0.9879 - val_loss: 2.1553 - val_accuracy: 0.4821\n",
      "Epoch 129/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1256 - accuracy: 0.9859 - val_loss: 2.1555 - val_accuracy: 0.4821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1193 - accuracy: 0.9940 - val_loss: 2.1557 - val_accuracy: 0.4821\n",
      "Epoch 131/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1516 - accuracy: 0.9819 - val_loss: 2.1563 - val_accuracy: 0.4821\n",
      "Epoch 132/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1456 - accuracy: 0.9819 - val_loss: 2.1563 - val_accuracy: 0.4872\n",
      "Epoch 133/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1200 - accuracy: 0.9960 - val_loss: 2.1570 - val_accuracy: 0.4872\n",
      "Epoch 134/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1307 - accuracy: 0.9920 - val_loss: 2.1573 - val_accuracy: 0.4872\n",
      "Epoch 135/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1427 - accuracy: 0.9738 - val_loss: 2.1574 - val_accuracy: 0.4872\n",
      "Epoch 136/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1454 - accuracy: 0.9819 - val_loss: 2.1578 - val_accuracy: 0.4872\n",
      "Epoch 137/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1248 - accuracy: 0.9899 - val_loss: 2.1581 - val_accuracy: 0.4872\n",
      "Epoch 138/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1210 - accuracy: 0.9960 - val_loss: 2.1581 - val_accuracy: 0.4872\n",
      "Epoch 139/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1351 - accuracy: 0.9879 - val_loss: 2.1584 - val_accuracy: 0.4872\n",
      "Epoch 140/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1282 - accuracy: 0.9879 - val_loss: 2.1588 - val_accuracy: 0.4872\n",
      "Epoch 141/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1470 - accuracy: 0.9799 - val_loss: 2.1590 - val_accuracy: 0.4872\n",
      "Epoch 142/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1185 - accuracy: 0.9920 - val_loss: 2.1594 - val_accuracy: 0.4872\n",
      "Epoch 143/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1243 - accuracy: 0.9879 - val_loss: 2.1592 - val_accuracy: 0.4872\n",
      "Epoch 144/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1401 - accuracy: 0.9819 - val_loss: 2.1589 - val_accuracy: 0.4872\n",
      "Epoch 145/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1375 - accuracy: 0.9899 - val_loss: 2.1587 - val_accuracy: 0.4872\n",
      "Epoch 146/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1278 - accuracy: 0.9940 - val_loss: 2.1583 - val_accuracy: 0.4872\n",
      "Epoch 147/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1185 - accuracy: 0.9940 - val_loss: 2.1585 - val_accuracy: 0.4872\n",
      "Epoch 148/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1463 - accuracy: 0.9899 - val_loss: 2.1583 - val_accuracy: 0.4872\n",
      "Epoch 149/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1291 - accuracy: 0.9879 - val_loss: 2.1580 - val_accuracy: 0.4872\n",
      "Epoch 150/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1239 - accuracy: 0.9940 - val_loss: 2.1576 - val_accuracy: 0.4872\n",
      "Epoch 151/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1393 - accuracy: 0.9879 - val_loss: 2.1579 - val_accuracy: 0.4872\n",
      "Epoch 152/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1064 - accuracy: 0.9940 - val_loss: 2.1577 - val_accuracy: 0.4872\n",
      "Epoch 153/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1486 - accuracy: 0.9940 - val_loss: 2.1575 - val_accuracy: 0.4872\n",
      "Epoch 154/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1381 - accuracy: 0.9920 - val_loss: 2.1573 - val_accuracy: 0.4872\n",
      "Epoch 155/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1292 - accuracy: 0.9879 - val_loss: 2.1569 - val_accuracy: 0.4872\n",
      "Epoch 156/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1234 - accuracy: 0.9920 - val_loss: 2.1568 - val_accuracy: 0.4872\n",
      "Epoch 157/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1195 - accuracy: 0.9960 - val_loss: 2.1565 - val_accuracy: 0.4872\n",
      "Epoch 158/600\n",
      "497/497 [==============================] - 0s 432us/step - loss: 0.1340 - accuracy: 0.9920 - val_loss: 2.1561 - val_accuracy: 0.4872\n",
      "Epoch 159/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1386 - accuracy: 0.9879 - val_loss: 2.1558 - val_accuracy: 0.4872\n",
      "Epoch 160/600\n",
      "497/497 [==============================] - 0s 445us/step - loss: 0.1228 - accuracy: 0.9899 - val_loss: 2.1555 - val_accuracy: 0.4872\n",
      "Epoch 161/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1199 - accuracy: 0.9920 - val_loss: 2.1556 - val_accuracy: 0.4872\n",
      "Epoch 162/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1193 - accuracy: 0.9899 - val_loss: 2.1556 - val_accuracy: 0.4872\n",
      "Epoch 163/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1183 - accuracy: 0.9940 - val_loss: 2.1557 - val_accuracy: 0.4872\n",
      "Epoch 164/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1122 - accuracy: 0.9899 - val_loss: 2.1556 - val_accuracy: 0.4872\n",
      "Epoch 165/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1172 - accuracy: 0.9940 - val_loss: 2.1557 - val_accuracy: 0.4872\n",
      "Epoch 166/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1314 - accuracy: 0.9920 - val_loss: 2.1558 - val_accuracy: 0.4872\n",
      "Epoch 167/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1281 - accuracy: 0.9839 - val_loss: 2.1560 - val_accuracy: 0.4872\n",
      "Epoch 168/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1312 - accuracy: 0.9920 - val_loss: 2.1561 - val_accuracy: 0.4872\n",
      "Epoch 169/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1301 - accuracy: 0.9879 - val_loss: 2.1562 - val_accuracy: 0.4872\n",
      "Epoch 170/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1179 - accuracy: 0.9960 - val_loss: 2.1562 - val_accuracy: 0.4872\n",
      "Epoch 171/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1229 - accuracy: 0.9879 - val_loss: 2.1563 - val_accuracy: 0.4872\n",
      "Epoch 172/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1199 - accuracy: 0.9940 - val_loss: 2.1567 - val_accuracy: 0.4872\n",
      "Epoch 173/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1199 - accuracy: 0.9899 - val_loss: 2.1571 - val_accuracy: 0.4872\n",
      "Epoch 174/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1348 - accuracy: 0.9899 - val_loss: 2.1569 - val_accuracy: 0.4872\n",
      "Epoch 175/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1275 - accuracy: 0.9960 - val_loss: 2.1571 - val_accuracy: 0.4872\n",
      "Epoch 176/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1364 - accuracy: 0.9879 - val_loss: 2.1576 - val_accuracy: 0.4872\n",
      "Epoch 177/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1356 - accuracy: 0.9839 - val_loss: 2.1577 - val_accuracy: 0.4872\n",
      "Epoch 178/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1411 - accuracy: 0.9899 - val_loss: 2.1581 - val_accuracy: 0.4872\n",
      "Epoch 179/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1271 - accuracy: 0.9920 - val_loss: 2.1583 - val_accuracy: 0.4872\n",
      "Epoch 180/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1224 - accuracy: 0.9839 - val_loss: 2.1588 - val_accuracy: 0.4872\n",
      "Epoch 181/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1259 - accuracy: 0.9940 - val_loss: 2.1591 - val_accuracy: 0.4872\n",
      "Epoch 182/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1433 - accuracy: 0.9819 - val_loss: 2.1595 - val_accuracy: 0.4872\n",
      "Epoch 183/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1232 - accuracy: 0.9920 - val_loss: 2.1599 - val_accuracy: 0.4872\n",
      "Epoch 184/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1298 - accuracy: 0.9799 - val_loss: 2.1603 - val_accuracy: 0.4872\n",
      "Epoch 185/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1327 - accuracy: 0.9819 - val_loss: 2.1604 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1216 - accuracy: 0.9899 - val_loss: 2.1607 - val_accuracy: 0.4872\n",
      "Epoch 187/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1141 - accuracy: 0.9920 - val_loss: 2.1612 - val_accuracy: 0.4872\n",
      "Epoch 188/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1129 - accuracy: 0.9980 - val_loss: 2.1619 - val_accuracy: 0.4872\n",
      "Epoch 189/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1391 - accuracy: 0.9839 - val_loss: 2.1623 - val_accuracy: 0.4872\n",
      "Epoch 190/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1269 - accuracy: 0.9899 - val_loss: 2.1629 - val_accuracy: 0.4872\n",
      "Epoch 191/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1338 - accuracy: 0.9879 - val_loss: 2.1633 - val_accuracy: 0.4872\n",
      "Epoch 192/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1383 - accuracy: 0.9839 - val_loss: 2.1637 - val_accuracy: 0.4872\n",
      "Epoch 193/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1106 - accuracy: 0.9879 - val_loss: 2.1639 - val_accuracy: 0.4872\n",
      "Epoch 194/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1237 - accuracy: 0.9920 - val_loss: 2.1643 - val_accuracy: 0.4872\n",
      "Epoch 195/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1184 - accuracy: 0.9940 - val_loss: 2.1648 - val_accuracy: 0.4872\n",
      "Epoch 196/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1323 - accuracy: 0.9839 - val_loss: 2.1651 - val_accuracy: 0.4872\n",
      "Epoch 197/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1174 - accuracy: 0.9980 - val_loss: 2.1656 - val_accuracy: 0.4872\n",
      "Epoch 198/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1464 - accuracy: 0.9839 - val_loss: 2.1661 - val_accuracy: 0.4872\n",
      "Epoch 199/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1109 - accuracy: 0.9980 - val_loss: 2.1667 - val_accuracy: 0.4821\n",
      "Epoch 200/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1391 - accuracy: 0.9839 - val_loss: 2.1673 - val_accuracy: 0.4821\n",
      "Epoch 201/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1247 - accuracy: 0.9859 - val_loss: 2.1678 - val_accuracy: 0.4821\n",
      "Epoch 202/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1226 - accuracy: 0.9920 - val_loss: 2.1679 - val_accuracy: 0.4821\n",
      "Epoch 203/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1246 - accuracy: 0.9859 - val_loss: 2.1682 - val_accuracy: 0.4821\n",
      "Epoch 204/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1222 - accuracy: 0.9899 - val_loss: 2.1682 - val_accuracy: 0.4821\n",
      "Epoch 205/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1349 - accuracy: 0.9859 - val_loss: 2.1680 - val_accuracy: 0.4821\n",
      "Epoch 206/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1205 - accuracy: 0.9899 - val_loss: 2.1677 - val_accuracy: 0.4821\n",
      "Epoch 207/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1247 - accuracy: 0.9859 - val_loss: 2.1673 - val_accuracy: 0.4821\n",
      "Epoch 208/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1245 - accuracy: 0.9899 - val_loss: 2.1670 - val_accuracy: 0.4821\n",
      "Epoch 209/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1241 - accuracy: 0.9879 - val_loss: 2.1667 - val_accuracy: 0.4821\n",
      "Epoch 210/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1278 - accuracy: 0.9839 - val_loss: 2.1670 - val_accuracy: 0.4821\n",
      "Epoch 211/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1081 - accuracy: 0.9960 - val_loss: 2.1670 - val_accuracy: 0.4821\n",
      "Epoch 212/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1364 - accuracy: 0.9839 - val_loss: 2.1667 - val_accuracy: 0.4821\n",
      "Epoch 213/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1169 - accuracy: 0.9960 - val_loss: 2.1666 - val_accuracy: 0.4821\n",
      "Epoch 214/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1353 - accuracy: 0.9859 - val_loss: 2.1664 - val_accuracy: 0.4821\n",
      "Epoch 215/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1412 - accuracy: 0.9859 - val_loss: 2.1663 - val_accuracy: 0.4821\n",
      "Epoch 216/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1341 - accuracy: 0.9940 - val_loss: 2.1663 - val_accuracy: 0.4769\n",
      "Epoch 217/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1370 - accuracy: 0.9899 - val_loss: 2.1662 - val_accuracy: 0.4769\n",
      "Epoch 218/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1235 - accuracy: 0.9920 - val_loss: 2.1659 - val_accuracy: 0.4769\n",
      "Epoch 219/600\n",
      "497/497 [==============================] - 0s 376us/step - loss: 0.1425 - accuracy: 0.9859 - val_loss: 2.1652 - val_accuracy: 0.4769\n",
      "Epoch 220/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1140 - accuracy: 0.9920 - val_loss: 2.1652 - val_accuracy: 0.4769\n",
      "Epoch 221/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1404 - accuracy: 0.9859 - val_loss: 2.1652 - val_accuracy: 0.4769\n",
      "Epoch 222/600\n",
      "497/497 [==============================] - 0s 437us/step - loss: 0.1380 - accuracy: 0.9879 - val_loss: 2.1654 - val_accuracy: 0.4769\n",
      "Epoch 223/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1083 - accuracy: 0.9899 - val_loss: 2.1653 - val_accuracy: 0.4769\n",
      "Epoch 224/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1290 - accuracy: 0.9839 - val_loss: 2.1652 - val_accuracy: 0.4769\n",
      "Epoch 225/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1179 - accuracy: 0.9920 - val_loss: 2.1652 - val_accuracy: 0.4769\n",
      "Epoch 226/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1253 - accuracy: 0.9920 - val_loss: 2.1650 - val_accuracy: 0.4769\n",
      "Epoch 227/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1397 - accuracy: 0.9899 - val_loss: 2.1651 - val_accuracy: 0.4769\n",
      "Epoch 228/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1396 - accuracy: 0.9839 - val_loss: 2.1645 - val_accuracy: 0.4769\n",
      "Epoch 229/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1240 - accuracy: 0.9859 - val_loss: 2.1644 - val_accuracy: 0.4821\n",
      "Epoch 230/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1293 - accuracy: 0.9879 - val_loss: 2.1643 - val_accuracy: 0.4821\n",
      "Epoch 231/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1235 - accuracy: 0.9920 - val_loss: 2.1645 - val_accuracy: 0.4821\n",
      "Epoch 232/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1437 - accuracy: 0.9859 - val_loss: 2.1652 - val_accuracy: 0.4821\n",
      "Epoch 233/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1458 - accuracy: 0.9779 - val_loss: 2.1654 - val_accuracy: 0.4821\n",
      "Epoch 234/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1249 - accuracy: 0.9899 - val_loss: 2.1656 - val_accuracy: 0.4821\n",
      "Epoch 235/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1119 - accuracy: 0.9940 - val_loss: 2.1660 - val_accuracy: 0.4821\n",
      "Epoch 236/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1230 - accuracy: 0.9899 - val_loss: 2.1661 - val_accuracy: 0.4821\n",
      "Epoch 237/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1101 - accuracy: 0.9920 - val_loss: 2.1663 - val_accuracy: 0.4821\n",
      "Epoch 238/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1256 - accuracy: 0.9879 - val_loss: 2.1663 - val_accuracy: 0.4821\n",
      "Epoch 239/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1179 - accuracy: 0.9899 - val_loss: 2.1666 - val_accuracy: 0.4821\n",
      "Epoch 240/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1216 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4821\n",
      "Epoch 241/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1353 - accuracy: 0.9899 - val_loss: 2.1673 - val_accuracy: 0.4821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1313 - accuracy: 0.9899 - val_loss: 2.1677 - val_accuracy: 0.4821\n",
      "Epoch 243/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1300 - accuracy: 0.9899 - val_loss: 2.1682 - val_accuracy: 0.4821\n",
      "Epoch 244/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1327 - accuracy: 0.9839 - val_loss: 2.1686 - val_accuracy: 0.4821\n",
      "Epoch 245/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1220 - accuracy: 0.9960 - val_loss: 2.1688 - val_accuracy: 0.4821\n",
      "Epoch 246/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1118 - accuracy: 0.9940 - val_loss: 2.1696 - val_accuracy: 0.4821\n",
      "Epoch 247/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1382 - accuracy: 0.9899 - val_loss: 2.1703 - val_accuracy: 0.4821\n",
      "Epoch 248/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1319 - accuracy: 0.9879 - val_loss: 2.1710 - val_accuracy: 0.4718\n",
      "Epoch 249/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1181 - accuracy: 0.9839 - val_loss: 2.1716 - val_accuracy: 0.4769\n",
      "Epoch 250/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1278 - accuracy: 0.9839 - val_loss: 2.1721 - val_accuracy: 0.4769\n",
      "Epoch 251/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1268 - accuracy: 0.9960 - val_loss: 2.1726 - val_accuracy: 0.4769\n",
      "Epoch 252/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1378 - accuracy: 0.9920 - val_loss: 2.1734 - val_accuracy: 0.4769\n",
      "Epoch 253/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1185 - accuracy: 0.9940 - val_loss: 2.1737 - val_accuracy: 0.4769\n",
      "Epoch 254/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1301 - accuracy: 0.9899 - val_loss: 2.1739 - val_accuracy: 0.4769\n",
      "Epoch 255/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1134 - accuracy: 0.9920 - val_loss: 2.1742 - val_accuracy: 0.4769\n",
      "Epoch 256/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1202 - accuracy: 0.9899 - val_loss: 2.1745 - val_accuracy: 0.4769\n",
      "Epoch 257/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1143 - accuracy: 0.9920 - val_loss: 2.1747 - val_accuracy: 0.4769\n",
      "Epoch 258/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1429 - accuracy: 0.9839 - val_loss: 2.1746 - val_accuracy: 0.4769\n",
      "Epoch 259/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1214 - accuracy: 0.9940 - val_loss: 2.1745 - val_accuracy: 0.4769\n",
      "Epoch 260/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1199 - accuracy: 0.9879 - val_loss: 2.1742 - val_accuracy: 0.4769\n",
      "Epoch 261/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1107 - accuracy: 0.9980 - val_loss: 2.1745 - val_accuracy: 0.4769\n",
      "Epoch 262/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1210 - accuracy: 0.9899 - val_loss: 2.1743 - val_accuracy: 0.4769\n",
      "Epoch 263/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1144 - accuracy: 0.9940 - val_loss: 2.1742 - val_accuracy: 0.4769\n",
      "Epoch 264/600\n",
      "497/497 [==============================] - 0s 371us/step - loss: 0.1270 - accuracy: 0.9899 - val_loss: 2.1746 - val_accuracy: 0.4769\n",
      "Epoch 265/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1055 - accuracy: 0.9960 - val_loss: 2.1749 - val_accuracy: 0.4769\n",
      "Epoch 266/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1346 - accuracy: 0.9920 - val_loss: 2.1748 - val_accuracy: 0.4769\n",
      "Epoch 267/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1274 - accuracy: 0.9879 - val_loss: 2.1748 - val_accuracy: 0.4769\n",
      "Epoch 268/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1196 - accuracy: 0.9899 - val_loss: 2.1750 - val_accuracy: 0.4769\n",
      "Epoch 269/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1246 - accuracy: 0.9879 - val_loss: 2.1752 - val_accuracy: 0.4769\n",
      "Epoch 270/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1351 - accuracy: 0.9859 - val_loss: 2.1752 - val_accuracy: 0.4769\n",
      "Epoch 271/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1299 - accuracy: 0.9859 - val_loss: 2.1754 - val_accuracy: 0.4769\n",
      "Epoch 272/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1126 - accuracy: 0.9940 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 273/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1288 - accuracy: 0.9819 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 274/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1398 - accuracy: 0.9879 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 275/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1306 - accuracy: 0.9899 - val_loss: 2.1751 - val_accuracy: 0.4769\n",
      "Epoch 276/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1234 - accuracy: 0.9859 - val_loss: 2.1746 - val_accuracy: 0.4769\n",
      "Epoch 277/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1344 - accuracy: 0.9859 - val_loss: 2.1742 - val_accuracy: 0.4769\n",
      "Epoch 278/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1188 - accuracy: 0.9940 - val_loss: 2.1740 - val_accuracy: 0.4769\n",
      "Epoch 279/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1168 - accuracy: 0.9879 - val_loss: 2.1735 - val_accuracy: 0.4769\n",
      "Epoch 280/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1146 - accuracy: 0.9940 - val_loss: 2.1731 - val_accuracy: 0.4769\n",
      "Epoch 281/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1253 - accuracy: 0.9960 - val_loss: 2.1723 - val_accuracy: 0.4718\n",
      "Epoch 282/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1182 - accuracy: 0.9920 - val_loss: 2.1720 - val_accuracy: 0.4718\n",
      "Epoch 283/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1017 - accuracy: 0.9899 - val_loss: 2.1718 - val_accuracy: 0.4718\n",
      "Epoch 284/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1297 - accuracy: 0.9879 - val_loss: 2.1714 - val_accuracy: 0.4718\n",
      "Epoch 285/600\n",
      "497/497 [==============================] - 0s 380us/step - loss: 0.1210 - accuracy: 0.9920 - val_loss: 2.1713 - val_accuracy: 0.4718\n",
      "Epoch 286/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1395 - accuracy: 0.9899 - val_loss: 2.1714 - val_accuracy: 0.4718\n",
      "Epoch 287/600\n",
      "497/497 [==============================] - 0s 374us/step - loss: 0.1125 - accuracy: 0.9920 - val_loss: 2.1718 - val_accuracy: 0.4718\n",
      "Epoch 288/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1231 - accuracy: 0.9879 - val_loss: 2.1720 - val_accuracy: 0.4718\n",
      "Epoch 289/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1231 - accuracy: 0.9899 - val_loss: 2.1721 - val_accuracy: 0.4718\n",
      "Epoch 290/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1140 - accuracy: 0.9980 - val_loss: 2.1720 - val_accuracy: 0.4718\n",
      "Epoch 291/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1209 - accuracy: 0.9879 - val_loss: 2.1721 - val_accuracy: 0.4718\n",
      "Epoch 292/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1254 - accuracy: 0.9859 - val_loss: 2.1720 - val_accuracy: 0.4718\n",
      "Epoch 293/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1361 - accuracy: 0.9940 - val_loss: 2.1718 - val_accuracy: 0.4718\n",
      "Epoch 294/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1127 - accuracy: 0.9859 - val_loss: 2.1718 - val_accuracy: 0.4718\n",
      "Epoch 295/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1350 - accuracy: 0.9859 - val_loss: 2.1720 - val_accuracy: 0.4769\n",
      "Epoch 296/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1267 - accuracy: 0.9899 - val_loss: 2.1721 - val_accuracy: 0.4769\n",
      "Epoch 297/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1119 - accuracy: 0.9980 - val_loss: 2.1723 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1223 - accuracy: 0.9960 - val_loss: 2.1724 - val_accuracy: 0.4769\n",
      "Epoch 299/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1194 - accuracy: 0.9940 - val_loss: 2.1726 - val_accuracy: 0.4769\n",
      "Epoch 300/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1366 - accuracy: 0.9899 - val_loss: 2.1725 - val_accuracy: 0.4769\n",
      "Epoch 301/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1228 - accuracy: 0.9879 - val_loss: 2.1725 - val_accuracy: 0.4769\n",
      "Epoch 302/600\n",
      "497/497 [==============================] - 0s 370us/step - loss: 0.1257 - accuracy: 0.9879 - val_loss: 2.1725 - val_accuracy: 0.4769\n",
      "Epoch 303/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1238 - accuracy: 0.9920 - val_loss: 2.1725 - val_accuracy: 0.4769\n",
      "Epoch 304/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1185 - accuracy: 0.9920 - val_loss: 2.1724 - val_accuracy: 0.4769\n",
      "Epoch 305/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1266 - accuracy: 0.9920 - val_loss: 2.1726 - val_accuracy: 0.4769\n",
      "Epoch 306/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1229 - accuracy: 0.9940 - val_loss: 2.1725 - val_accuracy: 0.4769\n",
      "Epoch 307/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1273 - accuracy: 0.9899 - val_loss: 2.1728 - val_accuracy: 0.4769\n",
      "Epoch 308/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1210 - accuracy: 0.9859 - val_loss: 2.1728 - val_accuracy: 0.4769\n",
      "Epoch 309/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1325 - accuracy: 0.9819 - val_loss: 2.1735 - val_accuracy: 0.4821\n",
      "Epoch 310/600\n",
      "497/497 [==============================] - 0s 437us/step - loss: 0.1184 - accuracy: 0.9899 - val_loss: 2.1739 - val_accuracy: 0.4821\n",
      "Epoch 311/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1197 - accuracy: 0.9879 - val_loss: 2.1742 - val_accuracy: 0.4821\n",
      "Epoch 312/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1243 - accuracy: 0.9819 - val_loss: 2.1746 - val_accuracy: 0.4821\n",
      "Epoch 313/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1266 - accuracy: 0.9940 - val_loss: 2.1749 - val_accuracy: 0.4821\n",
      "Epoch 314/600\n",
      "497/497 [==============================] - 0s 433us/step - loss: 0.1251 - accuracy: 0.9940 - val_loss: 2.1751 - val_accuracy: 0.4821\n",
      "Epoch 315/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1199 - accuracy: 0.9899 - val_loss: 2.1750 - val_accuracy: 0.4821\n",
      "Epoch 316/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1073 - accuracy: 0.9960 - val_loss: 2.1753 - val_accuracy: 0.4821\n",
      "Epoch 317/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1288 - accuracy: 0.9899 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 318/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1218 - accuracy: 0.9879 - val_loss: 2.1752 - val_accuracy: 0.4821\n",
      "Epoch 319/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1262 - accuracy: 0.9899 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 320/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1346 - accuracy: 0.9799 - val_loss: 2.1755 - val_accuracy: 0.4821\n",
      "Epoch 321/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1163 - accuracy: 0.9940 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 322/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1451 - accuracy: 0.9859 - val_loss: 2.1755 - val_accuracy: 0.4821\n",
      "Epoch 323/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1376 - accuracy: 0.9859 - val_loss: 2.1756 - val_accuracy: 0.4821\n",
      "Epoch 324/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1287 - accuracy: 0.9899 - val_loss: 2.1756 - val_accuracy: 0.4821\n",
      "Epoch 325/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1193 - accuracy: 0.9920 - val_loss: 2.1759 - val_accuracy: 0.4821\n",
      "Epoch 326/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1297 - accuracy: 0.9899 - val_loss: 2.1760 - val_accuracy: 0.4821\n",
      "Epoch 327/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1260 - accuracy: 0.9879 - val_loss: 2.1760 - val_accuracy: 0.4821\n",
      "Epoch 328/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1120 - accuracy: 0.9940 - val_loss: 2.1756 - val_accuracy: 0.4821\n",
      "Epoch 329/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1228 - accuracy: 0.9899 - val_loss: 2.1754 - val_accuracy: 0.4821\n",
      "Epoch 330/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1409 - accuracy: 0.9940 - val_loss: 2.1753 - val_accuracy: 0.4821\n",
      "Epoch 331/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1267 - accuracy: 0.9920 - val_loss: 2.1750 - val_accuracy: 0.4821\n",
      "Epoch 332/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1304 - accuracy: 0.9859 - val_loss: 2.1747 - val_accuracy: 0.4821\n",
      "Epoch 333/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1303 - accuracy: 0.9940 - val_loss: 2.1742 - val_accuracy: 0.4821\n",
      "Epoch 334/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1228 - accuracy: 0.9920 - val_loss: 2.1738 - val_accuracy: 0.4821\n",
      "Epoch 335/600\n",
      "497/497 [==============================] - 0s 417us/step - loss: 0.1339 - accuracy: 0.9899 - val_loss: 2.1738 - val_accuracy: 0.4821\n",
      "Epoch 336/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1419 - accuracy: 0.9879 - val_loss: 2.1738 - val_accuracy: 0.4821\n",
      "Epoch 337/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1274 - accuracy: 0.9940 - val_loss: 2.1737 - val_accuracy: 0.4821\n",
      "Epoch 338/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1179 - accuracy: 0.9920 - val_loss: 2.1736 - val_accuracy: 0.4821\n",
      "Epoch 339/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1166 - accuracy: 0.9940 - val_loss: 2.1732 - val_accuracy: 0.4821\n",
      "Epoch 340/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1221 - accuracy: 0.9920 - val_loss: 2.1730 - val_accuracy: 0.4821\n",
      "Epoch 341/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1124 - accuracy: 0.9960 - val_loss: 2.1728 - val_accuracy: 0.4821\n",
      "Epoch 342/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1162 - accuracy: 0.9879 - val_loss: 2.1731 - val_accuracy: 0.4821\n",
      "Epoch 343/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1302 - accuracy: 0.9859 - val_loss: 2.1734 - val_accuracy: 0.4821\n",
      "Epoch 344/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1281 - accuracy: 0.9839 - val_loss: 2.1734 - val_accuracy: 0.4821\n",
      "Epoch 345/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1114 - accuracy: 0.9940 - val_loss: 2.1733 - val_accuracy: 0.4821\n",
      "Epoch 346/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1255 - accuracy: 0.9899 - val_loss: 2.1730 - val_accuracy: 0.4821\n",
      "Epoch 347/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1321 - accuracy: 0.9899 - val_loss: 2.1728 - val_accuracy: 0.4821\n",
      "Epoch 348/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1397 - accuracy: 0.9859 - val_loss: 2.1729 - val_accuracy: 0.4821\n",
      "Epoch 349/600\n",
      "497/497 [==============================] - 0s 372us/step - loss: 0.1125 - accuracy: 0.9879 - val_loss: 2.1725 - val_accuracy: 0.4821\n",
      "Epoch 350/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1270 - accuracy: 0.9940 - val_loss: 2.1724 - val_accuracy: 0.4821\n",
      "Epoch 351/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1331 - accuracy: 0.9960 - val_loss: 2.1723 - val_accuracy: 0.4872\n",
      "Epoch 352/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1282 - accuracy: 0.9920 - val_loss: 2.1719 - val_accuracy: 0.4872\n",
      "Epoch 353/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1329 - accuracy: 0.9940 - val_loss: 2.1720 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1185 - accuracy: 0.9940 - val_loss: 2.1723 - val_accuracy: 0.4872\n",
      "Epoch 355/600\n",
      "497/497 [==============================] - 0s 425us/step - loss: 0.1133 - accuracy: 0.9839 - val_loss: 2.1724 - val_accuracy: 0.4872\n",
      "Epoch 356/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1219 - accuracy: 0.9960 - val_loss: 2.1722 - val_accuracy: 0.4872\n",
      "Epoch 357/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1279 - accuracy: 0.9819 - val_loss: 2.1722 - val_accuracy: 0.4872\n",
      "Epoch 358/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1114 - accuracy: 0.9839 - val_loss: 2.1723 - val_accuracy: 0.4872\n",
      "Epoch 359/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1257 - accuracy: 0.9859 - val_loss: 2.1723 - val_accuracy: 0.4872\n",
      "Epoch 360/600\n",
      "497/497 [==============================] - 0s 408us/step - loss: 0.1369 - accuracy: 0.9920 - val_loss: 2.1722 - val_accuracy: 0.4872\n",
      "Epoch 361/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1326 - accuracy: 0.9879 - val_loss: 2.1716 - val_accuracy: 0.4872\n",
      "Epoch 362/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1087 - accuracy: 0.9920 - val_loss: 2.1714 - val_accuracy: 0.4872\n",
      "Epoch 363/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1243 - accuracy: 0.9839 - val_loss: 2.1712 - val_accuracy: 0.4872\n",
      "Epoch 364/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1409 - accuracy: 0.9839 - val_loss: 2.1712 - val_accuracy: 0.4872\n",
      "Epoch 365/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1154 - accuracy: 0.9859 - val_loss: 2.1709 - val_accuracy: 0.4872\n",
      "Epoch 366/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1216 - accuracy: 0.9899 - val_loss: 2.1705 - val_accuracy: 0.4872\n",
      "Epoch 367/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1094 - accuracy: 0.9940 - val_loss: 2.1700 - val_accuracy: 0.4872\n",
      "Epoch 368/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1236 - accuracy: 0.9879 - val_loss: 2.1696 - val_accuracy: 0.4872\n",
      "Epoch 369/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1078 - accuracy: 0.9940 - val_loss: 2.1693 - val_accuracy: 0.4872\n",
      "Epoch 370/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1214 - accuracy: 0.9920 - val_loss: 2.1688 - val_accuracy: 0.4872\n",
      "Epoch 371/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1181 - accuracy: 0.9899 - val_loss: 2.1685 - val_accuracy: 0.4872\n",
      "Epoch 372/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1286 - accuracy: 0.9879 - val_loss: 2.1682 - val_accuracy: 0.4872\n",
      "Epoch 373/600\n",
      "497/497 [==============================] - 0s 371us/step - loss: 0.1415 - accuracy: 0.9839 - val_loss: 2.1682 - val_accuracy: 0.4872\n",
      "Epoch 374/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1356 - accuracy: 0.9899 - val_loss: 2.1679 - val_accuracy: 0.4872\n",
      "Epoch 375/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1123 - accuracy: 0.9920 - val_loss: 2.1679 - val_accuracy: 0.4872\n",
      "Epoch 376/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1174 - accuracy: 0.9899 - val_loss: 2.1675 - val_accuracy: 0.4872\n",
      "Epoch 377/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1277 - accuracy: 0.9920 - val_loss: 2.1671 - val_accuracy: 0.4872\n",
      "Epoch 378/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.0981 - accuracy: 0.9940 - val_loss: 2.1665 - val_accuracy: 0.4872\n",
      "Epoch 379/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1256 - accuracy: 0.9980 - val_loss: 2.1662 - val_accuracy: 0.4872\n",
      "Epoch 380/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1171 - accuracy: 0.9899 - val_loss: 2.1660 - val_accuracy: 0.4872\n",
      "Epoch 381/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1186 - accuracy: 0.9940 - val_loss: 2.1660 - val_accuracy: 0.4872\n",
      "Epoch 382/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1159 - accuracy: 0.9899 - val_loss: 2.1662 - val_accuracy: 0.4872\n",
      "Epoch 383/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1036 - accuracy: 0.9960 - val_loss: 2.1662 - val_accuracy: 0.4872\n",
      "Epoch 384/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1132 - accuracy: 0.9839 - val_loss: 2.1663 - val_accuracy: 0.4872\n",
      "Epoch 385/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1176 - accuracy: 0.9980 - val_loss: 2.1665 - val_accuracy: 0.4872\n",
      "Epoch 386/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1267 - accuracy: 0.9879 - val_loss: 2.1667 - val_accuracy: 0.4872\n",
      "Epoch 387/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1490 - accuracy: 0.9819 - val_loss: 2.1667 - val_accuracy: 0.4872\n",
      "Epoch 388/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1241 - accuracy: 0.9920 - val_loss: 2.1665 - val_accuracy: 0.4872\n",
      "Epoch 389/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1093 - accuracy: 0.9940 - val_loss: 2.1670 - val_accuracy: 0.4872\n",
      "Epoch 390/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1145 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 391/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1273 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 392/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1293 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 393/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1190 - accuracy: 0.9920 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 394/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1221 - accuracy: 0.9819 - val_loss: 2.1663 - val_accuracy: 0.4872\n",
      "Epoch 395/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1091 - accuracy: 0.9980 - val_loss: 2.1660 - val_accuracy: 0.4872\n",
      "Epoch 396/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1334 - accuracy: 0.9839 - val_loss: 2.1656 - val_accuracy: 0.4872\n",
      "Epoch 397/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1205 - accuracy: 0.9980 - val_loss: 2.1654 - val_accuracy: 0.4872\n",
      "Epoch 398/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1181 - accuracy: 0.9920 - val_loss: 2.1652 - val_accuracy: 0.4872\n",
      "Epoch 399/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1115 - accuracy: 0.9920 - val_loss: 2.1647 - val_accuracy: 0.4872\n",
      "Epoch 400/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1122 - accuracy: 0.9899 - val_loss: 2.1643 - val_accuracy: 0.4872\n",
      "Epoch 401/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1401 - accuracy: 0.9839 - val_loss: 2.1639 - val_accuracy: 0.4872\n",
      "Epoch 402/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1255 - accuracy: 0.9899 - val_loss: 2.1640 - val_accuracy: 0.4872\n",
      "Epoch 403/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1241 - accuracy: 0.9859 - val_loss: 2.1640 - val_accuracy: 0.4872\n",
      "Epoch 404/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1197 - accuracy: 0.9920 - val_loss: 2.1643 - val_accuracy: 0.4872\n",
      "Epoch 405/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1150 - accuracy: 0.9859 - val_loss: 2.1641 - val_accuracy: 0.4872\n",
      "Epoch 406/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1308 - accuracy: 0.9940 - val_loss: 2.1641 - val_accuracy: 0.4872\n",
      "Epoch 407/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1218 - accuracy: 0.9920 - val_loss: 2.1642 - val_accuracy: 0.4872\n",
      "Epoch 408/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1272 - accuracy: 0.9899 - val_loss: 2.1643 - val_accuracy: 0.4872\n",
      "Epoch 409/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1394 - accuracy: 0.9799 - val_loss: 2.1648 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/600\n",
      "497/497 [==============================] - 0s 377us/step - loss: 0.1323 - accuracy: 0.9859 - val_loss: 2.1650 - val_accuracy: 0.4872\n",
      "Epoch 411/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1111 - accuracy: 0.9899 - val_loss: 2.1653 - val_accuracy: 0.4872\n",
      "Epoch 412/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1274 - accuracy: 0.9899 - val_loss: 2.1655 - val_accuracy: 0.4872\n",
      "Epoch 413/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1211 - accuracy: 0.9839 - val_loss: 2.1659 - val_accuracy: 0.4872\n",
      "Epoch 414/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1131 - accuracy: 0.9879 - val_loss: 2.1662 - val_accuracy: 0.4872\n",
      "Epoch 415/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1330 - accuracy: 0.9819 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 416/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1121 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 417/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1204 - accuracy: 0.9859 - val_loss: 2.1672 - val_accuracy: 0.4872\n",
      "Epoch 418/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1280 - accuracy: 0.9839 - val_loss: 2.1672 - val_accuracy: 0.4872\n",
      "Epoch 419/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1291 - accuracy: 0.9859 - val_loss: 2.1671 - val_accuracy: 0.4872\n",
      "Epoch 420/600\n",
      "497/497 [==============================] - 0s 376us/step - loss: 0.1053 - accuracy: 0.9980 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 421/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1053 - accuracy: 0.9960 - val_loss: 2.1669 - val_accuracy: 0.4872\n",
      "Epoch 422/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1218 - accuracy: 0.9920 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 423/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1232 - accuracy: 0.9899 - val_loss: 2.1669 - val_accuracy: 0.4872\n",
      "Epoch 424/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1147 - accuracy: 0.9920 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 425/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1175 - accuracy: 0.9940 - val_loss: 2.1663 - val_accuracy: 0.4872\n",
      "Epoch 426/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1170 - accuracy: 0.9899 - val_loss: 2.1662 - val_accuracy: 0.4872\n",
      "Epoch 427/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1251 - accuracy: 0.9920 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 428/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1203 - accuracy: 0.9899 - val_loss: 2.1666 - val_accuracy: 0.4872\n",
      "Epoch 429/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1087 - accuracy: 0.9879 - val_loss: 2.1665 - val_accuracy: 0.4872\n",
      "Epoch 430/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1271 - accuracy: 0.9899 - val_loss: 2.1668 - val_accuracy: 0.4872\n",
      "Epoch 431/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1295 - accuracy: 0.9920 - val_loss: 2.1672 - val_accuracy: 0.4872\n",
      "Epoch 432/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1080 - accuracy: 0.9960 - val_loss: 2.1673 - val_accuracy: 0.4872\n",
      "Epoch 433/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1128 - accuracy: 0.9899 - val_loss: 2.1678 - val_accuracy: 0.4872\n",
      "Epoch 434/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1142 - accuracy: 0.9940 - val_loss: 2.1683 - val_accuracy: 0.4872\n",
      "Epoch 435/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1048 - accuracy: 0.9920 - val_loss: 2.1689 - val_accuracy: 0.4872\n",
      "Epoch 436/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1077 - accuracy: 0.9960 - val_loss: 2.1692 - val_accuracy: 0.4872\n",
      "Epoch 437/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1382 - accuracy: 0.9799 - val_loss: 2.1698 - val_accuracy: 0.4872\n",
      "Epoch 438/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1093 - accuracy: 0.9940 - val_loss: 2.1705 - val_accuracy: 0.4872\n",
      "Epoch 439/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1122 - accuracy: 0.9879 - val_loss: 2.1709 - val_accuracy: 0.4872\n",
      "Epoch 440/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1079 - accuracy: 0.9920 - val_loss: 2.1712 - val_accuracy: 0.4821\n",
      "Epoch 441/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1051 - accuracy: 0.9940 - val_loss: 2.1716 - val_accuracy: 0.4821\n",
      "Epoch 442/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1331 - accuracy: 0.9859 - val_loss: 2.1719 - val_accuracy: 0.4821\n",
      "Epoch 443/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1455 - accuracy: 0.9859 - val_loss: 2.1725 - val_accuracy: 0.4821\n",
      "Epoch 444/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1198 - accuracy: 0.9980 - val_loss: 2.1730 - val_accuracy: 0.4821\n",
      "Epoch 445/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.0974 - accuracy: 0.9980 - val_loss: 2.1732 - val_accuracy: 0.4821\n",
      "Epoch 446/600\n",
      "497/497 [==============================] - 0s 419us/step - loss: 0.1120 - accuracy: 0.9980 - val_loss: 2.1734 - val_accuracy: 0.4769\n",
      "Epoch 447/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1094 - accuracy: 0.9940 - val_loss: 2.1733 - val_accuracy: 0.4769\n",
      "Epoch 448/600\n",
      "497/497 [==============================] - 0s 375us/step - loss: 0.1093 - accuracy: 0.9899 - val_loss: 2.1733 - val_accuracy: 0.4769\n",
      "Epoch 449/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1229 - accuracy: 0.9920 - val_loss: 2.1734 - val_accuracy: 0.4769\n",
      "Epoch 450/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1123 - accuracy: 0.9960 - val_loss: 2.1735 - val_accuracy: 0.4769\n",
      "Epoch 451/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1080 - accuracy: 0.9940 - val_loss: 2.1733 - val_accuracy: 0.4769\n",
      "Epoch 452/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1211 - accuracy: 0.9859 - val_loss: 2.1734 - val_accuracy: 0.4769\n",
      "Epoch 453/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1171 - accuracy: 0.9940 - val_loss: 2.1736 - val_accuracy: 0.4769\n",
      "Epoch 454/600\n",
      "497/497 [==============================] - 0s 383us/step - loss: 0.1227 - accuracy: 0.9839 - val_loss: 2.1737 - val_accuracy: 0.4769\n",
      "Epoch 455/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1269 - accuracy: 0.9839 - val_loss: 2.1739 - val_accuracy: 0.4769\n",
      "Epoch 456/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1157 - accuracy: 0.9920 - val_loss: 2.1744 - val_accuracy: 0.4769\n",
      "Epoch 457/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1132 - accuracy: 0.9940 - val_loss: 2.1747 - val_accuracy: 0.4769\n",
      "Epoch 458/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1251 - accuracy: 0.9920 - val_loss: 2.1753 - val_accuracy: 0.4769\n",
      "Epoch 459/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.0989 - accuracy: 0.9960 - val_loss: 2.1756 - val_accuracy: 0.4769\n",
      "Epoch 460/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1045 - accuracy: 0.9960 - val_loss: 2.1760 - val_accuracy: 0.4769\n",
      "Epoch 461/600\n",
      "497/497 [==============================] - 0s 422us/step - loss: 0.1247 - accuracy: 0.9899 - val_loss: 2.1761 - val_accuracy: 0.4769\n",
      "Epoch 462/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1332 - accuracy: 0.9859 - val_loss: 2.1763 - val_accuracy: 0.4769\n",
      "Epoch 463/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1153 - accuracy: 0.9960 - val_loss: 2.1763 - val_accuracy: 0.4769\n",
      "Epoch 464/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1083 - accuracy: 0.9920 - val_loss: 2.1766 - val_accuracy: 0.4718\n",
      "Epoch 465/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1043 - accuracy: 0.9940 - val_loss: 2.1767 - val_accuracy: 0.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1201 - accuracy: 0.9819 - val_loss: 2.1770 - val_accuracy: 0.4718\n",
      "Epoch 467/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.0984 - accuracy: 0.9980 - val_loss: 2.1768 - val_accuracy: 0.4718\n",
      "Epoch 468/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.0956 - accuracy: 0.9940 - val_loss: 2.1771 - val_accuracy: 0.4718\n",
      "Epoch 469/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1067 - accuracy: 0.9940 - val_loss: 2.1769 - val_accuracy: 0.4718\n",
      "Epoch 470/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1149 - accuracy: 0.9920 - val_loss: 2.1767 - val_accuracy: 0.4718\n",
      "Epoch 471/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1606 - accuracy: 0.9759 - val_loss: 2.1770 - val_accuracy: 0.4718\n",
      "Epoch 472/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1341 - accuracy: 0.9920 - val_loss: 2.1771 - val_accuracy: 0.4718\n",
      "Epoch 473/600\n",
      "497/497 [==============================] - 0s 413us/step - loss: 0.1064 - accuracy: 0.9940 - val_loss: 2.1775 - val_accuracy: 0.4718\n",
      "Epoch 474/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1115 - accuracy: 0.9940 - val_loss: 2.1777 - val_accuracy: 0.4718\n",
      "Epoch 475/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1179 - accuracy: 0.9940 - val_loss: 2.1779 - val_accuracy: 0.4769\n",
      "Epoch 476/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1171 - accuracy: 0.9940 - val_loss: 2.1779 - val_accuracy: 0.4769\n",
      "Epoch 477/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1004 - accuracy: 0.9920 - val_loss: 2.1781 - val_accuracy: 0.4769\n",
      "Epoch 478/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1177 - accuracy: 0.9920 - val_loss: 2.1782 - val_accuracy: 0.4769\n",
      "Epoch 479/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1103 - accuracy: 0.9960 - val_loss: 2.1780 - val_accuracy: 0.4718\n",
      "Epoch 480/600\n",
      "497/497 [==============================] - 0s 416us/step - loss: 0.1222 - accuracy: 0.9940 - val_loss: 2.1783 - val_accuracy: 0.4718\n",
      "Epoch 481/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1254 - accuracy: 0.9879 - val_loss: 2.1785 - val_accuracy: 0.4718\n",
      "Epoch 482/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1310 - accuracy: 0.9879 - val_loss: 2.1785 - val_accuracy: 0.4718\n",
      "Epoch 483/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1197 - accuracy: 0.9879 - val_loss: 2.1787 - val_accuracy: 0.4718\n",
      "Epoch 484/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1287 - accuracy: 0.9920 - val_loss: 2.1791 - val_accuracy: 0.4718\n",
      "Epoch 485/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1074 - accuracy: 0.9920 - val_loss: 2.1795 - val_accuracy: 0.4718\n",
      "Epoch 486/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1288 - accuracy: 0.9920 - val_loss: 2.1796 - val_accuracy: 0.4718\n",
      "Epoch 487/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1115 - accuracy: 0.9940 - val_loss: 2.1793 - val_accuracy: 0.4718\n",
      "Epoch 488/600\n",
      "497/497 [==============================] - 0s 412us/step - loss: 0.1015 - accuracy: 0.9940 - val_loss: 2.1790 - val_accuracy: 0.4718\n",
      "Epoch 489/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1454 - accuracy: 0.9859 - val_loss: 2.1787 - val_accuracy: 0.4718\n",
      "Epoch 490/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1170 - accuracy: 0.9960 - val_loss: 2.1783 - val_accuracy: 0.4718\n",
      "Epoch 491/600\n",
      "497/497 [==============================] - 0s 409us/step - loss: 0.1330 - accuracy: 0.9899 - val_loss: 2.1782 - val_accuracy: 0.4718\n",
      "Epoch 492/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1182 - accuracy: 0.9819 - val_loss: 2.1782 - val_accuracy: 0.4718\n",
      "Epoch 493/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1019 - accuracy: 0.9980 - val_loss: 2.1780 - val_accuracy: 0.4718\n",
      "Epoch 494/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1187 - accuracy: 0.9920 - val_loss: 2.1780 - val_accuracy: 0.4718\n",
      "Epoch 495/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.0960 - accuracy: 0.9960 - val_loss: 2.1782 - val_accuracy: 0.4718\n",
      "Epoch 496/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1246 - accuracy: 0.9920 - val_loss: 2.1783 - val_accuracy: 0.4718\n",
      "Epoch 497/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1245 - accuracy: 0.9879 - val_loss: 2.1783 - val_accuracy: 0.4718\n",
      "Epoch 498/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1075 - accuracy: 0.9980 - val_loss: 2.1784 - val_accuracy: 0.4718\n",
      "Epoch 499/600\n",
      "497/497 [==============================] - 0s 421us/step - loss: 0.1248 - accuracy: 0.9879 - val_loss: 2.1791 - val_accuracy: 0.4718\n",
      "Epoch 500/600\n",
      "497/497 [==============================] - 0s 423us/step - loss: 0.1120 - accuracy: 0.9879 - val_loss: 2.1788 - val_accuracy: 0.4718\n",
      "Epoch 501/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1316 - accuracy: 0.9920 - val_loss: 2.1790 - val_accuracy: 0.4718\n",
      "Epoch 502/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1273 - accuracy: 0.9879 - val_loss: 2.1794 - val_accuracy: 0.4718\n",
      "Epoch 503/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1360 - accuracy: 0.9799 - val_loss: 2.1794 - val_accuracy: 0.4718\n",
      "Epoch 504/600\n",
      "497/497 [==============================] - 0s 418us/step - loss: 0.1215 - accuracy: 0.9859 - val_loss: 2.1793 - val_accuracy: 0.4718\n",
      "Epoch 505/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1077 - accuracy: 0.9920 - val_loss: 2.1790 - val_accuracy: 0.4718\n",
      "Epoch 506/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1150 - accuracy: 0.9899 - val_loss: 2.1786 - val_accuracy: 0.4718\n",
      "Epoch 507/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1135 - accuracy: 0.9940 - val_loss: 2.1783 - val_accuracy: 0.4718\n",
      "Epoch 508/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.4718\n",
      "Epoch 509/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1106 - accuracy: 0.9940 - val_loss: 2.1782 - val_accuracy: 0.4718\n",
      "Epoch 510/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1273 - accuracy: 0.9920 - val_loss: 2.1781 - val_accuracy: 0.4769\n",
      "Epoch 511/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1173 - accuracy: 0.9940 - val_loss: 2.1781 - val_accuracy: 0.4769\n",
      "Epoch 512/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1073 - accuracy: 0.9940 - val_loss: 2.1777 - val_accuracy: 0.4769\n",
      "Epoch 513/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1102 - accuracy: 0.9940 - val_loss: 2.1774 - val_accuracy: 0.4769\n",
      "Epoch 514/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1112 - accuracy: 0.9940 - val_loss: 2.1773 - val_accuracy: 0.4769\n",
      "Epoch 515/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.1147 - accuracy: 0.9940 - val_loss: 2.1769 - val_accuracy: 0.4769\n",
      "Epoch 516/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1102 - accuracy: 0.9940 - val_loss: 2.1768 - val_accuracy: 0.4769\n",
      "Epoch 517/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1035 - accuracy: 0.9980 - val_loss: 2.1767 - val_accuracy: 0.4769\n",
      "Epoch 518/600\n",
      "497/497 [==============================] - 0s 391us/step - loss: 0.1214 - accuracy: 0.9960 - val_loss: 2.1767 - val_accuracy: 0.4769\n",
      "Epoch 519/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1077 - accuracy: 0.9920 - val_loss: 2.1765 - val_accuracy: 0.4769\n",
      "Epoch 520/600\n",
      "497/497 [==============================] - 0s 420us/step - loss: 0.1248 - accuracy: 0.9879 - val_loss: 2.1758 - val_accuracy: 0.4769\n",
      "Epoch 521/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1185 - accuracy: 0.9879 - val_loss: 2.1759 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1225 - accuracy: 0.9859 - val_loss: 2.1760 - val_accuracy: 0.4769\n",
      "Epoch 523/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1110 - accuracy: 0.9920 - val_loss: 2.1760 - val_accuracy: 0.4769\n",
      "Epoch 524/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1260 - accuracy: 0.9940 - val_loss: 2.1763 - val_accuracy: 0.4769\n",
      "Epoch 525/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1171 - accuracy: 0.9879 - val_loss: 2.1763 - val_accuracy: 0.4769\n",
      "Epoch 526/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1187 - accuracy: 0.9859 - val_loss: 2.1762 - val_accuracy: 0.4821\n",
      "Epoch 527/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1334 - accuracy: 0.9859 - val_loss: 2.1765 - val_accuracy: 0.4821\n",
      "Epoch 528/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1171 - accuracy: 0.9920 - val_loss: 2.1767 - val_accuracy: 0.4821\n",
      "Epoch 529/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1132 - accuracy: 0.9859 - val_loss: 2.1767 - val_accuracy: 0.4821\n",
      "Epoch 530/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1292 - accuracy: 0.9879 - val_loss: 2.1770 - val_accuracy: 0.4821\n",
      "Epoch 531/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1169 - accuracy: 0.9920 - val_loss: 2.1772 - val_accuracy: 0.4821\n",
      "Epoch 532/600\n",
      "497/497 [==============================] - 0s 385us/step - loss: 0.1101 - accuracy: 0.9899 - val_loss: 2.1774 - val_accuracy: 0.4821\n",
      "Epoch 533/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.0939 - accuracy: 0.9960 - val_loss: 2.1776 - val_accuracy: 0.4821\n",
      "Epoch 534/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1209 - accuracy: 0.9859 - val_loss: 2.1779 - val_accuracy: 0.4821\n",
      "Epoch 535/600\n",
      "497/497 [==============================] - 0s 404us/step - loss: 0.1175 - accuracy: 0.9920 - val_loss: 2.1785 - val_accuracy: 0.4821\n",
      "Epoch 536/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1221 - accuracy: 0.9960 - val_loss: 2.1784 - val_accuracy: 0.4821\n",
      "Epoch 537/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1233 - accuracy: 0.9879 - val_loss: 2.1786 - val_accuracy: 0.4821\n",
      "Epoch 538/600\n",
      "497/497 [==============================] - 0s 376us/step - loss: 0.1215 - accuracy: 0.9920 - val_loss: 2.1786 - val_accuracy: 0.4821\n",
      "Epoch 539/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1194 - accuracy: 0.9920 - val_loss: 2.1785 - val_accuracy: 0.4821\n",
      "Epoch 540/600\n",
      "497/497 [==============================] - 0s 386us/step - loss: 0.1217 - accuracy: 0.9879 - val_loss: 2.1789 - val_accuracy: 0.4821\n",
      "Epoch 541/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1208 - accuracy: 0.9940 - val_loss: 2.1786 - val_accuracy: 0.4769\n",
      "Epoch 542/600\n",
      "497/497 [==============================] - 0s 393us/step - loss: 0.1043 - accuracy: 0.9899 - val_loss: 2.1785 - val_accuracy: 0.4769\n",
      "Epoch 543/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1198 - accuracy: 0.9920 - val_loss: 2.1784 - val_accuracy: 0.4769\n",
      "Epoch 544/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1188 - accuracy: 0.9920 - val_loss: 2.1785 - val_accuracy: 0.4769\n",
      "Epoch 545/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.0999 - accuracy: 0.9940 - val_loss: 2.1785 - val_accuracy: 0.4769\n",
      "Epoch 546/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1018 - accuracy: 0.9980 - val_loss: 2.1784 - val_accuracy: 0.4769\n",
      "Epoch 547/600\n",
      "497/497 [==============================] - 0s 406us/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 2.1780 - val_accuracy: 0.4769\n",
      "Epoch 548/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1270 - accuracy: 0.9879 - val_loss: 2.1776 - val_accuracy: 0.4769\n",
      "Epoch 549/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1149 - accuracy: 0.9899 - val_loss: 2.1774 - val_accuracy: 0.4769\n",
      "Epoch 550/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1158 - accuracy: 0.9899 - val_loss: 2.1778 - val_accuracy: 0.4769\n",
      "Epoch 551/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1398 - accuracy: 0.9879 - val_loss: 2.1780 - val_accuracy: 0.4769\n",
      "Epoch 552/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1129 - accuracy: 0.9920 - val_loss: 2.1779 - val_accuracy: 0.4769\n",
      "Epoch 553/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1198 - accuracy: 0.9899 - val_loss: 2.1778 - val_accuracy: 0.4769\n",
      "Epoch 554/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1334 - accuracy: 0.9899 - val_loss: 2.1778 - val_accuracy: 0.4769\n",
      "Epoch 555/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1116 - accuracy: 0.9920 - val_loss: 2.1778 - val_accuracy: 0.4769\n",
      "Epoch 556/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1161 - accuracy: 0.9899 - val_loss: 2.1781 - val_accuracy: 0.4769\n",
      "Epoch 557/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1368 - accuracy: 0.9819 - val_loss: 2.1782 - val_accuracy: 0.4769\n",
      "Epoch 558/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1323 - accuracy: 0.9879 - val_loss: 2.1787 - val_accuracy: 0.4769\n",
      "Epoch 559/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1174 - accuracy: 0.9899 - val_loss: 2.1787 - val_accuracy: 0.4769\n",
      "Epoch 560/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1355 - accuracy: 0.9799 - val_loss: 2.1794 - val_accuracy: 0.4769\n",
      "Epoch 561/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1161 - accuracy: 0.9859 - val_loss: 2.1800 - val_accuracy: 0.4769\n",
      "Epoch 562/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1102 - accuracy: 0.9960 - val_loss: 2.1806 - val_accuracy: 0.4769\n",
      "Epoch 563/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1166 - accuracy: 0.9859 - val_loss: 2.1809 - val_accuracy: 0.4769\n",
      "Epoch 564/600\n",
      "497/497 [==============================] - 0s 382us/step - loss: 0.1006 - accuracy: 0.9960 - val_loss: 2.1813 - val_accuracy: 0.4769\n",
      "Epoch 565/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1094 - accuracy: 0.9960 - val_loss: 2.1819 - val_accuracy: 0.4769\n",
      "Epoch 566/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1401 - accuracy: 0.9899 - val_loss: 2.1825 - val_accuracy: 0.4769\n",
      "Epoch 567/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1203 - accuracy: 0.9920 - val_loss: 2.1828 - val_accuracy: 0.4769\n",
      "Epoch 568/600\n",
      "497/497 [==============================] - 0s 401us/step - loss: 0.1230 - accuracy: 0.9879 - val_loss: 2.1832 - val_accuracy: 0.4769\n",
      "Epoch 569/600\n",
      "497/497 [==============================] - 0s 381us/step - loss: 0.1096 - accuracy: 0.9980 - val_loss: 2.1830 - val_accuracy: 0.4769\n",
      "Epoch 570/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1191 - accuracy: 0.9920 - val_loss: 2.1834 - val_accuracy: 0.4769\n",
      "Epoch 571/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1185 - accuracy: 0.9940 - val_loss: 2.1834 - val_accuracy: 0.4821\n",
      "Epoch 572/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1377 - accuracy: 0.9920 - val_loss: 2.1834 - val_accuracy: 0.4821\n",
      "Epoch 573/600\n",
      "497/497 [==============================] - 0s 399us/step - loss: 0.1040 - accuracy: 0.9960 - val_loss: 2.1835 - val_accuracy: 0.4821\n",
      "Epoch 574/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1052 - accuracy: 0.9960 - val_loss: 2.1837 - val_accuracy: 0.4769\n",
      "Epoch 575/600\n",
      "497/497 [==============================] - 0s 389us/step - loss: 0.1152 - accuracy: 0.9899 - val_loss: 2.1838 - val_accuracy: 0.4769\n",
      "Epoch 576/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1241 - accuracy: 0.9879 - val_loss: 2.1842 - val_accuracy: 0.4769\n",
      "Epoch 577/600\n",
      "497/497 [==============================] - 0s 403us/step - loss: 0.1102 - accuracy: 0.9920 - val_loss: 2.1844 - val_accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/600\n",
      "497/497 [==============================] - 0s 407us/step - loss: 0.1261 - accuracy: 0.9859 - val_loss: 2.1844 - val_accuracy: 0.4769\n",
      "Epoch 579/600\n",
      "497/497 [==============================] - 0s 398us/step - loss: 0.1055 - accuracy: 0.9940 - val_loss: 2.1846 - val_accuracy: 0.4769\n",
      "Epoch 580/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1162 - accuracy: 0.9940 - val_loss: 2.1849 - val_accuracy: 0.4769\n",
      "Epoch 581/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1192 - accuracy: 0.9879 - val_loss: 2.1852 - val_accuracy: 0.4769\n",
      "Epoch 582/600\n",
      "497/497 [==============================] - 0s 414us/step - loss: 0.1221 - accuracy: 0.9899 - val_loss: 2.1854 - val_accuracy: 0.4769\n",
      "Epoch 583/600\n",
      "497/497 [==============================] - 0s 388us/step - loss: 0.1182 - accuracy: 0.9960 - val_loss: 2.1857 - val_accuracy: 0.4769\n",
      "Epoch 584/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.0992 - accuracy: 0.9920 - val_loss: 2.1856 - val_accuracy: 0.4769\n",
      "Epoch 585/600\n",
      "497/497 [==============================] - 0s 415us/step - loss: 0.1308 - accuracy: 0.9819 - val_loss: 2.1855 - val_accuracy: 0.4769\n",
      "Epoch 586/600\n",
      "497/497 [==============================] - 0s 410us/step - loss: 0.1238 - accuracy: 0.9960 - val_loss: 2.1857 - val_accuracy: 0.4769\n",
      "Epoch 587/600\n",
      "497/497 [==============================] - 0s 411us/step - loss: 0.1361 - accuracy: 0.9879 - val_loss: 2.1858 - val_accuracy: 0.4769\n",
      "Epoch 588/600\n",
      "497/497 [==============================] - 0s 378us/step - loss: 0.1179 - accuracy: 0.9879 - val_loss: 2.1860 - val_accuracy: 0.4769\n",
      "Epoch 589/600\n",
      "497/497 [==============================] - 0s 392us/step - loss: 0.1191 - accuracy: 0.9920 - val_loss: 2.1861 - val_accuracy: 0.4769\n",
      "Epoch 590/600\n",
      "497/497 [==============================] - 0s 396us/step - loss: 0.1134 - accuracy: 0.9899 - val_loss: 2.1860 - val_accuracy: 0.4769\n",
      "Epoch 591/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1189 - accuracy: 0.9819 - val_loss: 2.1855 - val_accuracy: 0.4769\n",
      "Epoch 592/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 0.0984 - accuracy: 0.9920 - val_loss: 2.1851 - val_accuracy: 0.4769\n",
      "Epoch 593/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.0978 - accuracy: 0.9980 - val_loss: 2.1847 - val_accuracy: 0.4769\n",
      "Epoch 594/600\n",
      "497/497 [==============================] - 0s 387us/step - loss: 0.1031 - accuracy: 0.9940 - val_loss: 2.1847 - val_accuracy: 0.4769\n",
      "Epoch 595/600\n",
      "497/497 [==============================] - 0s 384us/step - loss: 0.1168 - accuracy: 0.9920 - val_loss: 2.1843 - val_accuracy: 0.4769\n",
      "Epoch 596/600\n",
      "497/497 [==============================] - 0s 405us/step - loss: 0.1219 - accuracy: 0.9920 - val_loss: 2.1840 - val_accuracy: 0.4769\n",
      "Epoch 597/600\n",
      "497/497 [==============================] - 0s 400us/step - loss: 0.1243 - accuracy: 0.9819 - val_loss: 2.1837 - val_accuracy: 0.4769\n",
      "Epoch 598/600\n",
      "497/497 [==============================] - 0s 402us/step - loss: 0.1048 - accuracy: 0.9899 - val_loss: 2.1826 - val_accuracy: 0.4769\n",
      "Epoch 599/600\n",
      "497/497 [==============================] - 0s 395us/step - loss: 0.1118 - accuracy: 0.9940 - val_loss: 2.1820 - val_accuracy: 0.4769\n",
      "Epoch 600/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 0.1084 - accuracy: 0.9920 - val_loss: 2.1815 - val_accuracy: 0.4769\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 132.51it/s]\n"
     ]
    }
   ],
   "source": [
    "pose_label = pickle.load(open('/home/ubuntu/roger_actions_output/pose_label.pkl', 'rb'))\n",
    "x_0, x_1, y = data_generator(pose_label,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for result in y:\n",
    "    print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = DD_Net.predict([X_0,X_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n"
     ]
    }
   ],
   "source": [
    "for i, label in zip(range(len(X_0)), Train['label']):\n",
    "    print(np.argmax(output[i]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wave'], dtype='<U14')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['clap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 658/658 [00:02<00:00, 280.40it/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 326.62it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"GT_train_2.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"GT_test_2.pkl\", \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-initialize weights, since training and testing data switch\n",
    "DD_Net = build_DD_Net(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    #callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    #callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/tIFGV/l18cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 663/663 [00:02<00:00, 269.67it/s]\n",
      "100%|██████████| 265/265 [00:00<00:00, 320.48it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"GT_train_3.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"GT_test_3.pkl\", \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-initialize weights, since training and testing data switch\n",
    "DD_Net = build_DD_Net(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd4VFX6wPHvmzrpgVQgpNCL9Ago\nKKKoYGPt4toQ5adrd13Lrrv2tsW1rsoqtrVh28WKiqAiigRBOtIChBpIqOnJ+f1x70wmySR3gEwK\neT/PM8/MPffce8+ZTO57zzm3iDEGpZRSqiFBzV0ApZRSLZ8GC6WUUo40WCillHKkwUIppZQjDRZK\nKaUcabBQSinlSIOFavNEJFNEjIiE+JH3ChGZ0xTlUqol0WChWhURyRWRMhFJrJW+yN7hZzZPyZQ6\nsmmwUK3RemCCe0JE+gERzVeclsGflpFSh0qDhWqNXgcu85q+HHjNO4OIxInIayKSLyIbRORuEQmy\n5wWLyN9FZKeIrANO97HsSyKyVUQ2i8iDIhLsT8FE5F0R2SYie0TkWxHp6zUvQkT+YZdnj4jMEZEI\ne95IEZkrIrtFZJOIXGGnzxaRq7zWUaMbzG5NXSciq4HVdtqT9jr2isgCETnOK3+wiPxRRNaKyD57\nfmcReVZE/lGrLh+JyM3+1Fsd+TRYqNboRyBWRHrbO/ELgf/UyvM0EAd0AUZhBZeJ9ryrgTOAQUA2\ncF6tZV8FKoBudp5TgKvwz2dAdyAZ+Bl4w2ve34EhwLFAe+B2oEpE0u3lngaSgIHAIj+3B/AbYBjQ\nx56eb6+jPfAm8K6IuOx5t2K1yk4DYoErgSK7zhO8AmoicBLw1kGUQx3JjDH60lereQG5wBjgbuAR\nYCzwJRACGCATCAZKgT5ey/0fMNv+/DVwjde8U+xlQ4AUe9kIr/kTgFn25yuAOX6WNd5ebxzWgVkx\nMMBHvruAD+tZx2zgKq/pGtu313+iQzkK3dsFVgHj68m3AjjZ/nw98Glz/7311XJe2sepWqvXgW+B\nLGp1QQGJQBiwwSttA9DJ/twR2FRrnlsGEApsFRF3WlCt/D7ZrZyHgPOxWghVXuUJB1zAWh+Ldq4n\n3V81yiYiv8dqCXXECiaxdhmctvUqcAlW8L0EePIwyqSOMNoNpVolY8wGrIHu04APas3eCZRj7fjd\n0oHN9uetWDtN73lum7BaFonGmHj7FWuM6Yuzi4HxWC2fOKxWDoDYZSoBuvpYblM96QAHgEiv6VQf\neTy3jrbHJ+4ALgDaGWPigT12GZy29R9gvIgMAHoD/60nn2qDNFio1mwSVhfMAe9EY0wlMA14SERi\nRCQDq6/ePa4xDbhRRNJEpB1wp9eyW4EvgH+ISKyIBIlIVxEZ5Ud5YrACzS6sHfzDXuutAqYCj4tI\nR3ug+RgRCcca1xgjIheISIiIJIjIQHvRRcA5IhIpIt3sOjuVoQLIB0JE5C9YLQu3F4EHRKS7WPqL\nSIJdxjys8Y7XgfeNMcV+1Fm1ERosVKtljFlrjMmpZ/YNWEfl64A5WAO9U+15/wZmAL9gDULXbplc\nhtWNtRyrv/89oIMfRXoNq0trs73sj7Xm3wYswdohFwCPAUHGmI1YLaTf2+mLgAH2Mv8EyoDtWN1E\nb9CwGViD5b/aZSmhZjfV41jB8gtgL/ASNU87fhXohxUwlPIQY/ThR0opi4gcj9UCy7RbQ0oB2rJQ\nStlEJBS4CXhRA4WqTYOFUgoR6Q3sxupue6KZi6NaIO2GUkop5UhbFkoppRwdMRflJSYmmszMzOYu\nhlJKtSoLFizYaYxJcsp3xASLzMxMcnLqO4tSKaWULyKywTmXdkMppZTygwYLpZRSjjRYKKWUcnTE\njFn4Ul5eTl5eHiUlJc1dlCbjcrlIS0sjNDS0uYuilDqCHNHBIi8vj5iYGDIzM/G63fQRyxjDrl27\nyMvLIysrq7mLo5Q6ggSsG0pEporIDhFZWs98EZGnRGSNiCwWkcFe8y4XkdX26/JDLUNJSQkJCQlt\nIlAAiAgJCQltqiWllGoagRyzeAXrKWb1GYf1+MnuwGTgOQARaQ/cg/WYyKHAPfZtpA9JWwkUbm2t\nvkqpphGwYGGM+Rbrdsv1GQ+8Ziw/AvEi0gE4FfjSGFNgjCnEempXQ0EnIAqLyig8UOZzXmVVFbv2\nl1JwoIyqKkPBgTJq3zalqKyCorKKOsuWlFeyv6QcY6zldu4vpaKy7j3byiuq2F1URkWl9e697cID\nZVTW2u7+Ut/ba8iaHfv5Ytm2BvPs2FfCk1+t5o15fp2KzaJNu1m0aTdL8vawYENDf37LpoIiZq3c\nUSPtsyVbySssqneZb3/NZ9W2fX6VZ+nmPfywdleDeTbvLq7zPcxYto2Nu6rL8N3qfNbl7wdg7tqd\nrNy2t856Fm3azcKNhVRVGd6Zv5HSikpWbtvr2f6qbfv4euX2Bsvy5fLt/OfHDfXWv6isgmk5m2r8\n3sorq3j7p41UVFZRWWV4+ydr2/WZ/ssWz29qi4+6A+zaX8oHP+fV2M7cNTv5dXv93/uCDYU8O2sN\nxWU1t22M4dW5uXW28/HiLeTvK613fYUHynhn/kaqqgx7S8p5c95GKqsO7vZExhjeX5DHvpLyGumf\nLN7K6z/ksmNf3Vb4rFU72LDrAHtLynl/QR5fLd/OS3PW19h2Tm4Br87N5ZdNuz1py7bsYd66Xbw5\nbyOvzs2lqKyCtfn7mbN6pyfPhl0H+Hxpw/9zDSmtqOSd+db3UF5ZxZvzNlJSXv/fujE155hFJ2re\nZz/PTqsvvQ4RmYzVKiE9Pd1XlkNSZQybCqx/1tiIEIKDasbUrbtLKLD/2TYXCgZDSFAUsRHVg8pr\nduxnd2EB119yNkEibN22jZDgYGLi2wPw7fc/sG2/tXPfvreE3qmxBAVZrYLisgq27C7hQFkFf771\nOiZddzOjhw0kNDiI7XtL2FNcTujeIMorq3CFRhMs4tmR9UyNqfcfauHGQvp1imNPcTmFRWWc8fQc\nSsqr+P7OE+kUbz3SYE9xOd+v2cmIronERYby+g8bePrrNQB0jI9gQFo87aPCWLNjP7GuEErKqwgP\nDSKvsJjkmHB+8+z3Nbb5wqVD6Ncpji27i0mIDicqLJgFGwoZ3SsZV2gw4578jv2lFfzvuhGUVlTR\nMzWGa9/4GYBf/nIK2/eVkBwTTnxkGOWVVcxZvZOJr8wH4M2rhrHzQBlDMtrRIdbFzJU7KC6vJDI0\nmNG9khHgjKfnADD7thPITIxi1/5SCovKSIwO59ft+wkOgnOf+wGAxfeewpbdxaTEuPi/1xcA8M7k\n4USEBXPpSz8BsP6R07j43/MAeO+aYxARkmPC2ba3hPOft9Zz1oCOTP9lC7/k7eHNeRs9y536xLcA\n/PSnk0iOcdX5+5SUV3L1a9aFpbGuEP5z1TB6pMSwcts+BnaOZ/3OA/xr1hreXZDHvpIKzuzfgeRY\nFx/8nMedHyzhg4WbSYuP4IOFm8krLGZUT+ui3Koqw5CMdizZvIfIsBBufGshY3qncMOJ3bj5nUWs\n33mAX+45hbiIUGsHt+MAb83fyJvzNpIQHc4xXRJYsnkPF79o1Tv30dMBa0e8YEMhQzLasWVPCRe8\n8AOVVYYgEYZktMMYw/Z9pZRXVHHP9GUAzP/TGHJyCxiYHs/1by6kV2oMj18wkPSESKLDrd3Riq17\n2VdSwd9nrOKn3ALy95WSs6GQ2avyySss4vgeSWQkRLJldzFDMtpjjCFnQyGd4iPYVFBEcqyLjQVF\nBIswd+1O/jV7LR2/cHH3GX0Y3TOZ/aUVXPem9Ru796PlvDpxKLuLyziuWxJb9xYz8eX5RIYFc2b/\njryTU70r2lxYzLh+qRyd2Z7z7L+1+287P7eQC16oTgPrIGTKt+tqfGf/9/oCVm7bx7MXDyYzMZKS\n8kp6psYSHR7C8i176RjvIj4yjNXb9xHjCmXRpkKiwkM4rnsSVVWGm95axOfLtlFlYOueEp6auZri\n8komjQz8GGVAbyQoIpnAx8aYo3zM+wR4xBgzx56eCdwOnAiEG2MetNP/DBQZY/7R0Lays7NN7Su4\nV6xYQe/evf0ub3mFdYRfUVXF6h3WzrdbcjSRYSFUVFURJEKQCLk7raMObx3iIkiICvM833LZlj2e\nebGuUB57+AGS2sVx3sRrAQgPCaa0otLzMPSUuAiSosOpMvg8aq1Pl6RoT6Bw275xHQP69WF/SQVd\nkqIBmLN6J5e8NI+7T+/Ng5+sqJH/L2f04Ur7x3b7e78wLSeP43sk8eJl2Yx94lvW7ax+EF1EaDBf\n3HI8Zz0zh27J0czPLfS7rAAjuiXw/Zpd/O6Erpw9qBMn//PbGvOHZLRjwQZrnVeOyGLq9+vpnxbH\nqxOH8vTXa5j6/fo66zyueyITR2Ry5SvVf/83rx5GaUUVE1+e70n76tZR3PH+YhZsKCQsJIiyipot\nuqlXZHPlKzmktYsgr9D3Q+K++cMJjPrb7IOqM8Drk4Z6As5tp/TgwqPTCRKIjwxjX0k5Ma5Q5ucW\ncNGUms9LmjA0nbd+2sjTEwZxw1sL66x34Z9P5u35m3js85U10hOiwtjl1TLuFB/B5t3FjOmdzFcr\ndhAZFkyRVwvgr+f15zcDO3HLO4v4ZMlWz/Kn9+tAXGSoJ+gBfHf7aOIjQ3n5+1we//JX/nJGHx78\nZDn+HPR3TYpibf4BeqbEsMqrlTKyWyL3nNmH2IhQhj0803lFthcvy6assorf2QcYTn53Qlf6p8Vz\nzX8W1Jl37uA03v85zzM9umcSs1bl18n35EUDuentRZ7p35/cg398+WudfOcPSePdBdb6/nvdCNLb\nR3L8X2exv7RmD0DvDrH8/fz+nP7UHAakxfHapGEMuO+LGnneuGoY3/ya7wk+rtAgSsqt32/n9hHM\nvm00wUGH1gUtIguMMdmO+ZoxWLwAzDbGvGVPrwJOcL+MMf/nK199DjVYGGMwWEdfK7btq9OdlN4+\nkhhXKMu27CEhKoxO7SLZWFBUo2vILSQoCBEIEqnTDfDc448SGRnF5dfcwMb167j5qt8yaOhwlixc\nwNMvv83Up//G4kWLKCkt4dQzz+aam28H4PJzxnLXA3+jW8/enDCgK+ddMpHvZ32FKyKSJ156gwHd\n0+vs2LZvXMfV07cC8O/Lsjm5TwqPfLqCF75dV+cfAuDq47L40+l9yN9XyohHv6bM7hZz71BO7ZvC\njGUNd58EQnJMODu8uil87eC7JEWxY28plwzP4MXv1vHcJUO4+rWcGv+o/jqxVzJf1+oSq+2pCYO4\n0cdO28lJvZKZ6WPdt57cg8e//JWLh6XX2CG7RYeH1Nm5HI7UWBfb9h7+CRDeO6uGJEaHs3N//V1N\ntbWPCqPAK8jdeFJ3Zq3cwZLNe7h0eAa5uw7wnVe3zh9P60VhUTnPzV7ruO7uydGeg0B/yuk+sImP\nDGXmraMY8uBXftcD4JQ+KXyxvPr/JiI0mOLySsb0TuGrFY37//TCpUM4ta+vx7M78zdYNGc31HTg\nehF5G2swe48xZquIzAAe9hrUPgW463A3dt9Hy1i+pe4RuwGK/PxnFIHIsBBKKyqpqDRkJUVx9XFd\nPPMrqvx/Xsy61au4/x/P8udH/okg3HjnPUTFxlNRUcFVF5zJyaedRZ8+fWsss2/vXrKHj+Dmu+7l\nb/f9if++8x8SrrsFgA5xLsorTZ0f/L+/W8fctTt5+ftcgDqBIjwkiPU7i+h3zwz22d/D9OtHcNYz\n31NUVkmXxCj+eu4AZiyreaQDEBUWzIGy+vtLrz2hK9+tzmfp5prfe31HyUkx4Z4+7Kiw4BqBAqgT\nKC4elk52RjtunfYLb87bQK8OMQxKjwdoMFAkx4Rzat9UXv+x5jhM7UDhqxX247qGxz9+OyydN3zs\n9H0FCoDnv7F2cr4CBXBQgeLHu05i+CPVR+WhwUJ5Zc2Dn/oCRcc4F1v2NBxEvI+0fQWKcUel0rl9\npOfoF2BwejyTRmaREB3GlG/XMS0nr06rwltBrXHC/p3iyMm1xr66p0QTFxFaI1g8/GnNFlV93z/A\nfeP7eroQvb17zTG89N16Pq81pvL9ml0M6BzPK1ccTbuoML79w2jGPP4NZZVV9EiJZnTPZF74dh2n\n9UvlqxU7PL/P84eksXTL3hqBAqDYHluYNDKL+bkF7Cmu2TvhS+0DJl86xUcwdc76Qw4W/gpYsBCR\nt7BaCYkikod1hlMogDHmeeBTrOcOrwGKgIn2vAIReQDrOcUA9xtjnEdKD7Wc1DxiDQ0J8nRHhYUE\nWUfZxp3Xaua5Gx/R4c4Xvvk6MgwLCaJzRhZHDbTOFo6PDOWtV97lw3f+Q2VFBfnbt7FnSy5dRg0l\nPLh6vMTlimDk6JMRhBHDj2bm7G888xKiwwHYV2JtK8YVwjWjuvK3Gav4aX0BPVKi+XV73aOqgZ3j\naxzl/OHUnvRPiycjIZINu4q4ZHgGcZGhnh35PWf2IUiEY7om8Oa8jbwyN7feup/erwNn9O/A3DW7\niAwPpqS8iq5JUYzqkURFVRUbdxXzz6+qm+8fXT/Ss7MblN6OOWt21rdqAE7okcTQrPa4QoPYW1JB\nz5RY4iPq/5sMSo9n4cbdnDmgI78dll4jWLgDpNtx3RM5a0DHOsHCvVO/7JgMXvvBWv79a49lbf5+\nBDhncBqXDM9gcd5uVmzdxytzczk6s12d7rpJI7N4Z/4mv4LBuKNS+cyPQdHUOBef3ngcD3y8nB/W\n7eLozPbMbWBw390l1a9THMFBwpY9JVx9XBZXjMhi9fZ93P7eYnbsK+W3w9KZNDKL1DgXny/dxq3T\nfqmxHvdv6+Q+KZ4dovsoPj4ylGFdEgD47bAMpuXkkRwb7gkWYcFBnpZs7w6xrNi6l6SYcLokRjFv\nfQGd2lU/Hjwl1sUF2Z3pmhzFLe/ULMOIbgmM7pnMJcMzPMHiiQsH0iMlhqVb9tC5XSTDu7Tnr+f1\nZ19JBZFhwQQHCUnR4Ryd2Z7MhChPsHB3/QE8fsEA2kWFAZCeEMnQrPbMWbOT0/p14PrR3eieEsNZ\nAzry8KcreGVuLtkZ7Xjw7KP48OfN3PnBEk/5vPcD/dPi+Pzm4zjmka8b/HtOGJrO1cdlsWNfKRNf\nnu/5bqHmgcwd43oBVi9JIM+GDFiwMMZMcJhvgOvqmTcVmNqY5bnnzL4Nzi8qraCovJKEqDCWbLbG\nG/p2jKO8soo9xdbZS/n7SolxhXKgtIJoVwgZCVHsLiojr7CYKq/uK3d/b5AIGQmRNfqGk2NchLaP\nJCYmmoyEKCqrqtiUu443pr7AGx/NpF+XDky64nJCqCA0OIgQr2ARGhZKYnQ4cRGhLI0Mp9Lu6spM\niCLI/pHER4ayEbj8mEwuPSaDv81YBcD5Qzrz0Kc1d3yAZ2AbrO6o60Z3A/CcYZGVGAXAB9cey7sL\n8rj8mEzPQPx1o7vx6g+5nuD55EUDWbCh0LMTTY1zkRgdTt+OcXW2e/agNHJyC/in3bIPCw4iNa56\n0PfKkZmkxrnomRLjKfeVI7LomRpNXEQYy7bs4cReyYQEBzE0K4Fvf82nS1IUIcFBxLhC2FdSQfuo\nMI7pmsAni7cypncyA9KsYFFZZchKjOK2U3qweXcJ14zqQkZCFJ/ffBxjn/gOgKuO6+IJwACTj+9S\n44j59yf39NRzSEY7hmRUn93du0MsvTvEUl5ZRXR4CFcdl8XyLXvJKyzm9vcXA3DXuF6cOaBjnRMC\nZt12AlO+XUfHOBdfrdjOL3l7yEqM8tlKcNdzSEY7rh3VFYA+HWM5sVcyP6zb5RkwBrjhxG6eExXc\nbjm5B0My2nNq3xQqqgxfLt/O707oiojQKT6CDnEuduwr5dwhaZ6xr3MGp/Hc7LU1unPeu/ZY/jVr\nLaf2TSU4SNhcWMykkVm8/H2uZywMoF+nOG49uQfnDO7E7qJyFmwoZFiX9rw8J5f0hEiSosO5/f3F\nlJZX8viFA3l/gdUKcf+2XaHBuEKDOXtQGmHBwcxcuZ3SiipiXaHcOa4XcfaBwuuThlJwoIzxAzt5\nvhO3C7I740tSTDizbzuBT5Zs5XcndKVnSjR9OsbR1a63W0RYMGB154UEB3HekDTAOsiKCAvmmlFd\nCQ8J5uzBncjdVcRlx2TwzvxNXHh0Z179IZfEqHCiwkOICg/hi1uO5+Xv15OZEEVocBADOsdz7nNz\nPds6a0BHuiRF0yUpmmO7JjBz5Q7OHNCR84ek2YP8UQgwpk+Kzzo1tiP6Cu6DERkeQqT9z5WVGMWe\nonKCg4TgIOsHWlRWwf7SSsorqwgLCfL8MOMjw9hTXM6e4nJcocEkRIURGxFKeaUhrV0EwUFBxLiC\niHWFEuEKITXOxf78IEKCxLOO9SVFREVHEx0Tw/6CnXzz9Vf85szTPWWLjwwlNc6FIHSIcyEiNY4g\nvM/CSogKIyI0iIkjMol1hfKXM/rwyZKtnNI3xbPTPaZLAvGRoVw3upun6yUuIpQ/nd7Hsx53N0Om\nHSw6t4/k1pN71PjOkmLC+eu5/fnDe4tJjgln/MBOjB/YybMTTbCPyOozoHM8w7LaM299AeGhNc84\nG5LRnhN7pWCMYVNhESO6JdZoZo89qvqzezuxLuvv1y4yjH0lFZw9qBOD09vxyeKtBIkwcWQWy7fu\n5eJh6YgI15/YvcY2e6XGEusKYW9JBVkJUQQHCZOP78KwrPac1DsFEfjg58386bTeRLuc/3VCg4O4\n7dSeABzbLRGAuMhQFm7cTUhwEAM7xzP1imxmLN1OSUUl5w1JIysxikfO6QdUd111iHMx/fqR3PLO\nIjrGR1BlDLNX5XtavGf071Bjh+E+Eg4NCeLJiwaSu7OIm8Z0p0+HWOatL/C0BpOiw7n2hK6e5Xqk\nxNQo/2Pn9edfs9ZyVK1gP+WybB76ZAV9OsSQGhfh2Vm73T7W+uyuu1tQkHDjSdZ3ntYOjuoU59kO\nwE/rrQ6EfaUVdIqP8OR94DdH8fcZqxiW1d6zrtP7d+D0/h18fu/HdXd8NINPmYlRnoOlK0b4PrvI\nFWoFi9qDyVHhIdwxtvo7CA8J9nwnt9j/N3eNqzl+2iMlhkfO6V8jzX1SB1hnYrrde1ZfgoOER87p\n5zkIOLmJgoSbBgsfYlyhxLhqdmdEhoXQLTnaZ/6kmHD22TuY0BBrp+feybpFhAUT7fLdRTJ48GD6\n9unDeWOOpVePbowYMaLG/OQYF8kxLkRqXnQXGiwkeh39AoQEB5EQHe45Kr5yZFaNozuAB88+ynPE\n5O4jrv3jv398Xx74eAVpXt0AvvTtGEeMK4SzB9c9u9mpSRwaHMTrk4Yx9OGvuNdu+T16Tj/+8eWv\nxNj/ECLC/ePrnB9Rw9XHdWHWqh2M7pUMWOMwYA1aHp3VjuAg4erjuxAdHsJzlwxpcF33je/LQ5+s\npGO81cr542nV/+B3jetd5x/+YJ3aN7VG0DuxVwon9vL9T19ud8+kxLro3SGWz28+HoCfNxby/Zqd\nPHXxIK5+NYcxvWsu7z5JIzRIPEfXAOP6dWBcvw6eYNHeIZj3So3lqQmD6qRnJUbx4uWO46EHLTMx\nEqju5vXe3rO/HexjiaZ39XFZfLl8GyO7JwZk/X85sw/Hdk3g5ncWkZFQvQ/p3D6SKZc1/nd+UNyn\nbrb215AhQ0xty5cvr5PWFtRX74w7PjYZd3xstu8p9qTtLiozGXd8bJ6bvabRtj/qr1+boQ992Wjr\nO1jjnvjWZNzxsXlz3oaAbsf9fQbKKY9/YzLu+Ngs2lh4UMut3LrXZNzxsZmxdKvP+Te+9XNAy32o\nqqqqTMYdH5s731/c3EVpU4Ac48c+VlsWbZB3F0pcRCgrHxjrORpvDF/dOqrR1nUorjg2k9vft7rG\nAi3kEM9t98ex3RJYtX1fjbEcf/RMjWHlA2M9XSa1/fOCgfz9/AGNUcRGJSKsenAsoUGBvAuROlQa\nLNqgiFo7kfp2KofKe1C+OVxwdGf6pcXRKzXGOfNh+OmPJxEawLr+8bTeXDI8g5TYgwsW0PDfNChI\nCKJl3kMsPKRxf4uq8WiwaIPaws0Ge3eIdc50mJIPYSd+MEKDg+qcjaNUc9H2nlJKKUfasmhDnvvt\nYDYU1H83V6WUqo8GizZkXD/f56UrpZQT7YYKoF27djFw4EAGDhxIamoqnTp18kyXlfl+VoYvU6dO\nZdu2Q78HvlJKHS5tWQRQQkICixZZtzK+9957iY6O5rbbbjvo9UydOpXBgweTmhrYG4UppVR9NFg0\nk1dffZVnn32WsrIyjj32WJ555hmqqqqYOHEiixYtwhjD5MmTSUlJYdGiRVx44YVERETw008/ERbW\n8JW3SinV2NpOsPjsTti2xDnfwUjtB+MePejFli5dyocffsjcuXMJCQlh8uTJvP3223Tt2pWdO3ey\nZIlVzt27dxMfH8/TTz/NM888w8CBAxu3/Eop5ae2EyxakK+++or58+eTnW3d66W4uJjOnTtz6qmn\nsmrVKm666SZOO+00TjnllGYuqVJKWdpOsDiEFkCgGGO48soreeCBB+rMW7x4MZ999hlPPfUU77//\nPlOmTGmGEiqlVE16NlQzGDNmDNOmTWPnTuvhPrt27WLjxo3k5+djjOH888/nvvvu4+efrecKx8TE\nsG+f7yeLKaVUU2g7LYsWpF+/ftxzzz2MGTOGqqoqQkNDef755wkODmbSpEmeJ1499thjAEycOJGr\nrrpKB7iVUs1GTO2bx7dS2dnZJicnp0baihUr6N378J4/0Bq11XorpQ6eiCwwxjg+LEO7oZRSSjnS\nYKGUUsrRER8sjpRuNn+1tfoqpZrGER0sXC4Xu3btajM7UGMMu3btwuUK7HMWlFJtzxF9NlRaWhp5\neXnk5+c3d1GajMvlIi0trbmLoZQ6whzRwSI0NJSsrKzmLoZSSrV6R3Q3lFJKqcahwUIppZQjDRZK\nKaUcabBQSinlSIOFUkopRxoslFJKOQposBCRsSKySkTWiMidPuZniMhMEVksIrNFJM1rXqWILLJf\n0wNZTqWUUg0L2HUWIhIMPAucDOQB80VkujFmuVe2vwOvGWNeFZETgUeAS+15xcYYfY6oUkq1AIFs\nWQwF1hhj1hljyoC3gfG18vSDRo43AAAZU0lEQVQBZtqfZ/mYr5RSqgUIZLDoBGzyms6z07z9Apxr\nfz4biBGRBHvaJSI5IvKjiPzG1wZEZLKdJ6ct3dJDKaWaWiCDhfhIq31Hv9uAUSKyEBgFbAYq7Hnp\n9gM5LgaeEJGudVZmzBRjTLYxJjspKakRi66UUspbIO8NlQd09ppOA7Z4ZzDGbAHOARCRaOBcY8we\nr3kYY9aJyGxgELA2gOVVSilVj0C2LOYD3UUkS0TCgIuAGmc1iUiiiLjLcBcw1U5vJyLh7jzACMB7\nYFwppVQTCliwMMZUANcDM4AVwDRjzDIRuV9EzrKznQCsEpFfgRTgITu9N5AjIr9gDXw/WussKqWU\nUk1IjpQHA2VnZ5ucnJzmLoZSSrUqIrLAHh9ukF7BrZRSypEGC6WUUo40WCillHKkwUIppZQjDRZK\nKaUcabBQSinlSIOFUkopRxoslFJKOdJgoZRSypEGC6WUUo40WCillHKkwUIppZQjDRZKKaUcabBQ\nSinlSIOFUkopRxoslFJKOdJgoZRSypEGC6WUUo40WCillHKkwUIppZQjDRZKKaUcabBQSinlSIOF\nUkopRxoslFJKOdJgoZRSypEGC6WUUo40WCillHKkwUIppZQjDRZKKaUcBTRYiMhYEVklImtE5E4f\n8zNEZKaILBaR2SKS5jXvchFZbb8uD2Q5lVJKNSxgwUJEgoFngXFAH2CCiPSple3vwGvGmP7A/cAj\n9rLtgXuAYcBQ4B4RaReosiqllGpYIFsWQ4E1xph1xpgy4G1gfK08fYCZ9udZXvNPBb40xhQYYwqB\nL4GxASyrUkqpBgQyWHQCNnlN59lp3n4BzrU/nw3EiEiCn8siIpNFJEdEcvLz8xut4EoppWoKZLAQ\nH2mm1vRtwCgRWQiMAjYDFX4uizFmijEm2xiTnZSUdLjlVUopVQ/HYCEi1x/ieEEe0NlrOg3Y4p3B\nGLPFGHOOMWYQ8Cc7bY8/yyqllGo6/rQsUoH5IjLNPrvJ11G/L/OB7iKSJSJhwEXAdO8MIpIoIu4y\n3AVMtT/PAE4RkXZ2oDrFTlNKKdUMHIOFMeZuoDvwEnAFsFpEHhaRrg7LVQDXY+3kVwDTjDHLROR+\nETnLznYCsEpEfgVSgIfsZQuAB7ACznzgfjtNKaVUMxBj6gwF+M4oMgCYiHVW0ixgONYZS7cHrnj+\ny87ONjk5Oc1dDKWUalVEZIExJtspX4gfK7oRuBzYCbwI/MEYU253H60GWkSwUEopFTiOwQJIBM4x\nxmzwTjTGVInIGYEpllJKqZbEnwHuTwHPeIGIxIjIMABjzIpAFUwppVTL4U+weA7Y7zV9wE5TSinV\nRvgTLMR4jYIbY6rwr/tKKaXUEcKfYLFORG4UkVD7dROwLtAFU0op1XL4EyyuAY7FuhVHHtadYCcH\nslBKKaVaFsfuJGPMDqyrr5VSSrVR/lxn4QImAX0BlzvdGHNlAMullFKqBfGnG+p1rPtDnQp8g3VT\nv32BLJRSSqmWxZ9g0c0Y82fggDHmVeB0oF9gi6WUUqol8SdYlNvvu0XkKCAOyAxYiZRSSrU4/lwv\nMcW+TfjdWLcYjwb+HNBSKaWUalEaDBb2zQL32s/B/hbo0iSlUkop1aI02A1lX619fROVRSmlVAvl\nz5jFlyJym4h0FpH27lfAS6aUUqrF8GfMwn09xXVeaQbtklJKqTbDnyu4s5qiIEoppVouf67gvsxX\nujHmtcYvjlJKqZbIn26oo70+u4CTgJ8BDRZKKdVG+NMNdYP3tIjEYd0CRCmlVBvhz9lQtRUB3Ru7\nIEoppVouf8YsPsI6+wms4NIHmBbIQimllGpZ/Bmz+LvX5wpggzEmL0DlUUop1QL5Eyw2AluNMSUA\nIhIhIpnGmNyAlkwppVSL4c+YxbtAldd0pZ2mlFKqjfAnWIQYY8rcE/bnsMAVSSmlVEvjT7DIF5Gz\n3BMiMh7YGbgiKaWUamn8GbO4BnhDRJ6xp/MAn1d1K6WUOjL5c1HeWmC4iEQDYozR528rpVQb49gN\nJSIPi0i8MWa/MWafiLQTkQf9WbmIjBWRVSKyRkTu9DE/XURmichCEVksIqfZ6ZkiUiwii+zX8wdf\nNaWUUo3FnzGLccaY3e4J+6l5pzktJCLBwLPAOKwL+SaISJ9a2e4GphljBgEXAf/ymrfWGDPQfl3j\nRzmVUkoFiD/BIlhEwt0TIhIBhDeQ320osMYYs84+g+ptYHytPAaItT/HAVv8WK9SSqkm5s8A93+A\nmSLysj09EXjVj+U6AZu8pvOAYbXy3At8ISI3AFHAGK95WSKyENgL3G2M+a72BkRkMjAZID093Y8i\nKaWUOhSOLQtjzF+BB4HeWN1JnwMZfqxbfK2u1vQE4BVjTBpW19brIhIEbAXS7e6pW4E3RSS21rIY\nY6YYY7KNMdlJSUl+FEkppdSh8Peus9uwruI+F+t5Fiv8WCYP6Ow1nUbdbqZJ2DclNMb8gPW8jERj\nTKkxZpedvgBYC/Tws6xKKaUaWb3BQkR6iMhfRGQF8AxWl5IYY0YbY56pbzkv84HuIpIlImFYA9jT\na+XZiBV8EJHeWMEiX0SS7AFyRKQL1i3R1x1k3ZRSSjWShsYsVgLfAWcaY9YAiMgt/q7YGFMhItcD\nM4BgYKoxZpmI3A/kGGOmA78H/m2v1wBXGGOMiBwP3C8iFVj3orrGGFNwKBVUSil1+MSY2sMI9gyR\ns7FaA8dijVO8DbxojMlquuL5Lzs72+Tk5DR3MZRSqlURkQXGmGynfPV2QxljPjTGXAj0AmYDtwAp\nIvKciJzSaCVVSinV4vlzNtQBY8wbxpgzsAapFwF1rsZWSil15DqoZ3AbYwqMMS8YY04MVIGUUkq1\nPAcVLJRSSrVNGiyUUko50mChlFLKkQYLpZRSjjRYKKWUcqTBQimllCMNFkoppRxpsFBKKeVIg4VS\nSilHGiyUUko50mChlFLKkQYLpZRSjjRYKKWUcqTBQimllCMNFkoppRxpsFBKKeVIg4VSSilHGiyU\nUko50mChlFLKkQYLpZRSjjRYKKWUcqTBQimllCMNFkoppRxpsFBKKeVIg4VSSilHGiyUUko5Cmiw\nEJGxIrJKRNaIyJ0+5qeLyCwRWSgii0XkNK95d9nLrRKRUwNZTqWUUg0LCdSKRSQYeBY4GcgD5ovI\ndGPMcq9sdwPTjDHPiUgf4FMg0/58EdAX6Ah8JSI9jDGVgSqvUkqp+gWyZTEUWGOMWWeMKQPeBsbX\nymOAWPtzHLDF/jweeNsYU2qMWQ+ssdenlFKqGQQyWHQCNnlN59lp3u4FLhGRPKxWxQ0HsSwiMllE\nckQkJz8/v7HKrZRSqpZABgvxkWZqTU8AXjHGpAGnAa+LSJCfy2KMmWKMyTbGZCclJR12gZVSSvkW\nsDELrNZAZ6/pNKq7mdwmAWMBjDE/iIgLSPRzWaWUUk0kkC2L+UB3EckSkTCsAevptfJsBE4CEJHe\ngAvIt/NdJCLhIpIFdAd+CmBZlVJKNSBgLQtjTIWIXA/MAIKBqcaYZSJyP5BjjJkO/B74t4jcgtXN\ndIUxxgDLRGQasByoAK7TM6GUUqr5iLVvbv2ys7NNTk5OcxdDKaVaFRFZYIzJdsqnV3ArpZRypMFC\nKaWUIw0WSimlHGmwUEop5UiDhVJKKUcaLJRSSjnSYKGUUsqRBgullFKONFgopZRypMFCKaWUIw0W\nSimlHGmwUEop5UiDhVJKKUcaLJRSSjnSYKGUUsqRBgullFKONFgopZRypMFCKaWUIw0WSimlHGmw\nUEop5UiDhVJKKUcaLJRSSjkKae4CtCh5OVBUACW7ofspEBHf3CVSSqkWQYOFW+k+ePGk6ulRd8Do\nPzZfeZRSqgXRbii34t01p7ctbZ5yKKVUC6QtC7fSvdWfOw+HvPmw/H/QZ3zDy+XOsbqvALqNgdSj\nYPMCWP+dlZY5EtKyA1Pm1mTHSvj185ppQSEw8GKIbN88ZVKNzxhY+j70PgtCwpq7NKoRabBwK/EK\nFgMuhI9vgWmXwZ+2Q6ir/uU+mAx7N1uf186Eyz+Cj26GbYuttI6DYfKswJW7tfjqnrrBAqCqHEbe\n0vTlUYGx8mN4fxKMvhtG/aG5S6MakQYLN3fL4qqvIW0IVJbDZ7dD0U6IS/O9THGhFShOvBsK1ls7\nw8oKyF8Fw38HRbsg9/umq0NLtn0Z9D0bxv+rOu2Zo610deTYvdF6L1jbvOVQjU6DhZu7ZeGKtd7j\nOlvv+3fUDBaL34UtC63PB/Kt9w4DISwaFr0B02+AylJI7Q/5K+DADqtpLtI09WhqJXvg+yehvKT+\nPKYK9myC7IkQFlmdntLH6q77vJ4TCeLTYfg1ddOX/w82zju8crckST1hyOX+5V0+HTb+CK44OO73\nEOz1L7zuG/h1RvV0SDiMuBEK1lnLhbigosQ6EAqUDXOs91/egrGPtq4zCndvgp+mQFVl466302Do\nd171dP6v8POr1n6hscR3huHXNt76fNBg4Va6x3oPt4NFdLL1fmBnzXyf3gZlB6x/PIC4dOg0BGI7\nQlQSrPgIolMh41irVVJZZrVaXHFNU4+mtuJj+O4fVrCkgYAYmQBdTqiZ1nOcteP7+bW6+avKrR1b\nn7Os79bNGKuLsGRv9d+gNasss179zoOwKOf8H98CxQVWAM4cCZkjqud9+RfYvhRCIgADZfuhXaY1\nhrD+m+p8IRHWeFGgrfgIBl8a+O00lgWvwNynICym8dZZWQo/h8NR51YfMP7wjPWbD4tuvO10HNi6\ng4WIjAWeBIKBF40xj9aa/09gtD0ZCSQbY+LteZXAEnveRmPMWYEsa52WRVSi9X5gR3WeilLrGgxf\n/bGR7eEPa2qmRSVZ7/vzj9xgsWO5tdO+cyMEBR/cstlXWi9fcufAK6fD9uU1g8X+7Vb33tjHfLc6\nWpvl02HapZC/0jroaMj+HdYByLE3wNynre/eHSyqKq11DLsGTn0IqqrgkTQrT8G6muuZ9AV06B+Y\n+oC17Yc7WttuTXYsh6RecF0jtlpzploBfvdGaJdRvZ3MkXDFx423nSYQsGAhIsHAs8DJQB4wX0Sm\nG2M8vyBjzC1e+W8ABnmtotgYMzBQ5ath4zyYeZ/12X206t7Rz3sB1roHqO1mozuQOHGv47M/QEQ9\nZ/x0Ggyl+61umpG3QELXgy7+IdvwA+S85Ls53L6LdZ3JT/+GTT9Sb6th449WN8rBBgonyX2s91kP\nWV0abkW7rPeUPo27veaS0td6//yP9Y+NuRUXWO9dT7KOTH+aYn3/YLXCKkqqv7egIEjuZQWjfVtq\nriexR+OV3xfPtv9nBbh68wVbv/nk3oe3vWUfWi3cw7Xhe+u7bUzJ9t93+g3V+4NtS2Cwn92OLUgg\nWxZDgTXGmHUAIvI2MB6o73BjAnBPAMtTv3nPQ3CYdZqsu6kYFgW9zoAdK6wxirIDsH+bNc/dReUk\ntb81nlG4wXrVVlwIS9+rnt66CK6Zc3h1ORjznoNVn9fdSZXus8o18GIr0IHVjeTy0f8cEg4DJjR+\n2SLbWwPiWxdXjxG5pQ2FjoN8L9fatMuydlCFudVjYA1JO9pqgQy6FFZ9VvO7Se0HWcdXT/e/yPpt\nJ/eBrifCojfhqHMaPruvsQyYYB1o1f7beStcb+1AT33o8Lb1zV+t8QZ//y/rE5UMfX9zeOuoLbUf\npB8De/KsF0B8BvQ6vXG30wTENOYgi/eKRc4DxhpjrrKnLwWGGWOu95E3A/gRSDPGVNppFcAioAJ4\n1BjzXx/LTQYmA6Snpw/ZsMHHDtkfzw6zjqQnvFV/ni0LYcoJ1udJX0LnoYe2LW+L3oL/enWlRCXV\n7coKpKezrVbBRW/UTF/3Dbx2Fpx0T3WL67ypVr+rUo3l+eOsVvqlHx76OirK4OEOVtfcmHsbq2Rt\niogsMMY4XgwWyJaFr36L+iLTRcB77kBhSzfGbBGRLsDXIrLEGFPjfDxjzBRgCkB2dvahRb2KUti5\n2mpFNCSpV/Vnf7uhnNTuSjmQD684lMMXVxyc/TyENzAwt+Q9awDPW8Fa6+i9TrnspvPcp6vTkg6z\nq0Cp2lL6Wl1Vh/Kbd6sohaqK6u4eFTCBDBZ5QGev6TRgSz15LwKu804wxmyx39eJyGys8YzGP3m7\nuNA6c8lpcDE0Ao65HvZusc6AagzJfaDvObDzVwgOhdCogz9tr2w/5H4Hm+ZZV5DXZ/6L1gCo904/\nc6TvK9SjEq2B5x0rrVNj04ZYLRClGtOACVb30eGcqhoUYv3uu5zQWKVS9QhkN1QI8CtwErAZmA9c\nbIxZVitfT2AGkGXswohIO6DIGFMqIonAD8B478Hx2rKzs01OTk5A6tKiFRXAX7Pg5Aesc+p9MQYe\nzbBOzzzj8aYtn1KqRWv2bihjTIWIXI8VCIKBqcaYZSJyP5BjjJluZ50AvG1qRq3ewAsiUoV1s8NH\nGwoUbVpke+u6jjmPWxcF+mKqrOtIjpQziJRSTS5gLYum1mZbFgALXrXuS9WQEBeMuQ9iOzRNmZRS\nrUKztyxUExpyuf+3i1BKqUOgz7NQSinlSIOFUkopRxoslFJKOdJgoZRSypEGC6WUUo40WCillHKk\nwUIppZQjDRZKKaUcHTFXcItIPnCI9ygHIBHY6Zir5TtS6gFal5ZK69IyHWpdMowxSU6ZjphgcbhE\nJMefS95buiOlHqB1aam0Li1ToOui3VBKKaUcabBQSinlSINFtSnNXYBGcqTUA7QuLZXWpWUKaF10\nzEIppZQjbVkopZRypMFCKaWUozYfLERkrIisEpE1InJnc5fHiYhMFZEdIrLUK629iHwpIqvt93Z2\nuojIU3bdFovI4OYreV0i0llEZonIChFZJiI32emtqj4i4hKRn0TkF7se99npWSIyz67HOyISZqeH\n29Nr7PmZzVl+X0QkWEQWisjH9nSrrIuI5IrIEhFZJCI5dlqr+n25iUi8iLwnIivt/5ljmrIubTpY\niEgw8CwwDugDTBCRlv6g6leAsbXS7gRmGmO6AzPtabDq1d1+TQaea6Iy+qsC+L0xpjcwHLjO/v5b\nW31KgRONMQOAgcBYERkOPAb8065HITDJzj8JKDTGdAP+aedraW4CVnhNt+a6jDbGDPS6BqG1/b7c\nngQ+N8b0AgZg/X2ari7GmDb7Ao4BZnhN3wXc1dzl8qPcmcBSr+lVQAf7cwdglf35BWCCr3wt8QX8\nDzi5NdcHiAR+BoZhXU0bUvu3BswAjrE/h9j5pLnL7lWHNHvHcyLwMSCtuC65QGKttFb3+wJigfW1\nv9umrEubblkAnYBNXtN5dlprk2KM2Qpgvyfb6a2mfnb3xSBgHq2wPna3zSJgB/AlsBbYbYypsLN4\nl9VTD3v+HiChaUvcoCeA24EqezqB1lsXA3whIgtEZLKd1up+X0AXIB942e4efFFEomjCurT1YCE+\n0o6kc4lbRf1EJBp4H7jZGLO3oaw+0lpEfYwxlcaYgVhH5UOB3r6y2e8tth4icgawwxizwDvZR9YW\nXxfbCGPMYKxumetE5PgG8rbkuoQAg4HnjDGDgANUdzn50uh1aevBIg/o7DWdBmxpprIcju0i0gHA\nft9hp7f4+olIKFageMMY84Gd3GrrY4zZDczGGoOJF5EQe5Z3WT31sOfHAQVNW9J6jQDOEpFc4G2s\nrqgnaJ11wRizxX7fAXyIFchb4+8rD8gzxsyzp9/DCh5NVpe2HizmA93tMz3CgIuA6c1cpkMxHbjc\n/nw5Vt+/O/0y+8yI4cAed5O1JRARAV4CVhhjHvea1arqIyJJIhJvf44AxmANPs4CzrOz1a6Hu37n\nAV8bu2O5uRlj7jLGpBljMrH+H742xvyWVlgXEYkSkRj3Z+AUYCmt7PcFYIzZBmwSkZ520knAcpqy\nLs09cNPcL+A04FesPuY/NXd5/CjvW8BWoBzr6GESVh/xTGC1/d7ezitYZ3utBZYA2c1d/lp1GYnV\nNF4MLLJfp7W2+gD9gYV2PZYCf7HTuwA/AWuAd4FwO91lT6+x53dp7jrUU68TgI9ba13sMv9iv5a5\n/79b2+/Lqz4DgRz7d/ZfoF1T1kVv96GUUspRW++GUkop5QcNFkoppRxpsFBKKeVIg4VSSilHGiyU\nUko50mCh1EEQkUr7DqbuV6PdqVhEMsXrbsJKtSQhzlmUUl6KjXVbD6XaFG1ZKNUI7OcmPCbWcy1+\nEpFudnqGiMy0nykwU0TS7fQUEflQrGdg/CIix9qrChaRf4v1XIwv7CvClWp2GiyUOjgRtbqhLvSa\nt9cYMxR4But+StifXzPG9AfeAJ6y058CvjHWMzAGY11hDNbzB541xvQFdgPnBrg+SvlFr+BW6iCI\nyH5jTLSP9FysByCts2+OuM0YkyAiO7GeI1Bup281xiSKSD6QZowp9VpHJvClsR5kg4jcAYQaYx4M\nfM2Uapi2LJRqPKaez/Xl8aXU63MlOq6oWggNFko1ngu93n+wP8/FunsrwG+BOfbnmcC14HlwUmxT\nFVKpQ6FHLUodnAj7iXhunxtj3KfPhovIPKyDsAl22o3AVBH5A9aTziba6TcBU0RkElYL4lqsuwkr\n1SLpmIVSjcAes8g2xuxs7rIoFQjaDaWUUsqRtiyUUko50paFUkopRxoslFJKOdJgoZRSypEGC6WU\nUo40WCillHL0/+6rCw3hAgcKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7716666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.76 + 0.80 + 0.755)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
