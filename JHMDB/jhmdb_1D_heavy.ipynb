{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 13 # the number of joints\n",
    "        self.joint_d = 2 # the dimension of joints\n",
    "        self.clc_num = 21 # the number of class\n",
    "        self.feat_d = 78\n",
    "        self.filters = 64\n",
    "        self.data_dir = os.path.join(os.path.abspath(''), '..', 'data', 'openpose_zeros')\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(T,C,le):\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(T['pose']))): \n",
    "        p = np.copy(T['pose'][i])\n",
    "        p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "\n",
    "        label = np.zeros(C.clc_num)\n",
    "        label[le.transform(T['label'])[i]-1] = 1   \n",
    "\n",
    "        M = get_CG(p,C)\n",
    "\n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "    return X_0,X_1,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H.value,W.value],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "    \n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "        \n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)\n",
    "\n",
    "\n",
    "def build_DD_Net(C):\n",
    "    M = Input(name='M', shape=(C.frame_l,C.feat_d))  \n",
    "    P = Input(name='P', shape=(C.frame_l,C.joint_n,C.joint_d)) \n",
    "    \n",
    "    FM = build_FM(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(C.clc_num, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  (None, 32, 78)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  (None, 32, 13, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 4, 512)       1710336     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 512)          0           model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65536       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 128)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16384       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 128)          0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 21)           2709        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,795,989\n",
      "Trainable params: 1,790,357\n",
      "Non-trainable params: 5,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C)\n",
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [00:01<00:00, 394.97it/s]\n",
      "100%|██████████| 195/195 [00:00<00:00, 417.17it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(os.path.join(C.data_dir, \"GT_train_1.pkl\"), \"rb\"))\n",
    "Test = pickle.load(open(os.path.join(C.data_dir, \"GT_test_1.pkl\"), \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 497 samples, validate on 195 samples\n",
      "Epoch 1/600\n",
      "497/497 [==============================] - 3s 6ms/step - loss: 3.7923 - accuracy: 0.0543 - val_loss: 3.2405 - val_accuracy: 0.0615\n",
      "Epoch 2/600\n",
      "497/497 [==============================] - 0s 394us/step - loss: 3.6402 - accuracy: 0.0563 - val_loss: 3.2293 - val_accuracy: 0.0359\n",
      "Epoch 3/600\n",
      "497/497 [==============================] - 0s 397us/step - loss: 3.4309 - accuracy: 0.0644 - val_loss: 3.3109 - val_accuracy: 0.0308\n",
      "Epoch 4/600\n",
      "497/497 [==============================] - 0s 360us/step - loss: 3.2568 - accuracy: 0.1066 - val_loss: 3.3837 - val_accuracy: 0.0308\n",
      "Epoch 5/600\n",
      "497/497 [==============================] - 0s 372us/step - loss: 3.1239 - accuracy: 0.1630 - val_loss: 3.4543 - val_accuracy: 0.0308\n",
      "Epoch 6/600\n",
      "497/497 [==============================] - 0s 359us/step - loss: 3.0681 - accuracy: 0.1328 - val_loss: 3.4781 - val_accuracy: 0.0359\n",
      "Epoch 7/600\n",
      "497/497 [==============================] - 0s 360us/step - loss: 2.9344 - accuracy: 0.1791 - val_loss: 3.4891 - val_accuracy: 0.0513\n",
      "Epoch 8/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 2.8907 - accuracy: 0.1771 - val_loss: 3.4831 - val_accuracy: 0.0513\n",
      "Epoch 9/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 2.8112 - accuracy: 0.1932 - val_loss: 3.4624 - val_accuracy: 0.0513\n",
      "Epoch 10/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 2.7050 - accuracy: 0.2193 - val_loss: 3.4319 - val_accuracy: 0.0513\n",
      "Epoch 11/600\n",
      "497/497 [==============================] - 0s 351us/step - loss: 2.5678 - accuracy: 0.2555 - val_loss: 3.4026 - val_accuracy: 0.0513\n",
      "Epoch 12/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 2.5892 - accuracy: 0.2636 - val_loss: 3.3587 - val_accuracy: 0.0718\n",
      "Epoch 13/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 2.5448 - accuracy: 0.2857 - val_loss: 3.3236 - val_accuracy: 0.0821\n",
      "Epoch 14/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 2.5196 - accuracy: 0.2636 - val_loss: 3.2863 - val_accuracy: 0.0769\n",
      "Epoch 15/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 2.4606 - accuracy: 0.2998 - val_loss: 3.2522 - val_accuracy: 0.0718\n",
      "Epoch 16/600\n",
      "497/497 [==============================] - 0s 368us/step - loss: 2.3296 - accuracy: 0.3239 - val_loss: 3.2087 - val_accuracy: 0.0615\n",
      "Epoch 17/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 2.3312 - accuracy: 0.3219 - val_loss: 3.1643 - val_accuracy: 0.0718\n",
      "Epoch 18/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 2.3792 - accuracy: 0.3219 - val_loss: 3.1279 - val_accuracy: 0.0718\n",
      "Epoch 19/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 2.2911 - accuracy: 0.3642 - val_loss: 3.0934 - val_accuracy: 0.0718\n",
      "Epoch 20/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 2.2002 - accuracy: 0.3581 - val_loss: 3.0663 - val_accuracy: 0.0769\n",
      "Epoch 21/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 2.2319 - accuracy: 0.3682 - val_loss: 3.0448 - val_accuracy: 0.0769\n",
      "Epoch 22/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 2.1031 - accuracy: 0.4004 - val_loss: 3.0261 - val_accuracy: 0.1026\n",
      "Epoch 23/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 2.0858 - accuracy: 0.3924 - val_loss: 3.0016 - val_accuracy: 0.1231\n",
      "Epoch 24/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 2.0608 - accuracy: 0.4105 - val_loss: 2.9740 - val_accuracy: 0.1385\n",
      "Epoch 25/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 1.9459 - accuracy: 0.4306 - val_loss: 2.9521 - val_accuracy: 0.1590\n",
      "Epoch 26/600\n",
      "497/497 [==============================] - 0s 351us/step - loss: 1.9143 - accuracy: 0.4567 - val_loss: 2.9343 - val_accuracy: 0.1590\n",
      "Epoch 27/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 1.9511 - accuracy: 0.4225 - val_loss: 2.9199 - val_accuracy: 0.1692\n",
      "Epoch 28/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 1.8131 - accuracy: 0.4809 - val_loss: 2.9098 - val_accuracy: 0.1590\n",
      "Epoch 29/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 1.8697 - accuracy: 0.4406 - val_loss: 2.9010 - val_accuracy: 0.1487\n",
      "Epoch 30/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 1.7712 - accuracy: 0.4708 - val_loss: 2.8928 - val_accuracy: 0.1436\n",
      "Epoch 31/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 1.7376 - accuracy: 0.5131 - val_loss: 2.8833 - val_accuracy: 0.1436\n",
      "Epoch 32/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 1.6955 - accuracy: 0.4829 - val_loss: 2.8761 - val_accuracy: 0.1436\n",
      "Epoch 33/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 1.6892 - accuracy: 0.4849 - val_loss: 2.8650 - val_accuracy: 0.1436\n",
      "Epoch 34/600\n",
      "497/497 [==============================] - 0s 364us/step - loss: 1.5664 - accuracy: 0.5332 - val_loss: 2.8506 - val_accuracy: 0.1385\n",
      "Epoch 35/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 1.5434 - accuracy: 0.5553 - val_loss: 2.8353 - val_accuracy: 0.1487\n",
      "Epoch 36/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 1.5562 - accuracy: 0.5412 - val_loss: 2.8247 - val_accuracy: 0.1487\n",
      "Epoch 37/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 1.4881 - accuracy: 0.5634 - val_loss: 2.8159 - val_accuracy: 0.1487\n",
      "Epoch 38/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 1.4556 - accuracy: 0.5634 - val_loss: 2.8114 - val_accuracy: 0.1487\n",
      "Epoch 39/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 1.4194 - accuracy: 0.5936 - val_loss: 2.8059 - val_accuracy: 0.1436\n",
      "Epoch 40/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 1.3904 - accuracy: 0.5795 - val_loss: 2.7987 - val_accuracy: 0.1590\n",
      "Epoch 41/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 1.3203 - accuracy: 0.6177 - val_loss: 2.7910 - val_accuracy: 0.1692\n",
      "Epoch 42/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 1.3090 - accuracy: 0.6278 - val_loss: 2.7814 - val_accuracy: 0.1744\n",
      "Epoch 43/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 1.3468 - accuracy: 0.6117 - val_loss: 2.7713 - val_accuracy: 0.1897\n",
      "Epoch 44/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 1.2754 - accuracy: 0.6479 - val_loss: 2.7607 - val_accuracy: 0.2000\n",
      "Epoch 45/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 1.2052 - accuracy: 0.6680 - val_loss: 2.7446 - val_accuracy: 0.2000\n",
      "Epoch 46/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 1.1891 - accuracy: 0.6680 - val_loss: 2.7244 - val_accuracy: 0.1949\n",
      "Epoch 47/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 1.1890 - accuracy: 0.6740 - val_loss: 2.7044 - val_accuracy: 0.2154\n",
      "Epoch 48/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 1.1915 - accuracy: 0.6559 - val_loss: 2.6913 - val_accuracy: 0.2103\n",
      "Epoch 49/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 1.1493 - accuracy: 0.6761 - val_loss: 2.6767 - val_accuracy: 0.2205\n",
      "Epoch 50/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 1.1048 - accuracy: 0.7042 - val_loss: 2.6633 - val_accuracy: 0.2205\n",
      "Epoch 51/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 1.1164 - accuracy: 0.6901 - val_loss: 2.6525 - val_accuracy: 0.2154\n",
      "Epoch 52/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 1.0565 - accuracy: 0.7223 - val_loss: 2.6418 - val_accuracy: 0.2308\n",
      "Epoch 53/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 1.0178 - accuracy: 0.7203 - val_loss: 2.6333 - val_accuracy: 0.2256\n",
      "Epoch 54/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 1.0079 - accuracy: 0.7183 - val_loss: 2.6322 - val_accuracy: 0.2205\n",
      "Epoch 55/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 1.0596 - accuracy: 0.7163 - val_loss: 2.6270 - val_accuracy: 0.2205\n",
      "Epoch 56/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.9538 - accuracy: 0.7465 - val_loss: 2.6220 - val_accuracy: 0.2256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.9742 - accuracy: 0.7404 - val_loss: 2.6143 - val_accuracy: 0.2256\n",
      "Epoch 58/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.9291 - accuracy: 0.7404 - val_loss: 2.6006 - val_accuracy: 0.2513\n",
      "Epoch 59/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.9321 - accuracy: 0.7465 - val_loss: 2.5885 - val_accuracy: 0.2667\n",
      "Epoch 60/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.9083 - accuracy: 0.7586 - val_loss: 2.5754 - val_accuracy: 0.2667\n",
      "Epoch 61/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.8964 - accuracy: 0.7686 - val_loss: 2.5625 - val_accuracy: 0.2872\n",
      "Epoch 62/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.8477 - accuracy: 0.7726 - val_loss: 2.5540 - val_accuracy: 0.2872\n",
      "Epoch 63/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.8148 - accuracy: 0.7767 - val_loss: 2.5510 - val_accuracy: 0.2718\n",
      "Epoch 64/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.7868 - accuracy: 0.7887 - val_loss: 2.5447 - val_accuracy: 0.2718\n",
      "Epoch 65/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.7813 - accuracy: 0.7948 - val_loss: 2.5450 - val_accuracy: 0.2769\n",
      "Epoch 66/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.7584 - accuracy: 0.8068 - val_loss: 2.5414 - val_accuracy: 0.2923\n",
      "Epoch 67/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.7939 - accuracy: 0.8089 - val_loss: 2.5321 - val_accuracy: 0.3077\n",
      "Epoch 68/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.7629 - accuracy: 0.7887 - val_loss: 2.5173 - val_accuracy: 0.3077\n",
      "Epoch 69/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.7049 - accuracy: 0.8169 - val_loss: 2.5019 - val_accuracy: 0.3128\n",
      "Epoch 70/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.6871 - accuracy: 0.8350 - val_loss: 2.4911 - val_accuracy: 0.3128\n",
      "Epoch 71/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.6990 - accuracy: 0.8290 - val_loss: 2.4813 - val_accuracy: 0.3282\n",
      "Epoch 72/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.6193 - accuracy: 0.8551 - val_loss: 2.4771 - val_accuracy: 0.3128\n",
      "Epoch 73/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.6572 - accuracy: 0.8370 - val_loss: 2.4866 - val_accuracy: 0.3128\n",
      "Epoch 74/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.6523 - accuracy: 0.8410 - val_loss: 2.4951 - val_accuracy: 0.3179\n",
      "Epoch 75/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.6427 - accuracy: 0.8390 - val_loss: 2.4979 - val_accuracy: 0.3179\n",
      "Epoch 76/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.5655 - accuracy: 0.8813 - val_loss: 2.4918 - val_accuracy: 0.3231\n",
      "Epoch 77/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.6318 - accuracy: 0.8531 - val_loss: 2.4873 - val_accuracy: 0.3231\n",
      "Epoch 78/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.5496 - accuracy: 0.8712 - val_loss: 2.4843 - val_accuracy: 0.3231\n",
      "Epoch 79/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.5438 - accuracy: 0.8753 - val_loss: 2.4753 - val_accuracy: 0.3231\n",
      "Epoch 80/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.5177 - accuracy: 0.8934 - val_loss: 2.4615 - val_accuracy: 0.3128\n",
      "Epoch 81/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.5014 - accuracy: 0.8893 - val_loss: 2.4478 - val_accuracy: 0.3231\n",
      "Epoch 82/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.4852 - accuracy: 0.8954 - val_loss: 2.4374 - val_accuracy: 0.3231\n",
      "Epoch 83/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.5039 - accuracy: 0.8934 - val_loss: 2.4265 - val_accuracy: 0.3179\n",
      "Epoch 84/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.4837 - accuracy: 0.8994 - val_loss: 2.4244 - val_accuracy: 0.3179\n",
      "Epoch 85/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.4809 - accuracy: 0.9155 - val_loss: 2.4254 - val_accuracy: 0.3282\n",
      "Epoch 86/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.4601 - accuracy: 0.9135 - val_loss: 2.4285 - val_accuracy: 0.3231\n",
      "Epoch 87/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.4207 - accuracy: 0.9316 - val_loss: 2.4308 - val_accuracy: 0.3231\n",
      "Epoch 88/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.4271 - accuracy: 0.9276 - val_loss: 2.4357 - val_accuracy: 0.3128\n",
      "Epoch 89/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.4081 - accuracy: 0.9457 - val_loss: 2.4390 - val_accuracy: 0.3026\n",
      "Epoch 90/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.4338 - accuracy: 0.9135 - val_loss: 2.4406 - val_accuracy: 0.3077\n",
      "Epoch 91/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.3731 - accuracy: 0.9416 - val_loss: 2.4324 - val_accuracy: 0.3231\n",
      "Epoch 92/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.3973 - accuracy: 0.9115 - val_loss: 2.4193 - val_accuracy: 0.3282\n",
      "Epoch 93/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.3741 - accuracy: 0.9276 - val_loss: 2.4142 - val_accuracy: 0.3282\n",
      "Epoch 94/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.3732 - accuracy: 0.9316 - val_loss: 2.4177 - val_accuracy: 0.3282\n",
      "Epoch 95/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.3346 - accuracy: 0.9416 - val_loss: 2.4212 - val_accuracy: 0.3333\n",
      "Epoch 96/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.3503 - accuracy: 0.9376 - val_loss: 2.4233 - val_accuracy: 0.3436\n",
      "Epoch 97/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.3296 - accuracy: 0.9416 - val_loss: 2.4294 - val_accuracy: 0.3436\n",
      "Epoch 98/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.3097 - accuracy: 0.9759 - val_loss: 2.4377 - val_accuracy: 0.3231\n",
      "Epoch 99/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.2927 - accuracy: 0.9598 - val_loss: 2.4391 - val_accuracy: 0.3282\n",
      "Epoch 100/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.3144 - accuracy: 0.9396 - val_loss: 2.4233 - val_accuracy: 0.3282\n",
      "Epoch 101/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.2972 - accuracy: 0.9537 - val_loss: 2.3981 - val_accuracy: 0.3333\n",
      "Epoch 102/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.3036 - accuracy: 0.9416 - val_loss: 2.3752 - val_accuracy: 0.3333\n",
      "Epoch 103/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.2593 - accuracy: 0.9678 - val_loss: 2.3488 - val_accuracy: 0.3487\n",
      "Epoch 104/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.2843 - accuracy: 0.9557 - val_loss: 2.3273 - val_accuracy: 0.3538\n",
      "Epoch 105/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.2551 - accuracy: 0.9457 - val_loss: 2.3108 - val_accuracy: 0.3692\n",
      "Epoch 106/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.2634 - accuracy: 0.9638 - val_loss: 2.3063 - val_accuracy: 0.3744\n",
      "Epoch 107/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.2340 - accuracy: 0.9678 - val_loss: 2.3040 - val_accuracy: 0.4000\n",
      "Epoch 108/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.2539 - accuracy: 0.9517 - val_loss: 2.3071 - val_accuracy: 0.4000\n",
      "Epoch 109/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.2823 - accuracy: 0.9598 - val_loss: 2.3069 - val_accuracy: 0.3846\n",
      "Epoch 110/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.2620 - accuracy: 0.9577 - val_loss: 2.3036 - val_accuracy: 0.4103\n",
      "Epoch 111/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.2396 - accuracy: 0.9638 - val_loss: 2.3014 - val_accuracy: 0.4103\n",
      "Epoch 112/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.2393 - accuracy: 0.9678 - val_loss: 2.3035 - val_accuracy: 0.4051\n",
      "Epoch 113/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.2322 - accuracy: 0.9678 - val_loss: 2.3008 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.2036 - accuracy: 0.9738 - val_loss: 2.3010 - val_accuracy: 0.3897\n",
      "Epoch 115/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.2063 - accuracy: 0.9718 - val_loss: 2.3023 - val_accuracy: 0.4000\n",
      "Epoch 116/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.2223 - accuracy: 0.9759 - val_loss: 2.3027 - val_accuracy: 0.4000\n",
      "Epoch 117/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.2147 - accuracy: 0.9598 - val_loss: 2.3004 - val_accuracy: 0.3949\n",
      "Epoch 118/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1922 - accuracy: 0.9839 - val_loss: 2.2959 - val_accuracy: 0.3897\n",
      "Epoch 119/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.2113 - accuracy: 0.9718 - val_loss: 2.2878 - val_accuracy: 0.4000\n",
      "Epoch 120/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1932 - accuracy: 0.9779 - val_loss: 2.2785 - val_accuracy: 0.4000\n",
      "Epoch 121/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.2192 - accuracy: 0.9577 - val_loss: 2.2716 - val_accuracy: 0.4000\n",
      "Epoch 122/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1982 - accuracy: 0.9658 - val_loss: 2.2652 - val_accuracy: 0.3949\n",
      "Epoch 123/600\n",
      "497/497 [==============================] - 0s 314us/step - loss: 0.2211 - accuracy: 0.9738 - val_loss: 2.2564 - val_accuracy: 0.3949\n",
      "Epoch 124/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.2138 - accuracy: 0.9738 - val_loss: 2.2513 - val_accuracy: 0.4051\n",
      "Epoch 125/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1839 - accuracy: 0.9799 - val_loss: 2.2481 - val_accuracy: 0.4051\n",
      "Epoch 126/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1883 - accuracy: 0.9779 - val_loss: 2.2438 - val_accuracy: 0.4051\n",
      "Epoch 127/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1859 - accuracy: 0.9759 - val_loss: 2.2389 - val_accuracy: 0.4103\n",
      "Epoch 128/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1718 - accuracy: 0.9879 - val_loss: 2.2352 - val_accuracy: 0.4103\n",
      "Epoch 129/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1853 - accuracy: 0.9779 - val_loss: 2.2329 - val_accuracy: 0.4103\n",
      "Epoch 130/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1998 - accuracy: 0.9779 - val_loss: 2.2305 - val_accuracy: 0.4103\n",
      "Epoch 131/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1947 - accuracy: 0.9738 - val_loss: 2.2278 - val_accuracy: 0.4051\n",
      "Epoch 132/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1830 - accuracy: 0.9759 - val_loss: 2.2253 - val_accuracy: 0.4000\n",
      "Epoch 133/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1823 - accuracy: 0.9738 - val_loss: 2.2224 - val_accuracy: 0.3949\n",
      "Epoch 134/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1734 - accuracy: 0.9819 - val_loss: 2.2195 - val_accuracy: 0.4000\n",
      "Epoch 135/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1649 - accuracy: 0.9779 - val_loss: 2.2171 - val_accuracy: 0.4000\n",
      "Epoch 136/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1774 - accuracy: 0.9799 - val_loss: 2.2143 - val_accuracy: 0.4000\n",
      "Epoch 137/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1748 - accuracy: 0.9859 - val_loss: 2.2112 - val_accuracy: 0.4000\n",
      "Epoch 138/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1763 - accuracy: 0.9839 - val_loss: 2.2079 - val_accuracy: 0.4000\n",
      "Epoch 139/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1774 - accuracy: 0.9839 - val_loss: 2.2049 - val_accuracy: 0.4000\n",
      "Epoch 140/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1590 - accuracy: 0.9859 - val_loss: 2.2022 - val_accuracy: 0.4000\n",
      "Epoch 141/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1737 - accuracy: 0.9819 - val_loss: 2.1988 - val_accuracy: 0.4000\n",
      "Epoch 142/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1771 - accuracy: 0.9779 - val_loss: 2.1955 - val_accuracy: 0.4000\n",
      "Epoch 143/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1749 - accuracy: 0.9759 - val_loss: 2.1919 - val_accuracy: 0.4103\n",
      "Epoch 144/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1582 - accuracy: 0.9779 - val_loss: 2.1867 - val_accuracy: 0.4051\n",
      "Epoch 145/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1602 - accuracy: 0.9839 - val_loss: 2.1819 - val_accuracy: 0.4051\n",
      "Epoch 146/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1415 - accuracy: 0.9920 - val_loss: 2.1776 - val_accuracy: 0.4103\n",
      "Epoch 147/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1774 - accuracy: 0.9839 - val_loss: 2.1734 - val_accuracy: 0.4103\n",
      "Epoch 148/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1677 - accuracy: 0.9879 - val_loss: 2.1699 - val_accuracy: 0.4103\n",
      "Epoch 149/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1890 - accuracy: 0.9698 - val_loss: 2.1665 - val_accuracy: 0.4103\n",
      "Epoch 150/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1519 - accuracy: 0.9879 - val_loss: 2.1635 - val_accuracy: 0.4154\n",
      "Epoch 151/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1633 - accuracy: 0.9839 - val_loss: 2.1612 - val_accuracy: 0.4103\n",
      "Epoch 152/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1744 - accuracy: 0.9738 - val_loss: 2.1590 - val_accuracy: 0.4103\n",
      "Epoch 153/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1682 - accuracy: 0.9819 - val_loss: 2.1564 - val_accuracy: 0.4154\n",
      "Epoch 154/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1510 - accuracy: 0.9839 - val_loss: 2.1537 - val_accuracy: 0.4205\n",
      "Epoch 155/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1546 - accuracy: 0.9879 - val_loss: 2.1513 - val_accuracy: 0.4256\n",
      "Epoch 156/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1684 - accuracy: 0.9839 - val_loss: 2.1496 - val_accuracy: 0.4256\n",
      "Epoch 157/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1828 - accuracy: 0.9718 - val_loss: 2.1481 - val_accuracy: 0.4308\n",
      "Epoch 158/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1853 - accuracy: 0.9779 - val_loss: 2.1467 - val_accuracy: 0.4308\n",
      "Epoch 159/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1566 - accuracy: 0.9899 - val_loss: 2.1452 - val_accuracy: 0.4308\n",
      "Epoch 160/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1646 - accuracy: 0.9859 - val_loss: 2.1439 - val_accuracy: 0.4359\n",
      "Epoch 161/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1569 - accuracy: 0.9859 - val_loss: 2.1424 - val_accuracy: 0.4359\n",
      "Epoch 162/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1807 - accuracy: 0.9859 - val_loss: 2.1409 - val_accuracy: 0.4410\n",
      "Epoch 163/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1556 - accuracy: 0.9899 - val_loss: 2.1398 - val_accuracy: 0.4410\n",
      "Epoch 164/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1432 - accuracy: 0.9940 - val_loss: 2.1384 - val_accuracy: 0.4462\n",
      "Epoch 165/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1690 - accuracy: 0.9839 - val_loss: 2.1375 - val_accuracy: 0.4462\n",
      "Epoch 166/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1338 - accuracy: 0.9899 - val_loss: 2.1365 - val_accuracy: 0.4513\n",
      "Epoch 167/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1881 - accuracy: 0.9638 - val_loss: 2.1355 - val_accuracy: 0.4462\n",
      "Epoch 168/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1487 - accuracy: 0.9940 - val_loss: 2.1345 - val_accuracy: 0.4462\n",
      "Epoch 169/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1556 - accuracy: 0.9920 - val_loss: 2.1336 - val_accuracy: 0.4462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1629 - accuracy: 0.9879 - val_loss: 2.1326 - val_accuracy: 0.4410\n",
      "Epoch 171/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1635 - accuracy: 0.9779 - val_loss: 2.1322 - val_accuracy: 0.4410\n",
      "Epoch 172/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1793 - accuracy: 0.9738 - val_loss: 2.1311 - val_accuracy: 0.4462\n",
      "Epoch 173/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1681 - accuracy: 0.9779 - val_loss: 2.1303 - val_accuracy: 0.4462\n",
      "Epoch 174/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1742 - accuracy: 0.9799 - val_loss: 2.1293 - val_accuracy: 0.4410\n",
      "Epoch 175/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1449 - accuracy: 0.9859 - val_loss: 2.1285 - val_accuracy: 0.4410\n",
      "Epoch 176/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1699 - accuracy: 0.9738 - val_loss: 2.1275 - val_accuracy: 0.4410\n",
      "Epoch 177/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1836 - accuracy: 0.9759 - val_loss: 2.1263 - val_accuracy: 0.4410\n",
      "Epoch 178/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1478 - accuracy: 0.9920 - val_loss: 2.1253 - val_accuracy: 0.4410\n",
      "Epoch 179/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1584 - accuracy: 0.9859 - val_loss: 2.1244 - val_accuracy: 0.4410\n",
      "Epoch 180/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1566 - accuracy: 0.9799 - val_loss: 2.1233 - val_accuracy: 0.4410\n",
      "Epoch 181/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1554 - accuracy: 0.9799 - val_loss: 2.1225 - val_accuracy: 0.4410\n",
      "Epoch 182/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1945 - accuracy: 0.9618 - val_loss: 2.1215 - val_accuracy: 0.4359\n",
      "Epoch 183/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1701 - accuracy: 0.9799 - val_loss: 2.1208 - val_accuracy: 0.4359\n",
      "Epoch 184/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1729 - accuracy: 0.9879 - val_loss: 2.1201 - val_accuracy: 0.4359\n",
      "Epoch 185/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1542 - accuracy: 0.9839 - val_loss: 2.1194 - val_accuracy: 0.4410\n",
      "Epoch 186/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1653 - accuracy: 0.9839 - val_loss: 2.1189 - val_accuracy: 0.4410\n",
      "Epoch 187/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1692 - accuracy: 0.9819 - val_loss: 2.1182 - val_accuracy: 0.4410\n",
      "Epoch 188/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1768 - accuracy: 0.9779 - val_loss: 2.1175 - val_accuracy: 0.4462\n",
      "Epoch 189/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1477 - accuracy: 0.9779 - val_loss: 2.1169 - val_accuracy: 0.4462\n",
      "Epoch 190/600\n",
      "497/497 [==============================] - 0s 312us/step - loss: 0.1748 - accuracy: 0.9920 - val_loss: 2.1161 - val_accuracy: 0.4462\n",
      "Epoch 191/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1644 - accuracy: 0.9678 - val_loss: 2.1155 - val_accuracy: 0.4462\n",
      "Epoch 192/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1638 - accuracy: 0.9779 - val_loss: 2.1149 - val_accuracy: 0.4462\n",
      "Epoch 193/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1509 - accuracy: 0.9819 - val_loss: 2.1140 - val_accuracy: 0.4462\n",
      "Epoch 194/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1472 - accuracy: 0.9899 - val_loss: 2.1135 - val_accuracy: 0.4462\n",
      "Epoch 195/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1539 - accuracy: 0.9819 - val_loss: 2.1130 - val_accuracy: 0.4462\n",
      "Epoch 196/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1555 - accuracy: 0.9859 - val_loss: 2.1127 - val_accuracy: 0.4462\n",
      "Epoch 197/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1529 - accuracy: 0.9819 - val_loss: 2.1121 - val_accuracy: 0.4513\n",
      "Epoch 198/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1613 - accuracy: 0.9779 - val_loss: 2.1117 - val_accuracy: 0.4513\n",
      "Epoch 199/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1724 - accuracy: 0.9819 - val_loss: 2.1115 - val_accuracy: 0.4513\n",
      "Epoch 200/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1670 - accuracy: 0.9779 - val_loss: 2.1112 - val_accuracy: 0.4513\n",
      "Epoch 201/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1543 - accuracy: 0.9859 - val_loss: 2.1109 - val_accuracy: 0.4564\n",
      "Epoch 202/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1582 - accuracy: 0.9779 - val_loss: 2.1106 - val_accuracy: 0.4564\n",
      "Epoch 203/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1621 - accuracy: 0.9819 - val_loss: 2.1102 - val_accuracy: 0.4564\n",
      "Epoch 204/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1597 - accuracy: 0.9839 - val_loss: 2.1100 - val_accuracy: 0.4564\n",
      "Epoch 205/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1424 - accuracy: 0.9899 - val_loss: 2.1095 - val_accuracy: 0.4564\n",
      "Epoch 206/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1768 - accuracy: 0.9779 - val_loss: 2.1092 - val_accuracy: 0.4564\n",
      "Epoch 207/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1446 - accuracy: 0.9819 - val_loss: 2.1088 - val_accuracy: 0.4564\n",
      "Epoch 208/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1586 - accuracy: 0.9899 - val_loss: 2.1085 - val_accuracy: 0.4564\n",
      "Epoch 209/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1602 - accuracy: 0.9859 - val_loss: 2.1080 - val_accuracy: 0.4564\n",
      "Epoch 210/600\n",
      "497/497 [==============================] - 0s 312us/step - loss: 0.1644 - accuracy: 0.9839 - val_loss: 2.1079 - val_accuracy: 0.4564\n",
      "Epoch 211/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1863 - accuracy: 0.9678 - val_loss: 2.1075 - val_accuracy: 0.4564\n",
      "Epoch 212/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1567 - accuracy: 0.9819 - val_loss: 2.1071 - val_accuracy: 0.4564\n",
      "Epoch 213/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1704 - accuracy: 0.9779 - val_loss: 2.1067 - val_accuracy: 0.4564\n",
      "Epoch 214/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1478 - accuracy: 0.9859 - val_loss: 2.1062 - val_accuracy: 0.4564\n",
      "Epoch 215/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1531 - accuracy: 0.9799 - val_loss: 2.1057 - val_accuracy: 0.4564\n",
      "Epoch 216/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1822 - accuracy: 0.9718 - val_loss: 2.1055 - val_accuracy: 0.4564\n",
      "Epoch 217/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1756 - accuracy: 0.9859 - val_loss: 2.1052 - val_accuracy: 0.4564\n",
      "Epoch 218/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1605 - accuracy: 0.9859 - val_loss: 2.1048 - val_accuracy: 0.4564\n",
      "Epoch 219/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1690 - accuracy: 0.9839 - val_loss: 2.1043 - val_accuracy: 0.4564\n",
      "Epoch 220/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1472 - accuracy: 0.9839 - val_loss: 2.1040 - val_accuracy: 0.4564\n",
      "Epoch 221/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1403 - accuracy: 0.9920 - val_loss: 2.1036 - val_accuracy: 0.4564\n",
      "Epoch 222/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1619 - accuracy: 0.9839 - val_loss: 2.1033 - val_accuracy: 0.4615\n",
      "Epoch 223/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1494 - accuracy: 0.9879 - val_loss: 2.1030 - val_accuracy: 0.4615\n",
      "Epoch 224/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1481 - accuracy: 0.9859 - val_loss: 2.1026 - val_accuracy: 0.4615\n",
      "Epoch 225/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1637 - accuracy: 0.9759 - val_loss: 2.1023 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1640 - accuracy: 0.9819 - val_loss: 2.1022 - val_accuracy: 0.4615\n",
      "Epoch 227/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1614 - accuracy: 0.9759 - val_loss: 2.1020 - val_accuracy: 0.4615\n",
      "Epoch 228/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1493 - accuracy: 0.9839 - val_loss: 2.1018 - val_accuracy: 0.4615\n",
      "Epoch 229/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1606 - accuracy: 0.9859 - val_loss: 2.1018 - val_accuracy: 0.4615\n",
      "Epoch 230/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1578 - accuracy: 0.9899 - val_loss: 2.1017 - val_accuracy: 0.4667\n",
      "Epoch 231/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1538 - accuracy: 0.9819 - val_loss: 2.1014 - val_accuracy: 0.4667\n",
      "Epoch 232/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1696 - accuracy: 0.9859 - val_loss: 2.1012 - val_accuracy: 0.4667\n",
      "Epoch 233/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1434 - accuracy: 0.9899 - val_loss: 2.1008 - val_accuracy: 0.4667\n",
      "Epoch 234/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1450 - accuracy: 0.9859 - val_loss: 2.1005 - val_accuracy: 0.4667\n",
      "Epoch 235/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 0.1781 - accuracy: 0.9759 - val_loss: 2.1003 - val_accuracy: 0.4667\n",
      "Epoch 236/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1653 - accuracy: 0.9819 - val_loss: 2.1000 - val_accuracy: 0.4667\n",
      "Epoch 237/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1410 - accuracy: 0.9920 - val_loss: 2.1001 - val_accuracy: 0.4667\n",
      "Epoch 238/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1626 - accuracy: 0.9759 - val_loss: 2.0998 - val_accuracy: 0.4667\n",
      "Epoch 239/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1710 - accuracy: 0.9859 - val_loss: 2.0997 - val_accuracy: 0.4667\n",
      "Epoch 240/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1423 - accuracy: 0.9839 - val_loss: 2.0996 - val_accuracy: 0.4667\n",
      "Epoch 241/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1593 - accuracy: 0.9799 - val_loss: 2.0997 - val_accuracy: 0.4667\n",
      "Epoch 242/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1464 - accuracy: 0.9879 - val_loss: 2.0997 - val_accuracy: 0.4667\n",
      "Epoch 243/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1501 - accuracy: 0.9799 - val_loss: 2.0997 - val_accuracy: 0.4667\n",
      "Epoch 244/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1602 - accuracy: 0.9839 - val_loss: 2.0998 - val_accuracy: 0.4667\n",
      "Epoch 245/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1530 - accuracy: 0.9839 - val_loss: 2.0999 - val_accuracy: 0.4667\n",
      "Epoch 246/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1452 - accuracy: 0.9879 - val_loss: 2.0999 - val_accuracy: 0.4667\n",
      "Epoch 247/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1548 - accuracy: 0.9839 - val_loss: 2.1000 - val_accuracy: 0.4667\n",
      "Epoch 248/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1570 - accuracy: 0.9859 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 249/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1614 - accuracy: 0.9839 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 250/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1676 - accuracy: 0.9819 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 251/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1437 - accuracy: 0.9899 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 252/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1442 - accuracy: 0.9859 - val_loss: 2.1001 - val_accuracy: 0.4667\n",
      "Epoch 253/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1677 - accuracy: 0.9738 - val_loss: 2.1001 - val_accuracy: 0.4667\n",
      "Epoch 254/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1634 - accuracy: 0.9839 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 255/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1836 - accuracy: 0.9799 - val_loss: 2.1001 - val_accuracy: 0.4667\n",
      "Epoch 256/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1403 - accuracy: 0.9920 - val_loss: 2.1001 - val_accuracy: 0.4667\n",
      "Epoch 257/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1668 - accuracy: 0.9718 - val_loss: 2.1002 - val_accuracy: 0.4667\n",
      "Epoch 258/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1687 - accuracy: 0.9819 - val_loss: 2.1004 - val_accuracy: 0.4667\n",
      "Epoch 259/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1610 - accuracy: 0.9920 - val_loss: 2.1005 - val_accuracy: 0.4667\n",
      "Epoch 260/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1528 - accuracy: 0.9839 - val_loss: 2.1006 - val_accuracy: 0.4667\n",
      "Epoch 261/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1610 - accuracy: 0.9879 - val_loss: 2.1009 - val_accuracy: 0.4667\n",
      "Epoch 262/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1637 - accuracy: 0.9819 - val_loss: 2.1011 - val_accuracy: 0.4667\n",
      "Epoch 263/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1472 - accuracy: 0.9859 - val_loss: 2.1012 - val_accuracy: 0.4667\n",
      "Epoch 264/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1358 - accuracy: 0.9899 - val_loss: 2.1011 - val_accuracy: 0.4667\n",
      "Epoch 265/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1619 - accuracy: 0.9738 - val_loss: 2.1012 - val_accuracy: 0.4667\n",
      "Epoch 266/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1475 - accuracy: 0.9879 - val_loss: 2.1014 - val_accuracy: 0.4615\n",
      "Epoch 267/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1859 - accuracy: 0.9658 - val_loss: 2.1017 - val_accuracy: 0.4615\n",
      "Epoch 268/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1667 - accuracy: 0.9819 - val_loss: 2.1018 - val_accuracy: 0.4615\n",
      "Epoch 269/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1627 - accuracy: 0.9839 - val_loss: 2.1019 - val_accuracy: 0.4615\n",
      "Epoch 270/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1849 - accuracy: 0.9759 - val_loss: 2.1023 - val_accuracy: 0.4615\n",
      "Epoch 271/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1374 - accuracy: 0.9879 - val_loss: 2.1025 - val_accuracy: 0.4615\n",
      "Epoch 272/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1491 - accuracy: 0.9899 - val_loss: 2.1028 - val_accuracy: 0.4615\n",
      "Epoch 273/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1503 - accuracy: 0.9859 - val_loss: 2.1031 - val_accuracy: 0.4615\n",
      "Epoch 274/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1438 - accuracy: 0.9859 - val_loss: 2.1033 - val_accuracy: 0.4615\n",
      "Epoch 275/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1696 - accuracy: 0.9839 - val_loss: 2.1036 - val_accuracy: 0.4615\n",
      "Epoch 276/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1706 - accuracy: 0.9738 - val_loss: 2.1036 - val_accuracy: 0.4615\n",
      "Epoch 277/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1576 - accuracy: 0.9879 - val_loss: 2.1037 - val_accuracy: 0.4615\n",
      "Epoch 278/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1461 - accuracy: 0.9899 - val_loss: 2.1037 - val_accuracy: 0.4615\n",
      "Epoch 279/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1548 - accuracy: 0.9779 - val_loss: 2.1039 - val_accuracy: 0.4615\n",
      "Epoch 280/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1928 - accuracy: 0.9598 - val_loss: 2.1041 - val_accuracy: 0.4615\n",
      "Epoch 281/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1582 - accuracy: 0.9839 - val_loss: 2.1042 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1431 - accuracy: 0.9879 - val_loss: 2.1044 - val_accuracy: 0.4615\n",
      "Epoch 283/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1551 - accuracy: 0.9879 - val_loss: 2.1046 - val_accuracy: 0.4615\n",
      "Epoch 284/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1659 - accuracy: 0.9759 - val_loss: 2.1045 - val_accuracy: 0.4615\n",
      "Epoch 285/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1819 - accuracy: 0.9779 - val_loss: 2.1045 - val_accuracy: 0.4615\n",
      "Epoch 286/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1642 - accuracy: 0.9819 - val_loss: 2.1048 - val_accuracy: 0.4615\n",
      "Epoch 287/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1584 - accuracy: 0.9759 - val_loss: 2.1050 - val_accuracy: 0.4667\n",
      "Epoch 288/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1924 - accuracy: 0.9779 - val_loss: 2.1051 - val_accuracy: 0.4667\n",
      "Epoch 289/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1699 - accuracy: 0.9779 - val_loss: 2.1050 - val_accuracy: 0.4667\n",
      "Epoch 290/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1345 - accuracy: 0.9859 - val_loss: 2.1052 - val_accuracy: 0.4667\n",
      "Epoch 291/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1792 - accuracy: 0.9718 - val_loss: 2.1055 - val_accuracy: 0.4667\n",
      "Epoch 292/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1393 - accuracy: 0.9879 - val_loss: 2.1056 - val_accuracy: 0.4667\n",
      "Epoch 293/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1454 - accuracy: 0.9819 - val_loss: 2.1056 - val_accuracy: 0.4667\n",
      "Epoch 294/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1483 - accuracy: 0.9819 - val_loss: 2.1058 - val_accuracy: 0.4718\n",
      "Epoch 295/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1621 - accuracy: 0.9759 - val_loss: 2.1060 - val_accuracy: 0.4718\n",
      "Epoch 296/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1571 - accuracy: 0.9779 - val_loss: 2.1062 - val_accuracy: 0.4769\n",
      "Epoch 297/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1475 - accuracy: 0.9819 - val_loss: 2.1064 - val_accuracy: 0.4769\n",
      "Epoch 298/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1472 - accuracy: 0.9799 - val_loss: 2.1066 - val_accuracy: 0.4769\n",
      "Epoch 299/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1539 - accuracy: 0.9799 - val_loss: 2.1069 - val_accuracy: 0.4769\n",
      "Epoch 300/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1367 - accuracy: 0.9940 - val_loss: 2.1072 - val_accuracy: 0.4769\n",
      "Epoch 301/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1641 - accuracy: 0.9799 - val_loss: 2.1074 - val_accuracy: 0.4769\n",
      "Epoch 302/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1344 - accuracy: 0.9920 - val_loss: 2.1076 - val_accuracy: 0.4769\n",
      "Epoch 303/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1457 - accuracy: 0.9819 - val_loss: 2.1079 - val_accuracy: 0.4769\n",
      "Epoch 304/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1553 - accuracy: 0.9759 - val_loss: 2.1082 - val_accuracy: 0.4821\n",
      "Epoch 305/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1381 - accuracy: 0.9799 - val_loss: 2.1084 - val_accuracy: 0.4821\n",
      "Epoch 306/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1752 - accuracy: 0.9779 - val_loss: 2.1087 - val_accuracy: 0.4821\n",
      "Epoch 307/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 0.1564 - accuracy: 0.9879 - val_loss: 2.1090 - val_accuracy: 0.4821\n",
      "Epoch 308/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1469 - accuracy: 0.9879 - val_loss: 2.1093 - val_accuracy: 0.4821\n",
      "Epoch 309/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1426 - accuracy: 0.9879 - val_loss: 2.1096 - val_accuracy: 0.4821\n",
      "Epoch 310/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1469 - accuracy: 0.9839 - val_loss: 2.1098 - val_accuracy: 0.4821\n",
      "Epoch 311/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1481 - accuracy: 0.9940 - val_loss: 2.1102 - val_accuracy: 0.4821\n",
      "Epoch 312/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1468 - accuracy: 0.9879 - val_loss: 2.1103 - val_accuracy: 0.4821\n",
      "Epoch 313/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1530 - accuracy: 0.9839 - val_loss: 2.1104 - val_accuracy: 0.4821\n",
      "Epoch 314/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.1629 - accuracy: 0.9879 - val_loss: 2.1106 - val_accuracy: 0.4821\n",
      "Epoch 315/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1438 - accuracy: 0.9879 - val_loss: 2.1109 - val_accuracy: 0.4821\n",
      "Epoch 316/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1517 - accuracy: 0.9920 - val_loss: 2.1111 - val_accuracy: 0.4821\n",
      "Epoch 317/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.1472 - accuracy: 0.9819 - val_loss: 2.1111 - val_accuracy: 0.4821\n",
      "Epoch 318/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1412 - accuracy: 0.9920 - val_loss: 2.1113 - val_accuracy: 0.4821\n",
      "Epoch 319/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1624 - accuracy: 0.9859 - val_loss: 2.1114 - val_accuracy: 0.4821\n",
      "Epoch 320/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1458 - accuracy: 0.9799 - val_loss: 2.1115 - val_accuracy: 0.4872\n",
      "Epoch 321/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1644 - accuracy: 0.9859 - val_loss: 2.1115 - val_accuracy: 0.4872\n",
      "Epoch 322/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1644 - accuracy: 0.9799 - val_loss: 2.1116 - val_accuracy: 0.4872\n",
      "Epoch 323/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1353 - accuracy: 0.9920 - val_loss: 2.1116 - val_accuracy: 0.4872\n",
      "Epoch 324/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1599 - accuracy: 0.9839 - val_loss: 2.1118 - val_accuracy: 0.4872\n",
      "Epoch 325/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1523 - accuracy: 0.9738 - val_loss: 2.1119 - val_accuracy: 0.4872\n",
      "Epoch 326/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1581 - accuracy: 0.9799 - val_loss: 2.1120 - val_accuracy: 0.4872\n",
      "Epoch 327/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1705 - accuracy: 0.9759 - val_loss: 2.1121 - val_accuracy: 0.4872\n",
      "Epoch 328/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1853 - accuracy: 0.9839 - val_loss: 2.1122 - val_accuracy: 0.4872\n",
      "Epoch 329/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1614 - accuracy: 0.9839 - val_loss: 2.1125 - val_accuracy: 0.4872\n",
      "Epoch 330/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1550 - accuracy: 0.9779 - val_loss: 2.1127 - val_accuracy: 0.4872\n",
      "Epoch 331/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1639 - accuracy: 0.9738 - val_loss: 2.1127 - val_accuracy: 0.4872\n",
      "Epoch 332/600\n",
      "497/497 [==============================] - 0s 312us/step - loss: 0.1646 - accuracy: 0.9819 - val_loss: 2.1131 - val_accuracy: 0.4872\n",
      "Epoch 333/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1787 - accuracy: 0.9698 - val_loss: 2.1132 - val_accuracy: 0.4872\n",
      "Epoch 334/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1635 - accuracy: 0.9779 - val_loss: 2.1132 - val_accuracy: 0.4872\n",
      "Epoch 335/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1552 - accuracy: 0.9799 - val_loss: 2.1131 - val_accuracy: 0.4872\n",
      "Epoch 336/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1490 - accuracy: 0.9879 - val_loss: 2.1131 - val_accuracy: 0.4872\n",
      "Epoch 337/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1565 - accuracy: 0.9839 - val_loss: 2.1132 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1615 - accuracy: 0.9879 - val_loss: 2.1134 - val_accuracy: 0.4872\n",
      "Epoch 339/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1583 - accuracy: 0.9879 - val_loss: 2.1135 - val_accuracy: 0.4872\n",
      "Epoch 340/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1577 - accuracy: 0.9839 - val_loss: 2.1137 - val_accuracy: 0.4872\n",
      "Epoch 341/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1518 - accuracy: 0.9920 - val_loss: 2.1137 - val_accuracy: 0.4872\n",
      "Epoch 342/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1533 - accuracy: 0.9819 - val_loss: 2.1138 - val_accuracy: 0.4872\n",
      "Epoch 343/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1452 - accuracy: 0.9879 - val_loss: 2.1139 - val_accuracy: 0.4872\n",
      "Epoch 344/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1619 - accuracy: 0.9839 - val_loss: 2.1140 - val_accuracy: 0.4872\n",
      "Epoch 345/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1595 - accuracy: 0.9859 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 346/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1484 - accuracy: 0.9899 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 347/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1550 - accuracy: 0.9799 - val_loss: 2.1139 - val_accuracy: 0.4872\n",
      "Epoch 348/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1615 - accuracy: 0.9779 - val_loss: 2.1139 - val_accuracy: 0.4872\n",
      "Epoch 349/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1671 - accuracy: 0.9819 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 350/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1746 - accuracy: 0.9779 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 351/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1462 - accuracy: 0.9879 - val_loss: 2.1142 - val_accuracy: 0.4872\n",
      "Epoch 352/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1358 - accuracy: 0.9940 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 353/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1558 - accuracy: 0.9879 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 354/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1474 - accuracy: 0.9819 - val_loss: 2.1141 - val_accuracy: 0.4872\n",
      "Epoch 355/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1483 - accuracy: 0.9920 - val_loss: 2.1139 - val_accuracy: 0.4872\n",
      "Epoch 356/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1443 - accuracy: 0.9899 - val_loss: 2.1137 - val_accuracy: 0.4872\n",
      "Epoch 357/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1842 - accuracy: 0.9799 - val_loss: 2.1137 - val_accuracy: 0.4872\n",
      "Epoch 358/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1519 - accuracy: 0.9839 - val_loss: 2.1137 - val_accuracy: 0.4872\n",
      "Epoch 359/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1594 - accuracy: 0.9819 - val_loss: 2.1138 - val_accuracy: 0.4872\n",
      "Epoch 360/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1590 - accuracy: 0.9879 - val_loss: 2.1135 - val_accuracy: 0.4872\n",
      "Epoch 361/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1429 - accuracy: 0.9940 - val_loss: 2.1135 - val_accuracy: 0.4923\n",
      "Epoch 362/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1767 - accuracy: 0.9718 - val_loss: 2.1135 - val_accuracy: 0.4923\n",
      "Epoch 363/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1671 - accuracy: 0.9779 - val_loss: 2.1133 - val_accuracy: 0.4923\n",
      "Epoch 364/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1731 - accuracy: 0.9738 - val_loss: 2.1132 - val_accuracy: 0.4923\n",
      "Epoch 365/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1685 - accuracy: 0.9819 - val_loss: 2.1134 - val_accuracy: 0.4923\n",
      "Epoch 366/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1913 - accuracy: 0.9678 - val_loss: 2.1135 - val_accuracy: 0.4923\n",
      "Epoch 367/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1216 - accuracy: 0.9960 - val_loss: 2.1134 - val_accuracy: 0.4923\n",
      "Epoch 368/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1360 - accuracy: 0.9920 - val_loss: 2.1136 - val_accuracy: 0.4923\n",
      "Epoch 369/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1561 - accuracy: 0.9859 - val_loss: 2.1138 - val_accuracy: 0.4923\n",
      "Epoch 370/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1589 - accuracy: 0.9899 - val_loss: 2.1141 - val_accuracy: 0.4923\n",
      "Epoch 371/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 2.1141 - val_accuracy: 0.4923\n",
      "Epoch 372/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1607 - accuracy: 0.9819 - val_loss: 2.1143 - val_accuracy: 0.4923\n",
      "Epoch 373/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1545 - accuracy: 0.9859 - val_loss: 2.1146 - val_accuracy: 0.4923\n",
      "Epoch 374/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1479 - accuracy: 0.9879 - val_loss: 2.1146 - val_accuracy: 0.4923\n",
      "Epoch 375/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1535 - accuracy: 0.9859 - val_loss: 2.1146 - val_accuracy: 0.4923\n",
      "Epoch 376/600\n",
      "497/497 [==============================] - 0s 356us/step - loss: 0.1560 - accuracy: 0.9839 - val_loss: 2.1147 - val_accuracy: 0.4923\n",
      "Epoch 377/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1462 - accuracy: 0.9899 - val_loss: 2.1148 - val_accuracy: 0.4923\n",
      "Epoch 378/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1624 - accuracy: 0.9839 - val_loss: 2.1149 - val_accuracy: 0.4923\n",
      "Epoch 379/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1819 - accuracy: 0.9738 - val_loss: 2.1149 - val_accuracy: 0.4923\n",
      "Epoch 380/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1588 - accuracy: 0.9819 - val_loss: 2.1149 - val_accuracy: 0.4923\n",
      "Epoch 381/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1567 - accuracy: 0.9859 - val_loss: 2.1150 - val_accuracy: 0.4923\n",
      "Epoch 382/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1655 - accuracy: 0.9819 - val_loss: 2.1151 - val_accuracy: 0.4923\n",
      "Epoch 383/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1612 - accuracy: 0.9859 - val_loss: 2.1152 - val_accuracy: 0.4923\n",
      "Epoch 384/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1639 - accuracy: 0.9799 - val_loss: 2.1152 - val_accuracy: 0.4923\n",
      "Epoch 385/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1542 - accuracy: 0.9819 - val_loss: 2.1153 - val_accuracy: 0.4923\n",
      "Epoch 386/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1613 - accuracy: 0.9779 - val_loss: 2.1155 - val_accuracy: 0.4923\n",
      "Epoch 387/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1525 - accuracy: 0.9799 - val_loss: 2.1158 - val_accuracy: 0.4923\n",
      "Epoch 388/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1622 - accuracy: 0.9779 - val_loss: 2.1159 - val_accuracy: 0.4923\n",
      "Epoch 389/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1660 - accuracy: 0.9819 - val_loss: 2.1161 - val_accuracy: 0.4923\n",
      "Epoch 390/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1464 - accuracy: 0.9819 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 391/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1492 - accuracy: 0.9899 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 392/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1481 - accuracy: 0.9839 - val_loss: 2.1163 - val_accuracy: 0.4923\n",
      "Epoch 393/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1712 - accuracy: 0.9799 - val_loss: 2.1162 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1536 - accuracy: 0.9799 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 395/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1478 - accuracy: 0.9819 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 396/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1459 - accuracy: 0.9839 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 397/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1684 - accuracy: 0.9799 - val_loss: 2.1162 - val_accuracy: 0.4923\n",
      "Epoch 398/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1685 - accuracy: 0.9819 - val_loss: 2.1165 - val_accuracy: 0.4923\n",
      "Epoch 399/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1638 - accuracy: 0.9859 - val_loss: 2.1165 - val_accuracy: 0.4923\n",
      "Epoch 400/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1600 - accuracy: 0.9839 - val_loss: 2.1167 - val_accuracy: 0.4923\n",
      "Epoch 401/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1548 - accuracy: 0.9879 - val_loss: 2.1168 - val_accuracy: 0.4923\n",
      "Epoch 402/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1317 - accuracy: 0.9920 - val_loss: 2.1168 - val_accuracy: 0.4923\n",
      "Epoch 403/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1547 - accuracy: 0.9859 - val_loss: 2.1171 - val_accuracy: 0.4923\n",
      "Epoch 404/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1658 - accuracy: 0.9738 - val_loss: 2.1172 - val_accuracy: 0.4923\n",
      "Epoch 405/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1675 - accuracy: 0.9799 - val_loss: 2.1172 - val_accuracy: 0.4923\n",
      "Epoch 406/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1441 - accuracy: 0.9819 - val_loss: 2.1170 - val_accuracy: 0.4923\n",
      "Epoch 407/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1436 - accuracy: 0.9899 - val_loss: 2.1169 - val_accuracy: 0.4923\n",
      "Epoch 408/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1733 - accuracy: 0.9759 - val_loss: 2.1170 - val_accuracy: 0.4923\n",
      "Epoch 409/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1609 - accuracy: 0.9819 - val_loss: 2.1170 - val_accuracy: 0.4923\n",
      "Epoch 410/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1545 - accuracy: 0.9899 - val_loss: 2.1170 - val_accuracy: 0.4923\n",
      "Epoch 411/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1528 - accuracy: 0.9960 - val_loss: 2.1172 - val_accuracy: 0.4923\n",
      "Epoch 412/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1452 - accuracy: 0.9839 - val_loss: 2.1174 - val_accuracy: 0.4923\n",
      "Epoch 413/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1599 - accuracy: 0.9819 - val_loss: 2.1173 - val_accuracy: 0.4923\n",
      "Epoch 414/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1406 - accuracy: 0.9899 - val_loss: 2.1173 - val_accuracy: 0.4923\n",
      "Epoch 415/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1489 - accuracy: 0.9920 - val_loss: 2.1174 - val_accuracy: 0.4923\n",
      "Epoch 416/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1714 - accuracy: 0.9799 - val_loss: 2.1176 - val_accuracy: 0.4923\n",
      "Epoch 417/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1615 - accuracy: 0.9738 - val_loss: 2.1178 - val_accuracy: 0.4923\n",
      "Epoch 418/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1303 - accuracy: 0.9920 - val_loss: 2.1177 - val_accuracy: 0.4923\n",
      "Epoch 419/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1599 - accuracy: 0.9839 - val_loss: 2.1177 - val_accuracy: 0.4923\n",
      "Epoch 420/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1478 - accuracy: 0.9899 - val_loss: 2.1177 - val_accuracy: 0.4923\n",
      "Epoch 421/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1543 - accuracy: 0.9819 - val_loss: 2.1178 - val_accuracy: 0.4923\n",
      "Epoch 422/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1569 - accuracy: 0.9839 - val_loss: 2.1178 - val_accuracy: 0.4923\n",
      "Epoch 423/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1374 - accuracy: 0.9879 - val_loss: 2.1178 - val_accuracy: 0.4923\n",
      "Epoch 424/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1589 - accuracy: 0.9839 - val_loss: 2.1180 - val_accuracy: 0.4923\n",
      "Epoch 425/600\n",
      "497/497 [==============================] - 0s 312us/step - loss: 0.1606 - accuracy: 0.9839 - val_loss: 2.1181 - val_accuracy: 0.4923\n",
      "Epoch 426/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1597 - accuracy: 0.9839 - val_loss: 2.1183 - val_accuracy: 0.4923\n",
      "Epoch 427/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1508 - accuracy: 0.9799 - val_loss: 2.1183 - val_accuracy: 0.4923\n",
      "Epoch 428/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1562 - accuracy: 0.9899 - val_loss: 2.1186 - val_accuracy: 0.4923\n",
      "Epoch 429/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1486 - accuracy: 0.9859 - val_loss: 2.1188 - val_accuracy: 0.4923\n",
      "Epoch 430/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1453 - accuracy: 0.9899 - val_loss: 2.1189 - val_accuracy: 0.4923\n",
      "Epoch 431/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1544 - accuracy: 0.9879 - val_loss: 2.1189 - val_accuracy: 0.4923\n",
      "Epoch 432/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1483 - accuracy: 0.9879 - val_loss: 2.1191 - val_accuracy: 0.4923\n",
      "Epoch 433/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1488 - accuracy: 0.9859 - val_loss: 2.1193 - val_accuracy: 0.4923\n",
      "Epoch 434/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1503 - accuracy: 0.9899 - val_loss: 2.1195 - val_accuracy: 0.4923\n",
      "Epoch 435/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1494 - accuracy: 0.9839 - val_loss: 2.1197 - val_accuracy: 0.4923\n",
      "Epoch 436/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1401 - accuracy: 0.9920 - val_loss: 2.1200 - val_accuracy: 0.4923\n",
      "Epoch 437/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1490 - accuracy: 0.9839 - val_loss: 2.1202 - val_accuracy: 0.4923\n",
      "Epoch 438/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1509 - accuracy: 0.9799 - val_loss: 2.1205 - val_accuracy: 0.4923\n",
      "Epoch 439/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1594 - accuracy: 0.9839 - val_loss: 2.1206 - val_accuracy: 0.4923\n",
      "Epoch 440/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1526 - accuracy: 0.9738 - val_loss: 2.1208 - val_accuracy: 0.4923\n",
      "Epoch 441/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1406 - accuracy: 0.9879 - val_loss: 2.1210 - val_accuracy: 0.4923\n",
      "Epoch 442/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1322 - accuracy: 0.9879 - val_loss: 2.1212 - val_accuracy: 0.4923\n",
      "Epoch 443/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1470 - accuracy: 0.9779 - val_loss: 2.1213 - val_accuracy: 0.4923\n",
      "Epoch 444/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1450 - accuracy: 0.9859 - val_loss: 2.1214 - val_accuracy: 0.4923\n",
      "Epoch 445/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1411 - accuracy: 0.9839 - val_loss: 2.1215 - val_accuracy: 0.4923\n",
      "Epoch 446/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1415 - accuracy: 0.9859 - val_loss: 2.1216 - val_accuracy: 0.4923\n",
      "Epoch 447/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1621 - accuracy: 0.9819 - val_loss: 2.1218 - val_accuracy: 0.4923\n",
      "Epoch 448/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1527 - accuracy: 0.9819 - val_loss: 2.1220 - val_accuracy: 0.4923\n",
      "Epoch 449/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1367 - accuracy: 0.9920 - val_loss: 2.1221 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1441 - accuracy: 0.9879 - val_loss: 2.1222 - val_accuracy: 0.4923\n",
      "Epoch 451/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1416 - accuracy: 0.9879 - val_loss: 2.1224 - val_accuracy: 0.4923\n",
      "Epoch 452/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1552 - accuracy: 0.9899 - val_loss: 2.1227 - val_accuracy: 0.4923\n",
      "Epoch 453/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1721 - accuracy: 0.9859 - val_loss: 2.1228 - val_accuracy: 0.4923\n",
      "Epoch 454/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1437 - accuracy: 0.9859 - val_loss: 2.1230 - val_accuracy: 0.4923\n",
      "Epoch 455/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1361 - accuracy: 0.9879 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 456/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1773 - accuracy: 0.9698 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 457/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1511 - accuracy: 0.9819 - val_loss: 2.1233 - val_accuracy: 0.4923\n",
      "Epoch 458/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1453 - accuracy: 0.9920 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 459/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1427 - accuracy: 0.9980 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 460/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1736 - accuracy: 0.9759 - val_loss: 2.1233 - val_accuracy: 0.4923\n",
      "Epoch 461/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1660 - accuracy: 0.9779 - val_loss: 2.1233 - val_accuracy: 0.4923\n",
      "Epoch 462/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1686 - accuracy: 0.9839 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 463/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1489 - accuracy: 0.9899 - val_loss: 2.1233 - val_accuracy: 0.4923\n",
      "Epoch 464/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1690 - accuracy: 0.9698 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 465/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1339 - accuracy: 0.9899 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 466/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1472 - accuracy: 0.9879 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 467/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1540 - accuracy: 0.9879 - val_loss: 2.1229 - val_accuracy: 0.4923\n",
      "Epoch 468/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1482 - accuracy: 0.9839 - val_loss: 2.1228 - val_accuracy: 0.4923\n",
      "Epoch 469/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1480 - accuracy: 0.9819 - val_loss: 2.1226 - val_accuracy: 0.4923\n",
      "Epoch 470/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1643 - accuracy: 0.9799 - val_loss: 2.1227 - val_accuracy: 0.4923\n",
      "Epoch 471/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1507 - accuracy: 0.9759 - val_loss: 2.1228 - val_accuracy: 0.4923\n",
      "Epoch 472/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1558 - accuracy: 0.9859 - val_loss: 2.1226 - val_accuracy: 0.4923\n",
      "Epoch 473/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1437 - accuracy: 0.9879 - val_loss: 2.1228 - val_accuracy: 0.4923\n",
      "Epoch 474/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1560 - accuracy: 0.9859 - val_loss: 2.1228 - val_accuracy: 0.4923\n",
      "Epoch 475/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1557 - accuracy: 0.9839 - val_loss: 2.1229 - val_accuracy: 0.4923\n",
      "Epoch 476/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1560 - accuracy: 0.9839 - val_loss: 2.1229 - val_accuracy: 0.4923\n",
      "Epoch 477/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1410 - accuracy: 0.9920 - val_loss: 2.1229 - val_accuracy: 0.4923\n",
      "Epoch 478/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1646 - accuracy: 0.9799 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 479/600\n",
      "497/497 [==============================] - 0s 314us/step - loss: 0.1616 - accuracy: 0.9819 - val_loss: 2.1230 - val_accuracy: 0.4923\n",
      "Epoch 480/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1339 - accuracy: 0.9940 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 481/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1341 - accuracy: 0.9859 - val_loss: 2.1230 - val_accuracy: 0.4923\n",
      "Epoch 482/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1512 - accuracy: 0.9799 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 483/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1484 - accuracy: 0.9940 - val_loss: 2.1231 - val_accuracy: 0.4923\n",
      "Epoch 484/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1719 - accuracy: 0.9799 - val_loss: 2.1232 - val_accuracy: 0.4923\n",
      "Epoch 485/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1373 - accuracy: 0.9920 - val_loss: 2.1234 - val_accuracy: 0.4923\n",
      "Epoch 486/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1434 - accuracy: 0.9839 - val_loss: 2.1234 - val_accuracy: 0.4923\n",
      "Epoch 487/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1571 - accuracy: 0.9738 - val_loss: 2.1237 - val_accuracy: 0.4923\n",
      "Epoch 488/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1422 - accuracy: 0.9839 - val_loss: 2.1237 - val_accuracy: 0.4923\n",
      "Epoch 489/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1670 - accuracy: 0.9779 - val_loss: 2.1238 - val_accuracy: 0.4923\n",
      "Epoch 490/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1536 - accuracy: 0.9859 - val_loss: 2.1239 - val_accuracy: 0.4923\n",
      "Epoch 491/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1722 - accuracy: 0.9819 - val_loss: 2.1240 - val_accuracy: 0.4923\n",
      "Epoch 492/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1486 - accuracy: 0.9899 - val_loss: 2.1241 - val_accuracy: 0.4923\n",
      "Epoch 493/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1600 - accuracy: 0.9799 - val_loss: 2.1243 - val_accuracy: 0.4923\n",
      "Epoch 494/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1382 - accuracy: 0.9839 - val_loss: 2.1245 - val_accuracy: 0.4923\n",
      "Epoch 495/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1484 - accuracy: 0.9859 - val_loss: 2.1248 - val_accuracy: 0.4923\n",
      "Epoch 496/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1391 - accuracy: 0.9879 - val_loss: 2.1250 - val_accuracy: 0.4923\n",
      "Epoch 497/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1435 - accuracy: 0.9859 - val_loss: 2.1250 - val_accuracy: 0.4923\n",
      "Epoch 498/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1397 - accuracy: 0.9920 - val_loss: 2.1250 - val_accuracy: 0.4923\n",
      "Epoch 499/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1682 - accuracy: 0.9859 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 500/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1583 - accuracy: 0.9819 - val_loss: 2.1250 - val_accuracy: 0.4923\n",
      "Epoch 501/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1546 - accuracy: 0.9839 - val_loss: 2.1249 - val_accuracy: 0.4923\n",
      "Epoch 502/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1656 - accuracy: 0.9819 - val_loss: 2.1250 - val_accuracy: 0.4923\n",
      "Epoch 503/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1857 - accuracy: 0.9698 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 504/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1553 - accuracy: 0.9799 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 505/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1450 - accuracy: 0.9859 - val_loss: 2.1251 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1507 - accuracy: 0.9839 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 507/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1473 - accuracy: 0.9859 - val_loss: 2.1249 - val_accuracy: 0.4923\n",
      "Epoch 508/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1553 - accuracy: 0.9839 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 509/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1589 - accuracy: 0.9779 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 510/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1601 - accuracy: 0.9839 - val_loss: 2.1253 - val_accuracy: 0.4923\n",
      "Epoch 511/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1457 - accuracy: 0.9879 - val_loss: 2.1253 - val_accuracy: 0.4923\n",
      "Epoch 512/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1719 - accuracy: 0.9839 - val_loss: 2.1252 - val_accuracy: 0.4923\n",
      "Epoch 513/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1488 - accuracy: 0.9799 - val_loss: 2.1252 - val_accuracy: 0.4923\n",
      "Epoch 514/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1440 - accuracy: 0.9859 - val_loss: 2.1253 - val_accuracy: 0.4923\n",
      "Epoch 515/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1414 - accuracy: 0.9859 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 516/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1479 - accuracy: 0.9899 - val_loss: 2.1252 - val_accuracy: 0.4923\n",
      "Epoch 517/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1287 - accuracy: 0.9879 - val_loss: 2.1251 - val_accuracy: 0.4923\n",
      "Epoch 518/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1482 - accuracy: 0.9859 - val_loss: 2.1253 - val_accuracy: 0.4923\n",
      "Epoch 519/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1303 - accuracy: 0.9899 - val_loss: 2.1253 - val_accuracy: 0.4923\n",
      "Epoch 520/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1653 - accuracy: 0.9879 - val_loss: 2.1255 - val_accuracy: 0.4923\n",
      "Epoch 521/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1381 - accuracy: 0.9879 - val_loss: 2.1256 - val_accuracy: 0.4923\n",
      "Epoch 522/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1712 - accuracy: 0.9799 - val_loss: 2.1257 - val_accuracy: 0.4923\n",
      "Epoch 523/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1321 - accuracy: 0.9940 - val_loss: 2.1258 - val_accuracy: 0.4923\n",
      "Epoch 524/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1493 - accuracy: 0.9879 - val_loss: 2.1258 - val_accuracy: 0.4923\n",
      "Epoch 525/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1367 - accuracy: 0.9859 - val_loss: 2.1258 - val_accuracy: 0.4923\n",
      "Epoch 526/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1560 - accuracy: 0.9779 - val_loss: 2.1259 - val_accuracy: 0.4923\n",
      "Epoch 527/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1378 - accuracy: 0.9859 - val_loss: 2.1260 - val_accuracy: 0.4923\n",
      "Epoch 528/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1544 - accuracy: 0.9839 - val_loss: 2.1260 - val_accuracy: 0.4923\n",
      "Epoch 529/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1400 - accuracy: 0.9940 - val_loss: 2.1262 - val_accuracy: 0.4923\n",
      "Epoch 530/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1338 - accuracy: 0.9859 - val_loss: 2.1261 - val_accuracy: 0.4923\n",
      "Epoch 531/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1465 - accuracy: 0.9899 - val_loss: 2.1263 - val_accuracy: 0.4923\n",
      "Epoch 532/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1477 - accuracy: 0.9839 - val_loss: 2.1263 - val_accuracy: 0.4923\n",
      "Epoch 533/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1713 - accuracy: 0.9698 - val_loss: 2.1265 - val_accuracy: 0.4923\n",
      "Epoch 534/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1554 - accuracy: 0.9839 - val_loss: 2.1264 - val_accuracy: 0.4923\n",
      "Epoch 535/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1474 - accuracy: 0.9839 - val_loss: 2.1264 - val_accuracy: 0.4923\n",
      "Epoch 536/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1428 - accuracy: 0.9859 - val_loss: 2.1267 - val_accuracy: 0.4923\n",
      "Epoch 537/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1432 - accuracy: 0.9879 - val_loss: 2.1266 - val_accuracy: 0.4923\n",
      "Epoch 538/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1436 - accuracy: 0.9899 - val_loss: 2.1266 - val_accuracy: 0.4923\n",
      "Epoch 539/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1237 - accuracy: 0.9940 - val_loss: 2.1267 - val_accuracy: 0.4923\n",
      "Epoch 540/600\n",
      "497/497 [==============================] - 0s 354us/step - loss: 0.1678 - accuracy: 0.9779 - val_loss: 2.1269 - val_accuracy: 0.4923\n",
      "Epoch 541/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1533 - accuracy: 0.9859 - val_loss: 2.1268 - val_accuracy: 0.4923\n",
      "Epoch 542/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1287 - accuracy: 0.9859 - val_loss: 2.1270 - val_accuracy: 0.4923\n",
      "Epoch 543/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1507 - accuracy: 0.9779 - val_loss: 2.1271 - val_accuracy: 0.4923\n",
      "Epoch 544/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1608 - accuracy: 0.9799 - val_loss: 2.1274 - val_accuracy: 0.4923\n",
      "Epoch 545/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1552 - accuracy: 0.9899 - val_loss: 2.1275 - val_accuracy: 0.4923\n",
      "Epoch 546/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1219 - accuracy: 0.9879 - val_loss: 2.1277 - val_accuracy: 0.4923\n",
      "Epoch 547/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1477 - accuracy: 0.9859 - val_loss: 2.1281 - val_accuracy: 0.4923\n",
      "Epoch 548/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1382 - accuracy: 0.9879 - val_loss: 2.1284 - val_accuracy: 0.4923\n",
      "Epoch 549/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1485 - accuracy: 0.9819 - val_loss: 2.1287 - val_accuracy: 0.4923\n",
      "Epoch 550/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1337 - accuracy: 0.9920 - val_loss: 2.1290 - val_accuracy: 0.4923\n",
      "Epoch 551/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1355 - accuracy: 0.9839 - val_loss: 2.1291 - val_accuracy: 0.4923\n",
      "Epoch 552/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1470 - accuracy: 0.9899 - val_loss: 2.1293 - val_accuracy: 0.4923\n",
      "Epoch 553/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1711 - accuracy: 0.9779 - val_loss: 2.1294 - val_accuracy: 0.4923\n",
      "Epoch 554/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1449 - accuracy: 0.9799 - val_loss: 2.1295 - val_accuracy: 0.4923\n",
      "Epoch 555/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1470 - accuracy: 0.9839 - val_loss: 2.1299 - val_accuracy: 0.4923\n",
      "Epoch 556/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1356 - accuracy: 0.9879 - val_loss: 2.1300 - val_accuracy: 0.4923\n",
      "Epoch 557/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1509 - accuracy: 0.9779 - val_loss: 2.1302 - val_accuracy: 0.4923\n",
      "Epoch 558/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1611 - accuracy: 0.9718 - val_loss: 2.1302 - val_accuracy: 0.4923\n",
      "Epoch 559/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1337 - accuracy: 0.9920 - val_loss: 2.1302 - val_accuracy: 0.4923\n",
      "Epoch 560/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1608 - accuracy: 0.9879 - val_loss: 2.1305 - val_accuracy: 0.4923\n",
      "Epoch 561/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1510 - accuracy: 0.9859 - val_loss: 2.1307 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 562/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1618 - accuracy: 0.9779 - val_loss: 2.1310 - val_accuracy: 0.4923\n",
      "Epoch 563/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1358 - accuracy: 0.9899 - val_loss: 2.1311 - val_accuracy: 0.4923\n",
      "Epoch 564/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1515 - accuracy: 0.9879 - val_loss: 2.1313 - val_accuracy: 0.4923\n",
      "Epoch 565/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1467 - accuracy: 0.9839 - val_loss: 2.1313 - val_accuracy: 0.4923\n",
      "Epoch 566/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1428 - accuracy: 0.9879 - val_loss: 2.1313 - val_accuracy: 0.4923\n",
      "Epoch 567/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1578 - accuracy: 0.9799 - val_loss: 2.1316 - val_accuracy: 0.4923\n",
      "Epoch 568/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1407 - accuracy: 0.9879 - val_loss: 2.1318 - val_accuracy: 0.4923\n",
      "Epoch 569/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1518 - accuracy: 0.9839 - val_loss: 2.1318 - val_accuracy: 0.4923\n",
      "Epoch 570/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1388 - accuracy: 0.9859 - val_loss: 2.1319 - val_accuracy: 0.4923\n",
      "Epoch 571/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1430 - accuracy: 0.9859 - val_loss: 2.1321 - val_accuracy: 0.4923\n",
      "Epoch 572/600\n",
      "497/497 [==============================] - 0s 314us/step - loss: 0.1526 - accuracy: 0.9779 - val_loss: 2.1322 - val_accuracy: 0.4923\n",
      "Epoch 573/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1607 - accuracy: 0.9799 - val_loss: 2.1323 - val_accuracy: 0.4923\n",
      "Epoch 574/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1552 - accuracy: 0.9799 - val_loss: 2.1325 - val_accuracy: 0.4923\n",
      "Epoch 575/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1614 - accuracy: 0.9859 - val_loss: 2.1325 - val_accuracy: 0.4923\n",
      "Epoch 576/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1535 - accuracy: 0.9759 - val_loss: 2.1325 - val_accuracy: 0.4923\n",
      "Epoch 577/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1468 - accuracy: 0.9859 - val_loss: 2.1326 - val_accuracy: 0.4923\n",
      "Epoch 578/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1289 - accuracy: 0.9859 - val_loss: 2.1325 - val_accuracy: 0.4923\n",
      "Epoch 579/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1756 - accuracy: 0.9678 - val_loss: 2.1328 - val_accuracy: 0.4923\n",
      "Epoch 580/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1460 - accuracy: 0.9839 - val_loss: 2.1329 - val_accuracy: 0.4923\n",
      "Epoch 581/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1581 - accuracy: 0.9859 - val_loss: 2.1330 - val_accuracy: 0.4923\n",
      "Epoch 582/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1383 - accuracy: 0.9879 - val_loss: 2.1328 - val_accuracy: 0.4923\n",
      "Epoch 583/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1644 - accuracy: 0.9819 - val_loss: 2.1328 - val_accuracy: 0.4923\n",
      "Epoch 584/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1545 - accuracy: 0.9799 - val_loss: 2.1329 - val_accuracy: 0.4923\n",
      "Epoch 585/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1395 - accuracy: 0.9859 - val_loss: 2.1330 - val_accuracy: 0.4923\n",
      "Epoch 586/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1650 - accuracy: 0.9738 - val_loss: 2.1331 - val_accuracy: 0.4923\n",
      "Epoch 587/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1561 - accuracy: 0.9859 - val_loss: 2.1331 - val_accuracy: 0.4923\n",
      "Epoch 588/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1651 - accuracy: 0.9759 - val_loss: 2.1331 - val_accuracy: 0.4923\n",
      "Epoch 589/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1485 - accuracy: 0.9859 - val_loss: 2.1332 - val_accuracy: 0.4923\n",
      "Epoch 590/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1391 - accuracy: 0.9899 - val_loss: 2.1331 - val_accuracy: 0.4923\n",
      "Epoch 591/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1564 - accuracy: 0.9839 - val_loss: 2.1331 - val_accuracy: 0.4923\n",
      "Epoch 592/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1495 - accuracy: 0.9879 - val_loss: 2.1330 - val_accuracy: 0.4923\n",
      "Epoch 593/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1258 - accuracy: 0.9899 - val_loss: 2.1328 - val_accuracy: 0.4923\n",
      "Epoch 594/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1370 - accuracy: 0.9899 - val_loss: 2.1326 - val_accuracy: 0.4923\n",
      "Epoch 595/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1453 - accuracy: 0.9799 - val_loss: 2.1323 - val_accuracy: 0.4923\n",
      "Epoch 596/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1546 - accuracy: 0.9839 - val_loss: 2.1321 - val_accuracy: 0.4923\n",
      "Epoch 597/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1644 - accuracy: 0.9759 - val_loss: 2.1320 - val_accuracy: 0.4923\n",
      "Epoch 598/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1501 - accuracy: 0.9859 - val_loss: 2.1319 - val_accuracy: 0.4923\n",
      "Epoch 599/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1416 - accuracy: 0.9879 - val_loss: 2.1317 - val_accuracy: 0.4923\n",
      "Epoch 600/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1499 - accuracy: 0.9779 - val_loss: 2.1316 - val_accuracy: 0.4923\n",
      "Train on 497 samples, validate on 195 samples\n",
      "Epoch 1/600\n",
      "497/497 [==============================] - 4s 7ms/step - loss: 0.1413 - accuracy: 0.9819 - val_loss: 2.1188 - val_accuracy: 0.4974\n",
      "Epoch 2/600\n",
      "497/497 [==============================] - 0s 379us/step - loss: 0.1360 - accuracy: 0.9879 - val_loss: 2.1128 - val_accuracy: 0.4974\n",
      "Epoch 3/600\n",
      "497/497 [==============================] - 0s 390us/step - loss: 0.1601 - accuracy: 0.9879 - val_loss: 2.1150 - val_accuracy: 0.4974\n",
      "Epoch 4/600\n",
      "497/497 [==============================] - 0s 359us/step - loss: 0.1614 - accuracy: 0.9899 - val_loss: 2.1186 - val_accuracy: 0.4974\n",
      "Epoch 5/600\n",
      "497/497 [==============================] - 0s 364us/step - loss: 0.1578 - accuracy: 0.9879 - val_loss: 2.1234 - val_accuracy: 0.5026\n",
      "Epoch 6/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1660 - accuracy: 0.9698 - val_loss: 2.1303 - val_accuracy: 0.4923\n",
      "Epoch 7/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1690 - accuracy: 0.9839 - val_loss: 2.1400 - val_accuracy: 0.4872\n",
      "Epoch 8/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1537 - accuracy: 0.9859 - val_loss: 2.1426 - val_accuracy: 0.4872\n",
      "Epoch 9/600\n",
      "497/497 [==============================] - 0s 351us/step - loss: 0.1635 - accuracy: 0.9819 - val_loss: 2.1449 - val_accuracy: 0.4872\n",
      "Epoch 10/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1532 - accuracy: 0.9839 - val_loss: 2.1447 - val_accuracy: 0.4872\n",
      "Epoch 11/600\n",
      "497/497 [==============================] - 0s 354us/step - loss: 0.1548 - accuracy: 0.9879 - val_loss: 2.1441 - val_accuracy: 0.4872\n",
      "Epoch 12/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1289 - accuracy: 0.9920 - val_loss: 2.1438 - val_accuracy: 0.4872\n",
      "Epoch 13/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1373 - accuracy: 0.9879 - val_loss: 2.1451 - val_accuracy: 0.4821\n",
      "Epoch 14/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1455 - accuracy: 0.9819 - val_loss: 2.1447 - val_accuracy: 0.4821\n",
      "Epoch 15/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1400 - accuracy: 0.9859 - val_loss: 2.1440 - val_accuracy: 0.4769\n",
      "Epoch 16/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1339 - accuracy: 0.9940 - val_loss: 2.1437 - val_accuracy: 0.4821\n",
      "Epoch 17/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1308 - accuracy: 0.9859 - val_loss: 2.1433 - val_accuracy: 0.4821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1466 - accuracy: 0.9839 - val_loss: 2.1438 - val_accuracy: 0.4821\n",
      "Epoch 19/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1506 - accuracy: 0.9819 - val_loss: 2.1438 - val_accuracy: 0.4821\n",
      "Epoch 20/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1314 - accuracy: 0.9899 - val_loss: 2.1436 - val_accuracy: 0.4821\n",
      "Epoch 21/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1548 - accuracy: 0.9799 - val_loss: 2.1433 - val_accuracy: 0.4769\n",
      "Epoch 22/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1504 - accuracy: 0.9839 - val_loss: 2.1427 - val_accuracy: 0.4769\n",
      "Epoch 23/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1491 - accuracy: 0.9859 - val_loss: 2.1413 - val_accuracy: 0.4769\n",
      "Epoch 24/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1273 - accuracy: 0.9920 - val_loss: 2.1400 - val_accuracy: 0.4769\n",
      "Epoch 25/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1473 - accuracy: 0.9799 - val_loss: 2.1382 - val_accuracy: 0.4821\n",
      "Epoch 26/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1381 - accuracy: 0.9920 - val_loss: 2.1367 - val_accuracy: 0.4821\n",
      "Epoch 27/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1370 - accuracy: 0.9899 - val_loss: 2.1349 - val_accuracy: 0.4872\n",
      "Epoch 28/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1587 - accuracy: 0.9779 - val_loss: 2.1333 - val_accuracy: 0.4872\n",
      "Epoch 29/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1334 - accuracy: 0.9920 - val_loss: 2.1325 - val_accuracy: 0.4872\n",
      "Epoch 30/600\n",
      "497/497 [==============================] - 0s 354us/step - loss: 0.1264 - accuracy: 0.9940 - val_loss: 2.1321 - val_accuracy: 0.4872\n",
      "Epoch 31/600\n",
      "497/497 [==============================] - 0s 316us/step - loss: 0.1507 - accuracy: 0.9799 - val_loss: 2.1320 - val_accuracy: 0.4872\n",
      "Epoch 32/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1428 - accuracy: 0.9839 - val_loss: 2.1319 - val_accuracy: 0.4872\n",
      "Epoch 33/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1474 - accuracy: 0.9879 - val_loss: 2.1321 - val_accuracy: 0.4872\n",
      "Epoch 34/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1437 - accuracy: 0.9859 - val_loss: 2.1322 - val_accuracy: 0.4872\n",
      "Epoch 35/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1509 - accuracy: 0.9899 - val_loss: 2.1321 - val_accuracy: 0.4872\n",
      "Epoch 36/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1233 - accuracy: 0.9980 - val_loss: 2.1324 - val_accuracy: 0.4872\n",
      "Epoch 37/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1387 - accuracy: 0.9839 - val_loss: 2.1327 - val_accuracy: 0.4872\n",
      "Epoch 38/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1280 - accuracy: 0.9879 - val_loss: 2.1336 - val_accuracy: 0.4872\n",
      "Epoch 39/600\n",
      "497/497 [==============================] - 0s 351us/step - loss: 0.1453 - accuracy: 0.9799 - val_loss: 2.1341 - val_accuracy: 0.4821\n",
      "Epoch 40/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1435 - accuracy: 0.9839 - val_loss: 2.1349 - val_accuracy: 0.4821\n",
      "Epoch 41/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1217 - accuracy: 0.9920 - val_loss: 2.1357 - val_accuracy: 0.4821\n",
      "Epoch 42/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1360 - accuracy: 0.9859 - val_loss: 2.1368 - val_accuracy: 0.4821\n",
      "Epoch 43/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1253 - accuracy: 0.9920 - val_loss: 2.1379 - val_accuracy: 0.4821\n",
      "Epoch 44/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1438 - accuracy: 0.9839 - val_loss: 2.1392 - val_accuracy: 0.4821\n",
      "Epoch 45/600\n",
      "497/497 [==============================] - 0s 353us/step - loss: 0.1381 - accuracy: 0.9839 - val_loss: 2.1403 - val_accuracy: 0.4821\n",
      "Epoch 46/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1375 - accuracy: 0.9819 - val_loss: 2.1415 - val_accuracy: 0.4872\n",
      "Epoch 47/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1268 - accuracy: 0.9940 - val_loss: 2.1420 - val_accuracy: 0.4872\n",
      "Epoch 48/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1281 - accuracy: 0.9879 - val_loss: 2.1425 - val_accuracy: 0.4872\n",
      "Epoch 49/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1437 - accuracy: 0.9799 - val_loss: 2.1428 - val_accuracy: 0.4872\n",
      "Epoch 50/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1551 - accuracy: 0.9799 - val_loss: 2.1429 - val_accuracy: 0.4872\n",
      "Epoch 51/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1161 - accuracy: 0.9920 - val_loss: 2.1430 - val_accuracy: 0.4872\n",
      "Epoch 52/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1294 - accuracy: 0.9879 - val_loss: 2.1432 - val_accuracy: 0.4872\n",
      "Epoch 53/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1478 - accuracy: 0.9899 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 54/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1506 - accuracy: 0.9799 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 55/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1303 - accuracy: 0.9879 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 56/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1306 - accuracy: 0.9920 - val_loss: 2.1433 - val_accuracy: 0.4872\n",
      "Epoch 57/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1338 - accuracy: 0.9920 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 58/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1321 - accuracy: 0.9839 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 59/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1322 - accuracy: 0.9920 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 60/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1299 - accuracy: 0.9859 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 61/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1541 - accuracy: 0.9859 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 62/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1251 - accuracy: 0.9940 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 63/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1120 - accuracy: 0.9980 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 64/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1337 - accuracy: 0.9799 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 65/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1473 - accuracy: 0.9738 - val_loss: 2.1433 - val_accuracy: 0.4872\n",
      "Epoch 66/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1428 - accuracy: 0.9819 - val_loss: 2.1435 - val_accuracy: 0.4872\n",
      "Epoch 67/600\n",
      "497/497 [==============================] - 0s 369us/step - loss: 0.1298 - accuracy: 0.9920 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 68/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1425 - accuracy: 0.9819 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 69/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1505 - accuracy: 0.9839 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 70/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1461 - accuracy: 0.9819 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 71/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1356 - accuracy: 0.9859 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 72/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1119 - accuracy: 0.9980 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 73/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1583 - accuracy: 0.9799 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 74/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1287 - accuracy: 0.9859 - val_loss: 2.1445 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1181 - accuracy: 0.9980 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 76/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1300 - accuracy: 0.9879 - val_loss: 2.1447 - val_accuracy: 0.4872\n",
      "Epoch 77/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1409 - accuracy: 0.9799 - val_loss: 2.1448 - val_accuracy: 0.4872\n",
      "Epoch 78/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1325 - accuracy: 0.9920 - val_loss: 2.1448 - val_accuracy: 0.4872\n",
      "Epoch 79/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1221 - accuracy: 0.9940 - val_loss: 2.1447 - val_accuracy: 0.4872\n",
      "Epoch 80/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1450 - accuracy: 0.9859 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 81/600\n",
      "497/497 [==============================] - 0s 354us/step - loss: 0.1415 - accuracy: 0.9799 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 82/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 0.1539 - accuracy: 0.9799 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 83/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1243 - accuracy: 0.9960 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 84/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1303 - accuracy: 0.9899 - val_loss: 2.1444 - val_accuracy: 0.4872\n",
      "Epoch 85/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1310 - accuracy: 0.9819 - val_loss: 2.1444 - val_accuracy: 0.4872\n",
      "Epoch 86/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1211 - accuracy: 0.9940 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 87/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1187 - accuracy: 0.9940 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 88/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1342 - accuracy: 0.9799 - val_loss: 2.1449 - val_accuracy: 0.4872\n",
      "Epoch 89/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1632 - accuracy: 0.9738 - val_loss: 2.1450 - val_accuracy: 0.4872\n",
      "Epoch 90/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1410 - accuracy: 0.9859 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 91/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1375 - accuracy: 0.9899 - val_loss: 2.1452 - val_accuracy: 0.4872\n",
      "Epoch 92/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1356 - accuracy: 0.9839 - val_loss: 2.1450 - val_accuracy: 0.4872\n",
      "Epoch 93/600\n",
      "497/497 [==============================] - 0s 351us/step - loss: 0.1264 - accuracy: 0.9859 - val_loss: 2.1447 - val_accuracy: 0.4872\n",
      "Epoch 94/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1298 - accuracy: 0.9899 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 95/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1313 - accuracy: 0.9899 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 96/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1397 - accuracy: 0.9799 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 97/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1502 - accuracy: 0.9759 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 98/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1330 - accuracy: 0.9920 - val_loss: 2.1441 - val_accuracy: 0.4872\n",
      "Epoch 99/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1142 - accuracy: 0.9920 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 100/600\n",
      "497/497 [==============================] - 0s 354us/step - loss: 0.1209 - accuracy: 0.9859 - val_loss: 2.1443 - val_accuracy: 0.4872\n",
      "Epoch 101/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1138 - accuracy: 0.9920 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 102/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1212 - accuracy: 0.9940 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 103/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1476 - accuracy: 0.9779 - val_loss: 2.1438 - val_accuracy: 0.4872\n",
      "Epoch 104/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1358 - accuracy: 0.9920 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 105/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1594 - accuracy: 0.9879 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 106/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1341 - accuracy: 0.9879 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 107/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1311 - accuracy: 0.9859 - val_loss: 2.1433 - val_accuracy: 0.4872\n",
      "Epoch 108/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1397 - accuracy: 0.9839 - val_loss: 2.1432 - val_accuracy: 0.4872\n",
      "Epoch 109/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1112 - accuracy: 0.9940 - val_loss: 2.1430 - val_accuracy: 0.4872\n",
      "Epoch 110/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1408 - accuracy: 0.9879 - val_loss: 2.1428 - val_accuracy: 0.4872\n",
      "Epoch 111/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1367 - accuracy: 0.9920 - val_loss: 2.1426 - val_accuracy: 0.4872\n",
      "Epoch 112/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1462 - accuracy: 0.9839 - val_loss: 2.1425 - val_accuracy: 0.4872\n",
      "Epoch 113/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1305 - accuracy: 0.9859 - val_loss: 2.1425 - val_accuracy: 0.4872\n",
      "Epoch 114/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1390 - accuracy: 0.9839 - val_loss: 2.1425 - val_accuracy: 0.4872\n",
      "Epoch 115/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1439 - accuracy: 0.9839 - val_loss: 2.1425 - val_accuracy: 0.4872\n",
      "Epoch 116/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1154 - accuracy: 0.9960 - val_loss: 2.1423 - val_accuracy: 0.4872\n",
      "Epoch 117/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1281 - accuracy: 0.9859 - val_loss: 2.1422 - val_accuracy: 0.4872\n",
      "Epoch 118/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1334 - accuracy: 0.9839 - val_loss: 2.1424 - val_accuracy: 0.4872\n",
      "Epoch 119/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1532 - accuracy: 0.9759 - val_loss: 2.1421 - val_accuracy: 0.4872\n",
      "Epoch 120/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1287 - accuracy: 0.9920 - val_loss: 2.1420 - val_accuracy: 0.4872\n",
      "Epoch 121/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1454 - accuracy: 0.9920 - val_loss: 2.1420 - val_accuracy: 0.4872\n",
      "Epoch 122/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1138 - accuracy: 0.9980 - val_loss: 2.1419 - val_accuracy: 0.4872\n",
      "Epoch 123/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1302 - accuracy: 0.9940 - val_loss: 2.1415 - val_accuracy: 0.4872\n",
      "Epoch 124/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1233 - accuracy: 0.9920 - val_loss: 2.1414 - val_accuracy: 0.4872\n",
      "Epoch 125/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1190 - accuracy: 0.9920 - val_loss: 2.1412 - val_accuracy: 0.4872\n",
      "Epoch 126/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1456 - accuracy: 0.9899 - val_loss: 2.1409 - val_accuracy: 0.4872\n",
      "Epoch 127/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1093 - accuracy: 0.9940 - val_loss: 2.1408 - val_accuracy: 0.4872\n",
      "Epoch 128/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1211 - accuracy: 0.9859 - val_loss: 2.1405 - val_accuracy: 0.4872\n",
      "Epoch 129/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1189 - accuracy: 0.9879 - val_loss: 2.1402 - val_accuracy: 0.4872\n",
      "Epoch 130/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1433 - accuracy: 0.9839 - val_loss: 2.1402 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1235 - accuracy: 0.9920 - val_loss: 2.1403 - val_accuracy: 0.4872\n",
      "Epoch 132/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1340 - accuracy: 0.9920 - val_loss: 2.1403 - val_accuracy: 0.4872\n",
      "Epoch 133/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1180 - accuracy: 0.9920 - val_loss: 2.1402 - val_accuracy: 0.4872\n",
      "Epoch 134/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1491 - accuracy: 0.9879 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 135/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1399 - accuracy: 0.9839 - val_loss: 2.1399 - val_accuracy: 0.4872\n",
      "Epoch 136/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1175 - accuracy: 0.9819 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 137/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1176 - accuracy: 0.9920 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 138/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1405 - accuracy: 0.9819 - val_loss: 2.1399 - val_accuracy: 0.4872\n",
      "Epoch 139/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1352 - accuracy: 0.9899 - val_loss: 2.1398 - val_accuracy: 0.4872\n",
      "Epoch 140/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1236 - accuracy: 0.9879 - val_loss: 2.1397 - val_accuracy: 0.4872\n",
      "Epoch 141/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1355 - accuracy: 0.9839 - val_loss: 2.1397 - val_accuracy: 0.4872\n",
      "Epoch 142/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1414 - accuracy: 0.9920 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 143/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1344 - accuracy: 0.9879 - val_loss: 2.1405 - val_accuracy: 0.4872\n",
      "Epoch 144/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1441 - accuracy: 0.9920 - val_loss: 2.1407 - val_accuracy: 0.4872\n",
      "Epoch 145/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1332 - accuracy: 0.9819 - val_loss: 2.1412 - val_accuracy: 0.4872\n",
      "Epoch 146/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1094 - accuracy: 0.9920 - val_loss: 2.1415 - val_accuracy: 0.4872\n",
      "Epoch 147/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1532 - accuracy: 0.9799 - val_loss: 2.1416 - val_accuracy: 0.4872\n",
      "Epoch 148/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1335 - accuracy: 0.9859 - val_loss: 2.1418 - val_accuracy: 0.4872\n",
      "Epoch 149/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1282 - accuracy: 0.9839 - val_loss: 2.1421 - val_accuracy: 0.4872\n",
      "Epoch 150/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1320 - accuracy: 0.9899 - val_loss: 2.1422 - val_accuracy: 0.4872\n",
      "Epoch 151/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1475 - accuracy: 0.9839 - val_loss: 2.1424 - val_accuracy: 0.4872\n",
      "Epoch 152/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1213 - accuracy: 0.9899 - val_loss: 2.1426 - val_accuracy: 0.4872\n",
      "Epoch 153/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1269 - accuracy: 0.9799 - val_loss: 2.1427 - val_accuracy: 0.4872\n",
      "Epoch 154/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1300 - accuracy: 0.9879 - val_loss: 2.1429 - val_accuracy: 0.4872\n",
      "Epoch 155/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1381 - accuracy: 0.9819 - val_loss: 2.1431 - val_accuracy: 0.4872\n",
      "Epoch 156/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1441 - accuracy: 0.9859 - val_loss: 2.1431 - val_accuracy: 0.4872\n",
      "Epoch 157/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1443 - accuracy: 0.9859 - val_loss: 2.1431 - val_accuracy: 0.4872\n",
      "Epoch 158/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1355 - accuracy: 0.9839 - val_loss: 2.1431 - val_accuracy: 0.4872\n",
      "Epoch 159/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1493 - accuracy: 0.9738 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 160/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1354 - accuracy: 0.9819 - val_loss: 2.1433 - val_accuracy: 0.4872\n",
      "Epoch 161/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1155 - accuracy: 0.9940 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 162/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1137 - accuracy: 0.9920 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 163/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1291 - accuracy: 0.9899 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 164/600\n",
      "497/497 [==============================] - 0s 355us/step - loss: 0.1388 - accuracy: 0.9819 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 165/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1310 - accuracy: 0.9879 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 166/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1341 - accuracy: 0.9920 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 167/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1470 - accuracy: 0.9819 - val_loss: 2.1438 - val_accuracy: 0.4872\n",
      "Epoch 168/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1226 - accuracy: 0.9960 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 169/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1198 - accuracy: 0.9920 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 170/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1291 - accuracy: 0.9899 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 171/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1313 - accuracy: 0.9940 - val_loss: 2.1433 - val_accuracy: 0.4872\n",
      "Epoch 172/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1665 - accuracy: 0.9799 - val_loss: 2.1437 - val_accuracy: 0.4872\n",
      "Epoch 173/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1193 - accuracy: 0.9940 - val_loss: 2.1437 - val_accuracy: 0.4872\n",
      "Epoch 174/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1232 - accuracy: 0.9899 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 175/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1083 - accuracy: 0.9920 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 176/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1398 - accuracy: 0.9859 - val_loss: 2.1443 - val_accuracy: 0.4872\n",
      "Epoch 177/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1316 - accuracy: 0.9920 - val_loss: 2.1444 - val_accuracy: 0.4872\n",
      "Epoch 178/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1330 - accuracy: 0.9899 - val_loss: 2.1449 - val_accuracy: 0.4872\n",
      "Epoch 179/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1363 - accuracy: 0.9920 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 180/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1331 - accuracy: 0.9839 - val_loss: 2.1453 - val_accuracy: 0.4872\n",
      "Epoch 181/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1327 - accuracy: 0.9839 - val_loss: 2.1454 - val_accuracy: 0.4872\n",
      "Epoch 182/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1260 - accuracy: 0.9920 - val_loss: 2.1455 - val_accuracy: 0.4872\n",
      "Epoch 183/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1292 - accuracy: 0.9920 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 184/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1250 - accuracy: 0.9920 - val_loss: 2.1457 - val_accuracy: 0.4872\n",
      "Epoch 185/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1372 - accuracy: 0.9879 - val_loss: 2.1457 - val_accuracy: 0.4872\n",
      "Epoch 186/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1192 - accuracy: 0.9920 - val_loss: 2.1456 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/600\n",
      "497/497 [==============================] - 0s 317us/step - loss: 0.1276 - accuracy: 0.9879 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 188/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1196 - accuracy: 0.9839 - val_loss: 2.1462 - val_accuracy: 0.4872\n",
      "Epoch 189/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1302 - accuracy: 0.9859 - val_loss: 2.1464 - val_accuracy: 0.4872\n",
      "Epoch 190/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1313 - accuracy: 0.9819 - val_loss: 2.1467 - val_accuracy: 0.4872\n",
      "Epoch 191/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1328 - accuracy: 0.9899 - val_loss: 2.1470 - val_accuracy: 0.4872\n",
      "Epoch 192/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1497 - accuracy: 0.9819 - val_loss: 2.1470 - val_accuracy: 0.4872\n",
      "Epoch 193/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1160 - accuracy: 0.9899 - val_loss: 2.1472 - val_accuracy: 0.4872\n",
      "Epoch 194/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1178 - accuracy: 0.9920 - val_loss: 2.1472 - val_accuracy: 0.4872\n",
      "Epoch 195/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1321 - accuracy: 0.9920 - val_loss: 2.1471 - val_accuracy: 0.4872\n",
      "Epoch 196/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1238 - accuracy: 0.9859 - val_loss: 2.1472 - val_accuracy: 0.4872\n",
      "Epoch 197/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1223 - accuracy: 0.9960 - val_loss: 2.1474 - val_accuracy: 0.4872\n",
      "Epoch 198/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1298 - accuracy: 0.9920 - val_loss: 2.1475 - val_accuracy: 0.4872\n",
      "Epoch 199/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1213 - accuracy: 0.9879 - val_loss: 2.1473 - val_accuracy: 0.4872\n",
      "Epoch 200/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1378 - accuracy: 0.9819 - val_loss: 2.1473 - val_accuracy: 0.4872\n",
      "Epoch 201/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1295 - accuracy: 0.9839 - val_loss: 2.1472 - val_accuracy: 0.4872\n",
      "Epoch 202/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1257 - accuracy: 0.9920 - val_loss: 2.1470 - val_accuracy: 0.4872\n",
      "Epoch 203/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1054 - accuracy: 0.9920 - val_loss: 2.1469 - val_accuracy: 0.4872\n",
      "Epoch 204/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1247 - accuracy: 0.9839 - val_loss: 2.1468 - val_accuracy: 0.4872\n",
      "Epoch 205/600\n",
      "497/497 [==============================] - 0s 349us/step - loss: 0.1386 - accuracy: 0.9859 - val_loss: 2.1466 - val_accuracy: 0.4872\n",
      "Epoch 206/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1461 - accuracy: 0.9899 - val_loss: 2.1464 - val_accuracy: 0.4872\n",
      "Epoch 207/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1304 - accuracy: 0.9879 - val_loss: 2.1462 - val_accuracy: 0.4872\n",
      "Epoch 208/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1210 - accuracy: 0.9859 - val_loss: 2.1459 - val_accuracy: 0.4872\n",
      "Epoch 209/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1344 - accuracy: 0.9859 - val_loss: 2.1456 - val_accuracy: 0.4872\n",
      "Epoch 210/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1389 - accuracy: 0.9920 - val_loss: 2.1450 - val_accuracy: 0.4872\n",
      "Epoch 211/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1270 - accuracy: 0.9920 - val_loss: 2.1449 - val_accuracy: 0.4872\n",
      "Epoch 212/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1451 - accuracy: 0.9799 - val_loss: 2.1445 - val_accuracy: 0.4872\n",
      "Epoch 213/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1319 - accuracy: 0.9839 - val_loss: 2.1443 - val_accuracy: 0.4872\n",
      "Epoch 214/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1294 - accuracy: 0.9839 - val_loss: 2.1441 - val_accuracy: 0.4872\n",
      "Epoch 215/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.0991 - accuracy: 0.9980 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 216/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1429 - accuracy: 0.9799 - val_loss: 2.1437 - val_accuracy: 0.4872\n",
      "Epoch 217/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1108 - accuracy: 0.9960 - val_loss: 2.1438 - val_accuracy: 0.4872\n",
      "Epoch 218/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1235 - accuracy: 0.9839 - val_loss: 2.1440 - val_accuracy: 0.4872\n",
      "Epoch 219/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1261 - accuracy: 0.9899 - val_loss: 2.1442 - val_accuracy: 0.4872\n",
      "Epoch 220/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1275 - accuracy: 0.9839 - val_loss: 2.1444 - val_accuracy: 0.4872\n",
      "Epoch 221/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1415 - accuracy: 0.9839 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 222/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1330 - accuracy: 0.9920 - val_loss: 2.1448 - val_accuracy: 0.4872\n",
      "Epoch 223/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1452 - accuracy: 0.9879 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 224/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1404 - accuracy: 0.9779 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 225/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1209 - accuracy: 0.9879 - val_loss: 2.1454 - val_accuracy: 0.4872\n",
      "Epoch 226/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1155 - accuracy: 0.9920 - val_loss: 2.1455 - val_accuracy: 0.4872\n",
      "Epoch 227/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1339 - accuracy: 0.9859 - val_loss: 2.1457 - val_accuracy: 0.4872\n",
      "Epoch 228/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1358 - accuracy: 0.9859 - val_loss: 2.1457 - val_accuracy: 0.4872\n",
      "Epoch 229/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1263 - accuracy: 0.9819 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 230/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1475 - accuracy: 0.9738 - val_loss: 2.1459 - val_accuracy: 0.4872\n",
      "Epoch 231/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1241 - accuracy: 0.9920 - val_loss: 2.1454 - val_accuracy: 0.4872\n",
      "Epoch 232/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1253 - accuracy: 0.9960 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 233/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1347 - accuracy: 0.9819 - val_loss: 2.1452 - val_accuracy: 0.4872\n",
      "Epoch 234/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1075 - accuracy: 0.9960 - val_loss: 2.1454 - val_accuracy: 0.4872\n",
      "Epoch 235/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1375 - accuracy: 0.9839 - val_loss: 2.1455 - val_accuracy: 0.4872\n",
      "Epoch 236/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1414 - accuracy: 0.9879 - val_loss: 2.1456 - val_accuracy: 0.4872\n",
      "Epoch 237/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1492 - accuracy: 0.9859 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 238/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1288 - accuracy: 0.9899 - val_loss: 2.1461 - val_accuracy: 0.4872\n",
      "Epoch 239/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1199 - accuracy: 0.9960 - val_loss: 2.1461 - val_accuracy: 0.4872\n",
      "Epoch 240/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1187 - accuracy: 0.9940 - val_loss: 2.1461 - val_accuracy: 0.4872\n",
      "Epoch 241/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1229 - accuracy: 0.9879 - val_loss: 2.1459 - val_accuracy: 0.4872\n",
      "Epoch 242/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1290 - accuracy: 0.9920 - val_loss: 2.1457 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1174 - accuracy: 0.9899 - val_loss: 2.1454 - val_accuracy: 0.4872\n",
      "Epoch 244/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1179 - accuracy: 0.9920 - val_loss: 2.1451 - val_accuracy: 0.4872\n",
      "Epoch 245/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1357 - accuracy: 0.9899 - val_loss: 2.1450 - val_accuracy: 0.4872\n",
      "Epoch 246/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1213 - accuracy: 0.9859 - val_loss: 2.1449 - val_accuracy: 0.4872\n",
      "Epoch 247/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1313 - accuracy: 0.9899 - val_loss: 2.1446 - val_accuracy: 0.4872\n",
      "Epoch 248/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1238 - accuracy: 0.9879 - val_loss: 2.1443 - val_accuracy: 0.4872\n",
      "Epoch 249/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1251 - accuracy: 0.9899 - val_loss: 2.1441 - val_accuracy: 0.4872\n",
      "Epoch 250/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1405 - accuracy: 0.9859 - val_loss: 2.1439 - val_accuracy: 0.4872\n",
      "Epoch 251/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1142 - accuracy: 0.9960 - val_loss: 2.1436 - val_accuracy: 0.4872\n",
      "Epoch 252/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1171 - accuracy: 0.9839 - val_loss: 2.1434 - val_accuracy: 0.4872\n",
      "Epoch 253/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1199 - accuracy: 0.9879 - val_loss: 2.1431 - val_accuracy: 0.4872\n",
      "Epoch 254/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1207 - accuracy: 0.9920 - val_loss: 2.1428 - val_accuracy: 0.4872\n",
      "Epoch 255/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1208 - accuracy: 0.9899 - val_loss: 2.1424 - val_accuracy: 0.4872\n",
      "Epoch 256/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1298 - accuracy: 0.9920 - val_loss: 2.1421 - val_accuracy: 0.4872\n",
      "Epoch 257/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1301 - accuracy: 0.9879 - val_loss: 2.1421 - val_accuracy: 0.4872\n",
      "Epoch 258/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1380 - accuracy: 0.9839 - val_loss: 2.1419 - val_accuracy: 0.4872\n",
      "Epoch 259/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1339 - accuracy: 0.9799 - val_loss: 2.1417 - val_accuracy: 0.4872\n",
      "Epoch 260/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1214 - accuracy: 0.9879 - val_loss: 2.1413 - val_accuracy: 0.4872\n",
      "Epoch 261/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1302 - accuracy: 0.9940 - val_loss: 2.1413 - val_accuracy: 0.4872\n",
      "Epoch 262/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1180 - accuracy: 0.9920 - val_loss: 2.1410 - val_accuracy: 0.4872\n",
      "Epoch 263/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1269 - accuracy: 0.9879 - val_loss: 2.1409 - val_accuracy: 0.4872\n",
      "Epoch 264/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1240 - accuracy: 0.9879 - val_loss: 2.1407 - val_accuracy: 0.4872\n",
      "Epoch 265/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1306 - accuracy: 0.9819 - val_loss: 2.1404 - val_accuracy: 0.4872\n",
      "Epoch 266/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1376 - accuracy: 0.9920 - val_loss: 2.1400 - val_accuracy: 0.4872\n",
      "Epoch 267/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1336 - accuracy: 0.9899 - val_loss: 2.1398 - val_accuracy: 0.4872\n",
      "Epoch 268/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1285 - accuracy: 0.9899 - val_loss: 2.1398 - val_accuracy: 0.4872\n",
      "Epoch 269/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1376 - accuracy: 0.9920 - val_loss: 2.1397 - val_accuracy: 0.4872\n",
      "Epoch 270/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1136 - accuracy: 0.9960 - val_loss: 2.1395 - val_accuracy: 0.4872\n",
      "Epoch 271/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1506 - accuracy: 0.9799 - val_loss: 2.1397 - val_accuracy: 0.4872\n",
      "Epoch 272/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1198 - accuracy: 0.9920 - val_loss: 2.1397 - val_accuracy: 0.4872\n",
      "Epoch 273/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1220 - accuracy: 0.9920 - val_loss: 2.1399 - val_accuracy: 0.4872\n",
      "Epoch 274/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1292 - accuracy: 0.9859 - val_loss: 2.1400 - val_accuracy: 0.4872\n",
      "Epoch 275/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1425 - accuracy: 0.9779 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 276/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1123 - accuracy: 0.9879 - val_loss: 2.1401 - val_accuracy: 0.4872\n",
      "Epoch 277/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1322 - accuracy: 0.9819 - val_loss: 2.1402 - val_accuracy: 0.4872\n",
      "Epoch 278/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1314 - accuracy: 0.9859 - val_loss: 2.1404 - val_accuracy: 0.4872\n",
      "Epoch 279/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1160 - accuracy: 0.9859 - val_loss: 2.1405 - val_accuracy: 0.4872\n",
      "Epoch 280/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1245 - accuracy: 0.9879 - val_loss: 2.1406 - val_accuracy: 0.4872\n",
      "Epoch 281/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.1363 - accuracy: 0.9899 - val_loss: 2.1410 - val_accuracy: 0.4872\n",
      "Epoch 282/600\n",
      "497/497 [==============================] - 0s 352us/step - loss: 0.1345 - accuracy: 0.9839 - val_loss: 2.1412 - val_accuracy: 0.4872\n",
      "Epoch 283/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1348 - accuracy: 0.9920 - val_loss: 2.1413 - val_accuracy: 0.4872\n",
      "Epoch 284/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1357 - accuracy: 0.9839 - val_loss: 2.1418 - val_accuracy: 0.4872\n",
      "Epoch 285/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1226 - accuracy: 0.9940 - val_loss: 2.1421 - val_accuracy: 0.4923\n",
      "Epoch 286/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1546 - accuracy: 0.9819 - val_loss: 2.1426 - val_accuracy: 0.4923\n",
      "Epoch 287/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1257 - accuracy: 0.9879 - val_loss: 2.1427 - val_accuracy: 0.4923\n",
      "Epoch 288/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1249 - accuracy: 0.9920 - val_loss: 2.1429 - val_accuracy: 0.4923\n",
      "Epoch 289/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1320 - accuracy: 0.9859 - val_loss: 2.1430 - val_accuracy: 0.4923\n",
      "Epoch 290/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1278 - accuracy: 0.9940 - val_loss: 2.1430 - val_accuracy: 0.4923\n",
      "Epoch 291/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1290 - accuracy: 0.9920 - val_loss: 2.1429 - val_accuracy: 0.4923\n",
      "Epoch 292/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1345 - accuracy: 0.9899 - val_loss: 2.1428 - val_accuracy: 0.4923\n",
      "Epoch 293/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1257 - accuracy: 0.9940 - val_loss: 2.1427 - val_accuracy: 0.4923\n",
      "Epoch 294/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1162 - accuracy: 0.9899 - val_loss: 2.1426 - val_accuracy: 0.4923\n",
      "Epoch 295/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1241 - accuracy: 0.9980 - val_loss: 2.1429 - val_accuracy: 0.4923\n",
      "Epoch 296/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1285 - accuracy: 0.9879 - val_loss: 2.1429 - val_accuracy: 0.4923\n",
      "Epoch 297/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1140 - accuracy: 0.9940 - val_loss: 2.1432 - val_accuracy: 0.4923\n",
      "Epoch 298/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1279 - accuracy: 0.9879 - val_loss: 2.1432 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1136 - accuracy: 0.9940 - val_loss: 2.1430 - val_accuracy: 0.4923\n",
      "Epoch 300/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1418 - accuracy: 0.9839 - val_loss: 2.1431 - val_accuracy: 0.4923\n",
      "Epoch 301/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1280 - accuracy: 0.9859 - val_loss: 2.1432 - val_accuracy: 0.4923\n",
      "Epoch 302/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1306 - accuracy: 0.9920 - val_loss: 2.1436 - val_accuracy: 0.4923\n",
      "Epoch 303/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1328 - accuracy: 0.9859 - val_loss: 2.1437 - val_accuracy: 0.4923\n",
      "Epoch 304/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1387 - accuracy: 0.9879 - val_loss: 2.1437 - val_accuracy: 0.4923\n",
      "Epoch 305/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1187 - accuracy: 0.9899 - val_loss: 2.1434 - val_accuracy: 0.4923\n",
      "Epoch 306/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1068 - accuracy: 0.9920 - val_loss: 2.1433 - val_accuracy: 0.4923\n",
      "Epoch 307/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1273 - accuracy: 0.9920 - val_loss: 2.1431 - val_accuracy: 0.4923\n",
      "Epoch 308/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1273 - accuracy: 0.9839 - val_loss: 2.1430 - val_accuracy: 0.4923\n",
      "Epoch 309/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1479 - accuracy: 0.9779 - val_loss: 2.1430 - val_accuracy: 0.4923\n",
      "Epoch 310/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.0989 - accuracy: 0.9940 - val_loss: 2.1431 - val_accuracy: 0.4923\n",
      "Epoch 311/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1194 - accuracy: 0.9920 - val_loss: 2.1431 - val_accuracy: 0.4923\n",
      "Epoch 312/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1395 - accuracy: 0.9819 - val_loss: 2.1432 - val_accuracy: 0.4923\n",
      "Epoch 313/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1261 - accuracy: 0.9879 - val_loss: 2.1434 - val_accuracy: 0.4923\n",
      "Epoch 314/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1154 - accuracy: 0.9920 - val_loss: 2.1435 - val_accuracy: 0.4923\n",
      "Epoch 315/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1541 - accuracy: 0.9799 - val_loss: 2.1435 - val_accuracy: 0.4923\n",
      "Epoch 316/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1179 - accuracy: 0.9940 - val_loss: 2.1436 - val_accuracy: 0.4923\n",
      "Epoch 317/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1091 - accuracy: 0.9980 - val_loss: 2.1437 - val_accuracy: 0.4923\n",
      "Epoch 318/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1250 - accuracy: 0.9899 - val_loss: 2.1436 - val_accuracy: 0.4923\n",
      "Epoch 319/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1217 - accuracy: 0.9879 - val_loss: 2.1438 - val_accuracy: 0.4923\n",
      "Epoch 320/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1371 - accuracy: 0.9779 - val_loss: 2.1438 - val_accuracy: 0.4923\n",
      "Epoch 321/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1078 - accuracy: 0.9940 - val_loss: 2.1441 - val_accuracy: 0.4923\n",
      "Epoch 322/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1149 - accuracy: 0.9899 - val_loss: 2.1443 - val_accuracy: 0.4923\n",
      "Epoch 323/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1364 - accuracy: 0.9839 - val_loss: 2.1444 - val_accuracy: 0.4923\n",
      "Epoch 324/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1419 - accuracy: 0.9839 - val_loss: 2.1446 - val_accuracy: 0.4923\n",
      "Epoch 325/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1383 - accuracy: 0.9839 - val_loss: 2.1446 - val_accuracy: 0.4923\n",
      "Epoch 326/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1258 - accuracy: 0.9879 - val_loss: 2.1447 - val_accuracy: 0.4923\n",
      "Epoch 327/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1282 - accuracy: 0.9879 - val_loss: 2.1448 - val_accuracy: 0.4923\n",
      "Epoch 328/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1315 - accuracy: 0.9799 - val_loss: 2.1449 - val_accuracy: 0.4923\n",
      "Epoch 329/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1341 - accuracy: 0.9759 - val_loss: 2.1448 - val_accuracy: 0.4923\n",
      "Epoch 330/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1195 - accuracy: 0.9920 - val_loss: 2.1450 - val_accuracy: 0.4923\n",
      "Epoch 331/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1352 - accuracy: 0.9879 - val_loss: 2.1452 - val_accuracy: 0.4872\n",
      "Epoch 332/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1095 - accuracy: 0.9899 - val_loss: 2.1457 - val_accuracy: 0.4872\n",
      "Epoch 333/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1232 - accuracy: 0.9899 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 334/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1223 - accuracy: 0.9839 - val_loss: 2.1460 - val_accuracy: 0.4872\n",
      "Epoch 335/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1257 - accuracy: 0.9879 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 336/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1296 - accuracy: 0.9859 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 337/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1118 - accuracy: 0.9940 - val_loss: 2.1458 - val_accuracy: 0.4872\n",
      "Epoch 338/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1202 - accuracy: 0.9899 - val_loss: 2.1460 - val_accuracy: 0.4872\n",
      "Epoch 339/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1294 - accuracy: 0.9859 - val_loss: 2.1462 - val_accuracy: 0.4872\n",
      "Epoch 340/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1431 - accuracy: 0.9879 - val_loss: 2.1466 - val_accuracy: 0.4872\n",
      "Epoch 341/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1328 - accuracy: 0.9920 - val_loss: 2.1471 - val_accuracy: 0.4872\n",
      "Epoch 342/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1142 - accuracy: 0.9980 - val_loss: 2.1476 - val_accuracy: 0.4923\n",
      "Epoch 343/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1205 - accuracy: 0.9960 - val_loss: 2.1481 - val_accuracy: 0.4923\n",
      "Epoch 344/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1286 - accuracy: 0.9879 - val_loss: 2.1485 - val_accuracy: 0.4923\n",
      "Epoch 345/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1308 - accuracy: 0.9879 - val_loss: 2.1487 - val_accuracy: 0.4923\n",
      "Epoch 346/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1344 - accuracy: 0.9899 - val_loss: 2.1490 - val_accuracy: 0.4923\n",
      "Epoch 347/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1299 - accuracy: 0.9859 - val_loss: 2.1493 - val_accuracy: 0.4923\n",
      "Epoch 348/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1135 - accuracy: 0.9899 - val_loss: 2.1495 - val_accuracy: 0.4923\n",
      "Epoch 349/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1279 - accuracy: 0.9879 - val_loss: 2.1494 - val_accuracy: 0.4923\n",
      "Epoch 350/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1065 - accuracy: 0.9940 - val_loss: 2.1495 - val_accuracy: 0.4923\n",
      "Epoch 351/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1346 - accuracy: 0.9920 - val_loss: 2.1497 - val_accuracy: 0.4923\n",
      "Epoch 352/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1176 - accuracy: 0.9879 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 353/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1083 - accuracy: 0.9980 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 354/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1059 - accuracy: 0.9920 - val_loss: 2.1497 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1090 - accuracy: 0.9899 - val_loss: 2.1494 - val_accuracy: 0.4923\n",
      "Epoch 356/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1436 - accuracy: 0.9819 - val_loss: 2.1494 - val_accuracy: 0.4923\n",
      "Epoch 357/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1206 - accuracy: 0.9899 - val_loss: 2.1492 - val_accuracy: 0.4923\n",
      "Epoch 358/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1203 - accuracy: 0.9859 - val_loss: 2.1493 - val_accuracy: 0.4923\n",
      "Epoch 359/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1191 - accuracy: 0.9920 - val_loss: 2.1493 - val_accuracy: 0.4923\n",
      "Epoch 360/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1121 - accuracy: 0.9879 - val_loss: 2.1495 - val_accuracy: 0.4923\n",
      "Epoch 361/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1003 - accuracy: 0.9920 - val_loss: 2.1495 - val_accuracy: 0.4923\n",
      "Epoch 362/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1205 - accuracy: 0.9859 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 363/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1228 - accuracy: 0.9879 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 364/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1035 - accuracy: 0.9920 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 365/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1160 - accuracy: 0.9879 - val_loss: 2.1498 - val_accuracy: 0.4923\n",
      "Epoch 366/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1243 - accuracy: 0.9859 - val_loss: 2.1498 - val_accuracy: 0.4923\n",
      "Epoch 367/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1155 - accuracy: 0.9899 - val_loss: 2.1497 - val_accuracy: 0.4923\n",
      "Epoch 368/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1172 - accuracy: 0.9940 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 369/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1269 - accuracy: 0.9859 - val_loss: 2.1498 - val_accuracy: 0.4923\n",
      "Epoch 370/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1185 - accuracy: 0.9859 - val_loss: 2.1497 - val_accuracy: 0.4923\n",
      "Epoch 371/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1113 - accuracy: 0.9940 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 372/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1446 - accuracy: 0.9839 - val_loss: 2.1499 - val_accuracy: 0.4923\n",
      "Epoch 373/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1301 - accuracy: 0.9899 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 374/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1249 - accuracy: 0.9920 - val_loss: 2.1502 - val_accuracy: 0.4872\n",
      "Epoch 375/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1179 - accuracy: 0.9920 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 376/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1296 - accuracy: 0.9839 - val_loss: 2.1500 - val_accuracy: 0.4872\n",
      "Epoch 377/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1240 - accuracy: 0.9940 - val_loss: 2.1499 - val_accuracy: 0.4872\n",
      "Epoch 378/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1246 - accuracy: 0.9940 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 379/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1233 - accuracy: 0.9920 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 380/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1182 - accuracy: 0.9899 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 381/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1180 - accuracy: 0.9920 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 382/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1104 - accuracy: 0.9899 - val_loss: 2.1503 - val_accuracy: 0.4872\n",
      "Epoch 383/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1158 - accuracy: 0.9960 - val_loss: 2.1505 - val_accuracy: 0.4872\n",
      "Epoch 384/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1247 - accuracy: 0.9920 - val_loss: 2.1506 - val_accuracy: 0.4872\n",
      "Epoch 385/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1079 - accuracy: 0.9920 - val_loss: 2.1508 - val_accuracy: 0.4872\n",
      "Epoch 386/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1341 - accuracy: 0.9940 - val_loss: 2.1509 - val_accuracy: 0.4872\n",
      "Epoch 387/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1339 - accuracy: 0.9839 - val_loss: 2.1513 - val_accuracy: 0.4872\n",
      "Epoch 388/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1171 - accuracy: 0.9920 - val_loss: 2.1514 - val_accuracy: 0.4872\n",
      "Epoch 389/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1232 - accuracy: 0.9879 - val_loss: 2.1516 - val_accuracy: 0.4872\n",
      "Epoch 390/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1345 - accuracy: 0.9879 - val_loss: 2.1517 - val_accuracy: 0.4872\n",
      "Epoch 391/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1388 - accuracy: 0.9859 - val_loss: 2.1519 - val_accuracy: 0.4872\n",
      "Epoch 392/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1431 - accuracy: 0.9819 - val_loss: 2.1517 - val_accuracy: 0.4872\n",
      "Epoch 393/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1468 - accuracy: 0.9839 - val_loss: 2.1517 - val_accuracy: 0.4872\n",
      "Epoch 394/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1168 - accuracy: 0.9940 - val_loss: 2.1514 - val_accuracy: 0.4872\n",
      "Epoch 395/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1472 - accuracy: 0.9899 - val_loss: 2.1511 - val_accuracy: 0.4872\n",
      "Epoch 396/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1370 - accuracy: 0.9839 - val_loss: 2.1510 - val_accuracy: 0.4872\n",
      "Epoch 397/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1168 - accuracy: 0.9940 - val_loss: 2.1511 - val_accuracy: 0.4872\n",
      "Epoch 398/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 2.1509 - val_accuracy: 0.4872\n",
      "Epoch 399/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1319 - accuracy: 0.9879 - val_loss: 2.1510 - val_accuracy: 0.4872\n",
      "Epoch 400/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1124 - accuracy: 0.9920 - val_loss: 2.1510 - val_accuracy: 0.4872\n",
      "Epoch 401/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1281 - accuracy: 0.9899 - val_loss: 2.1508 - val_accuracy: 0.4872\n",
      "Epoch 402/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1293 - accuracy: 0.9940 - val_loss: 2.1505 - val_accuracy: 0.4872\n",
      "Epoch 403/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1202 - accuracy: 0.9940 - val_loss: 2.1502 - val_accuracy: 0.4872\n",
      "Epoch 404/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1150 - accuracy: 0.9920 - val_loss: 2.1502 - val_accuracy: 0.4872\n",
      "Epoch 405/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1163 - accuracy: 0.9879 - val_loss: 2.1502 - val_accuracy: 0.4872\n",
      "Epoch 406/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1198 - accuracy: 0.9899 - val_loss: 2.1501 - val_accuracy: 0.4872\n",
      "Epoch 407/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1129 - accuracy: 0.9940 - val_loss: 2.1502 - val_accuracy: 0.4872\n",
      "Epoch 408/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1242 - accuracy: 0.9899 - val_loss: 2.1503 - val_accuracy: 0.4872\n",
      "Epoch 409/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1385 - accuracy: 0.9799 - val_loss: 2.1500 - val_accuracy: 0.4923\n",
      "Epoch 410/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1114 - accuracy: 0.9940 - val_loss: 2.1499 - val_accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1338 - accuracy: 0.9920 - val_loss: 2.1498 - val_accuracy: 0.4923\n",
      "Epoch 412/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1142 - accuracy: 0.9899 - val_loss: 2.1496 - val_accuracy: 0.4923\n",
      "Epoch 413/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1466 - accuracy: 0.9819 - val_loss: 2.1492 - val_accuracy: 0.4923\n",
      "Epoch 414/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1254 - accuracy: 0.9899 - val_loss: 2.1490 - val_accuracy: 0.4923\n",
      "Epoch 415/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1218 - accuracy: 0.9879 - val_loss: 2.1485 - val_accuracy: 0.4923\n",
      "Epoch 416/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1295 - accuracy: 0.9879 - val_loss: 2.1483 - val_accuracy: 0.4923\n",
      "Epoch 417/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1233 - accuracy: 0.9899 - val_loss: 2.1482 - val_accuracy: 0.4923\n",
      "Epoch 418/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1087 - accuracy: 0.9980 - val_loss: 2.1480 - val_accuracy: 0.4923\n",
      "Epoch 419/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1177 - accuracy: 0.9920 - val_loss: 2.1479 - val_accuracy: 0.4923\n",
      "Epoch 420/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1310 - accuracy: 0.9879 - val_loss: 2.1479 - val_accuracy: 0.4923\n",
      "Epoch 421/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1258 - accuracy: 0.9940 - val_loss: 2.1476 - val_accuracy: 0.4923\n",
      "Epoch 422/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1161 - accuracy: 0.9899 - val_loss: 2.1477 - val_accuracy: 0.4923\n",
      "Epoch 423/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1152 - accuracy: 0.9920 - val_loss: 2.1474 - val_accuracy: 0.4923\n",
      "Epoch 424/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1289 - accuracy: 0.9899 - val_loss: 2.1473 - val_accuracy: 0.4923\n",
      "Epoch 425/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1244 - accuracy: 0.9879 - val_loss: 2.1470 - val_accuracy: 0.4923\n",
      "Epoch 426/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1167 - accuracy: 0.9899 - val_loss: 2.1466 - val_accuracy: 0.4923\n",
      "Epoch 427/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1017 - accuracy: 0.9920 - val_loss: 2.1462 - val_accuracy: 0.4923\n",
      "Epoch 428/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1418 - accuracy: 0.9738 - val_loss: 2.1460 - val_accuracy: 0.4923\n",
      "Epoch 429/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1272 - accuracy: 0.9879 - val_loss: 2.1456 - val_accuracy: 0.4923\n",
      "Epoch 430/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1307 - accuracy: 0.9859 - val_loss: 2.1452 - val_accuracy: 0.4923\n",
      "Epoch 431/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1133 - accuracy: 0.9960 - val_loss: 2.1451 - val_accuracy: 0.4923\n",
      "Epoch 432/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1239 - accuracy: 0.9859 - val_loss: 2.1449 - val_accuracy: 0.4923\n",
      "Epoch 433/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1227 - accuracy: 0.9920 - val_loss: 2.1448 - val_accuracy: 0.4923\n",
      "Epoch 434/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1230 - accuracy: 0.9859 - val_loss: 2.1448 - val_accuracy: 0.4923\n",
      "Epoch 435/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1297 - accuracy: 0.9899 - val_loss: 2.1449 - val_accuracy: 0.4923\n",
      "Epoch 436/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1203 - accuracy: 0.9899 - val_loss: 2.1450 - val_accuracy: 0.4923\n",
      "Epoch 437/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1269 - accuracy: 0.9920 - val_loss: 2.1447 - val_accuracy: 0.4923\n",
      "Epoch 438/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1252 - accuracy: 0.9879 - val_loss: 2.1448 - val_accuracy: 0.4923\n",
      "Epoch 439/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1297 - accuracy: 0.9899 - val_loss: 2.1449 - val_accuracy: 0.4923\n",
      "Epoch 440/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1193 - accuracy: 0.9940 - val_loss: 2.1449 - val_accuracy: 0.4923\n",
      "Epoch 441/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1290 - accuracy: 0.9879 - val_loss: 2.1453 - val_accuracy: 0.4923\n",
      "Epoch 442/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1167 - accuracy: 0.9879 - val_loss: 2.1456 - val_accuracy: 0.4923\n",
      "Epoch 443/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1220 - accuracy: 0.9899 - val_loss: 2.1457 - val_accuracy: 0.4923\n",
      "Epoch 444/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1231 - accuracy: 0.9899 - val_loss: 2.1457 - val_accuracy: 0.4923\n",
      "Epoch 445/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1193 - accuracy: 0.9940 - val_loss: 2.1460 - val_accuracy: 0.4923\n",
      "Epoch 446/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1154 - accuracy: 0.9940 - val_loss: 2.1462 - val_accuracy: 0.4923\n",
      "Epoch 447/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1171 - accuracy: 0.9879 - val_loss: 2.1463 - val_accuracy: 0.4923\n",
      "Epoch 448/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1123 - accuracy: 0.9960 - val_loss: 2.1464 - val_accuracy: 0.4923\n",
      "Epoch 449/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1196 - accuracy: 0.9879 - val_loss: 2.1465 - val_accuracy: 0.4923\n",
      "Epoch 450/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1235 - accuracy: 0.9859 - val_loss: 2.1467 - val_accuracy: 0.4923\n",
      "Epoch 451/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1037 - accuracy: 0.9899 - val_loss: 2.1468 - val_accuracy: 0.4923\n",
      "Epoch 452/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1177 - accuracy: 0.9940 - val_loss: 2.1468 - val_accuracy: 0.4923\n",
      "Epoch 453/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1117 - accuracy: 0.9920 - val_loss: 2.1470 - val_accuracy: 0.4923\n",
      "Epoch 454/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1189 - accuracy: 0.9960 - val_loss: 2.1472 - val_accuracy: 0.4923\n",
      "Epoch 455/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1270 - accuracy: 0.9799 - val_loss: 2.1475 - val_accuracy: 0.4923\n",
      "Epoch 456/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1154 - accuracy: 0.9920 - val_loss: 2.1478 - val_accuracy: 0.4923\n",
      "Epoch 457/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1488 - accuracy: 0.9779 - val_loss: 2.1481 - val_accuracy: 0.4923\n",
      "Epoch 458/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1325 - accuracy: 0.9799 - val_loss: 2.1482 - val_accuracy: 0.4974\n",
      "Epoch 459/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1197 - accuracy: 0.9819 - val_loss: 2.1484 - val_accuracy: 0.4974\n",
      "Epoch 460/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1112 - accuracy: 0.9920 - val_loss: 2.1486 - val_accuracy: 0.4974\n",
      "Epoch 461/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.0922 - accuracy: 0.9980 - val_loss: 2.1490 - val_accuracy: 0.4974\n",
      "Epoch 462/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1473 - accuracy: 0.9879 - val_loss: 2.1491 - val_accuracy: 0.4974\n",
      "Epoch 463/600\n",
      "497/497 [==============================] - 0s 350us/step - loss: 0.1343 - accuracy: 0.9859 - val_loss: 2.1492 - val_accuracy: 0.4974\n",
      "Epoch 464/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1019 - accuracy: 0.9960 - val_loss: 2.1489 - val_accuracy: 0.4974\n",
      "Epoch 465/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1144 - accuracy: 0.9940 - val_loss: 2.1489 - val_accuracy: 0.4974\n",
      "Epoch 466/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.0979 - accuracy: 0.9940 - val_loss: 2.1490 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/600\n",
      "497/497 [==============================] - 0s 344us/step - loss: 0.1216 - accuracy: 0.9920 - val_loss: 2.1491 - val_accuracy: 0.4974\n",
      "Epoch 468/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1238 - accuracy: 0.9879 - val_loss: 2.1491 - val_accuracy: 0.4974\n",
      "Epoch 469/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1299 - accuracy: 0.9899 - val_loss: 2.1491 - val_accuracy: 0.4974\n",
      "Epoch 470/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1163 - accuracy: 0.9940 - val_loss: 2.1493 - val_accuracy: 0.4974\n",
      "Epoch 471/600\n",
      "497/497 [==============================] - 0s 348us/step - loss: 0.1250 - accuracy: 0.9920 - val_loss: 2.1495 - val_accuracy: 0.4974\n",
      "Epoch 472/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1323 - accuracy: 0.9839 - val_loss: 2.1497 - val_accuracy: 0.4974\n",
      "Epoch 473/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1321 - accuracy: 0.9879 - val_loss: 2.1498 - val_accuracy: 0.4974\n",
      "Epoch 474/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1061 - accuracy: 0.9940 - val_loss: 2.1498 - val_accuracy: 0.4974\n",
      "Epoch 475/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1290 - accuracy: 0.9879 - val_loss: 2.1497 - val_accuracy: 0.4974\n",
      "Epoch 476/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1170 - accuracy: 0.9899 - val_loss: 2.1499 - val_accuracy: 0.4974\n",
      "Epoch 477/600\n",
      "497/497 [==============================] - 0s 343us/step - loss: 0.1142 - accuracy: 0.9899 - val_loss: 2.1500 - val_accuracy: 0.4974\n",
      "Epoch 478/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1405 - accuracy: 0.9839 - val_loss: 2.1503 - val_accuracy: 0.4974\n",
      "Epoch 479/600\n",
      "497/497 [==============================] - 0s 373us/step - loss: 0.1274 - accuracy: 0.9839 - val_loss: 2.1503 - val_accuracy: 0.4974\n",
      "Epoch 480/600\n",
      "497/497 [==============================] - 0s 360us/step - loss: 0.1147 - accuracy: 0.9859 - val_loss: 2.1505 - val_accuracy: 0.4974\n",
      "Epoch 481/600\n",
      "497/497 [==============================] - 0s 346us/step - loss: 0.1275 - accuracy: 0.9920 - val_loss: 2.1506 - val_accuracy: 0.4974\n",
      "Epoch 482/600\n",
      "497/497 [==============================] - 0s 345us/step - loss: 0.1370 - accuracy: 0.9839 - val_loss: 2.1508 - val_accuracy: 0.4974\n",
      "Epoch 483/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1178 - accuracy: 0.9920 - val_loss: 2.1510 - val_accuracy: 0.4974\n",
      "Epoch 484/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1114 - accuracy: 0.9899 - val_loss: 2.1512 - val_accuracy: 0.4974\n",
      "Epoch 485/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1340 - accuracy: 0.9859 - val_loss: 2.1513 - val_accuracy: 0.4974\n",
      "Epoch 486/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1058 - accuracy: 0.9899 - val_loss: 2.1513 - val_accuracy: 0.4974\n",
      "Epoch 487/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1470 - accuracy: 0.9799 - val_loss: 2.1514 - val_accuracy: 0.4974\n",
      "Epoch 488/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1216 - accuracy: 0.9899 - val_loss: 2.1514 - val_accuracy: 0.4974\n",
      "Epoch 489/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1354 - accuracy: 0.9879 - val_loss: 2.1511 - val_accuracy: 0.4974\n",
      "Epoch 490/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1210 - accuracy: 0.9879 - val_loss: 2.1510 - val_accuracy: 0.4974\n",
      "Epoch 491/600\n",
      "497/497 [==============================] - 0s 315us/step - loss: 0.1173 - accuracy: 0.9839 - val_loss: 2.1507 - val_accuracy: 0.4974\n",
      "Epoch 492/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1199 - accuracy: 0.9879 - val_loss: 2.1507 - val_accuracy: 0.4974\n",
      "Epoch 493/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1098 - accuracy: 0.9879 - val_loss: 2.1505 - val_accuracy: 0.4974\n",
      "Epoch 494/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1071 - accuracy: 0.9920 - val_loss: 2.1503 - val_accuracy: 0.4974\n",
      "Epoch 495/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1028 - accuracy: 0.9940 - val_loss: 2.1502 - val_accuracy: 0.4974\n",
      "Epoch 496/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1209 - accuracy: 0.9879 - val_loss: 2.1503 - val_accuracy: 0.4974\n",
      "Epoch 497/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1179 - accuracy: 0.9940 - val_loss: 2.1504 - val_accuracy: 0.4974\n",
      "Epoch 498/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1051 - accuracy: 0.9920 - val_loss: 2.1504 - val_accuracy: 0.4974\n",
      "Epoch 499/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1243 - accuracy: 0.9859 - val_loss: 2.1504 - val_accuracy: 0.4974\n",
      "Epoch 500/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1283 - accuracy: 0.9899 - val_loss: 2.1505 - val_accuracy: 0.4974\n",
      "Epoch 501/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1163 - accuracy: 0.9839 - val_loss: 2.1505 - val_accuracy: 0.4974\n",
      "Epoch 502/600\n",
      "497/497 [==============================] - 0s 353us/step - loss: 0.1261 - accuracy: 0.9899 - val_loss: 2.1504 - val_accuracy: 0.4974\n",
      "Epoch 503/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1048 - accuracy: 0.9940 - val_loss: 2.1503 - val_accuracy: 0.4974\n",
      "Epoch 504/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1236 - accuracy: 0.9899 - val_loss: 2.1502 - val_accuracy: 0.4974\n",
      "Epoch 505/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1049 - accuracy: 0.9879 - val_loss: 2.1500 - val_accuracy: 0.4974\n",
      "Epoch 506/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1057 - accuracy: 0.9980 - val_loss: 2.1502 - val_accuracy: 0.4974\n",
      "Epoch 507/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1067 - accuracy: 0.9920 - val_loss: 2.1500 - val_accuracy: 0.4974\n",
      "Epoch 508/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1140 - accuracy: 0.9980 - val_loss: 2.1499 - val_accuracy: 0.4974\n",
      "Epoch 509/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1200 - accuracy: 0.9899 - val_loss: 2.1494 - val_accuracy: 0.4974\n",
      "Epoch 510/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1437 - accuracy: 0.9819 - val_loss: 2.1492 - val_accuracy: 0.4974\n",
      "Epoch 511/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1328 - accuracy: 0.9799 - val_loss: 2.1489 - val_accuracy: 0.4974\n",
      "Epoch 512/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1323 - accuracy: 0.9940 - val_loss: 2.1491 - val_accuracy: 0.4974\n",
      "Epoch 513/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1050 - accuracy: 0.9879 - val_loss: 2.1488 - val_accuracy: 0.4974\n",
      "Epoch 514/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1394 - accuracy: 0.9819 - val_loss: 2.1487 - val_accuracy: 0.4974\n",
      "Epoch 515/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1180 - accuracy: 0.9940 - val_loss: 2.1486 - val_accuracy: 0.4974\n",
      "Epoch 516/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1243 - accuracy: 0.9920 - val_loss: 2.1489 - val_accuracy: 0.4974\n",
      "Epoch 517/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1036 - accuracy: 0.9920 - val_loss: 2.1488 - val_accuracy: 0.4974\n",
      "Epoch 518/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1168 - accuracy: 0.9960 - val_loss: 2.1488 - val_accuracy: 0.4974\n",
      "Epoch 519/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1099 - accuracy: 0.9920 - val_loss: 2.1489 - val_accuracy: 0.4974\n",
      "Epoch 520/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1314 - accuracy: 0.9879 - val_loss: 2.1492 - val_accuracy: 0.4974\n",
      "Epoch 521/600\n",
      "497/497 [==============================] - 0s 347us/step - loss: 0.1294 - accuracy: 0.9859 - val_loss: 2.1493 - val_accuracy: 0.4974\n",
      "Epoch 522/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1273 - accuracy: 0.9879 - val_loss: 2.1494 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1204 - accuracy: 0.9879 - val_loss: 2.1496 - val_accuracy: 0.4974\n",
      "Epoch 524/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1167 - accuracy: 0.9940 - val_loss: 2.1495 - val_accuracy: 0.4974\n",
      "Epoch 525/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1003 - accuracy: 0.9940 - val_loss: 2.1495 - val_accuracy: 0.4974\n",
      "Epoch 526/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1142 - accuracy: 0.9879 - val_loss: 2.1494 - val_accuracy: 0.4974\n",
      "Epoch 527/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1145 - accuracy: 0.9839 - val_loss: 2.1494 - val_accuracy: 0.4974\n",
      "Epoch 528/600\n",
      "497/497 [==============================] - 0s 323us/step - loss: 0.1188 - accuracy: 0.9920 - val_loss: 2.1495 - val_accuracy: 0.4974\n",
      "Epoch 529/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1244 - accuracy: 0.9859 - val_loss: 2.1500 - val_accuracy: 0.4974\n",
      "Epoch 530/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1153 - accuracy: 0.9940 - val_loss: 2.1502 - val_accuracy: 0.4974\n",
      "Epoch 531/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1350 - accuracy: 0.9879 - val_loss: 2.1505 - val_accuracy: 0.4974\n",
      "Epoch 532/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1187 - accuracy: 0.9899 - val_loss: 2.1508 - val_accuracy: 0.4974\n",
      "Epoch 533/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1127 - accuracy: 0.9920 - val_loss: 2.1510 - val_accuracy: 0.4974\n",
      "Epoch 534/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1485 - accuracy: 0.9759 - val_loss: 2.1511 - val_accuracy: 0.4974\n",
      "Epoch 535/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.0920 - accuracy: 0.9960 - val_loss: 2.1511 - val_accuracy: 0.4974\n",
      "Epoch 536/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1039 - accuracy: 0.9920 - val_loss: 2.1512 - val_accuracy: 0.4974\n",
      "Epoch 537/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1021 - accuracy: 0.9960 - val_loss: 2.1514 - val_accuracy: 0.4974\n",
      "Epoch 538/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1090 - accuracy: 0.9920 - val_loss: 2.1517 - val_accuracy: 0.4974\n",
      "Epoch 539/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1179 - accuracy: 0.9899 - val_loss: 2.1520 - val_accuracy: 0.4974\n",
      "Epoch 540/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1191 - accuracy: 0.9940 - val_loss: 2.1522 - val_accuracy: 0.4974\n",
      "Epoch 541/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1261 - accuracy: 0.9859 - val_loss: 2.1523 - val_accuracy: 0.4974\n",
      "Epoch 542/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1018 - accuracy: 0.9899 - val_loss: 2.1524 - val_accuracy: 0.4974\n",
      "Epoch 543/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1083 - accuracy: 0.9879 - val_loss: 2.1525 - val_accuracy: 0.4974\n",
      "Epoch 544/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1078 - accuracy: 0.9920 - val_loss: 2.1527 - val_accuracy: 0.4974\n",
      "Epoch 545/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1249 - accuracy: 0.9879 - val_loss: 2.1529 - val_accuracy: 0.4974\n",
      "Epoch 546/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1093 - accuracy: 0.9980 - val_loss: 2.1529 - val_accuracy: 0.4974\n",
      "Epoch 547/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1171 - accuracy: 0.9879 - val_loss: 2.1532 - val_accuracy: 0.4974\n",
      "Epoch 548/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1089 - accuracy: 0.9940 - val_loss: 2.1535 - val_accuracy: 0.4974\n",
      "Epoch 549/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1254 - accuracy: 0.9879 - val_loss: 2.1538 - val_accuracy: 0.4974\n",
      "Epoch 550/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1335 - accuracy: 0.9839 - val_loss: 2.1542 - val_accuracy: 0.4974\n",
      "Epoch 551/600\n",
      "497/497 [==============================] - 0s 342us/step - loss: 0.1155 - accuracy: 0.9960 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 552/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1194 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 553/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1227 - accuracy: 0.9799 - val_loss: 2.1549 - val_accuracy: 0.4923\n",
      "Epoch 554/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1295 - accuracy: 0.9920 - val_loss: 2.1553 - val_accuracy: 0.4923\n",
      "Epoch 555/600\n",
      "497/497 [==============================] - 0s 325us/step - loss: 0.1181 - accuracy: 0.9839 - val_loss: 2.1554 - val_accuracy: 0.4923\n",
      "Epoch 556/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1259 - accuracy: 0.9899 - val_loss: 2.1555 - val_accuracy: 0.4923\n",
      "Epoch 557/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1244 - accuracy: 0.9920 - val_loss: 2.1555 - val_accuracy: 0.4923\n",
      "Epoch 558/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1105 - accuracy: 0.9960 - val_loss: 2.1556 - val_accuracy: 0.4974\n",
      "Epoch 559/600\n",
      "497/497 [==============================] - 0s 321us/step - loss: 0.1308 - accuracy: 0.9859 - val_loss: 2.1559 - val_accuracy: 0.4974\n",
      "Epoch 560/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1323 - accuracy: 0.9899 - val_loss: 2.1561 - val_accuracy: 0.4974\n",
      "Epoch 561/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1181 - accuracy: 0.9940 - val_loss: 2.1562 - val_accuracy: 0.4974\n",
      "Epoch 562/600\n",
      "497/497 [==============================] - 0s 337us/step - loss: 0.1082 - accuracy: 0.9940 - val_loss: 2.1563 - val_accuracy: 0.4974\n",
      "Epoch 563/600\n",
      "497/497 [==============================] - 0s 326us/step - loss: 0.1213 - accuracy: 0.9920 - val_loss: 2.1566 - val_accuracy: 0.4923\n",
      "Epoch 564/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1175 - accuracy: 0.9879 - val_loss: 2.1568 - val_accuracy: 0.4923\n",
      "Epoch 565/600\n",
      "497/497 [==============================] - 0s 340us/step - loss: 0.1238 - accuracy: 0.9879 - val_loss: 2.1568 - val_accuracy: 0.4923\n",
      "Epoch 566/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1074 - accuracy: 0.9899 - val_loss: 2.1567 - val_accuracy: 0.4923\n",
      "Epoch 567/600\n",
      "497/497 [==============================] - 0s 341us/step - loss: 0.1090 - accuracy: 0.9960 - val_loss: 2.1567 - val_accuracy: 0.4923\n",
      "Epoch 568/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1095 - accuracy: 0.9899 - val_loss: 2.1568 - val_accuracy: 0.4923\n",
      "Epoch 569/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.1240 - accuracy: 0.9859 - val_loss: 2.1566 - val_accuracy: 0.4974\n",
      "Epoch 570/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1253 - accuracy: 0.9899 - val_loss: 2.1565 - val_accuracy: 0.4974\n",
      "Epoch 571/600\n",
      "497/497 [==============================] - 0s 336us/step - loss: 0.1144 - accuracy: 0.9960 - val_loss: 2.1561 - val_accuracy: 0.4974\n",
      "Epoch 572/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1288 - accuracy: 0.9899 - val_loss: 2.1557 - val_accuracy: 0.4974\n",
      "Epoch 573/600\n",
      "497/497 [==============================] - 0s 333us/step - loss: 0.1245 - accuracy: 0.9779 - val_loss: 2.1553 - val_accuracy: 0.4974\n",
      "Epoch 574/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1089 - accuracy: 0.9899 - val_loss: 2.1552 - val_accuracy: 0.4974\n",
      "Epoch 575/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1286 - accuracy: 0.9920 - val_loss: 2.1549 - val_accuracy: 0.4974\n",
      "Epoch 576/600\n",
      "497/497 [==============================] - 0s 318us/step - loss: 0.1191 - accuracy: 0.9960 - val_loss: 2.1549 - val_accuracy: 0.4974\n",
      "Epoch 577/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1141 - accuracy: 0.9920 - val_loss: 2.1547 - val_accuracy: 0.4974\n",
      "Epoch 578/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1126 - accuracy: 0.9960 - val_loss: 2.1545 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1221 - accuracy: 0.9940 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 580/600\n",
      "497/497 [==============================] - 0s 320us/step - loss: 0.1185 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 581/600\n",
      "497/497 [==============================] - 0s 338us/step - loss: 0.1095 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 582/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1209 - accuracy: 0.9879 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 583/600\n",
      "497/497 [==============================] - 0s 329us/step - loss: 0.1151 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 584/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1131 - accuracy: 0.9920 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 585/600\n",
      "497/497 [==============================] - 0s 319us/step - loss: 0.0988 - accuracy: 0.9960 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 586/600\n",
      "497/497 [==============================] - 0s 324us/step - loss: 0.1107 - accuracy: 0.9940 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 587/600\n",
      "497/497 [==============================] - 0s 327us/step - loss: 0.1303 - accuracy: 0.9879 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 588/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1133 - accuracy: 0.9940 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 589/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1132 - accuracy: 0.9879 - val_loss: 2.1545 - val_accuracy: 0.4974\n",
      "Epoch 590/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1190 - accuracy: 0.9899 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 591/600\n",
      "497/497 [==============================] - 0s 322us/step - loss: 0.1228 - accuracy: 0.9879 - val_loss: 2.1544 - val_accuracy: 0.4974\n",
      "Epoch 592/600\n",
      "497/497 [==============================] - 0s 328us/step - loss: 0.1022 - accuracy: 0.9940 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 593/600\n",
      "497/497 [==============================] - 0s 334us/step - loss: 0.1144 - accuracy: 0.9839 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 594/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1113 - accuracy: 0.9920 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 595/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1159 - accuracy: 0.9899 - val_loss: 2.1546 - val_accuracy: 0.4974\n",
      "Epoch 596/600\n",
      "497/497 [==============================] - 0s 339us/step - loss: 0.1046 - accuracy: 0.9920 - val_loss: 2.1547 - val_accuracy: 0.4974\n",
      "Epoch 597/600\n",
      "497/497 [==============================] - 0s 332us/step - loss: 0.1255 - accuracy: 0.9920 - val_loss: 2.1547 - val_accuracy: 0.4974\n",
      "Epoch 598/600\n",
      "497/497 [==============================] - 0s 331us/step - loss: 0.1154 - accuracy: 0.9920 - val_loss: 2.1549 - val_accuracy: 0.4974\n",
      "Epoch 599/600\n",
      "497/497 [==============================] - 0s 330us/step - loss: 0.1331 - accuracy: 0.9859 - val_loss: 2.1551 - val_accuracy: 0.4974\n",
      "Epoch 600/600\n",
      "497/497 [==============================] - 0s 335us/step - loss: 0.1208 - accuracy: 0.9940 - val_loss: 2.1552 - val_accuracy: 0.4974\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXwU9f348dc7dyAXJOE+EiDIIYKSgheeiBwerUeF6k/Fg6/Wu9WCldbWo9XWaq1aWw/qfVtRUTwAb7EQIMgN4Q5nEghX7uT9+2MmyybZwALZhGTez8djH9n5zGdn3p/N7rzn85nZGVFVjDHGeFdYUwdgjDGmaVkiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYTRCRNRFREIoKoe7WIfNsYcRlzNLBEYI46IrJORMpEJKVW+QJ3Y57WNJEZ0zJZIjBHq7XAuOoJERkAtGq6cI4OwfRojDlUlgjM0epl4Eq/6auAl/wriEiiiLwkInkisl5EJotImDsvXEQeEZF8EVkDjAnw2udFZIuIbBKRB0QkPJjARORtEdkqIrtE5GsR6e83L1ZE/ubGs0tEvhWRWHfeqSLyvYgUishGEbnaLf9SRK7zW0aNoSm3F3STiKwCVrllj7vL2C0i80RkmF/9cBH5rYisFpE97vyuIvKUiPytVls+EJE7gmm3abksEZij1Q9Agoj0dTfQY4FXatV5AkgEegCn4ySO8e6864HzgOOBTOCSWq99AagAerl1RgDXEZzpQAbQDpgPvOo37xFgMHAy0Bb4DVAlIt3d1z0BpAKDgOwg1wfwU2Ao0M+dnusuoy3wGvC2iMS4836F05saDSQA1wBFwIvAOL9kmQIMd19vvExV7WGPo+oBrMPZQE0G/gyMBD4HIgAF0oBwoAzo5/e6/wO+dJ/PAm7wmzfCfW0E0B4oBWL95o8DvnCfXw18G2SsSe5yE3F2rIqBgQHq3Q28V88yvgSu85uusX53+WcdJI6d1esFVgAX1lNvGXCO+/xm4OOm/n/bo+kfNt5ojmYvA18D6dQaFgJSgEhgvV/ZeqCz+7wTsLHWvGrd3dduEZHqsrBa9QNyeycPApfi7NlX+cUTDcQAqwO8tGs95cGqEZuI3Alci9NOxdnzrz64fqB1vQhcgZNYrwAeP4KYTAthQ0PmqKWq63EOGo8G/ltrdj5QjrNRr9YN2OQ+34KzQfSfV20jTo8gRVWT3EeCqvbn4H4BXIjTY0nE6Z0AiBtTCdAzwOs21lMOsI+aB8I7BKjju0ywezzgN8DPgTaqmgTscmM42LpeAS4UkYFAX2BqPfWMh1giMEe7a3GGRfb5F6pqJfAW8KCIxLtj8L9i/3GEt4BbRaSLiLQBJvm9dgvwGfA3EUkQkTAR6SkipwcRTzxOEinA2Xj/yW+5VcAU4FER6eQetD1JRKJxjiMMF5Gfi0iEiCSLyCD3pdnARSLSSkR6uW0+WAwVQB4QISK/x+kRVHsOuF9EMsRxnIgkuzHm4hxfeBl4V1WLg2izaeEsEZijmqquVtWsembfgrM3vQb4Fueg5xR33rPAp8BCnAO6tXsUVwJRwFKc8fV3gI5BhPQSzjDTJve1P9SafyewCGdjuwN4GAhT1Q04PZtfu+XZwED3NY/hHO/YhjN08yoH9inwCbDSjaWEmkNHj+Ikws+A3cDzQKzf/BeBATjJwBhE1W5MY4yXiMhpOD2n7mobAIP1CIzxFBGJBG4DnrMkYKpZIjDGI0SkL1CIMwT29yYOxxxFbGjIGGM8znoExhjjcc3uB2UpKSmalpbW1GEYY0yzMm/evHxVTQ00r9klgrS0NLKy6jub0BhjTCAisr6+eTY0ZIwxHmeJwBhjPM4SgTHGeFyzO0YQSHl5Obm5uZSUlDR1KI0mJiaGLl26EBkZ2dShGGOauRaRCHJzc4mPjyctLQ2/ywq3WKpKQUEBubm5pKenN3U4xphmLmRDQyIyRUS2i8jieuaLiPxDRHJE5EcROeFw11VSUkJycrInkgCAiJCcnOypHpAxJnRCeYzgBZw7S9VnFM7t/jKACcDTR7IyrySBal5rrzEmdEKWCFT1a5zL7dbnQuAldfwAJIlIMJcBNsaEyMKNhczfsLOpwzCNrCnPGupMzWuo57L/NoM1iMgEEckSkay8vLxGCa4+hUVl5O8trVFWUFDAoEGDGDRoEB06dKBz586+6bKyMgC27Cpmb2mF7zWlFZXk7ixi+54SdhWXM378eFasWNHg8T4wbSmzVxc0+HIbw9QFm3h9zoamDqNelVXK5KmLWLF1T1D1/z5jJTOXbQt6+XtKyrn9jQWsydtbo/yLFdt5fMaqQ4o1WBc+9R0X/fP7g9b7ZlUef/us4T+v78zL5ZUf6v3d0xH591erueTp7/l40ZYGWd6ctTv4yyfLG2RZTa1ZnD6qqs+oaqaqZqamBvyF9BGrqKyisirwBfgqq6qoqHRuTbthRxGbC2ve1Ck5OZk5WfNZsGABN9xwA3fccQfZ2dlkZ2cTFRVFSXkl23eXsD5//xd6445iduwrY+uuEtYX7OPZ556nV0Zv1hfsY0NBEcVllb51BlJWUUX19QJLyispcJNTRWUVA+79lDfnbmDLrmKe+3Yt4579gaoqZcuuI78ZVe7OIqovVPjs12s459Gv2LqrhI07iqiq5/0L5Or/zOG+D5cesM7tb2Zz938X8Ytna9/7xbFzXxm975lO2qSPeD97E2/O3cA5j37FruLyGvU+XLiZ3pOnU1S2PxFXVSkbdxTVqHfVlDnc+37AQ1oAbC4sRlUpLqskf28pX63czis/bODy535gc2Ex5bX+XxWVVWzd5RzH2bKrmL/PWMW1L2axc19ZjVhq211Szq6icr5dlc/U7M1c8dz/fPM27ihi/H/m8tiMlewrDbyM7XtKKC6rZNtuZ92VVcqi3F2UVVSRtW4HmQ/MYNmW3TV2THYVl/tirZ5evnU34PzPi8oqfJ8xgP/3/ByemJXD8q27a3xvVJUT/zST575Z4yurqlI2ud+Z7XtKeGPOBjLu+Zgtu4p5P3sT/X7/ie87defbC5k8dTEn/mkmL89e52uzqrOMYD5jlVXKhoL939Pq1/55+nKy1u/kl6/OZ1dROXtLK8jdWcTEd37kt+8t8rV78aZdqCr7SisoLCpjb2kFaZM+Im3SR3y2ZCt5e5z34ef/ns0/v1zNuvx9nP23L5ny7VrA2YE5+c8zWV+wz/cZG/vMbB7+ZDlXTZnD/dOWsnjTLt8yF7g9sN+/v5hrXpjra2/15626Dd/l5FNYVHbQ9h+OpjxraBM17ynbhf33m200e0sriAgTVm7bQ3REOMd0iAeguKyC4vIqoiPCWJ23l5jIcDLaxflep6rsKi5HFVpHh7N86x5S46MpKa+kVZVSVlHFgsXLuXLsxfQfMJCFC7N56Z0PGP/7O/kxO5vde/dxzvk/44bbfwPAT046mQcefoyO6RmcMbAnl1wxntlfziQpIY7333+fdu3aoarsKCqjtLyK/L2l7C4qY19pBTe9Np8vV+Tx8rVD6Jkax57SCu55bzEXn9DFF2+vez6mSuHru87ks6VbSYiJ5IJBnZi5bDujB3Qge2MhOdv3Eh4m9O+U6Hsf/G3cUcSwv3zB/zuxO9eems6DHy8D4MQ/zwQgISaCSaP6UqXKoK5JfL86n+iIcNonxDDyWOc2vLuKy3l3Xi5frsjjyxV53HFOBm9n5XJSz2T6dkygrKKK1/63nuO7tfGt9/vVBagqHyzczLn9O/D50m2c1acdny7ZSpm78X1o+nJio8JZk7ePK5//H2OHdOOsPu1onxDDnz5eRllFFa/P2UhkuHBqrxQWbdrFbW9k868rTqBdQgxFpZV8tTKPr4AeqXGMG9KNqIgw3//6sc9X8o9ZOVxzSjqfLtnq27AB5O8t4+SHZnHBwE5cdEJn+ndK5IOFm9m6q5hnv1nLS9cM4T/frfXVP/7+z+mUGMP3d58NQHllFR8v2sJ5x3UiPEwY/fg35O4sZsJpPXzLV1VydxYz7C9f+JazMLeQtOTWfJuTT7v4aMorlYx2cZzxyJe+Ov+8/ARe/d96vsspoH+nBJZsdjbuox7/huTWUbw+4UR6t4/nrEe+pGDf/o3MTx6YQVllFT87vjPvLdj/tcyaPJyUuGjf9Mi/f0OnxBg+uOVU5q/fSVpKa7buLuGBj5YxekBHVm7bw9QFm5iavZlvJ57JhU9+51vP76YuYYbbQ/rjh0t48GcDfMvduruE372/hIW5u3hnXi4j+3fgkyVbmTiyDzee0ZPNhcV8l5NPclwUZ/VpX+NzeuMr8/hsqbPcd288iTlrd/JwrT33gfd9Rm2TRvXhl6/O47ucAiaP6csDHzmf7xtO33/75wkvzwPgu0ln+cqq3+/7pi0lLaUVt7+ZDcDpf3XKn78qkx/W7OCHNc5I+Vcr82rsTI579gduH96bl2Y7PaFZy7cz/pQ0/vPdOk7s0ZbRAzqycUcRz36zlj9e0J+rTk6rE/uRCullqEUkDZimqscGmDcGuBnn9n1DgX+o6pCDLTMzM1NrX2to2bJl9O3bF3A+UEvdD3sg5ZVVhIkQHuYcbK29VxUdGYYglJRX+srSU1tz/bAe9O2QwDJ3Lyk9pTVr853b6MZGhVNc5tR/+tGHaNWqNTfccjsrVq7igtMzefXDmfQfeDxx0RFs2ppH2+S2aFUlV140ht899Bg9e/fhqotGcvf9f6XXMX0ZnJ7KUy+9xWlnjeCfD/2e5JRUrr/5V4SFwQ6/L+u2DWt4fWUls5Zv95W99X8n8fN/z67RppS4KPL3Oq87t397Pl3ifEmO7ZzA4k276d0+jpXbag4/PHbZQD7I3sz5AztxkZtQvl6Zx5VT5tT73h7IjF+dxsxl2/n312tqtOHiE7rw7vxcOifFMiwjhWM7JzJ56mJ6tYsjZ/v+mH46qBNTszfTKTGGzbtKuOaUdIrKKnhj7kZfG8srtU5vYHD3NsxbX3PMu3tyK05MT+bNrI0M7JrEwo2FdeL91xWDGXlsBwqLyjjviW/J3Rl8b2pA50QWbdp10HpL/nguraMjeCtrI79550cA/nrJcdzlPm8dFc4+93M1NL0t/1tb85BbYmxknfYejnUPjSFt0kdB1W3TKpKxQ7rx9Jera5THx0Swp6SCPh3iWV7PUFmbVpHsLKo/3ur/cbWubWPZuKPu+37H8N68OHud73N0fLck4mMiufWsXqSntGbwAzOCakttj1w6kN/+d5Fv56Ix+H83g/Ha9UM5uWfKYa1LROapamageaE8ffR1YDZwjIjkisi1InKDiNzgVvkY516zOTj3l/1lqGKpVlxeSVlFFSXllShQEaCbWVpeVSMJ+KtOAoAvCQC+JFB7XQBdu6fTf+DxzrIrqpj+/jtccu5pXDziNNbmrGTNqrrjrDExsZx65jko0LV3f5bnrKawuKzGBrSafxIAfHtY1f54QX++n3Q2J/dMBvAlgaiIMBZvctpTOwkA3PHmQr5Ykcev3lrITa/OZ33BvkMeWkpqtf/Hbi9+v54/T19epw3vzs8FYFNhMW/M3cjkqc7QTO1hm+oNxGZ3+OK7nPwae7D5e8sCbhRrJwGA9QVFfJuTD1AjCVTvHADc8Mo8bnxlHte8MLfeJNA5KTZgeTBJAOCF79dxwv2f85dP9n8GqpMAwL6ySka5PanaSQA45CQw/pQ0EmMjeeyygVx0wv7DcXe4e7C13TO6b52ynUXldZIAwJ4SZ4eqviRQ/Vr/XjXAhYM6+Z7P31AzIU8e0y/gch6bsbLG52jBhkK+XpnHJf+afdAkULtNYQLL7htJp8QY7nx74QGTwGvXDyU+5tAGUcafklbvvOm3DSNr8jlMGtUHgNuHZwSsd3rv/cPhvdvX7ak3hJANDanquIPMV+Cmhl7vvef3D1heVlF5wA9pqMS2auV7npOzilen/JtXP5xJQmIid986gdLSur8FiIxyNqCqSlhYOJUVgRNTIM98vabGdGp8NFERYbx63VDS7/7YV35aRmqdpFGfjxZt4aNFW0iNj0YE/DuRwzJS+GZVvm9deXtKfb2OYRmpnNE7lTvfWcjLfgcAq/eCurVtxYZaG/xqpRUH3itbsW0PK7bV/X9Ou+VUlm/dwzn92jPwj3W7/9NuOZXznviWTYXFXJbZlTeznB7Fgz87loK9ZTz6+Upf3emLt9a7/lvP6sWvRhxDzva9TF+0hb/5vW543/a0aRXJ2/Ny67yu+j0CeOzzlTV2RvyHbqrd/9Nj6dsxwRfXk784np37yiivVO6bduBjLLXde35/3/fjqxX7T7rwH/oBmDymL5cP7U5EuKAo+XvL6nyuHh87yBfvBQM78VbWRia+u6jOOt+98SSyN+4iuXUU2/c4PblvVuXzxKxVzN9QyLgh3XjfTfL+n4XE2EjO7tOOe0b3pU3rKO58eyFAnaGqQEYP6MCoYzvyfvYmZixzdpT+9LMBFJdXMmZAR9+QJkD7hBhio8K5dlgP7p+2lGEZKXRIiPH97zonxfqGAbsktWLWr8/gJw86yebWs3oRGR5W43/vr3tyK248vSfREeGMHtCBC578rsb8tOTWAFx9chrhIlxxYneGZaTw9cp8issrfe/5c1dlcs6jX7GuoKjGsFxDahG/LA5GkbvX3j4hxncQDaBtqyh2HMIBmJ6pcaz2O4sjKTaKwuLAr4+Ldt7e7smt2VNSztI9e2gdF0dcfDx527Yy+6tZnHLG2UGtNz4mkj0lzh5gj5TWrHF7JG9MOJGxz/zAY5cN5I43nS9LRJj4NjDJraMA53cHn91xGiMe+5rrTk1nULekOong9N6pfLWy/rOy8vaU1tiQATV6T1NvOoXiskpmr87n0yXb+ElaGy4e3IUq1Rp7uk9fMZjYyHA+/HEz//5qjW8I4OVrhxAuwuw1BTwxK6feOI7tnMDKrXvr7L19fOsw+nVK4NjOiQB8fsdpdEyKZfvuEs557Gt+dnxn+ndK8NXPTGtD3t5SZi3fTmJsJNt21zwbrPq97pbcii/9Npz//eXJHOeuo1e7OG45O4PW0RHcN20pr1w7lBO6J/H6nI11lgXOZ6L6/fNPAjGRYTx00XGc/+S3/O68fowZ0JHyyipS4qK59ewMLh/ajX2llXRLdnYsFuXu73Usv38kq/P20jM1jrX5+0iJi2bRpkKueSGLq07qzouz1/OLod1qxPHT4zszNXszH958Kuc/+S3g9BKP65zIdcN6+OpNOK0n7y1wNoptW0exY18ZA7smceGgzm77nT3Uy37Sjb98soKCfWVceVJ3Lh3clYhwoW/HBAZ3b1tj3Wf2acdpvVP5MbewxrEggB6prXnj+hMpq6wiIjyM60/rsT9xXjaQs45pz4yl24iKCKNgXxl3jujNI585G+KLT+jCfxfk8tdLBtI6OoJz+3fgr58u59lv1jKif3tS4qKpPRTeITEGgGtOSeOkHsn07RjPsi17eHteLpPH9OWaU9Lp8VtnByoxNpLEVpF8dOupZLSL9x1DKiqvrNFLun5YOuOGdCMlPpqEmEjfHv/Xd52Jor5jB7FR4e7/Ppzr3eNBg7u39b1fG3cUMXtNAZHhYbx/06nsDNGBYvBQIqhSJToijNbR+5scFx1Bh8QYwsOFqIgwWkWGs8odlw4XobLWh6ZNqyhaR0fQIzWONXl7SYiJpGvbWFrtDWd3SbnvLIwwd4ihY1IsMZHhJMZGUlpeSd8BA+mRcQw/PWMInbt2Y1Dm0HqilRob/qRWkaTGR/um/dswNL0tOQ+OIiI8jPOP60RFlSICx0z+BIDkuChf3d7t41nzp9GEhYlzFsKQfGYu286dI47hksFd2Lq7hJMfmgXAXeceQ0pclG8vb9SxHZi+eCudkmKZOLIPP+YWsrmwhF+P6M2ox78BoFNiDCJCr3ZxXHh8ZxJinJ7NpZldSUtpza2vL+CYDvEc1yWR6IhwoiLCWLJpN3/7+UCSW0cREe58sfLcs1PCBKoUbjqzJzed2YuZy7Zzy+sLaNs6mv93UjLPf7uWhJgIzhvYiQcuPNb3vlfLcLvRcalx5Dw4ynlnxTlY/G1OPj1S47j3/H5UVCnDMlJ949GxkeG+ob0XrxlClzaxiAjvzMtl5bY9nFBr4wVwzanpXHlSd18bBnVN8s2rPtDp/O+cL/9r1w+lT4cEZizbxm/e+ZGS8ioGdEn0/X9qS46LJtlvVOWYDvGM6NeeX57Zi5jIcPp3chJT345OojurT3vW/nk0AH+8sM4hOs44ph3rHhoDOHu2YWHCbWdnBPyhYptWzmdoWEYKe0sq+PWIY+rUAXxnTY3o14EBXRID1qkWHiZ1kgDA0PRk2iXE1ChLjY+u8b7MnTyc8DAh0n2vX/h+Pfl7S7nvwv789ZLjfPWiIsK4Z0w/7vEbYhIR347HGcekclafdr7yfu5OQr9OCQH/D9XDQtXvdbXfnHsMt52dQZ/ffUJCTAS/Hd034PtYncSD9fQVg33PE1s5SShkVLVZPQYPHqy1LV26tE5ZfYrLKnThxp26cOPOgPMrKqt0665iLa+o1G27in11t+4q1orKSlVVraqq0m1unWpVVc7r8veUaHFZhRbsLamx3MKi0jrr3bmvVPeVlGthUanuLSnXnftKdXNhkVZWVWlpec04Kyqrakwv3lSon303r952dp84TbtPnKYFe0uDfm9UVYtKK/SJmSu1uKxCS8sr9YmZK3Vfabm+8sM67T5xml7x3A91XrNsyy797/yNh7SeAykuq9DHZ6zUwqIyfXLWKi0qrVBV1YUbd2r3idP0kU+X65tzNmj3idP0l6/U/x7UJ29PiT45a5VWVFbVWe+Ts1bpu/M2aveJ0/TtrMNvU0l5hXafOE1//q/vVVV16oJcXbypUO//cIl2nzhNV27draqqGwr2+f5XR6vKyip9+ssc3bnvwJ+lPpOna/eJ03SF27Zgfbliu+89ONg6Alm9fY++9r/1QdfP21Oij89YqWV+398DCfb/8+acDZqzfU+DLa+hAVlaz3bVMz2CahEB9rb8hYcJ7d09knYJMSS1igKUqIhwXx0RqbPXIrL/deB09/y1iqr7Vie1iqpb5v6t3tvxjys2MtzXS+ndPp7KHfWPF15zSjpTvltLUuyh7UXERoVz81n7D1pVP68e5qrdLoA+HRLo0yGhTvnhiokM59aznfXedGYvX/lxXZJ454aTGNQ1yXcqnv8wVbBS4qJrLNd/vTed2QtVpXNSLEPS2wZ4dXCiI8KZftswOiU6B5Srh1J6t49n1IAOvt5K17atiI+JqNGDONqEhUmNUyjrU1Hl9AhSD3Ec+/TeqXx915lA4O/EwfRIjaNHatzBK7qqh9uC5X8c7EB+/pOuB60D8OWdZwT8HjUlzyWC8IMkgtqqxwGPVGR4GEmtokgI8qyD6mTjH20vvzMuIsPD6iQLf5PH9GXSqD4BhxkOxxnHtCOzexsmjgw8LNBYMtOcjfPg7m0Y3L0Nvx1T98yWIyUiDO2RfMTLqR6m8RcZHlZnzHz+784hvAVcO+rpywfz3LdrapwtFqxDHTZpTC+OH0JVA55mn5bSusGW1VA8lwiqx+4iwhr/R9Xd2h7ah71DgF5HsMLChKgGSgLgHCh758aTG2x5Ryo2Kpx3j6J4jsSBEnpzMrxfe4b3a3/wis1MWJgQRvNP1AfiuUQAkNEuzndQzxhjvM6TiSA2wHi9McZ4le0WG2OMx1kiaADBXIY6GFOmTGHr1vp/zWqMMaFgYyQNIDk5mexs53otf/jDH4iLi+POO+885OVMmTKFE044gQ4dOjR0iMYYUy9LBCH24osv8tRTT1FWVsbJJ5/Mk08+SVVVFePHjyc7OxtVZcKECbRv357s7Gwuu+wyYmNjmTNnDlFRh35OtTHGHKqWlwimT4KtdS9+dUQ6DIBRDx3yyxYvXsx7773H999/T0REBBMmTOCNN96gZ8+e5Ofns2iRE2dhYSFJSUk88cQTPPnkkwwaNKhh4zfGmANoeYngKDJjxgzmzp1LZqZzCfDi4mK6du3Kueeey4oVK7j11lsZM2YMI0aMaOJIjTFe1vISwWHsuYeKqnLNNddw//3315n3448/Mn36dJ566ineffddnnnmmSaI0Bhj7KyhkBo+fDhvvfUW+fnOdUoKCgrYsGEDeXl5qCqXXnop9913H/PnzwcgPj6ePXsa/54Jxhhva3k9gqPIgAEDuPfeexk+fDhVVVVERkbyr3/9i/DwcK699lpUFRHh4YcfBmD8+PFcd911drDYGNOoQnrP4lA42D2LvcSr7TbGHLomuWexMcaY5sESgTHGeFyLSQTNbYjrSHmtvcaY0GkRiSAmJoaCggLPbBxVlYKCAmJiYg5e2RhjDqJFnDXUpUsXcnNzycvLa+pQGk1MTAxdunRp6jCMMS1Ai0gEkZGRpKenN3UYxhjTLLWIoSFjjDGHzxKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG40KaCERkpIisEJEcEZkUYH53EZkpIj+KyJciYudDGmNMIwtZIhCRcOApYBTQDxgnIv1qVXsEeElVjwPuA/4cqniMMcYEFsoewRAgR1XXqGoZ8AZwYa06/YBZ7vMvAsw3xhgTYqFMBJ2BjX7TuW6Zv4XARe7znwHxIpJce0EiMkFEskQky0u/HjbGmMbQ1AeL7wROF5EFwOnAJqCydiVVfUZVM1U1MzU1tbFjNMaYFi2Ul5jYBHT1m+7ilvmo6mbcHoGIxAEXq2phCGMyxhhTSyh7BHOBDBFJF5EoYCzwgX8FEUkRkeoY7gamhDAeY4wxAYQsEahqBXAz8CmwDHhLVZeIyH0icoFb7QxghYisBNoDD4YqHmOMMYG1iHsWG2OMOTC7Z7Exxph6WSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZwjzzmIAABJvSURBVInAGGM8zhKBMcZ4XEgTgYiMFJEVIpIjIpMCzO8mIl+IyAIR+VFERocyHmOMMXWFLBGISDjwFDAK6AeME5F+tapNBt5S1eOBscA/QxWPMcaYwELZIxgC5KjqGlUtA94ALqxVR4EE93kisDmE8RhjjAkglImgM7DRbzrXLfP3B+AKEckFPgZuCbQgEZkgIlkikpWXlxeKWI0xxrOa+mDxOOAFVe0CjAZeFpE6ManqM6qaqaqZqampjR6kMca0ZKFMBJuArn7TXdwyf9cCbwGo6mwgBkgJYUzGGGNqOWgiEJFbRKTNYSx7LpAhIukiEoVzMPiDWnU2AGe76+mLkwhs7McYYxpRMD2C9sBcEXnLPR1UglmwqlYANwOfAstwzg5aIiL3icgFbrVfA9eLyELgdeBqVdVDb4YxxpjDJcFsd92N/whgPJCJM5zzvKquDm14dWVmZmpWVlZjr9YYY5o1EZmnqpmB5gV1jMDdS9/qPiqANsA7IvKXBovSGGNMk4g4WAURuQ24EsgHngPuUtVy9+yeVcBvQhuiMcaYUDpoIgDaAhep6nr/QlWtEpHzQhOWMcaYxhLM0NB0YEf1hIgkiMhQAFVdFqrAjDHGNI5gEsHTwF6/6b1umTHGmBYgmEQg/qd0qmoVwQ0pGWOMaQaCSQRrRORWEYl0H7cBa0IdmDHGmMYRTCK4ATgZ5/IQucBQYEIogzLGGNN4DjrEo6rbcS4PYYwxpgUK5ncEMTgXh+uPcy0gAFT1mhDGZYwxppEEMzT0MtABOBf4CucqontCGZQxxpjGE0wi6KWqvwP2qeqLwBic4wTGGGNagGASQbn7t1BEjsW5pWS70IVkjDGmMQXze4Bn3PsRTMa5n0Ac8LuQRmWMMabRHDARuBeW262qO4GvgR6NEpUxxphGc8ChIfdXxHZ1UWOMacGCOUYwQ0TuFJGuItK2+hHyyIwxxjSKYI4RXOb+vcmvTLFhImOMaRGC+WVxemMEYowxpmkE88viKwOVq+pLDR+OMcaYxhbM0NBP/J7HAGcD8wFLBMYY0wIEMzR0i/+0iCQBb4QsImOMMY0qmLOGatsH2HEDY4xpIYI5RvAhzllC4CSOfsBboQzKGGNM4wnmGMEjfs8rgPWqmhuieIwxxjSyYBLBBmCLqpYAiEisiKSp6rqQRmaMMaZRBHOM4G2gym+60i0zxhjTAgSTCCJUtax6wn0eFbqQjDHGNKZgEkGeiFxQPSEiFwL5wSxcREaKyAoRyRGRSQHmPyYi2e5jpYgUBh+6McaYhhDMMYIbgFdF5El3OhcI+GtjfyISDjwFnOO+Zq6IfKCqS6vrqOodfvVvAY4/hNiNMcY0gGB+ULYaOFFE4tzpvUEuewiQo6prAETkDeBCYGk99ccB9wa5bGOMMQ3koENDIvInEUlS1b2quldE2ojIA0EsuzOw0W861y0LtI7uOD9SmxVM0MYYYxpOMMcIRqmqb+zevVvZ6AaOYyzwjqpWBpopIhNEJEtEsvLy8hp41cYY423BJIJwEYmunhCRWCD6APWrbQK6+k13ccsCGQu8Xt+CVPUZVc1U1czU1NQgVm2MMSZYwRwsfhWYKSL/AQS4GngxiNfNBTJEJB0nAYwFflG7koj0AdoAs4OM2RhjTAMK5mDxwyKyEBiOc82hT4HuQbyuQkRuduuHA1NUdYmI3AdkqeoHbtWxwBuqqvUtyxhjTOgE0yMA2IaTBC4F1gLvBvMiVf0Y+LhW2e9rTf8hyBiMMcaEQL2JQER645zSOQ7nB2RvAqKqZzZSbMYYYxrBgXoEy4FvgPNUNQdARO44QH1jjDHN0IHOGroI2AJ8ISLPisjZOAeLjTHGtCD1JgJVnaqqY4E+wBfA7UA7EXlaREY0VoDGGGNC66C/I1DVfar6mqqej/NbgAXAxJBHZowxplEc0j2LVXWn++Ous0MVkDHGmMZ1ODevN8YY04JYIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43EhTQQiMlJEVohIjohMqqfOz0VkqYgsEZHXQhmPMcaYuiJCtWARCQeeAs4BcoG5IvKBqi71q5MB3A2coqo7RaRdqOIxxhgTWCh7BEOAHFVdo6plwBvAhbXqXA88pao7AVR1ewjjMcYYE0AoE0FnYKPfdK5b5q830FtEvhORH0RkZKAFicgEEckSkay8vLwQhWuMMd7U1AeLI4AM4AxgHPCsiCTVrqSqz6hqpqpmpqamNnKIxhjTsoUyEWwCuvpNd3HL/OUCH6hquaquBVbiJAZjjDGNJJSJYC6QISLpIhIFjAU+qFVnKk5vABFJwRkqWhPCmIwxxtQSskSgqhXAzcCnwDLgLVVdIiL3icgFbrVPgQIRWQp8AdylqgWhiskYY0xdoqpNHcMhyczM1KysrKYOwxhjmhURmaeqmYHmNfXBYmOMMU3MEoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4SwTGGONxlgiMMcbjQpoIRGSkiKwQkRwRmRRg/tUikici2e7julDGY4wxpq6QJQIRCQeeAkYB/YBxItIvQNU3VXWQ+3guVPH47MuH7NdCvhpjjGkuQtkjGALkqOoaVS0D3gAuDOH6gvP6OJh6IxRuaOpIjDHmqBARwmV3Bjb6TecCQwPUu1hETgNWAneo6sbaFURkAjABoFu3bocXzepZsGwa5M5xpneuh6TDXJYxpmGV7oWvHoKyoqaO5PC1SYNTboWd62D2P6GqAuLaw2l3QVgY/Pg2bJh9ZOsYcAl0P7khoq0hlIkgGB8Cr6tqqYj8H/AicFbtSqr6DPAMQGZmph7WmgpWw9L3908XrgeGHdaijDENbPk0+P4JiG0L0gzPYaksg9Ld0Pd8mPsczHkGYhKgZBf0Gg4dj4Npd4BWQmSrw19P58HNLhFsArr6TXdxy3xUtcBv8jngLyGLZsj1zqOyHB5o52RtY4JVUQqf3gPFO0Oz/Og4GPGg87daWRF8dg+U7D68ZYrAkAnQdciRxVZR5sRRtOPIlnMgW390ksBdq5295+YmbwU8NQSm/hIKciB9GFw8BR7pBdPvgtapULYHLn0R+v+0qaOtI5SJYC6QISLpOAlgLPAL/woi0lFVt7iTFwDLQhiPIzwSkjNgc3bIV2VakLXfwNxnIbErhEc17LKrKpweatowp+tfLWcGZE1xhjDDIg99ubs3QXkxjH31yOJb97WzhxuKtvsb+n/NMwkApPSGY0Y7CSEmAQZfDXGpMOhy2PADFBdCl59AzzObOtKARPXwRlqCWrjIaODvQDgwRVUfFJH7gCxV/UBE/oyTACqAHcCNqrr8QMvMzMzUrKysIwvsozth/kuQfpq70PHQZ0zdekU7YNrtgcct04fBKbc5z1fNgDn/hhC+l6aJ7VznbKwnroeoI+jaB1JVCQ+nQ6u2kNxrf/mONbBnK0xcBxGHsQH+4BZnXDrt1COLr3A97FgLk9ZDVOsjW5ZpMiIyT1UzA80L6TECVf0Y+LhW2e/9nt8N3B3KGAI6/nKnK1pUADtWQ0lh4ESw7APnuELHgSDh+8v3boN138LQGyAiGr77O2xZWPNLbFqW6Hg46eaGTwIAYeFw6m3OyQxFfqOlMYlw3GWHlwQAjr8Sti+vuczDERUHJ99sSaAFC2mPIBQapEfgb9YD8PVfIaELJHRyygb9AnqPhEf7QHxH+NUyZ7y12orp8PpY6DAAImJh83wnKZz7YMPFZYwxDehAPYJmOiDXgAaOc/7uznX2nHblwnePO70BcA62+ScBgPTTof9F0CrF2UvqeRYcf0Xjxm2MMQ2kqU8fbXrJPeHYS2DxOzD8Xti9GT6ZBF88CEndYdiv6r4mqhVc+p/Gj9UYY0LAEgE4QzrxHZzhoJLdzhlFFcXQ94KmjswYY0LOjhEYY4wH2DECY4wx9bJEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMc1ux+UiUgesP4wX54C5DdgOE3J2nJ0srYcfVpKO+DI2tJdVVMDzWh2ieBIiEhWfb+sa26sLUcna8vRp6W0A0LXFhsaMsYYj7NEYIwxHue1RPBMUwfQgKwtRydry9GnpbQDQtQWTx0jMMYYU5fXegTGGGNqsURgjDEe55lEICIjRWSFiOSIyKSmjudgRGSKiGwXkcV+ZW1F5HMRWeX+beOWi4j8w23bjyJyQtNFXpOIdBWRL0RkqYgsEZHb3PLm2JYYEZkjIgvdtvzRLU8Xkf+5Mb8pIlFuebQ7nePOT2vK+AMRkXARWSAi09zpZtkWEVknIotEJFtEstyy5vgZSxKRd0RkuYgsE5GTGqMdnkgEIhIOPAWMAvoB40SkX9NGdVAvACNrlU0CZqpqBjDTnQanXRnuYwLwdCPFGIwK4Neq2g84EbjJfe+bY1tKgbNUdSAwCBgpIicCDwOPqWovYCdwrVv/WmCnW/6YW+9ocxuwzG+6ObflTFUd5HeefXP8jD0OfKKqfYCBOP+b0LdDVVv8AzgJ+NRv+m7g7qaOK4i404DFftMrgI7u847ACvf5v4FxgeodbQ/gfeCc5t4WoBUwHxiK80vPiNqfNeBT4CT3eYRbT5o6dr82dHE3LGcB0wBpxm1ZB6TUKmtWnzEgEVhb+31tjHZ4okcAdAY2+k3numXNTXtV3eI+3wq0d583i/a5wwnHA/+jmbbFHUrJBrYDnwOrgUJVrXCr+Mfra4s7fxeQ3LgRH9Dfgd8AVe50Ms23LQp8JiLzRGSCW9bcPmPpQB7wH3e47jkRaU0jtMMriaDFUWcXoNmc+ysiccC7wO2qutt/XnNqi6pWquognL3pIUCfJg7psIjIecB2VZ3X1LE0kFNV9QSc4ZKbROQ0/5nN5DMWAZwAPK2qxwP72D8MBISuHV5JBJuArn7TXdyy5mabiHQEcP9ud8uP6vaJSCROEnhVVf/rFjfLtlRT1ULgC5zhkyQRiXBn+cfra4s7PxEoaORQ63MKcIGIrAPewBkeepzm2RZUdZP7dzvwHk6Sbm6fsVwgV1X/506/g5MYQt4OrySCuUCGe0ZEFDAW+KCJYzocHwBXuc+vwhlvry6/0j2L4ERgl19XskmJiADPA8tU9VG/Wc2xLakikuQ+j8U51rEMJyFc4lar3ZbqNl4CzHL36Jqcqt6tql1UNQ3n+zBLVS+nGbZFRFqLSHz1c2AEsJhm9hlT1a3ARhE5xi06G1hKY7SjqQ+QNOKBmNHASpwx3XuaOp4g4n0d2AKU4+wpXIszJjsTWAXMANq6dQXnrKjVwCIgs6nj92vHqThd2R+BbPcxupm25ThggduWxcDv3fIewBwgB3gbiHbLY9zpHHd+j6ZuQz3tOgOY1lzb4sa80H0sqf5+N9PP2CAgy/2MTQXaNEY77BITxhjjcV4ZGjLGGFMPSwTGGONxlgiMMcbjLBEYY4zHWSIwxhiPs0RgTC0iUulexbL60WBXqxWRNPG7oqwxR4OIg1cxxnOK1bmMhDGeYD0CY4LkXvP+L+517+eISC+3PE1EZrnXhJ8pIt3c8vYi8p449y9YKCInu4sKF5FnxbmnwWfur5SNaTKWCIypK7bW0NBlfvN2qeoA4Emcq3cCPAG8qKrHAa8C/3DL/wF8pc79C07A+dUrONePf0pV+wOFwMUhbo8xB2S/LDamFhHZq6pxAcrX4dyYZo17Ib2tqposIvk414Evd8u3qGqKiOQBXVS11G8ZacDn6txkBBGZCESq6gOhb5kxgVmPwJhDo/U8PxSlfs8rsWN1polZIjDm0Fzm93e2+/x7nCt4AlwOfOM+nwncCL4b2iQ2VpDGHArbEzGmrlj3LmTVPlHV6lNI24jIjzh79ePcsltw7ip1F84dpsa75bcBz4jItTh7/jfiXFHWmKOKHSMwJkjuMYJMVc1v6liMaUg2NGSMMR5nPQJjjPE46xEYY4zHWSIwxhiPs0RgjDEeZ4nAGGM8zhKBMcZ43P8Hi7MEjTtmkXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 132.51it/s]\n"
     ]
    }
   ],
   "source": [
    "pose_label = pickle.load(open('/home/ubuntu/roger_actions_output/pose_label.pkl', 'rb'))\n",
    "x_0, x_1, y = data_generator(pose_label,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for result in y:\n",
    "    print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = DD_Net.predict([X_0,X_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "9 push\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "15 stand\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "10 run\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "11 shoot_ball\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "1 clap\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "8 pullup\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "20 brush_hair\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "13 shoot_gun\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "6 pick\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "12 shoot_bow\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "17 throw\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "2 climb_stairs\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "19 wave\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "3 golf\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "5 kick_ball\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "14 sit\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "0 catch\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "4 jump\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "18 walk\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "16 swing_baseball\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n",
      "7 pour\n"
     ]
    }
   ],
   "source": [
    "for i, label in zip(range(len(X_0)), Train['label']):\n",
    "    print(np.argmax(output[i]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wave'], dtype='<U14')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['clap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 658/658 [00:02<00:00, 280.40it/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 326.62it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"GT_train_2.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"GT_test_2.pkl\", \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-initialize weights, since training and testing data switch\n",
    "DD_Net = build_DD_Net(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    #callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    #callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/tIFGV/l18cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on GT_split 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 663/663 [00:02<00:00, 269.67it/s]\n",
      "100%|██████████| 265/265 [00:00<00:00, 320.48it/s]\n"
     ]
    }
   ],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"GT_train_3.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"GT_test_3.pkl\", \"rb\"))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Train['label'])\n",
    "\n",
    "X_0,X_1,Y = data_generator(Train,C,le)\n",
    "X_test_0,X_test_1,Y_test = data_generator(Test,C,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-initialize weights, since training and testing data switch\n",
    "DD_Net = build_DD_Net(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )\n",
    "\n",
    "lr = 1e-4\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUo40WCillHL0/+6rCw3hAgcKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7716666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.76 + 0.80 + 0.755)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
